[
  {
    "title": "The Pile",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "BPB",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\nBits/byte: Average number of bits per byte according to model probabilities.",
        "markdown": false,
        "lower_is_better": true,
        "metadata": {
          "metric": "BPB",
          "run_group": "The Pile"
        }
      },
      {
        "value": "Denoised inference time (s)",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\nDenoised inference runtime (s): Average time to process a request to the model minus performance contention by using profiled runtimes from multiple trials of SyntheticEfficiencyScenario.",
        "markdown": false,
        "lower_is_better": true,
        "metadata": {
          "metric": "Denoised inference time (s)",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# eval",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# train",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "The Pile"
        }
      },
      {
        "value": "truncated",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# output tokens",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# trials",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "The Pile"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "J1-Jumbo v1 (178B)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.5446759805962651,
          "description": "min=0.28, mean=0.545, max=0.745, sum=3.268 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.8475487923672765,
          "description": "min=0.422, mean=0.848, max=1.13, sum=5.085 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 492.0,
          "description": "min=28, mean=492, max=1000, sum=2952 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1374.2057250112794,
          "description": "min=361.567, mean=1374.206, max=2046.982, sum=8245.234 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=6 (6)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.6450688489525521,
          "description": "min=0.358, mean=0.645, max=0.833, sum=3.87 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.6419919242598767,
          "description": "min=0.35, mean=0.642, max=0.835, sum=3.852 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 492.0,
          "description": "min=28, mean=492, max=1000, sum=2952 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1374.2057250112794,
          "description": "min=361.567, mean=1374.206, max=2046.982, sum=8245.234 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=6 (6)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.6004897010269956,
          "description": "min=0.314, mean=0.6, max=0.792, sum=3.603 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.753306670563767,
          "description": "min=0.426, mean=0.753, max=0.969, sum=4.52 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 492.0,
          "description": "min=28, mean=492, max=1000, sum=2952 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1374.2057250112794,
          "description": "min=361.567, mean=1374.206, max=2046.982, sum=8245.234 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=6 (6)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.6017824615646595,
          "description": "min=0.333, mean=0.602, max=0.767, sum=3.611 (6)",
          "style": {},
          "markdown": false
        },
        {
          "description": "6 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 492.0,
          "description": "min=28, mean=492, max=1000, sum=2952 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1374.2057250112794,
          "description": "min=361.567, mean=1374.206, max=2046.982, sum=8245.234 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=6 (6)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.5329256754326485,
          "description": "min=0.241, mean=0.533, max=0.715, sum=3.198 (6)",
          "style": {},
          "markdown": false
        },
        {
          "description": "6 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 492.0,
          "description": "min=28, mean=492, max=1000, sum=2952 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 3256.851718945114,
          "description": "min=352.627, mean=3256.852, max=5999.966, sum=19541.11 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=6 (6)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.5925241942233298,
          "description": "min=0.322, mean=0.593, max=0.762, sum=3.555 (6)",
          "style": {},
          "markdown": false
        },
        {
          "description": "6 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 492.0,
          "description": "min=28, mean=492, max=1000, sum=2952 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1374.2057250112794,
          "description": "min=361.567, mean=1374.206, max=2046.982, sum=8245.234 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=6 (6)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.6387153068049641,
          "description": "min=0.343, mean=0.639, max=0.81, sum=3.832 (6)",
          "style": {},
          "markdown": false
        },
        {
          "description": "6 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 492.0,
          "description": "min=28, mean=492, max=1000, sum=2952 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1374.2057250112794,
          "description": "min=361.567, mean=1374.206, max=2046.982, sum=8245.234 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=6 (6)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B)\u2620",
          "description": "Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "markdown": false
        },
        {
          "value": 0.5972066883968664,
          "description": "min=0.336, mean=0.597, max=0.874, sum=3.583 (6)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 2.9107060307669976,
          "description": "min=0.771, mean=2.911, max=9.758, sum=17.464 (6)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 492.0,
          "description": "min=28, mean=492, max=1000, sum=2952 (6)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 4398.179624638534,
          "description": "min=426.794, mean=4398.18, max=8191.98, sum=26389.078 (6)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 24.407303790787452,
          "description": "min=0.011, mean=24.407, max=128.85, sum=146.444 (6)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=6 (6)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "BLOOM (176B)\u2620",
          "description": "BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "markdown": false
        },
        {
          "value": 0.5705008762275305,
          "description": "min=0.269, mean=0.571, max=0.828, sum=3.423 (6)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.9687673335811681,
          "description": "min=0.628, mean=0.969, max=1.172, sum=5.813 (6)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 492.0,
          "description": "min=28, mean=492, max=1000, sum=2952 (6)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1376.4098097975045,
          "description": "min=378.692, mean=1376.41, max=2048.999, sum=8258.459 (6)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=6 (6)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.7568403374591455,
          "description": "min=0.565, mean=0.757, max=0.936, sum=2.271 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.6536378630351761,
          "description": "min=0.471, mean=0.654, max=0.944, sum=1.961 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 376.6666666666667,
          "description": "min=28, mean=376.667, max=1000, sum=1130 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1058.016029755685,
          "description": "min=446.848, mean=1058.016, max=2039.941, sum=3174.048 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=3 (3)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.8105335374648689,
          "description": "min=0.64, mean=0.811, max=0.984, sum=2.432 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.45567770648827927,
          "description": "min=0.31, mean=0.456, max=0.69, sum=1.367 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 376.6666666666667,
          "description": "min=28, mean=376.667, max=1000, sum=1130 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1058.016029755685,
          "description": "min=446.848, mean=1058.016, max=2039.941, sum=3174.048 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=3 (3)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.8445509042661411,
          "description": "min=0.68, mean=0.845, max=1.017, sum=2.534 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.3698902792855998,
          "description": "min=0.268, mean=0.37, max=0.533, sum=1.11 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 376.6666666666667,
          "description": "min=28, mean=376.667, max=1000, sum=1130 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1058.016029755685,
          "description": "min=446.848, mean=1058.016, max=2039.941, sum=3174.048 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=3 (3)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.9956816345252987,
          "description": "min=0.837, mean=0.996, max=1.182, sum=2.987 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.39354988136346974,
          "description": "min=0.283, mean=0.394, max=0.572, sum=1.181 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 376.6666666666667,
          "description": "min=28, mean=376.667, max=1000, sum=1130 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1058.016029755685,
          "description": "min=446.848, mean=1058.016, max=2039.941, sum=3174.048 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=3 (3)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.741373702319429,
          "description": "min=0.544, mean=0.741, max=0.932, sum=2.224 (3)",
          "style": {},
          "markdown": false
        },
        {
          "description": "3 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 376.6666666666667,
          "description": "min=28, mean=376.667, max=1000, sum=1130 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1058.016029755685,
          "description": "min=446.848, mean=1058.016, max=2039.941, sum=3174.048 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=3 (3)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.8579217585101606,
          "description": "min=0.711, mean=0.858, max=1.049, sum=2.574 (3)",
          "style": {},
          "markdown": false
        },
        {
          "description": "3 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 376.6666666666667,
          "description": "min=28, mean=376.667, max=1000, sum=1130 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1058.016029755685,
          "description": "min=446.848, mean=1058.016, max=2039.941, sum=3174.048 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=3 (3)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.8749858012544512,
          "description": "min=0.735, mean=0.875, max=1.053, sum=2.625 (3)",
          "style": {},
          "markdown": false
        },
        {
          "description": "3 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 376.6666666666667,
          "description": "min=28, mean=376.667, max=1000, sum=1130 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1049.3075368121931,
          "description": "min=445.514, mean=1049.308, max=2012.12, sum=3147.923 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0006386520853068,
          "description": "min=0.998, mean=1.001, max=1.004, sum=3.002 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=3 (3)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.7814220850110823,
          "description": "min=0.611, mean=0.781, max=0.961, sum=2.344 (3)",
          "style": {},
          "markdown": false
        },
        {
          "description": "3 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 376.6666666666667,
          "description": "min=28, mean=376.667, max=1000, sum=1130 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1049.3075368121931,
          "description": "min=445.514, mean=1049.308, max=2012.12, sum=3147.923 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0006386520853068,
          "description": "min=0.998, mean=1.001, max=1.004, sum=3.002 (3)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=3 (3)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B)\u2620",
          "description": "GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "markdown": false
        },
        {
          "value": 0.4903116839910649,
          "description": "min=0.234, mean=0.49, max=0.701, sum=2.942 (6)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.4545487957788817,
          "description": "min=0.45, mean=0.455, max=0.458, sum=2.727 (6)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 492.0,
          "description": "min=28, mean=492, max=1000, sum=2952 (6)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1442.1915224110446,
          "description": "min=438.952, mean=1442.192, max=2048.976, sum=8653.149 (6)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=6 (6)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B)\u2620",
          "description": "GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "markdown": false
        },
        {
          "value": 0.4659283446665785,
          "description": "min=0.212, mean=0.466, max=0.677, sum=2.796 (6)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray",
            "font-weight": "bold"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.9020064701332329,
          "description": "min=0.85, mean=0.902, max=0.94, sum=5.412 (6)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 492.0,
          "description": "min=28, mean=492, max=1000, sum=2952 (6)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1407.5179849310268,
          "description": "min=408.865, mean=1407.518, max=2048.969, sum=8445.108 (6)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=6 (6)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "OPT (175B)\u2620",
          "description": "OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "markdown": false
        },
        {
          "value": 0.5923991536514844,
          "description": "min=0.443, mean=0.592, max=0.73, sum=3.554 (6)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.8291283641986077,
          "description": "min=0.751, mean=0.829, max=0.884, sum=4.975 (6)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 492.0,
          "description": "min=28, mean=492, max=1000, sum=2952 (6)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1442.1907989529147,
          "description": "min=438.952, mean=1442.191, max=2048.976, sum=8653.145 (6)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=6 (6)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "OPT (66B)\u2620",
          "description": "OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "markdown": false
        },
        {
          "value": 0.617650458554565,
          "description": "min=0.468, mean=0.618, max=0.756, sum=3.706 (6)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.4954892173905541,
          "description": "min=0.323, mean=0.495, max=0.782, sum=2.973 (6)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 492.0,
          "description": "min=28, mean=492, max=1000, sum=2952 (6)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1442.1907989529147,
          "description": "min=438.952, mean=1442.191, max=2048.976, sum=8653.145 (6)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=6 (6)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "TNLG v2 (530B)\u2620",
          "description": "MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "markdown": false
        },
        {
          "value": 0.6102107496083775,
          "description": "min=0.319, mean=0.61, max=0.872, sum=3.661 (6)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "description": "6 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 492.0,
          "description": "min=28, mean=492, max=1000, sum=2952 (6)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1441.579879002146,
          "description": "min=438.905, mean=1441.58, max=2047.976, sum=8649.479 (6)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.007348234199533665,
          "description": "min=0, mean=0.007, max=0.02, sum=0.044 (6)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=6 (6)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B)\u2620",
          "description": "MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "markdown": false
        },
        {
          "value": 0.7043563640119105,
          "description": "min=0.418, mean=0.704, max=0.981, sum=4.226 (6)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "description": "6 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 492.0,
          "description": "min=28, mean=492, max=1000, sum=2952 (6)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1441.579879002146,
          "description": "min=438.905, mean=1441.58, max=2047.976, sum=8649.479 (6)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.007348234199533665,
          "description": "min=0, mean=0.007, max=0.02, sum=0.044 (6)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=6 (6)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "davinci (175B)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.7130778918416715,
          "description": "min=0.515, mean=0.713, max=0.979, sum=4.278 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.22648630444649456,
          "description": "min=0.205, mean=0.226, max=0.239, sum=1.359 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 492.0,
          "description": "min=28, mean=492, max=1000, sum=2952 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1442.1915224110446,
          "description": "min=438.952, mean=1442.192, max=2048.976, sum=8653.149 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=6 (6)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.789139881233082,
          "description": "min=0.587, mean=0.789, max=1.054, sum=4.735 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.10946915104340038,
          "description": "min=0.091, mean=0.109, max=0.12, sum=0.657 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 492.0,
          "description": "min=28, mean=492, max=1000, sum=2952 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1442.1915224110446,
          "description": "min=438.952, mean=1442.192, max=2048.976, sum=8653.149 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=6 (6)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.8657412068723543,
          "description": "min=0.687, mean=0.866, max=1.123, sum=5.194 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.12766683943867405,
          "description": "min=0.118, mean=0.128, max=0.134, sum=0.766 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 492.0,
          "description": "min=28, mean=492, max=1000, sum=2952 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1442.1915224110446,
          "description": "min=438.952, mean=1442.192, max=2048.976, sum=8653.149 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=6 (6)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M)",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.9604306414992282,
          "description": "min=0.823, mean=0.96, max=1.212, sum=5.763 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.1423994499242065,
          "description": "min=0.14, mean=0.142, max=0.144, sum=0.854 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 492.0,
          "description": "min=28, mean=492, max=1000, sum=2952 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1442.1915224110446,
          "description": "min=438.952, mean=1442.192, max=2048.976, sum=8653.149 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=6 (6)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.5757934583803997,
          "description": "min=0.205, mean=0.576, max=0.863, sum=3.455 (6)",
          "style": {},
          "markdown": false
        },
        {
          "description": "6 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 492.0,
          "description": "min=28, mean=492, max=1000, sum=2952 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2476.021535372013,
          "description": "min=447.971, mean=2476.022, max=4000.966, sum=14856.129 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=6 (6)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.5776114680706049,
          "description": "min=0.214, mean=0.578, max=0.827, sum=3.466 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.27909842959569836,
          "description": "min=0.189, mean=0.279, max=0.347, sum=1.675 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 492.0,
          "description": "min=28, mean=492, max=1000, sum=2952 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2476.021535372013,
          "description": "min=447.971, mean=2476.022, max=4000.966, sum=14856.129 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=6 (6)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001",
          "description": "",
          "markdown": false
        },
        {
          "value": 0.9685573509261866,
          "description": "min=0.677, mean=0.969, max=1.275, sum=5.811 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.14748904771651317,
          "description": "min=0.133, mean=0.147, max=0.156, sum=0.885 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 492.0,
          "description": "min=28, mean=492, max=1000, sum=2952 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1442.1915224110446,
          "description": "min=438.952, mean=1442.192, max=2048.976, sum=8653.149 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=6 (6)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001",
          "description": "",
          "markdown": false
        },
        {
          "value": 1.103368716007582,
          "description": "min=0.814, mean=1.103, max=1.435, sum=6.62 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.15499952592827024,
          "description": "min=0.132, mean=0.155, max=0.169, sum=0.93 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 492.0,
          "description": "min=28, mean=492, max=1000, sum=2952 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1442.1915224110446,
          "description": "min=438.952, mean=1442.192, max=2048.976, sum=8653.149 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=6 (6)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001",
          "description": "",
          "markdown": false
        },
        {
          "value": 1.610207406363304,
          "description": "min=1.156, mean=1.61, max=2.003, sum=9.661 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.10754665397556828,
          "description": "min=0.087, mean=0.108, max=0.12, sum=0.645 (6)",
          "style": {
            "font-weight": "bold"
          },
          "markdown": false
        },
        {
          "value": 492.0,
          "description": "min=28, mean=492, max=1000, sum=2952 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1442.1915224110446,
          "description": "min=438.952, mean=1442.192, max=2048.976, sum=8653.149 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (6)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=6 (6)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/the_pile_the_pile.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/the_pile_the_pile.json"
      }
    ],
    "name": "the_pile"
  },
  {
    "title": "subset: ArXiv",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "BPB",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\nBits/byte: Average number of bits per byte according to model probabilities.",
        "markdown": false,
        "lower_is_better": true,
        "metadata": {
          "metric": "BPB",
          "run_group": "The Pile"
        }
      },
      {
        "value": "Denoised inference time (s)",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\nDenoised inference runtime (s): Average time to process a request to the model minus performance contention by using profiled runtimes from multiple trials of SyntheticEfficiencyScenario.",
        "markdown": false,
        "lower_is_better": true,
        "metadata": {
          "metric": "Denoised inference time (s)",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# eval",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# train",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "The Pile"
        }
      },
      {
        "value": "truncated",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# output tokens",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# trials",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "The Pile"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "J1-Jumbo v1 (178B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20ArXiv&runSpecs=%5B%22the_pile%3Asubset%3DArXiv%2Cmodel%3Dai21_j1-jumbo%22%5D",
          "markdown": false
        },
        {
          "value": 0.6176228232061851,
          "description": "min=0.618, mean=0.618, max=0.618, sum=0.618 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.1256930189420729,
          "description": "min=1.126, mean=1.126, max=1.126, sum=1.126 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 238.0,
          "description": "min=238, mean=238, max=238, sum=238 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2036.9977653631286,
          "description": "min=2036.998, mean=2036.998, max=2036.998, sum=2036.998 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20ArXiv&runSpecs=%5B%22the_pile%3Asubset%3DArXiv%2Cmodel%3Dai21_j1-large%22%5D",
          "markdown": false
        },
        {
          "value": 0.6788673122988067,
          "description": "min=0.679, mean=0.679, max=0.679, sum=0.679 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.8324681891585252,
          "description": "min=0.832, mean=0.832, max=0.832, sum=0.832 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 238.0,
          "description": "min=238, mean=238, max=238, sum=238 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2036.9977653631286,
          "description": "min=2036.998, mean=2036.998, max=2036.998, sum=2036.998 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20ArXiv&runSpecs=%5B%22the_pile%3Asubset%3DArXiv%2Cmodel%3Dai21_j1-grande%22%5D",
          "markdown": false
        },
        {
          "value": 0.6431964949286737,
          "description": "min=0.643, mean=0.643, max=0.643, sum=0.643 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.9655248712464828,
          "description": "min=0.966, mean=0.966, max=0.966, sum=0.966 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 238.0,
          "description": "min=238, mean=238, max=238, sum=238 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2036.9977653631286,
          "description": "min=2036.998, mean=2036.998, max=2036.998, sum=2036.998 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20ArXiv&runSpecs=%5B%22the_pile%3Asubset%3DArXiv%2Cmodel%3Dai21_j1-grande-v2-beta%22%5D",
          "markdown": false
        },
        {
          "value": 0.6280570561577926,
          "description": "min=0.628, mean=0.628, max=0.628, sum=0.628 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 238.0,
          "description": "min=238, mean=238, max=238, sum=238 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2036.9977653631286,
          "description": "min=2036.998, mean=2036.998, max=2036.998, sum=2036.998 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20ArXiv&runSpecs=%5B%22the_pile%3Asubset%3DArXiv%2Cmodel%3Dai21_j2-jumbo%22%5D",
          "markdown": false
        },
        {
          "value": 0.5368363850354955,
          "description": "min=0.537, mean=0.537, max=0.537, sum=0.537 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 238.0,
          "description": "min=238, mean=238, max=238, sum=238 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 5765.888888888889,
          "description": "min=5765.889, mean=5765.889, max=5765.889, sum=5765.889 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20ArXiv&runSpecs=%5B%22the_pile%3Asubset%3DArXiv%2Cmodel%3Dai21_j2-grande%22%5D",
          "markdown": false
        },
        {
          "value": 0.6179282656169972,
          "description": "min=0.618, mean=0.618, max=0.618, sum=0.618 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 238.0,
          "description": "min=238, mean=238, max=238, sum=238 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2036.9977653631286,
          "description": "min=2036.998, mean=2036.998, max=2036.998, sum=2036.998 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20ArXiv&runSpecs=%5B%22the_pile%3Asubset%3DArXiv%2Cmodel%3Dai21_j2-large%22%5D",
          "markdown": false
        },
        {
          "value": 0.6611090933503669,
          "description": "min=0.661, mean=0.661, max=0.661, sum=0.661 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 238.0,
          "description": "min=238, mean=238, max=238, sum=238 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2036.9977653631286,
          "description": "min=2036.998, mean=2036.998, max=2036.998, sum=2036.998 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B)\u2620",
          "description": "Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "href": "?group=the_pile&subgroup=subset%3A%20ArXiv&runSpecs=%5B%22the_pile%3Asubset%3DArXiv%2Cmodel%3Danthropic_stanford-online-all-v4-s3%22%5D",
          "markdown": false
        },
        {
          "value": 0.5286644019824496,
          "description": "min=0.529, mean=0.529, max=0.529, sum=0.529 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 2.3807853898820572,
          "description": "min=2.381, mean=2.381, max=2.381, sum=2.381 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 238.0,
          "description": "min=238, mean=238, max=238, sum=238 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 7832.226726726727,
          "description": "min=7832.227, mean=7832.227, max=7832.227, sum=7832.227 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.010510510510510511,
          "description": "min=0.011, mean=0.011, max=0.011, sum=0.011 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "BLOOM (176B)\u2620",
          "description": "BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "href": "?group=the_pile&subgroup=subset%3A%20ArXiv&runSpecs=%5B%22the_pile%3Asubset%3DArXiv%2Cmodel%3Dtogether_bloom%22%5D",
          "markdown": false
        },
        {
          "value": 0.5773238862011882,
          "description": "min=0.577, mean=0.577, max=0.577, sum=0.577 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.1676210155526539,
          "description": "min=1.168, mean=1.168, max=1.168, sum=1.168 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 238.0,
          "description": "min=238, mean=238, max=238, sum=238 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 2039.7127487896719,
          "description": "min=2039.713, mean=2039.713, max=2039.713, sum=2039.713 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "GPT-J (6B)\u2620",
          "description": "GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "href": "?group=the_pile&subgroup=subset%3A%20ArXiv&runSpecs=%5B%22the_pile%3Asubset%3DArXiv%2Cmodel%3Dtogether_gpt-j-6b%22%5D",
          "markdown": false
        },
        {
          "value": 0.5250146407524553,
          "description": "min=0.525, mean=0.525, max=0.525, sum=0.525 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.4560336179683862,
          "description": "min=0.456, mean=0.456, max=0.456, sum=0.456 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 238.0,
          "description": "min=238, mean=238, max=238, sum=238 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 2041.7305699481865,
          "description": "min=2041.731, mean=2041.731, max=2041.731, sum=2041.731 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B)\u2620",
          "description": "GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "href": "?group=the_pile&subgroup=subset%3A%20ArXiv&runSpecs=%5B%22the_pile%3Asubset%3DArXiv%2Cmodel%3Dtogether_gpt-neox-20b%22%5D",
          "markdown": false
        },
        {
          "value": 0.5032158997910714,
          "description": "min=0.503, mean=0.503, max=0.503, sum=0.503 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray",
            "font-weight": "bold"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.9326426548808966,
          "description": "min=0.933, mean=0.933, max=0.933, sum=0.933 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 238.0,
          "description": "min=238, mean=238, max=238, sum=238 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 2040.2154554759468,
          "description": "min=2040.215, mean=2040.215, max=2040.215, sum=2040.215 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "OPT (175B)\u2620",
          "description": "OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "href": "?group=the_pile&subgroup=subset%3A%20ArXiv&runSpecs=%5B%22the_pile%3Asubset%3DArXiv%2Cmodel%3Dtogether_opt-175b%22%5D",
          "markdown": false
        },
        {
          "value": 0.7295592861239729,
          "description": "min=0.73, mean=0.73, max=0.73, sum=0.73 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.8805291163938334,
          "description": "min=0.881, mean=0.881, max=0.881, sum=0.881 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 238.0,
          "description": "min=238, mean=238, max=238, sum=238 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 2041.7305699481865,
          "description": "min=2041.731, mean=2041.731, max=2041.731, sum=2041.731 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "OPT (66B)\u2620",
          "description": "OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "href": "?group=the_pile&subgroup=subset%3A%20ArXiv&runSpecs=%5B%22the_pile%3Asubset%3DArXiv%2Cmodel%3Dtogether_opt-66b%22%5D",
          "markdown": false
        },
        {
          "value": 0.7557707873100006,
          "description": "min=0.756, mean=0.756, max=0.756, sum=0.756 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.33011185243539104,
          "description": "min=0.33, mean=0.33, max=0.33, sum=0.33 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 238.0,
          "description": "min=238, mean=238, max=238, sum=238 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 2041.7305699481865,
          "description": "min=2041.731, mean=2041.731, max=2041.731, sum=2041.731 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "TNLG v2 (530B)\u2620",
          "description": "MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "href": "?group=the_pile&subgroup=subset%3A%20ArXiv&runSpecs=%5B%22the_pile%3Asubset%3DArXiv%2Cmodel%3Dmicrosoft_TNLGv2_530B%22%5D",
          "markdown": false
        },
        {
          "value": 0.6076407527680043,
          "description": "min=0.608, mean=0.608, max=0.608, sum=0.608 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 238.0,
          "description": "min=238, mean=238, max=238, sum=238 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 2040.7406128614589,
          "description": "min=2040.741, mean=2040.741, max=2040.741, sum=2040.741 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0043159257660768235,
          "description": "min=0.004, mean=0.004, max=0.004, sum=0.004 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B)\u2620",
          "description": "MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "href": "?group=the_pile&subgroup=subset%3A%20ArXiv&runSpecs=%5B%22the_pile%3Asubset%3DArXiv%2Cmodel%3Dmicrosoft_TNLGv2_7B%22%5D",
          "markdown": false
        },
        {
          "value": 0.7012454079154359,
          "description": "min=0.701, mean=0.701, max=0.701, sum=0.701 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 238.0,
          "description": "min=238, mean=238, max=238, sum=238 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 2040.7406128614589,
          "description": "min=2040.741, mean=2040.741, max=2040.741, sum=2040.741 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0043159257660768235,
          "description": "min=0.004, mean=0.004, max=0.004, sum=0.004 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "davinci (175B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20ArXiv&runSpecs=%5B%22the_pile%3Asubset%3DArXiv%2Cmodel%3Dopenai_davinci%22%5D",
          "markdown": false
        },
        {
          "value": 0.7883099201057752,
          "description": "min=0.788, mean=0.788, max=0.788, sum=0.788 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.23889577851765612,
          "description": "min=0.239, mean=0.239, max=0.239, sum=0.239 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 238.0,
          "description": "min=238, mean=238, max=238, sum=238 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2041.7305699481865,
          "description": "min=2041.731, mean=2041.731, max=2041.731, sum=2041.731 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20ArXiv&runSpecs=%5B%22the_pile%3Asubset%3DArXiv%2Cmodel%3Dopenai_curie%22%5D",
          "markdown": false
        },
        {
          "value": 0.8653232045904805,
          "description": "min=0.865, mean=0.865, max=0.865, sum=0.865 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.12022281142055341,
          "description": "min=0.12, mean=0.12, max=0.12, sum=0.12 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 238.0,
          "description": "min=238, mean=238, max=238, sum=238 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2041.7305699481865,
          "description": "min=2041.731, mean=2041.731, max=2041.731, sum=2041.731 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20ArXiv&runSpecs=%5B%22the_pile%3Asubset%3DArXiv%2Cmodel%3Dopenai_babbage%22%5D",
          "markdown": false
        },
        {
          "value": 0.9497478298733175,
          "description": "min=0.95, mean=0.95, max=0.95, sum=0.95 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.13360900984320906,
          "description": "min=0.134, mean=0.134, max=0.134, sum=0.134 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 238.0,
          "description": "min=238, mean=238, max=238, sum=238 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2041.7305699481865,
          "description": "min=2041.731, mean=2041.731, max=2041.731, sum=2041.731 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20ArXiv&runSpecs=%5B%22the_pile%3Asubset%3DArXiv%2Cmodel%3Dopenai_ada%22%5D",
          "markdown": false
        },
        {
          "value": 1.0549232841684306,
          "description": "min=1.055, mean=1.055, max=1.055, sum=1.055 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.14398581707416078,
          "description": "min=0.144, mean=0.144, max=0.144, sum=0.144 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 238.0,
          "description": "min=238, mean=238, max=238, sum=238 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2041.7305699481865,
          "description": "min=2041.731, mean=2041.731, max=2041.731, sum=2041.731 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20ArXiv&runSpecs=%5B%22the_pile%3Asubset%3DArXiv%2Cmodel%3Dopenai_text-davinci-003%22%5D",
          "markdown": false
        },
        {
          "value": 0.5551128772216812,
          "description": "min=0.555, mean=0.555, max=0.555, sum=0.555 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 238.0,
          "description": "min=238, mean=238, max=238, sum=238 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 3965.6793214862682,
          "description": "min=3965.679, mean=3965.679, max=3965.679, sum=3965.679 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20ArXiv&runSpecs=%5B%22the_pile%3Asubset%3DArXiv%2Cmodel%3Dopenai_text-davinci-002%22%5D",
          "markdown": false
        },
        {
          "value": 0.5626794131796818,
          "description": "min=0.563, mean=0.563, max=0.563, sum=0.563 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.3456447799920937,
          "description": "min=0.346, mean=0.346, max=0.346, sum=0.346 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 238.0,
          "description": "min=238, mean=238, max=238, sum=238 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 3965.6793214862682,
          "description": "min=3965.679, mean=3965.679, max=3965.679, sum=3965.679 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20ArXiv&runSpecs=%5B%22the_pile%3Asubset%3DArXiv%2Cmodel%3Dopenai_text-curie-001%22%5D",
          "markdown": false
        },
        {
          "value": 1.0711668693150587,
          "description": "min=1.071, mean=1.071, max=1.071, sum=1.071 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.15623710566439597,
          "description": "min=0.156, mean=0.156, max=0.156, sum=0.156 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 238.0,
          "description": "min=238, mean=238, max=238, sum=238 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2041.7305699481865,
          "description": "min=2041.731, mean=2041.731, max=2041.731, sum=2041.731 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20ArXiv&runSpecs=%5B%22the_pile%3Asubset%3DArXiv%2Cmodel%3Dopenai_text-babbage-001%22%5D",
          "markdown": false
        },
        {
          "value": 1.2289552553877345,
          "description": "min=1.229, mean=1.229, max=1.229, sum=1.229 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.16852607539940273,
          "description": "min=0.169, mean=0.169, max=0.169, sum=0.169 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 238.0,
          "description": "min=238, mean=238, max=238, sum=238 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2041.7305699481865,
          "description": "min=2041.731, mean=2041.731, max=2041.731, sum=2041.731 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20ArXiv&runSpecs=%5B%22the_pile%3Asubset%3DArXiv%2Cmodel%3Dopenai_text-ada-001%22%5D",
          "markdown": false
        },
        {
          "value": 1.7705244839642018,
          "description": "min=1.771, mean=1.771, max=1.771, sum=1.771 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.11987363888439273,
          "description": "min=0.12, mean=0.12, max=0.12, sum=0.12 (1)",
          "style": {
            "font-weight": "bold"
          },
          "markdown": false
        },
        {
          "value": 238.0,
          "description": "min=238, mean=238, max=238, sum=238 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2041.7305699481865,
          "description": "min=2041.731, mean=2041.731, max=2041.731, sum=2041.731 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/the_pile_the_pile_subset:ArXiv.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/the_pile_the_pile_subset:ArXiv.json"
      }
    ],
    "name": "the_pile_subset:ArXiv"
  },
  {
    "title": "subset: BookCorpus2",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "BPB",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\nBits/byte: Average number of bits per byte according to model probabilities.",
        "markdown": false,
        "lower_is_better": true,
        "metadata": {
          "metric": "BPB",
          "run_group": "The Pile"
        }
      },
      {
        "value": "Denoised inference time (s)",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\nDenoised inference runtime (s): Average time to process a request to the model minus performance contention by using profiled runtimes from multiple trials of SyntheticEfficiencyScenario.",
        "markdown": false,
        "lower_is_better": true,
        "metadata": {
          "metric": "Denoised inference time (s)",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# eval",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# train",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "The Pile"
        }
      },
      {
        "value": "truncated",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# output tokens",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# trials",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "The Pile"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "J1-Jumbo v1 (178B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20BookCorpus2&runSpecs=%5B%22the_pile%3Asubset%3DBookCorpus2%2Cmodel%3Dai21_j1-jumbo%22%5D",
          "markdown": false
        },
        {
          "value": 0.7454053038790346,
          "description": "min=0.745, mean=0.745, max=0.745, sum=0.745 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.129899203707875,
          "description": "min=1.13, mean=1.13, max=1.13, sum=1.13 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 28.0,
          "description": "min=28, mean=28, max=28, sum=28 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2046.9819494584838,
          "description": "min=2046.982, mean=2046.982, max=2046.982, sum=2046.982 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20BookCorpus2&runSpecs=%5B%22the_pile%3Asubset%3DBookCorpus2%2Cmodel%3Dai21_j1-large%22%5D",
          "markdown": false
        },
        {
          "value": 0.8333170684962155,
          "description": "min=0.833, mean=0.833, max=0.833, sum=0.833 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.8353690724654084,
          "description": "min=0.835, mean=0.835, max=0.835, sum=0.835 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 28.0,
          "description": "min=28, mean=28, max=28, sum=28 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2046.9819494584838,
          "description": "min=2046.982, mean=2046.982, max=2046.982, sum=2046.982 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20BookCorpus2&runSpecs=%5B%22the_pile%3Asubset%3DBookCorpus2%2Cmodel%3Dai21_j1-grande%22%5D",
          "markdown": false
        },
        {
          "value": 0.7919153286747992,
          "description": "min=0.792, mean=0.792, max=0.792, sum=0.792 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.96865601026625,
          "description": "min=0.969, mean=0.969, max=0.969, sum=0.969 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 28.0,
          "description": "min=28, mean=28, max=28, sum=28 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2046.9819494584838,
          "description": "min=2046.982, mean=2046.982, max=2046.982, sum=2046.982 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20BookCorpus2&runSpecs=%5B%22the_pile%3Asubset%3DBookCorpus2%2Cmodel%3Dai21_j1-grande-v2-beta%22%5D",
          "markdown": false
        },
        {
          "value": 0.767416637709135,
          "description": "min=0.767, mean=0.767, max=0.767, sum=0.767 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 28.0,
          "description": "min=28, mean=28, max=28, sum=28 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2046.9819494584838,
          "description": "min=2046.982, mean=2046.982, max=2046.982, sum=2046.982 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20BookCorpus2&runSpecs=%5B%22the_pile%3Asubset%3DBookCorpus2%2Cmodel%3Dai21_j2-jumbo%22%5D",
          "markdown": false
        },
        {
          "value": 0.7151311406362821,
          "description": "min=0.715, mean=0.715, max=0.715, sum=0.715 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 28.0,
          "description": "min=28, mean=28, max=28, sum=28 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 5999.965870307167,
          "description": "min=5999.966, mean=5999.966, max=5999.966, sum=5999.966 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20BookCorpus2&runSpecs=%5B%22the_pile%3Asubset%3DBookCorpus2%2Cmodel%3Dai21_j2-grande%22%5D",
          "markdown": false
        },
        {
          "value": 0.7618074342179425,
          "description": "min=0.762, mean=0.762, max=0.762, sum=0.762 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 28.0,
          "description": "min=28, mean=28, max=28, sum=28 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2046.9819494584838,
          "description": "min=2046.982, mean=2046.982, max=2046.982, sum=2046.982 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20BookCorpus2&runSpecs=%5B%22the_pile%3Asubset%3DBookCorpus2%2Cmodel%3Dai21_j2-large%22%5D",
          "markdown": false
        },
        {
          "value": 0.8029656248505845,
          "description": "min=0.803, mean=0.803, max=0.803, sum=0.803 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 28.0,
          "description": "min=28, mean=28, max=28, sum=28 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2046.9819494584838,
          "description": "min=2046.982, mean=2046.982, max=2046.982, sum=2046.982 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B)\u2620",
          "description": "Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "href": "?group=the_pile&subgroup=subset%3A%20BookCorpus2&runSpecs=%5B%22the_pile%3Asubset%3DBookCorpus2%2Cmodel%3Danthropic_stanford-online-all-v4-s3%22%5D",
          "markdown": false
        },
        {
          "value": 0.7086244331872464,
          "description": "min=0.709, mean=0.709, max=0.709, sum=0.709 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 9.758047266069388,
          "description": "min=9.758, mean=9.758, max=9.758, sum=9.758 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 28.0,
          "description": "min=28, mean=28, max=28, sum=28 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 8191.979522184301,
          "description": "min=8191.98, mean=8191.98, max=8191.98, sum=8191.98 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 128.84982935153585,
          "description": "min=128.85, mean=128.85, max=128.85, sum=128.85 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "BLOOM (176B)\u2620",
          "description": "BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "href": "?group=the_pile&subgroup=subset%3A%20BookCorpus2&runSpecs=%5B%22the_pile%3Asubset%3DBookCorpus2%2Cmodel%3Dtogether_bloom%22%5D",
          "markdown": false
        },
        {
          "value": 0.6910869201359839,
          "description": "min=0.691, mean=0.691, max=0.691, sum=0.691 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.1718357091934393,
          "description": "min=1.172, mean=1.172, max=1.172, sum=1.172 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 28.0,
          "description": "min=28, mean=28, max=28, sum=28 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 2048.9991063449506,
          "description": "min=2048.999, mean=2048.999, max=2048.999, sum=2048.999 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20BookCorpus2&runSpecs=%5B%22the_pile%3Asubset%3DBookCorpus2%2Cmodel%3Dcohere_xlarge-20220609%22%5D",
          "markdown": false
        },
        {
          "value": 0.7690641529019876,
          "description": "min=0.769, mean=0.769, max=0.769, sum=0.769 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.9444974205280127,
          "description": "min=0.944, mean=0.944, max=0.944, sum=0.944 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 28.0,
          "description": "min=28, mean=28, max=28, sum=28 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2039.941379310345,
          "description": "min=2039.941, mean=2039.941, max=2039.941, sum=2039.941 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20BookCorpus2&runSpecs=%5B%22the_pile%3Asubset%3DBookCorpus2%2Cmodel%3Dcohere_large-20220720%22%5D",
          "markdown": false
        },
        {
          "value": 0.8074866630774923,
          "description": "min=0.807, mean=0.807, max=0.807, sum=0.807 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.6900640422952624,
          "description": "min=0.69, mean=0.69, max=0.69, sum=0.69 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 28.0,
          "description": "min=28, mean=28, max=28, sum=28 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2039.941379310345,
          "description": "min=2039.941, mean=2039.941, max=2039.941, sum=2039.941 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20BookCorpus2&runSpecs=%5B%22the_pile%3Asubset%3DBookCorpus2%2Cmodel%3Dcohere_medium-20220720%22%5D",
          "markdown": false
        },
        {
          "value": 0.8371299755951346,
          "description": "min=0.837, mean=0.837, max=0.837, sum=0.837 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.5326306640624953,
          "description": "min=0.533, mean=0.533, max=0.533, sum=0.533 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 28.0,
          "description": "min=28, mean=28, max=28, sum=28 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2039.941379310345,
          "description": "min=2039.941, mean=2039.941, max=2039.941, sum=2039.941 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20BookCorpus2&runSpecs=%5B%22the_pile%3Asubset%3DBookCorpus2%2Cmodel%3Dcohere_small-20220720%22%5D",
          "markdown": false
        },
        {
          "value": 0.9673218714241474,
          "description": "min=0.967, mean=0.967, max=0.967, sum=0.967 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.5715834455818875,
          "description": "min=0.572, mean=0.572, max=0.572, sum=0.572 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 28.0,
          "description": "min=28, mean=28, max=28, sum=28 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2039.941379310345,
          "description": "min=2039.941, mean=2039.941, max=2039.941, sum=2039.941 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20BookCorpus2&runSpecs=%5B%22the_pile%3Asubset%3DBookCorpus2%2Cmodel%3Dcohere_xlarge-20221108%22%5D",
          "markdown": false
        },
        {
          "value": 0.7473802792369411,
          "description": "min=0.747, mean=0.747, max=0.747, sum=0.747 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 28.0,
          "description": "min=28, mean=28, max=28, sum=28 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2039.941379310345,
          "description": "min=2039.941, mean=2039.941, max=2039.941, sum=2039.941 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20BookCorpus2&runSpecs=%5B%22the_pile%3Asubset%3DBookCorpus2%2Cmodel%3Dcohere_medium-20221108%22%5D",
          "markdown": false
        },
        {
          "value": 0.8132595019330152,
          "description": "min=0.813, mean=0.813, max=0.813, sum=0.813 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 28.0,
          "description": "min=28, mean=28, max=28, sum=28 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2039.941379310345,
          "description": "min=2039.941, mean=2039.941, max=2039.941, sum=2039.941 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20BookCorpus2&runSpecs=%5B%22the_pile%3Asubset%3DBookCorpus2%2Cmodel%3Dcohere_command-medium-beta%22%5D",
          "markdown": false
        },
        {
          "value": 0.8367938378804554,
          "description": "min=0.837, mean=0.837, max=0.837, sum=0.837 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 28.0,
          "description": "min=28, mean=28, max=28, sum=28 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2012.1198979591836,
          "description": "min=2012.12, mean=2012.12, max=2012.12, sum=2012.12 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.9982993197278912,
          "description": "min=0.998, mean=0.998, max=0.998, sum=0.998 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20BookCorpus2&runSpecs=%5B%22the_pile%3Asubset%3DBookCorpus2%2Cmodel%3Dcohere_command-xlarge-beta%22%5D",
          "markdown": false
        },
        {
          "value": 0.7724640693001713,
          "description": "min=0.772, mean=0.772, max=0.772, sum=0.772 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 28.0,
          "description": "min=28, mean=28, max=28, sum=28 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2012.1198979591836,
          "description": "min=2012.12, mean=2012.12, max=2012.12, sum=2012.12 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.9982993197278912,
          "description": "min=0.998, mean=0.998, max=0.998, sum=0.998 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B)\u2620",
          "description": "GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "href": "?group=the_pile&subgroup=subset%3A%20BookCorpus2&runSpecs=%5B%22the_pile%3Asubset%3DBookCorpus2%2Cmodel%3Dtogether_gpt-j-6b%22%5D",
          "markdown": false
        },
        {
          "value": 0.7009516451483246,
          "description": "min=0.701, mean=0.701, max=0.701, sum=0.701 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.4580637211149388,
          "description": "min=0.458, mean=0.458, max=0.458, sum=0.458 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 28.0,
          "description": "min=28, mean=28, max=28, sum=28 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 2048.9755244755243,
          "description": "min=2048.976, mean=2048.976, max=2048.976, sum=2048.976 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B)\u2620",
          "description": "GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "href": "?group=the_pile&subgroup=subset%3A%20BookCorpus2&runSpecs=%5B%22the_pile%3Asubset%3DBookCorpus2%2Cmodel%3Dtogether_gpt-neox-20b%22%5D",
          "markdown": false
        },
        {
          "value": 0.6767698580911153,
          "description": "min=0.677, mean=0.677, max=0.677, sum=0.677 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.9208491672882794,
          "description": "min=0.921, mean=0.921, max=0.921, sum=0.921 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 28.0,
          "description": "min=28, mean=28, max=28, sum=28 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 2048.9688041594454,
          "description": "min=2048.969, mean=2048.969, max=2048.969, sum=2048.969 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "OPT (175B)\u2620",
          "description": "OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "href": "?group=the_pile&subgroup=subset%3A%20BookCorpus2&runSpecs=%5B%22the_pile%3Asubset%3DBookCorpus2%2Cmodel%3Dtogether_opt-175b%22%5D",
          "markdown": false
        },
        {
          "value": 0.6651806417807913,
          "description": "min=0.665, mean=0.665, max=0.665, sum=0.665 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray",
            "font-weight": "bold"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.8836887945810893,
          "description": "min=0.884, mean=0.884, max=0.884, sum=0.884 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 28.0,
          "description": "min=28, mean=28, max=28, sum=28 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 2048.9755244755243,
          "description": "min=2048.976, mean=2048.976, max=2048.976, sum=2048.976 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "OPT (66B)\u2620",
          "description": "OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "href": "?group=the_pile&subgroup=subset%3A%20BookCorpus2&runSpecs=%5B%22the_pile%3Asubset%3DBookCorpus2%2Cmodel%3Dtogether_opt-66b%22%5D",
          "markdown": false
        },
        {
          "value": 0.6840351841709138,
          "description": "min=0.684, mean=0.684, max=0.684, sum=0.684 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.32296739406333813,
          "description": "min=0.323, mean=0.323, max=0.323, sum=0.323 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 28.0,
          "description": "min=28, mean=28, max=28, sum=28 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 2048.9755244755243,
          "description": "min=2048.976, mean=2048.976, max=2048.976, sum=2048.976 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "TNLG v2 (530B)\u2620",
          "description": "MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "href": "?group=the_pile&subgroup=subset%3A%20BookCorpus2&runSpecs=%5B%22the_pile%3Asubset%3DBookCorpus2%2Cmodel%3Dmicrosoft_TNLGv2_530B%22%5D",
          "markdown": false
        },
        {
          "value": 0.7208768854514948,
          "description": "min=0.721, mean=0.721, max=0.721, sum=0.721 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 28.0,
          "description": "min=28, mean=28, max=28, sum=28 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 2047.9755244755245,
          "description": "min=2047.976, mean=2047.976, max=2047.976, sum=2047.976 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.020104895104895104,
          "description": "min=0.02, mean=0.02, max=0.02, sum=0.02 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B)\u2620",
          "description": "MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "href": "?group=the_pile&subgroup=subset%3A%20BookCorpus2&runSpecs=%5B%22the_pile%3Asubset%3DBookCorpus2%2Cmodel%3Dmicrosoft_TNLGv2_7B%22%5D",
          "markdown": false
        },
        {
          "value": 0.8179556197434932,
          "description": "min=0.818, mean=0.818, max=0.818, sum=0.818 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 28.0,
          "description": "min=28, mean=28, max=28, sum=28 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 2047.9755244755245,
          "description": "min=2047.976, mean=2047.976, max=2047.976, sum=2047.976 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.020104895104895104,
          "description": "min=0.02, mean=0.02, max=0.02, sum=0.02 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "davinci (175B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20BookCorpus2&runSpecs=%5B%22the_pile%3Asubset%3DBookCorpus2%2Cmodel%3Dopenai_davinci%22%5D",
          "markdown": false
        },
        {
          "value": 0.7635585724624353,
          "description": "min=0.764, mean=0.764, max=0.764, sum=0.764 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.23902667449737655,
          "description": "min=0.239, mean=0.239, max=0.239, sum=0.239 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 28.0,
          "description": "min=28, mean=28, max=28, sum=28 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2048.9755244755243,
          "description": "min=2048.976, mean=2048.976, max=2048.976, sum=2048.976 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20BookCorpus2&runSpecs=%5B%22the_pile%3Asubset%3DBookCorpus2%2Cmodel%3Dopenai_curie%22%5D",
          "markdown": false
        },
        {
          "value": 0.8284286137531937,
          "description": "min=0.828, mean=0.828, max=0.828, sum=0.828 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.12035302165282499,
          "description": "min=0.12, mean=0.12, max=0.12, sum=0.12 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 28.0,
          "description": "min=28, mean=28, max=28, sum=28 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2048.9755244755243,
          "description": "min=2048.976, mean=2048.976, max=2048.976, sum=2048.976 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20BookCorpus2&runSpecs=%5B%22the_pile%3Asubset%3DBookCorpus2%2Cmodel%3Dopenai_babbage%22%5D",
          "markdown": false
        },
        {
          "value": 0.8887344168022883,
          "description": "min=0.889, mean=0.889, max=0.889, sum=0.889 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.13367746348703272,
          "description": "min=0.134, mean=0.134, max=0.134, sum=0.134 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 28.0,
          "description": "min=28, mean=28, max=28, sum=28 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2048.9755244755243,
          "description": "min=2048.976, mean=2048.976, max=2048.976, sum=2048.976 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20BookCorpus2&runSpecs=%5B%22the_pile%3Asubset%3DBookCorpus2%2Cmodel%3Dopenai_ada%22%5D",
          "markdown": false
        },
        {
          "value": 0.9579650035523608,
          "description": "min=0.958, mean=0.958, max=0.958, sum=0.958 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.1440038106424829,
          "description": "min=0.144, mean=0.144, max=0.144, sum=0.144 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 28.0,
          "description": "min=28, mean=28, max=28, sum=28 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2048.9755244755243,
          "description": "min=2048.976, mean=2048.976, max=2048.976, sum=2048.976 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20BookCorpus2&runSpecs=%5B%22the_pile%3Asubset%3DBookCorpus2%2Cmodel%3Dopenai_text-davinci-003%22%5D",
          "markdown": false
        },
        {
          "value": 0.7394684405667127,
          "description": "min=0.739, mean=0.739, max=0.739, sum=0.739 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 28.0,
          "description": "min=28, mean=28, max=28, sum=28 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4000.9661590524533,
          "description": "min=4000.966, mean=4000.966, max=4000.966, sum=4000.966 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20BookCorpus2&runSpecs=%5B%22the_pile%3Asubset%3DBookCorpus2%2Cmodel%3Dopenai_text-davinci-002%22%5D",
          "markdown": false
        },
        {
          "value": 0.7413747484759958,
          "description": "min=0.741, mean=0.741, max=0.741, sum=0.741 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.34715008438205225,
          "description": "min=0.347, mean=0.347, max=0.347, sum=0.347 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 28.0,
          "description": "min=28, mean=28, max=28, sum=28 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 4000.9661590524533,
          "description": "min=4000.966, mean=4000.966, max=4000.966, sum=4000.966 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20BookCorpus2&runSpecs=%5B%22the_pile%3Asubset%3DBookCorpus2%2Cmodel%3Dopenai_text-curie-001%22%5D",
          "markdown": false
        },
        {
          "value": 1.0652966325793036,
          "description": "min=1.065, mean=1.065, max=1.065, sum=1.065 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.15635111633158494,
          "description": "min=0.156, mean=0.156, max=0.156, sum=0.156 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 28.0,
          "description": "min=28, mean=28, max=28, sum=28 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2048.9755244755243,
          "description": "min=2048.976, mean=2048.976, max=2048.976, sum=2048.976 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20BookCorpus2&runSpecs=%5B%22the_pile%3Asubset%3DBookCorpus2%2Cmodel%3Dopenai_text-babbage-001%22%5D",
          "markdown": false
        },
        {
          "value": 1.1679146599664156,
          "description": "min=1.168, mean=1.168, max=1.168, sum=1.168 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.1686888954144842,
          "description": "min=0.169, mean=0.169, max=0.169, sum=0.169 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 28.0,
          "description": "min=28, mean=28, max=28, sum=28 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2048.9755244755243,
          "description": "min=2048.976, mean=2048.976, max=2048.976, sum=2048.976 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20BookCorpus2&runSpecs=%5B%22the_pile%3Asubset%3DBookCorpus2%2Cmodel%3Dopenai_text-ada-001%22%5D",
          "markdown": false
        },
        {
          "value": 1.7946277783123723,
          "description": "min=1.795, mean=1.795, max=1.795, sum=1.795 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.12002095853365506,
          "description": "min=0.12, mean=0.12, max=0.12, sum=0.12 (1)",
          "style": {
            "font-weight": "bold"
          },
          "markdown": false
        },
        {
          "value": 28.0,
          "description": "min=28, mean=28, max=28, sum=28 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2048.9755244755243,
          "description": "min=2048.976, mean=2048.976, max=2048.976, sum=2048.976 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/the_pile_the_pile_subset:BookCorpus2.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/the_pile_the_pile_subset:BookCorpus2.json"
      }
    ],
    "name": "the_pile_subset:BookCorpus2"
  },
  {
    "title": "subset: Enron Emails",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "BPB",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\nBits/byte: Average number of bits per byte according to model probabilities.",
        "markdown": false,
        "lower_is_better": true,
        "metadata": {
          "metric": "BPB",
          "run_group": "The Pile"
        }
      },
      {
        "value": "Denoised inference time (s)",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\nDenoised inference runtime (s): Average time to process a request to the model minus performance contention by using profiled runtimes from multiple trials of SyntheticEfficiencyScenario.",
        "markdown": false,
        "lower_is_better": true,
        "metadata": {
          "metric": "Denoised inference time (s)",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# eval",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# train",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "The Pile"
        }
      },
      {
        "value": "truncated",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# output tokens",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# trials",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "The Pile"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "J1-Jumbo v1 (178B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dai21_j1-jumbo%22%5D",
          "markdown": false
        },
        {
          "value": 0.5586372781430737,
          "description": "min=0.559, mean=0.559, max=0.559, sum=0.559 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.4218728966346155,
          "description": "min=0.422, mean=0.422, max=0.422, sum=0.422 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 102.0,
          "description": "min=102, mean=102, max=102, sum=102 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 361.5673076923077,
          "description": "min=361.567, mean=361.567, max=361.567, sum=361.567 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dai21_j1-large%22%5D",
          "markdown": false
        },
        {
          "value": 0.7673018540199894,
          "description": "min=0.767, mean=0.767, max=0.767, sum=0.767 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.35003825495793284,
          "description": "min=0.35, mean=0.35, max=0.35, sum=0.35 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 102.0,
          "description": "min=102, mean=102, max=102, sum=102 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 361.5673076923077,
          "description": "min=361.567, mean=361.567, max=361.567, sum=361.567 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dai21_j1-grande%22%5D",
          "markdown": false
        },
        {
          "value": 0.6901915547980926,
          "description": "min=0.69, mean=0.69, max=0.69, sum=0.69 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.42614610877403847,
          "description": "min=0.426, mean=0.426, max=0.426, sum=0.426 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 102.0,
          "description": "min=102, mean=102, max=102, sum=102 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 361.5673076923077,
          "description": "min=361.567, mean=361.567, max=361.567, sum=361.567 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dai21_j1-grande-v2-beta%22%5D",
          "markdown": false
        },
        {
          "value": 0.7436628178994338,
          "description": "min=0.744, mean=0.744, max=0.744, sum=0.744 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 102.0,
          "description": "min=102, mean=102, max=102, sum=102 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 361.5673076923077,
          "description": "min=361.567, mean=361.567, max=361.567, sum=361.567 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dai21_j2-jumbo%22%5D",
          "markdown": false
        },
        {
          "value": 0.6834391925190553,
          "description": "min=0.683, mean=0.683, max=0.683, sum=0.683 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 102.0,
          "description": "min=102, mean=102, max=102, sum=102 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 352.62745098039215,
          "description": "min=352.627, mean=352.627, max=352.627, sum=352.627 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dai21_j2-grande%22%5D",
          "markdown": false
        },
        {
          "value": 0.7353955287785678,
          "description": "min=0.735, mean=0.735, max=0.735, sum=0.735 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 102.0,
          "description": "min=102, mean=102, max=102, sum=102 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 361.5673076923077,
          "description": "min=361.567, mean=361.567, max=361.567, sum=361.567 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dai21_j2-large%22%5D",
          "markdown": false
        },
        {
          "value": 0.8099813134177772,
          "description": "min=0.81, mean=0.81, max=0.81, sum=0.81 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 102.0,
          "description": "min=102, mean=102, max=102, sum=102 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 361.5673076923077,
          "description": "min=361.567, mean=361.567, max=361.567, sum=361.567 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B)\u2620",
          "description": "Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Danthropic_stanford-online-all-v4-s3%22%5D",
          "markdown": false
        },
        {
          "value": 0.8738712360692764,
          "description": "min=0.874, mean=0.874, max=0.874, sum=0.874 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.7712531403186277,
          "description": "min=0.771, mean=0.771, max=0.771, sum=0.771 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 102.0,
          "description": "min=102, mean=102, max=102, sum=102 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 426.79411764705884,
          "description": "min=426.794, mean=426.794, max=426.794, sum=426.794 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 3.9607843137254903,
          "description": "min=3.961, mean=3.961, max=3.961, sum=3.961 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "BLOOM (176B)\u2620",
          "description": "BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dtogether_bloom%22%5D",
          "markdown": false
        },
        {
          "value": 0.8275444757820553,
          "description": "min=0.828, mean=0.828, max=0.828, sum=0.828 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.6277824397318257,
          "description": "min=0.628, mean=0.628, max=0.628, sum=0.628 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 102.0,
          "description": "min=102, mean=102, max=102, sum=102 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 378.6923076923077,
          "description": "min=378.692, mean=378.692, max=378.692, sum=378.692 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dcohere_xlarge-20220609%22%5D",
          "markdown": false
        },
        {
          "value": 0.9363645608160398,
          "description": "min=0.936, mean=0.936, max=0.936, sum=0.936 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.4710873883928569,
          "description": "min=0.471, mean=0.471, max=0.471, sum=0.471 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 102.0,
          "description": "min=102, mean=102, max=102, sum=102 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 446.84761904761905,
          "description": "min=446.848, mean=446.848, max=446.848, sum=446.848 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dcohere_large-20220720%22%5D",
          "markdown": false
        },
        {
          "value": 0.9836258840801502,
          "description": "min=0.984, mean=0.984, max=0.984, sum=0.984 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.30965760788690466,
          "description": "min=0.31, mean=0.31, max=0.31, sum=0.31 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 102.0,
          "description": "min=102, mean=102, max=102, sum=102 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 446.84761904761905,
          "description": "min=446.848, mean=446.848, max=446.848, sum=446.848 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dcohere_medium-20220720%22%5D",
          "markdown": false
        },
        {
          "value": 1.0169704296539641,
          "description": "min=1.017, mean=1.017, max=1.017, sum=1.017 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.26816454613095225,
          "description": "min=0.268, mean=0.268, max=0.268, sum=0.268 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 102.0,
          "description": "min=102, mean=102, max=102, sum=102 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 446.84761904761905,
          "description": "min=446.848, mean=446.848, max=446.848, sum=446.848 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dcohere_small-20220720%22%5D",
          "markdown": false
        },
        {
          "value": 1.1824377664200978,
          "description": "min=1.182, mean=1.182, max=1.182, sum=1.182 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2831417968749999,
          "description": "min=0.283, mean=0.283, max=0.283, sum=0.283 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 102.0,
          "description": "min=102, mean=102, max=102, sum=102 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 446.84761904761905,
          "description": "min=446.848, mean=446.848, max=446.848, sum=446.848 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dcohere_xlarge-20221108%22%5D",
          "markdown": false
        },
        {
          "value": 0.9323164837336272,
          "description": "min=0.932, mean=0.932, max=0.932, sum=0.932 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 102.0,
          "description": "min=102, mean=102, max=102, sum=102 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 446.84761904761905,
          "description": "min=446.848, mean=446.848, max=446.848, sum=446.848 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dcohere_medium-20221108%22%5D",
          "markdown": false
        },
        {
          "value": 1.0492286807383089,
          "description": "min=1.049, mean=1.049, max=1.049, sum=1.049 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 102.0,
          "description": "min=102, mean=102, max=102, sum=102 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 446.84761904761905,
          "description": "min=446.848, mean=446.848, max=446.848, sum=446.848 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dcohere_command-medium-beta%22%5D",
          "markdown": false
        },
        {
          "value": 1.0527257306688016,
          "description": "min=1.053, mean=1.053, max=1.053, sum=1.053 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 102.0,
          "description": "min=102, mean=102, max=102, sum=102 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 445.51428571428573,
          "description": "min=445.514, mean=445.514, max=445.514, sum=445.514 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dcohere_command-xlarge-beta%22%5D",
          "markdown": false
        },
        {
          "value": 0.9608436655343752,
          "description": "min=0.961, mean=0.961, max=0.961, sum=0.961 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 102.0,
          "description": "min=102, mean=102, max=102, sum=102 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 445.51428571428573,
          "description": "min=445.514, mean=445.514, max=445.514, sum=445.514 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B)\u2620",
          "description": "GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dtogether_gpt-j-6b%22%5D",
          "markdown": false
        },
        {
          "value": 0.4719483919683847,
          "description": "min=0.472, mean=0.472, max=0.472, sum=0.472 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.45039792106265086,
          "description": "min=0.45, mean=0.45, max=0.45, sum=0.45 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 102.0,
          "description": "min=102, mean=102, max=102, sum=102 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 438.95238095238096,
          "description": "min=438.952, mean=438.952, max=438.952, sum=438.952 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B)\u2620",
          "description": "GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dtogether_gpt-neox-20b%22%5D",
          "markdown": false
        },
        {
          "value": 0.415984556470918,
          "description": "min=0.416, mean=0.416, max=0.416, sum=0.416 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray",
            "font-weight": "bold"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.8498413511193715,
          "description": "min=0.85, mean=0.85, max=0.85, sum=0.85 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 102.0,
          "description": "min=102, mean=102, max=102, sum=102 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 408.86538461538464,
          "description": "min=408.865, mean=408.865, max=408.865, sum=408.865 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "OPT (175B)\u2620",
          "description": "OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dtogether_opt-175b%22%5D",
          "markdown": false
        },
        {
          "value": 0.6103518190290984,
          "description": "min=0.61, mean=0.61, max=0.61, sum=0.61 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.7509441199797202,
          "description": "min=0.751, mean=0.751, max=0.751, sum=0.751 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 102.0,
          "description": "min=102, mean=102, max=102, sum=102 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 438.95238095238096,
          "description": "min=438.952, mean=438.952, max=438.952, sum=438.952 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "OPT (66B)\u2620",
          "description": "OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dtogether_opt-66b%22%5D",
          "markdown": false
        },
        {
          "value": 0.6516029874902458,
          "description": "min=0.652, mean=0.652, max=0.652, sum=0.652 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.7818579669532142,
          "description": "min=0.782, mean=0.782, max=0.782, sum=0.782 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 102.0,
          "description": "min=102, mean=102, max=102, sum=102 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 438.95238095238096,
          "description": "min=438.952, mean=438.952, max=438.952, sum=438.952 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "TNLG v2 (530B)\u2620",
          "description": "MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dmicrosoft_TNLGv2_530B%22%5D",
          "markdown": false
        },
        {
          "value": 0.8719475521068547,
          "description": "min=0.872, mean=0.872, max=0.872, sum=0.872 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 102.0,
          "description": "min=102, mean=102, max=102, sum=102 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 438.9047619047619,
          "description": "min=438.905, mean=438.905, max=438.905, sum=438.905 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B)\u2620",
          "description": "MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dmicrosoft_TNLGv2_7B%22%5D",
          "markdown": false
        },
        {
          "value": 0.9812304149641637,
          "description": "min=0.981, mean=0.981, max=0.981, sum=0.981 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 102.0,
          "description": "min=102, mean=102, max=102, sum=102 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 438.9047619047619,
          "description": "min=438.905, mean=438.905, max=438.905, sum=438.905 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "davinci (175B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dopenai_davinci%22%5D",
          "markdown": false
        },
        {
          "value": 0.9790026759479636,
          "description": "min=0.979, mean=0.979, max=0.979, sum=0.979 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.20530081845238102,
          "description": "min=0.205, mean=0.205, max=0.205, sum=0.205 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 102.0,
          "description": "min=102, mean=102, max=102, sum=102 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 438.95238095238096,
          "description": "min=438.952, mean=438.952, max=438.952, sum=438.952 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dopenai_curie%22%5D",
          "markdown": false
        },
        {
          "value": 1.0541406102414068,
          "description": "min=1.054, mean=1.054, max=1.054, sum=1.054 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.09134916914682542,
          "description": "min=0.091, mean=0.091, max=0.091, sum=0.091 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 102.0,
          "description": "min=102, mean=102, max=102, sum=102 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 438.95238095238096,
          "description": "min=438.952, mean=438.952, max=438.952, sum=438.952 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dopenai_babbage%22%5D",
          "markdown": false
        },
        {
          "value": 1.123187940160497,
          "description": "min=1.123, mean=1.123, max=1.123, sum=1.123 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.11765336061507939,
          "description": "min=0.118, mean=0.118, max=0.118, sum=0.118 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 102.0,
          "description": "min=102, mean=102, max=102, sum=102 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 438.95238095238096,
          "description": "min=438.952, mean=438.952, max=438.952, sum=438.952 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dopenai_ada%22%5D",
          "markdown": false
        },
        {
          "value": 1.2122512727979304,
          "description": "min=1.212, mean=1.212, max=1.212, sum=1.212 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.13967581845238097,
          "description": "min=0.14, mean=0.14, max=0.14, sum=0.14 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 102.0,
          "description": "min=102, mean=102, max=102, sum=102 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 438.95238095238096,
          "description": "min=438.952, mean=438.952, max=438.952, sum=438.952 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dopenai_text-davinci-003%22%5D",
          "markdown": false
        },
        {
          "value": 0.8633977697757586,
          "description": "min=0.863, mean=0.863, max=0.863, sum=0.863 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 102.0,
          "description": "min=102, mean=102, max=102, sum=102 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 447.97087378640776,
          "description": "min=447.971, mean=447.971, max=447.971, sum=447.971 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dopenai_text-davinci-002%22%5D",
          "markdown": false
        },
        {
          "value": 0.8269553503052298,
          "description": "min=0.827, mean=0.827, max=0.827, sum=0.827 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.18883556457322007,
          "description": "min=0.189, mean=0.189, max=0.189, sum=0.189 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 102.0,
          "description": "min=102, mean=102, max=102, sum=102 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 447.97087378640776,
          "description": "min=447.971, mean=447.971, max=447.971, sum=447.971 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dopenai_text-curie-001%22%5D",
          "markdown": false
        },
        {
          "value": 1.2749034435651114,
          "description": "min=1.275, mean=1.275, max=1.275, sum=1.275 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.13262703373015872,
          "description": "min=0.133, mean=0.133, max=0.133, sum=0.133 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 102.0,
          "description": "min=102, mean=102, max=102, sum=102 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 438.95238095238096,
          "description": "min=438.952, mean=438.952, max=438.952, sum=438.952 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dopenai_text-babbage-001%22%5D",
          "markdown": false
        },
        {
          "value": 1.4354041718632282,
          "description": "min=1.435, mean=1.435, max=1.435, sum=1.435 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.13237560763888895,
          "description": "min=0.132, mean=0.132, max=0.132, sum=0.132 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 102.0,
          "description": "min=102, mean=102, max=102, sum=102 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 438.95238095238096,
          "description": "min=438.952, mean=438.952, max=438.952, sum=438.952 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Enron%20Emails&runSpecs=%5B%22the_pile%3Asubset%3DEnron%20Emails%2Cmodel%3Dopenai_text-ada-001%22%5D",
          "markdown": false
        },
        {
          "value": 2.0025518558810145,
          "description": "min=2.003, mean=2.003, max=2.003, sum=2.003 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.08688396577380951,
          "description": "min=0.087, mean=0.087, max=0.087, sum=0.087 (1)",
          "style": {
            "font-weight": "bold"
          },
          "markdown": false
        },
        {
          "value": 102.0,
          "description": "min=102, mean=102, max=102, sum=102 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 438.95238095238096,
          "description": "min=438.952, mean=438.952, max=438.952, sum=438.952 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/the_pile_the_pile_subset:EnronEmails.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/the_pile_the_pile_subset:EnronEmails.json"
      }
    ],
    "name": "the_pile_subset:EnronEmails"
  },
  {
    "title": "subset: Github",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "BPB",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\nBits/byte: Average number of bits per byte according to model probabilities.",
        "markdown": false,
        "lower_is_better": true,
        "metadata": {
          "metric": "BPB",
          "run_group": "The Pile"
        }
      },
      {
        "value": "Denoised inference time (s)",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\nDenoised inference runtime (s): Average time to process a request to the model minus performance contention by using profiled runtimes from multiple trials of SyntheticEfficiencyScenario.",
        "markdown": false,
        "lower_is_better": true,
        "metadata": {
          "metric": "Denoised inference time (s)",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# eval",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# train",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "The Pile"
        }
      },
      {
        "value": "truncated",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# output tokens",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# trials",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "The Pile"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "J1-Jumbo v1 (178B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Github&runSpecs=%5B%22the_pile%3Asubset%3DGithub%2Cmodel%3Dai21_j1-jumbo%22%5D",
          "markdown": false
        },
        {
          "value": 0.2800739418582162,
          "description": "min=0.28, mean=0.28, max=0.28, sum=0.28 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.8164250060946903,
          "description": "min=0.816, mean=0.816, max=0.816, sum=0.816 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1298.6695598264105,
          "description": "min=1298.67, mean=1298.67, max=1298.67, sum=1298.67 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Github&runSpecs=%5B%22the_pile%3Asubset%3DGithub%2Cmodel%3Dai21_j1-large%22%5D",
          "markdown": false
        },
        {
          "value": 0.3576289040766366,
          "description": "min=0.358, mean=0.358, max=0.358, sum=0.358 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.6213299178872199,
          "description": "min=0.621, mean=0.621, max=0.621, sum=0.621 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1298.6695598264105,
          "description": "min=1298.67, mean=1298.67, max=1298.67, sum=1298.67 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Github&runSpecs=%5B%22the_pile%3Asubset%3DGithub%2Cmodel%3Dai21_j1-grande%22%5D",
          "markdown": false
        },
        {
          "value": 0.313759974971845,
          "description": "min=0.314, mean=0.314, max=0.314, sum=0.314 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.7284567678868936,
          "description": "min=0.728, mean=0.728, max=0.728, sum=0.728 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1298.6695598264105,
          "description": "min=1298.67, mean=1298.67, max=1298.67, sum=1298.67 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Github&runSpecs=%5B%22the_pile%3Asubset%3DGithub%2Cmodel%3Dai21_j1-grande-v2-beta%22%5D",
          "markdown": false
        },
        {
          "value": 0.33287492450443024,
          "description": "min=0.333, mean=0.333, max=0.333, sum=0.333 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1298.6695598264105,
          "description": "min=1298.67, mean=1298.67, max=1298.67, sum=1298.67 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Github&runSpecs=%5B%22the_pile%3Asubset%3DGithub%2Cmodel%3Dai21_j2-jumbo%22%5D",
          "markdown": false
        },
        {
          "value": 0.24116383874483038,
          "description": "min=0.241, mean=0.241, max=0.241, sum=0.241 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1867.8085106382978,
          "description": "min=1867.809, mean=1867.809, max=1867.809, sum=1867.809 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Github&runSpecs=%5B%22the_pile%3Asubset%3DGithub%2Cmodel%3Dai21_j2-grande%22%5D",
          "markdown": false
        },
        {
          "value": 0.3215633133788175,
          "description": "min=0.322, mean=0.322, max=0.322, sum=0.322 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1298.6695598264105,
          "description": "min=1298.67, mean=1298.67, max=1298.67, sum=1298.67 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Github&runSpecs=%5B%22the_pile%3Asubset%3DGithub%2Cmodel%3Dai21_j2-large%22%5D",
          "markdown": false
        },
        {
          "value": 0.34267403154112086,
          "description": "min=0.343, mean=0.343, max=0.343, sum=0.343 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1298.6695598264105,
          "description": "min=1298.67, mean=1298.67, max=1298.67, sum=1298.67 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B)\u2620",
          "description": "Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "href": "?group=the_pile&subgroup=subset%3A%20Github&runSpecs=%5B%22the_pile%3Asubset%3DGithub%2Cmodel%3Danthropic_stanford-online-all-v4-s3%22%5D",
          "markdown": false
        },
        {
          "value": 0.3359887330970304,
          "description": "min=0.336, mean=0.336, max=0.336, sum=0.336 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0696491819646836,
          "description": "min=1.07, mean=1.07, max=1.07, sum=1.07 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 2431.429596412556,
          "description": "min=2431.43, mean=2431.43, max=2431.43, sum=2431.43 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.30672645739910315,
          "description": "min=0.307, mean=0.307, max=0.307, sum=0.307 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "BLOOM (176B)\u2620",
          "description": "BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "href": "?group=the_pile&subgroup=subset%3A%20Github&runSpecs=%5B%22the_pile%3Asubset%3DGithub%2Cmodel%3Dtogether_bloom%22%5D",
          "markdown": false
        },
        {
          "value": 0.268879922084521,
          "description": "min=0.269, mean=0.269, max=0.269, sum=0.269 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.8782009340476657,
          "description": "min=0.878, mean=0.878, max=0.878, sum=0.878 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1178.3655030800821,
          "description": "min=1178.366, mean=1178.366, max=1178.366, sum=1178.366 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "GPT-J (6B)\u2620",
          "description": "GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "href": "?group=the_pile&subgroup=subset%3A%20Github&runSpecs=%5B%22the_pile%3Asubset%3DGithub%2Cmodel%3Dtogether_gpt-j-6b%22%5D",
          "markdown": false
        },
        {
          "value": 0.23424010598353212,
          "description": "min=0.234, mean=0.234, max=0.234, sum=0.234 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.45537515178169125,
          "description": "min=0.455, mean=0.455, max=0.455, sum=0.455 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1454.8128052088985,
          "description": "min=1454.813, mean=1454.813, max=1454.813, sum=1454.813 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B)\u2620",
          "description": "GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "href": "?group=the_pile&subgroup=subset%3A%20Github&runSpecs=%5B%22the_pile%3Asubset%3DGithub%2Cmodel%3Dtogether_gpt-neox-20b%22%5D",
          "markdown": false
        },
        {
          "value": 0.2119857337505652,
          "description": "min=0.212, mean=0.212, max=0.212, sum=0.212 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.8952432262377223,
          "description": "min=0.895, mean=0.895, max=0.895, sum=0.895 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1289.8342820999367,
          "description": "min=1289.834, mean=1289.834, max=1289.834, sum=1289.834 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "OPT (175B)\u2620",
          "description": "OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "href": "?group=the_pile&subgroup=subset%3A%20Github&runSpecs=%5B%22the_pile%3Asubset%3DGithub%2Cmodel%3Dtogether_opt-175b%22%5D",
          "markdown": false
        },
        {
          "value": 0.4434375607967696,
          "description": "min=0.443, mean=0.443, max=0.443, sum=0.443 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.8063871718441558,
          "description": "min=0.806, mean=0.806, max=0.806, sum=0.806 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1454.8084644601195,
          "description": "min=1454.808, mean=1454.808, max=1454.808, sum=1454.808 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "OPT (66B)\u2620",
          "description": "OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "href": "?group=the_pile&subgroup=subset%3A%20Github&runSpecs=%5B%22the_pile%3Asubset%3DGithub%2Cmodel%3Dtogether_opt-66b%22%5D",
          "markdown": false
        },
        {
          "value": 0.46848626812783656,
          "description": "min=0.468, mean=0.468, max=0.468, sum=0.468 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.54763185502262,
          "description": "min=0.548, mean=0.548, max=0.548, sum=0.548 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1454.8084644601195,
          "description": "min=1454.808, mean=1454.808, max=1454.808, sum=1454.808 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "TNLG v2 (530B)\u2620",
          "description": "MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "href": "?group=the_pile&subgroup=subset%3A%20Github&runSpecs=%5B%22the_pile%3Asubset%3DGithub%2Cmodel%3Dmicrosoft_TNLGv2_530B%22%5D",
          "markdown": false
        },
        {
          "value": 0.318670779268459,
          "description": "min=0.319, mean=0.319, max=0.319, sum=0.319 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1454.2805208898535,
          "description": "min=1454.281, mean=1454.281, max=1454.281, sum=1454.281 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.008138903960933261,
          "description": "min=0.008, mean=0.008, max=0.008, sum=0.008 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B)\u2620",
          "description": "MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "href": "?group=the_pile&subgroup=subset%3A%20Github&runSpecs=%5B%22the_pile%3Asubset%3DGithub%2Cmodel%3Dmicrosoft_TNLGv2_7B%22%5D",
          "markdown": false
        },
        {
          "value": 0.41776881045756503,
          "description": "min=0.418, mean=0.418, max=0.418, sum=0.418 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1454.2805208898535,
          "description": "min=1454.281, mean=1454.281, max=1454.281, sum=1454.281 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.008138903960933261,
          "description": "min=0.008, mean=0.008, max=0.008, sum=0.008 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "davinci (175B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Github&runSpecs=%5B%22the_pile%3Asubset%3DGithub%2Cmodel%3Dopenai_davinci%22%5D",
          "markdown": false
        },
        {
          "value": 0.5153979863550764,
          "description": "min=0.515, mean=0.515, max=0.515, sum=0.515 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.22648988465647477,
          "description": "min=0.226, mean=0.226, max=0.226, sum=0.226 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1454.8128052088985,
          "description": "min=1454.813, mean=1454.813, max=1454.813, sum=1454.813 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Github&runSpecs=%5B%22the_pile%3Asubset%3DGithub%2Cmodel%3Dopenai_curie%22%5D",
          "markdown": false
        },
        {
          "value": 0.5872642356983604,
          "description": "min=0.587, mean=0.587, max=0.587, sum=0.587 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.10968025093540792,
          "description": "min=0.11, mean=0.11, max=0.11, sum=0.11 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1454.8128052088985,
          "description": "min=1454.813, mean=1454.813, max=1454.813, sum=1454.813 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Github&runSpecs=%5B%22the_pile%3Asubset%3DGithub%2Cmodel%3Dopenai_babbage%22%5D",
          "markdown": false
        },
        {
          "value": 0.6870191925887574,
          "description": "min=0.687, mean=0.687, max=0.687, sum=0.687 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.12774164208039368,
          "description": "min=0.128, mean=0.128, max=0.128, sum=0.128 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1454.8128052088985,
          "description": "min=1454.813, mean=1454.813, max=1454.813, sum=1454.813 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Github&runSpecs=%5B%22the_pile%3Asubset%3DGithub%2Cmodel%3Dopenai_ada%22%5D",
          "markdown": false
        },
        {
          "value": 0.8229704634127093,
          "description": "min=0.823, mean=0.823, max=0.823, sum=0.823 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.1424025620591416,
          "description": "min=0.142, mean=0.142, max=0.142, sum=0.142 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1454.8128052088985,
          "description": "min=1454.813, mean=1454.813, max=1454.813, sum=1454.813 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Github&runSpecs=%5B%22the_pile%3Asubset%3DGithub%2Cmodel%3Dopenai_text-davinci-003%22%5D",
          "markdown": false
        },
        {
          "value": 0.20453628215117323,
          "description": "min=0.205, mean=0.205, max=0.205, sum=0.205 (1)",
          "style": {
            "font-weight": "bold"
          },
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2014.117472118959,
          "description": "min=2014.117, mean=2014.117, max=2014.117, sum=2014.117 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Github&runSpecs=%5B%22the_pile%3Asubset%3DGithub%2Cmodel%3Dopenai_text-davinci-002%22%5D",
          "markdown": false
        },
        {
          "value": 0.21415132230600212,
          "description": "min=0.214, mean=0.214, max=0.214, sum=0.214 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2570115875735758,
          "description": "min=0.257, mean=0.257, max=0.257, sum=0.257 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 2014.117472118959,
          "description": "min=2014.117, mean=2014.117, max=2014.117, sum=2014.117 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Github&runSpecs=%5B%22the_pile%3Asubset%3DGithub%2Cmodel%3Dopenai_text-curie-001%22%5D",
          "markdown": false
        },
        {
          "value": 0.6766078318081764,
          "description": "min=0.677, mean=0.677, max=0.677, sum=0.677 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.14779921988040184,
          "description": "min=0.148, mean=0.148, max=0.148, sum=0.148 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1454.8128052088985,
          "description": "min=1454.813, mean=1454.813, max=1454.813, sum=1454.813 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Github&runSpecs=%5B%22the_pile%3Asubset%3DGithub%2Cmodel%3Dopenai_text-babbage-001%22%5D",
          "markdown": false
        },
        {
          "value": 0.814312951276125,
          "description": "min=0.814, mean=0.814, max=0.814, sum=0.814 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.15523417400016165,
          "description": "min=0.155, mean=0.155, max=0.155, sum=0.155 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1454.8128052088985,
          "description": "min=1454.813, mean=1454.813, max=1454.813, sum=1454.813 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Github&runSpecs=%5B%22the_pile%3Asubset%3DGithub%2Cmodel%3Dopenai_text-ada-001%22%5D",
          "markdown": false
        },
        {
          "value": 1.1556670142138152,
          "description": "min=1.156, mean=1.156, max=1.156, sum=1.156 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.10774693625373105,
          "description": "min=0.108, mean=0.108, max=0.108, sum=0.108 (1)",
          "style": {
            "font-weight": "bold"
          },
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1454.8128052088985,
          "description": "min=1454.813, mean=1454.813, max=1454.813, sum=1454.813 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/the_pile_the_pile_subset:Github.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/the_pile_the_pile_subset:Github.json"
      }
    ],
    "name": "the_pile_subset:Github"
  },
  {
    "title": "subset: PubMed Central",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "BPB",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\nBits/byte: Average number of bits per byte according to model probabilities.",
        "markdown": false,
        "lower_is_better": true,
        "metadata": {
          "metric": "BPB",
          "run_group": "The Pile"
        }
      },
      {
        "value": "Denoised inference time (s)",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\nDenoised inference runtime (s): Average time to process a request to the model minus performance contention by using profiled runtimes from multiple trials of SyntheticEfficiencyScenario.",
        "markdown": false,
        "lower_is_better": true,
        "metadata": {
          "metric": "Denoised inference time (s)",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# eval",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# train",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "The Pile"
        }
      },
      {
        "value": "truncated",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# output tokens",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# trials",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "The Pile"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "J1-Jumbo v1 (178B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20PubMed%20Central&runSpecs=%5B%22the_pile%3Asubset%3DPubMed%20Central%2Cmodel%3Dai21_j1-jumbo%22%5D",
          "markdown": false
        },
        {
          "value": 0.5283351218772983,
          "description": "min=0.528, mean=0.528, max=0.528, sum=0.528 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0927147580324625,
          "description": "min=1.093, mean=1.093, max=1.093, sum=1.093 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 584.0,
          "description": "min=584, mean=584, max=584, sum=584 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1958.0243902439024,
          "description": "min=1958.024, mean=1958.024, max=1958.024, sum=1958.024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20PubMed%20Central&runSpecs=%5B%22the_pile%3Asubset%3DPubMed%20Central%2Cmodel%3Dai21_j1-large%22%5D",
          "markdown": false
        },
        {
          "value": 0.5743754107726443,
          "description": "min=0.574, mean=0.574, max=0.574, sum=0.574 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.8098543860330151,
          "description": "min=0.81, mean=0.81, max=0.81, sum=0.81 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 584.0,
          "description": "min=584, mean=584, max=584, sum=584 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1958.0243902439024,
          "description": "min=1958.024, mean=1958.024, max=1958.024, sum=1958.024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20PubMed%20Central&runSpecs=%5B%22the_pile%3Asubset%3DPubMed%20Central%2Cmodel%3Dai21_j1-grande%22%5D",
          "markdown": false
        },
        {
          "value": 0.5478503354820519,
          "description": "min=0.548, mean=0.548, max=0.548, sum=0.548 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.9396586296543025,
          "description": "min=0.94, mean=0.94, max=0.94, sum=0.94 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 584.0,
          "description": "min=584, mean=584, max=584, sum=584 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1958.0243902439024,
          "description": "min=1958.024, mean=1958.024, max=1958.024, sum=1958.024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20PubMed%20Central&runSpecs=%5B%22the_pile%3Asubset%3DPubMed%20Central%2Cmodel%3Dai21_j1-grande-v2-beta%22%5D",
          "markdown": false
        },
        {
          "value": 0.5331407433664197,
          "description": "min=0.533, mean=0.533, max=0.533, sum=0.533 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 584.0,
          "description": "min=584, mean=584, max=584, sum=584 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1958.0243902439024,
          "description": "min=1958.024, mean=1958.024, max=1958.024, sum=1958.024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20PubMed%20Central&runSpecs=%5B%22the_pile%3Asubset%3DPubMed%20Central%2Cmodel%3Dai21_j2-jumbo%22%5D",
          "markdown": false
        },
        {
          "value": 0.4753736459267423,
          "description": "min=0.475, mean=0.475, max=0.475, sum=0.475 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 584.0,
          "description": "min=584, mean=584, max=584, sum=584 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 5018.687122736418,
          "description": "min=5018.687, mean=5018.687, max=5018.687, sum=5018.687 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20PubMed%20Central&runSpecs=%5B%22the_pile%3Asubset%3DPubMed%20Central%2Cmodel%3Dai21_j2-grande%22%5D",
          "markdown": false
        },
        {
          "value": 0.5269710877820014,
          "description": "min=0.527, mean=0.527, max=0.527, sum=0.527 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 584.0,
          "description": "min=584, mean=584, max=584, sum=584 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1958.0243902439024,
          "description": "min=1958.024, mean=1958.024, max=1958.024, sum=1958.024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20PubMed%20Central&runSpecs=%5B%22the_pile%3Asubset%3DPubMed%20Central%2Cmodel%3Dai21_j2-large%22%5D",
          "markdown": false
        },
        {
          "value": 0.5582129912415978,
          "description": "min=0.558, mean=0.558, max=0.558, sum=0.558 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 584.0,
          "description": "min=584, mean=584, max=584, sum=584 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1958.0243902439024,
          "description": "min=1958.024, mean=1958.024, max=1958.024, sum=1958.024 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B)\u2620",
          "description": "Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "href": "?group=the_pile&subgroup=subset%3A%20PubMed%20Central&runSpecs=%5B%22the_pile%3Asubset%3DPubMed%20Central%2Cmodel%3Danthropic_stanford-online-all-v4-s3%22%5D",
          "markdown": false
        },
        {
          "value": 0.532452222662542,
          "description": "min=0.532, mean=0.532, max=0.532, sum=0.532 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 2.1485038072916574,
          "description": "min=2.149, mean=2.149, max=2.149, sum=2.149 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 584.0,
          "description": "min=584, mean=584, max=584, sum=584 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 6830.844,
          "description": "min=6830.844, mean=6830.844, max=6830.844, sum=6830.844 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.309,
          "description": "min=0.309, mean=0.309, max=0.309, sum=0.309 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "BLOOM (176B)\u2620",
          "description": "BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "href": "?group=the_pile&subgroup=subset%3A%20PubMed%20Central&runSpecs=%5B%22the_pile%3Asubset%3DPubMed%20Central%2Cmodel%3Dtogether_bloom%22%5D",
          "markdown": false
        },
        {
          "value": 0.4702219963723856,
          "description": "min=0.47, mean=0.47, max=0.47, sum=0.47 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.1403030374192258,
          "description": "min=1.14, mean=1.14, max=1.14, sum=1.14 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 584.0,
          "description": "min=584, mean=584, max=584, sum=584 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1974.8286203941732,
          "description": "min=1974.829, mean=1974.829, max=1974.829, sum=1974.829 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "GPT-J (6B)\u2620",
          "description": "GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "href": "?group=the_pile&subgroup=subset%3A%20PubMed%20Central&runSpecs=%5B%22the_pile%3Asubset%3DPubMed%20Central%2Cmodel%3Dtogether_gpt-j-6b%22%5D",
          "markdown": false
        },
        {
          "value": 0.4469028997732635,
          "description": "min=0.447, mean=0.447, max=0.447, sum=0.447 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray",
            "font-weight": "bold"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.4533673888036644,
          "description": "min=0.453, mean=0.453, max=0.453, sum=0.453 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 584.0,
          "description": "min=584, mean=584, max=584, sum=584 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1991.2842465753424,
          "description": "min=1991.284, mean=1991.284, max=1991.284, sum=1991.284 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B)\u2620",
          "description": "GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "href": "?group=the_pile&subgroup=subset%3A%20PubMed%20Central&runSpecs=%5B%22the_pile%3Asubset%3DPubMed%20Central%2Cmodel%3Dtogether_gpt-neox-20b%22%5D",
          "markdown": false
        },
        {
          "value": 0.4519227783388039,
          "description": "min=0.452, mean=0.452, max=0.452, sum=0.452 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.9396488961461302,
          "description": "min=0.94, mean=0.94, max=0.94, sum=0.94 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 584.0,
          "description": "min=584, mean=584, max=584, sum=584 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1973.1757575757576,
          "description": "min=1973.176, mean=1973.176, max=1973.176, sum=1973.176 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "OPT (175B)\u2620",
          "description": "OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "href": "?group=the_pile&subgroup=subset%3A%20PubMed%20Central&runSpecs=%5B%22the_pile%3Asubset%3DPubMed%20Central%2Cmodel%3Dtogether_opt-175b%22%5D",
          "markdown": false
        },
        {
          "value": 0.5537030135679142,
          "description": "min=0.554, mean=0.554, max=0.554, sum=0.554 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.8629164962651704,
          "description": "min=0.863, mean=0.863, max=0.863, sum=0.863 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 584.0,
          "description": "min=584, mean=584, max=584, sum=584 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1991.2842465753424,
          "description": "min=1991.284, mean=1991.284, max=1991.284, sum=1991.284 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "OPT (66B)\u2620",
          "description": "OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "href": "?group=the_pile&subgroup=subset%3A%20PubMed%20Central&runSpecs=%5B%22the_pile%3Asubset%3DPubMed%20Central%2Cmodel%3Dtogether_opt-66b%22%5D",
          "markdown": false
        },
        {
          "value": 0.5725222823035323,
          "description": "min=0.573, mean=0.573, max=0.573, sum=0.573 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.39014951150024235,
          "description": "min=0.39, mean=0.39, max=0.39, sum=0.39 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 584.0,
          "description": "min=584, mean=584, max=584, sum=584 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1991.2842465753424,
          "description": "min=1991.284, mean=1991.284, max=1991.284, sum=1991.284 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "TNLG v2 (530B)\u2620",
          "description": "MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "href": "?group=the_pile&subgroup=subset%3A%20PubMed%20Central&runSpecs=%5B%22the_pile%3Asubset%3DPubMed%20Central%2Cmodel%3Dmicrosoft_TNLGv2_530B%22%5D",
          "markdown": false
        },
        {
          "value": 0.5714357354361154,
          "description": "min=0.571, mean=0.571, max=0.571, sum=0.571 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 584.0,
          "description": "min=584, mean=584, max=584, sum=584 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1990.3267123287671,
          "description": "min=1990.327, mean=1990.327, max=1990.327, sum=1990.327 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.010616438356164383,
          "description": "min=0.011, mean=0.011, max=0.011, sum=0.011 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B)\u2620",
          "description": "MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "href": "?group=the_pile&subgroup=subset%3A%20PubMed%20Central&runSpecs=%5B%22the_pile%3Asubset%3DPubMed%20Central%2Cmodel%3Dmicrosoft_TNLGv2_7B%22%5D",
          "markdown": false
        },
        {
          "value": 0.6459060766120218,
          "description": "min=0.646, mean=0.646, max=0.646, sum=0.646 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 584.0,
          "description": "min=584, mean=584, max=584, sum=584 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1990.3267123287671,
          "description": "min=1990.327, mean=1990.327, max=1990.327, sum=1990.327 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.010616438356164383,
          "description": "min=0.011, mean=0.011, max=0.011, sum=0.011 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "davinci (175B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20PubMed%20Central&runSpecs=%5B%22the_pile%3Asubset%3DPubMed%20Central%2Cmodel%3Dopenai_davinci%22%5D",
          "markdown": false
        },
        {
          "value": 0.6358856126002035,
          "description": "min=0.636, mean=0.636, max=0.636, sum=0.636 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.2376606405179789,
          "description": "min=0.238, mean=0.238, max=0.238, sum=0.238 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 584.0,
          "description": "min=584, mean=584, max=584, sum=584 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1991.2842465753424,
          "description": "min=1991.284, mean=1991.284, max=1991.284, sum=1991.284 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20PubMed%20Central&runSpecs=%5B%22the_pile%3Asubset%3DPubMed%20Central%2Cmodel%3Dopenai_curie%22%5D",
          "markdown": false
        },
        {
          "value": 0.6948681927182813,
          "description": "min=0.695, mean=0.695, max=0.695, sum=0.695 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.11926289463827631,
          "description": "min=0.119, mean=0.119, max=0.119, sum=0.119 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 584.0,
          "description": "min=584, mean=584, max=584, sum=584 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1991.2842465753424,
          "description": "min=1991.284, mean=1991.284, max=1991.284, sum=1991.284 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20PubMed%20Central&runSpecs=%5B%22the_pile%3Asubset%3DPubMed%20Central%2Cmodel%3Dopenai_babbage%22%5D",
          "markdown": false
        },
        {
          "value": 0.7583631792520841,
          "description": "min=0.758, mean=0.758, max=0.758, sum=0.758 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.1330757939586889,
          "description": "min=0.133, mean=0.133, max=0.133, sum=0.133 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 584.0,
          "description": "min=584, mean=584, max=584, sum=584 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1991.2842465753424,
          "description": "min=1991.284, mean=1991.284, max=1991.284, sum=1991.284 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20PubMed%20Central&runSpecs=%5B%22the_pile%3Asubset%3DPubMed%20Central%2Cmodel%3Dopenai_ada%22%5D",
          "markdown": false
        },
        {
          "value": 0.8391688670184556,
          "description": "min=0.839, mean=0.839, max=0.839, sum=0.839 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.1438196409460678,
          "description": "min=0.144, mean=0.144, max=0.144, sum=0.144 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 584.0,
          "description": "min=584, mean=584, max=584, sum=584 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1991.2842465753424,
          "description": "min=1991.284, mean=1991.284, max=1991.284, sum=1991.284 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20PubMed%20Central&runSpecs=%5B%22the_pile%3Asubset%3DPubMed%20Central%2Cmodel%3Dopenai_text-davinci-003%22%5D",
          "markdown": false
        },
        {
          "value": 0.5349255098210643,
          "description": "min=0.535, mean=0.535, max=0.535, sum=0.535 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 584.0,
          "description": "min=584, mean=584, max=584, sum=584 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 3737.731971153846,
          "description": "min=3737.732, mean=3737.732, max=3737.732, sum=3737.732 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20PubMed%20Central&runSpecs=%5B%22the_pile%3Asubset%3DPubMed%20Central%2Cmodel%3Dopenai_text-davinci-002%22%5D",
          "markdown": false
        },
        {
          "value": 0.5397742927572723,
          "description": "min=0.54, mean=0.54, max=0.54, sum=0.54 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.3349947310227603,
          "description": "min=0.335, mean=0.335, max=0.335, sum=0.335 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 584.0,
          "description": "min=584, mean=584, max=584, sum=584 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 3737.731971153846,
          "description": "min=3737.732, mean=3737.732, max=3737.732, sum=3737.732 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20PubMed%20Central&runSpecs=%5B%22the_pile%3Asubset%3DPubMed%20Central%2Cmodel%3Dopenai_text-curie-001%22%5D",
          "markdown": false
        },
        {
          "value": 0.8630863344279125,
          "description": "min=0.863, mean=0.863, max=0.863, sum=0.863 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.1554221853595846,
          "description": "min=0.155, mean=0.155, max=0.155, sum=0.155 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 584.0,
          "description": "min=584, mean=584, max=584, sum=584 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1991.2842465753424,
          "description": "min=1991.284, mean=1991.284, max=1991.284, sum=1991.284 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20PubMed%20Central&runSpecs=%5B%22the_pile%3Asubset%3DPubMed%20Central%2Cmodel%3Dopenai_text-babbage-001%22%5D",
          "markdown": false
        },
        {
          "value": 0.9744831840095227,
          "description": "min=0.974, mean=0.974, max=0.974, sum=0.974 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.16738192556721662,
          "description": "min=0.167, mean=0.167, max=0.167, sum=0.167 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 584.0,
          "description": "min=584, mean=584, max=584, sum=584 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1991.2842465753424,
          "description": "min=1991.284, mean=1991.284, max=1991.284, sum=1991.284 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20PubMed%20Central&runSpecs=%5B%22the_pile%3Asubset%3DPubMed%20Central%2Cmodel%3Dopenai_text-ada-001%22%5D",
          "markdown": false
        },
        {
          "value": 1.4359041624420645,
          "description": "min=1.436, mean=1.436, max=1.436, sum=1.436 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.11881167326626864,
          "description": "min=0.119, mean=0.119, max=0.119, sum=0.119 (1)",
          "style": {
            "font-weight": "bold"
          },
          "markdown": false
        },
        {
          "value": 584.0,
          "description": "min=584, mean=584, max=584, sum=584 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1991.2842465753424,
          "description": "min=1991.284, mean=1991.284, max=1991.284, sum=1991.284 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/the_pile_the_pile_subset:PubMedCentral.tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/the_pile_the_pile_subset:PubMedCentral.json"
      }
    ],
    "name": "the_pile_subset:PubMedCentral"
  },
  {
    "title": "subset: Wikipedia (en)",
    "header": [
      {
        "value": "Model/adapter",
        "markdown": false,
        "metadata": {}
      },
      {
        "value": "BPB",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\nBits/byte: Average number of bits per byte according to model probabilities.",
        "markdown": false,
        "lower_is_better": true,
        "metadata": {
          "metric": "BPB",
          "run_group": "The Pile"
        }
      },
      {
        "value": "Denoised inference time (s)",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\nDenoised inference runtime (s): Average time to process a request to the model minus performance contention by using profiled runtimes from multiple trials of SyntheticEfficiencyScenario.",
        "markdown": false,
        "lower_is_better": true,
        "metadata": {
          "metric": "Denoised inference time (s)",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# eval",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# eval: Number of evaluation instances.",
        "markdown": false,
        "metadata": {
          "metric": "# eval",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# train",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# train: Number of training instances (e.g., in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "# train",
          "run_group": "The Pile"
        }
      },
      {
        "value": "truncated",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
        "markdown": false,
        "metadata": {
          "metric": "truncated",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# prompt tokens",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# prompt tokens: Number of tokens in the prompt.",
        "markdown": false,
        "metadata": {
          "metric": "# prompt tokens",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# output tokens",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# output tokens: Actual number of output tokens.",
        "markdown": false,
        "metadata": {
          "metric": "# output tokens",
          "run_group": "The Pile"
        }
      },
      {
        "value": "# trials",
        "description": "The Pile corpus for measuring lanugage model performance across various domains [(Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf).\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
        "markdown": false,
        "metadata": {
          "metric": "# trials",
          "run_group": "The Pile"
        }
      }
    ],
    "rows": [
      [
        {
          "value": "J1-Jumbo v1 (178B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Wikipedia%20%28en%29&runSpecs=%5B%22the_pile%3Asubset%3DWikipedia%20%28en%29%2Cmodel%3Dai21_j1-jumbo%22%5D",
          "markdown": false
        },
        {
          "value": 0.5379814146137826,
          "description": "min=0.538, mean=0.538, max=0.538, sum=0.538 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.49868787079194293,
          "description": "min=0.499, mean=0.499, max=0.499, sum=0.499 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 542.9933774834437,
          "description": "min=542.993, mean=542.993, max=542.993, sum=542.993 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Large v1 (7.5B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Wikipedia%20%28en%29&runSpecs=%5B%22the_pile%3Asubset%3DWikipedia%20%28en%29%2Cmodel%3Dai21_j1-large%22%5D",
          "markdown": false
        },
        {
          "value": 0.6589225440510201,
          "description": "min=0.659, mean=0.659, max=0.659, sum=0.659 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.402891725057159,
          "description": "min=0.403, mean=0.403, max=0.403, sum=0.403 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 542.9933774834437,
          "description": "min=542.993, mean=542.993, max=542.993, sum=542.993 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v1 (17B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Wikipedia%20%28en%29&runSpecs=%5B%22the_pile%3Asubset%3DWikipedia%20%28en%29%2Cmodel%3Dai21_j1-grande%22%5D",
          "markdown": false
        },
        {
          "value": 0.6160245173065109,
          "description": "min=0.616, mean=0.616, max=0.616, sum=0.616 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.4913976355546349,
          "description": "min=0.491, mean=0.491, max=0.491, sum=0.491 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 542.9933774834437,
          "description": "min=542.993, mean=542.993, max=542.993, sum=542.993 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "J1-Grande v2 beta (17B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Wikipedia%20%28en%29&runSpecs=%5B%22the_pile%3Asubset%3DWikipedia%20%28en%29%2Cmodel%3Dai21_j1-grande-v2-beta%22%5D",
          "markdown": false
        },
        {
          "value": 0.6055425897507457,
          "description": "min=0.606, mean=0.606, max=0.606, sum=0.606 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 542.9933774834437,
          "description": "min=542.993, mean=542.993, max=542.993, sum=542.993 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Jumbo (178B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Wikipedia%20%28en%29&runSpecs=%5B%22the_pile%3Asubset%3DWikipedia%20%28en%29%2Cmodel%3Dai21_j2-jumbo%22%5D",
          "markdown": false
        },
        {
          "value": 0.5456098497334849,
          "description": "min=0.546, mean=0.546, max=0.546, sum=0.546 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 536.1324701195219,
          "description": "min=536.132, mean=536.132, max=536.132, sum=536.132 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Grande (17B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Wikipedia%20%28en%29&runSpecs=%5B%22the_pile%3Asubset%3DWikipedia%20%28en%29%2Cmodel%3Dai21_j2-grande%22%5D",
          "markdown": false
        },
        {
          "value": 0.5914795355656525,
          "description": "min=0.591, mean=0.591, max=0.591, sum=0.591 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 542.9933774834437,
          "description": "min=542.993, mean=542.993, max=542.993, sum=542.993 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Jurassic-2 Large (7.5B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Wikipedia%20%28en%29&runSpecs=%5B%22the_pile%3Asubset%3DWikipedia%20%28en%29%2Cmodel%3Dai21_j2-large%22%5D",
          "markdown": false
        },
        {
          "value": 0.657348786428337,
          "description": "min=0.657, mean=0.657, max=0.657, sum=0.657 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 542.9933774834437,
          "description": "min=542.993, mean=542.993, max=542.993, sum=542.993 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Anthropic-LM v4-s3 (52B)\u2620",
          "description": "Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "href": "?group=the_pile&subgroup=subset%3A%20Wikipedia%20%28en%29&runSpecs=%5B%22the_pile%3Asubset%3DWikipedia%20%28en%29%2Cmodel%3Danthropic_stanford-online-all-v4-s3%22%5D",
          "markdown": false
        },
        {
          "value": 0.6036391033826531,
          "description": "min=0.604, mean=0.604, max=0.604, sum=0.604 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.3359973990755731,
          "description": "min=1.336, mean=1.336, max=1.336, sum=1.336 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 675.8037848605578,
          "description": "min=675.804, mean=675.804, max=675.804, sum=675.804 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 13.006972111553784,
          "description": "min=13.007, mean=13.007, max=13.007, sum=13.007 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 Anthropic is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2112.00861.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "BLOOM (176B)\u2620",
          "description": "BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "href": "?group=the_pile&subgroup=subset%3A%20Wikipedia%20%28en%29&runSpecs=%5B%22the_pile%3Asubset%3DWikipedia%20%28en%29%2Cmodel%3Dtogether_bloom%22%5D",
          "markdown": false
        },
        {
          "value": 0.5879480567890493,
          "description": "min=0.588, mean=0.588, max=0.588, sum=0.588 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.8268608655421981,
          "description": "min=0.827, mean=0.827, max=0.827, sum=0.827 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 637.8605724838412,
          "description": "min=637.861, mean=637.861, max=637.861, sum=637.861 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 BLOOM is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://huggingface.co/spaces/bigscience/BigScienceCorpus.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "Cohere xlarge v20220609 (52.4B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Wikipedia%20%28en%29&runSpecs=%5B%22the_pile%3Asubset%3DWikipedia%20%28en%29%2Cmodel%3Dcohere_xlarge-20220609%22%5D",
          "markdown": false
        },
        {
          "value": 0.5650922986594089,
          "description": "min=0.565, mean=0.565, max=0.565, sum=0.565 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.545328780184659,
          "description": "min=0.545, mean=0.545, max=0.545, sum=0.545 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 687.2590909090909,
          "description": "min=687.259, mean=687.259, max=687.259, sum=687.259 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere large v20220720 (13.1B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Wikipedia%20%28en%29&runSpecs=%5B%22the_pile%3Asubset%3DWikipedia%20%28en%29%2Cmodel%3Dcohere_large-20220720%22%5D",
          "markdown": false
        },
        {
          "value": 0.6404880652369643,
          "description": "min=0.64, mean=0.64, max=0.64, sum=0.64 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.3673114692826707,
          "description": "min=0.367, mean=0.367, max=0.367, sum=0.367 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 687.2590909090909,
          "description": "min=687.259, mean=687.259, max=687.259, sum=687.259 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20220720 (6.1B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Wikipedia%20%28en%29&runSpecs=%5B%22the_pile%3Asubset%3DWikipedia%20%28en%29%2Cmodel%3Dcohere_medium-20220720%22%5D",
          "markdown": false
        },
        {
          "value": 0.6795523075493248,
          "description": "min=0.68, mean=0.68, max=0.68, sum=0.68 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.30887562766335197,
          "description": "min=0.309, mean=0.309, max=0.309, sum=0.309 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 687.2590909090909,
          "description": "min=687.259, mean=687.259, max=687.259, sum=687.259 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere small v20220720 (410M)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Wikipedia%20%28en%29&runSpecs=%5B%22the_pile%3Asubset%3DWikipedia%20%28en%29%2Cmodel%3Dcohere_small-20220720%22%5D",
          "markdown": false
        },
        {
          "value": 0.8372852657316503,
          "description": "min=0.837, mean=0.837, max=0.837, sum=0.837 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.32592440163352177,
          "description": "min=0.326, mean=0.326, max=0.326, sum=0.326 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 687.2590909090909,
          "description": "min=687.259, mean=687.259, max=687.259, sum=687.259 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere xlarge v20221108 (52.4B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Wikipedia%20%28en%29&runSpecs=%5B%22the_pile%3Asubset%3DWikipedia%20%28en%29%2Cmodel%3Dcohere_xlarge-20221108%22%5D",
          "markdown": false
        },
        {
          "value": 0.5444243439877186,
          "description": "min=0.544, mean=0.544, max=0.544, sum=0.544 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 687.2590909090909,
          "description": "min=687.259, mean=687.259, max=687.259, sum=687.259 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere medium v20221108 (6.1B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Wikipedia%20%28en%29&runSpecs=%5B%22the_pile%3Asubset%3DWikipedia%20%28en%29%2Cmodel%3Dcohere_medium-20221108%22%5D",
          "markdown": false
        },
        {
          "value": 0.7112770928591574,
          "description": "min=0.711, mean=0.711, max=0.711, sum=0.711 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 687.2590909090909,
          "description": "min=687.259, mean=687.259, max=687.259, sum=687.259 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (6.1B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Wikipedia%20%28en%29&runSpecs=%5B%22the_pile%3Asubset%3DWikipedia%20%28en%29%2Cmodel%3Dcohere_command-medium-beta%22%5D",
          "markdown": false
        },
        {
          "value": 0.7354378352140966,
          "description": "min=0.735, mean=0.735, max=0.735, sum=0.735 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 690.2884267631104,
          "description": "min=690.288, mean=690.288, max=690.288, sum=690.288 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.003616636528029,
          "description": "min=1.004, mean=1.004, max=1.004, sum=1.004 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "Cohere Command beta (52.4B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Wikipedia%20%28en%29&runSpecs=%5B%22the_pile%3Asubset%3DWikipedia%20%28en%29%2Cmodel%3Dcohere_command-xlarge-beta%22%5D",
          "markdown": false
        },
        {
          "value": 0.6109585201987006,
          "description": "min=0.611, mean=0.611, max=0.611, sum=0.611 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 690.2884267631104,
          "description": "min=690.288, mean=690.288, max=690.288, sum=690.288 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.003616636528029,
          "description": "min=1.004, mean=1.004, max=1.004, sum=1.004 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "GPT-J (6B)\u2620",
          "description": "GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "href": "?group=the_pile&subgroup=subset%3A%20Wikipedia%20%28en%29&runSpecs=%5B%22the_pile%3Asubset%3DWikipedia%20%28en%29%2Cmodel%3Dtogether_gpt-j-6b%22%5D",
          "markdown": false
        },
        {
          "value": 0.5628124203204293,
          "description": "min=0.563, mean=0.563, max=0.563, sum=0.563 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.454054973941959,
          "description": "min=0.454, mean=0.454, max=0.454, sum=0.454 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 677.393607305936,
          "description": "min=677.394, mean=677.394, max=677.394, sum=677.394 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 GPT-J is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "GPT-NeoX (20B)\u2620",
          "description": "GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "href": "?group=the_pile&subgroup=subset%3A%20Wikipedia%20%28en%29&runSpecs=%5B%22the_pile%3Asubset%3DWikipedia%20%28en%29%2Cmodel%3Dtogether_gpt-neox-20b%22%5D",
          "markdown": false
        },
        {
          "value": 0.5356912415569973,
          "description": "min=0.536, mean=0.536, max=0.536, sum=0.536 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray",
            "font-weight": "bold"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.8738135251269978,
          "description": "min=0.874, mean=0.874, max=0.874, sum=0.874 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 684.0482256596906,
          "description": "min=684.048, mean=684.048, max=684.048, sum=684.048 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 GPT-NeoX is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2204.06745.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "OPT (175B)\u2620",
          "description": "OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "href": "?group=the_pile&subgroup=subset%3A%20Wikipedia%20%28en%29&runSpecs=%5B%22the_pile%3Asubset%3DWikipedia%20%28en%29%2Cmodel%3Dtogether_opt-175b%22%5D",
          "markdown": false
        },
        {
          "value": 0.5521626006103604,
          "description": "min=0.552, mean=0.552, max=0.552, sum=0.552 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.7903044861276777,
          "description": "min=0.79, mean=0.79, max=0.79, sum=0.79 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 677.393607305936,
          "description": "min=677.394, mean=677.394, max=677.394, sum=677.394 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "OPT (66B)\u2620",
          "description": "OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "href": "?group=the_pile&subgroup=subset%3A%20Wikipedia%20%28en%29&runSpecs=%5B%22the_pile%3Asubset%3DWikipedia%20%28en%29%2Cmodel%3Dtogether_opt-66b%22%5D",
          "markdown": false
        },
        {
          "value": 0.5734852419248613,
          "description": "min=0.573, mean=0.573, max=0.573, sum=0.573 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.600216724368519,
          "description": "min=0.6, mean=0.6, max=0.6, sum=0.6 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 677.393607305936,
          "description": "min=677.394, mean=677.394, max=677.394, sum=677.394 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 OPT is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2205.01068.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "TNLG v2 (530B)\u2620",
          "description": "MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "href": "?group=the_pile&subgroup=subset%3A%20Wikipedia%20%28en%29&runSpecs=%5B%22the_pile%3Asubset%3DWikipedia%20%28en%29%2Cmodel%3Dmicrosoft_TNLGv2_530B%22%5D",
          "markdown": false
        },
        {
          "value": 0.5706927926193364,
          "description": "min=0.571, mean=0.571, max=0.571, sum=0.571 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 677.2511415525114,
          "description": "min=677.251, mean=677.251, max=677.251, sum=677.251 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0009132420091324201,
          "description": "min=0.001, mean=0.001, max=0.001, sum=0.001 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "TNLG v2 (6.7B)\u2620",
          "description": "MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "href": "?group=the_pile&subgroup=subset%3A%20Wikipedia%20%28en%29&runSpecs=%5B%22the_pile%3Asubset%3DWikipedia%20%28en%29%2Cmodel%3Dmicrosoft_TNLGv2_7B%22%5D",
          "markdown": false
        },
        {
          "value": 0.6620318543787829,
          "description": "min=0.662, mean=0.662, max=0.662, sum=0.662 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 677.2511415525114,
          "description": "min=677.251, mean=677.251, max=677.251, sum=677.251 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 0.0009132420091324201,
          "description": "min=0.001, mean=0.001, max=0.001, sum=0.001 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)\n\u2620 MT-NLG is explicitly trained on the Pile, i.e. data from the same distribution as the test set. See https://arxiv.org/abs/2201.11990.",
          "style": {
            "color": "lightgray"
          },
          "markdown": false,
          "contamination_level": "strong"
        }
      ],
      [
        {
          "value": "davinci (175B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Wikipedia%20%28en%29&runSpecs=%5B%22the_pile%3Asubset%3DWikipedia%20%28en%29%2Cmodel%3Dopenai_davinci%22%5D",
          "markdown": false
        },
        {
          "value": 0.5963125835785745,
          "description": "min=0.596, mean=0.596, max=0.596, sum=0.596 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.21154403003709998,
          "description": "min=0.212, mean=0.212, max=0.212, sum=0.212 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 677.393607305936,
          "description": "min=677.394, mean=677.394, max=677.394, sum=677.394 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "curie (6.7B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Wikipedia%20%28en%29&runSpecs=%5B%22the_pile%3Asubset%3DWikipedia%20%28en%29%2Cmodel%3Dopenai_curie%22%5D",
          "markdown": false
        },
        {
          "value": 0.7048144303967697,
          "description": "min=0.705, mean=0.705, max=0.705, sum=0.705 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.09594675846651424,
          "description": "min=0.096, mean=0.096, max=0.096, sum=0.096 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 677.393607305936,
          "description": "min=677.394, mean=677.394, max=677.394, sum=677.394 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "babbage (1.3B)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Wikipedia%20%28en%29&runSpecs=%5B%22the_pile%3Asubset%3DWikipedia%20%28en%29%2Cmodel%3Dopenai_babbage%22%5D",
          "markdown": false
        },
        {
          "value": 0.7873946825571815,
          "description": "min=0.787, mean=0.787, max=0.787, sum=0.787 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.1202437666476407,
          "description": "min=0.12, mean=0.12, max=0.12, sum=0.12 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 677.393607305936,
          "description": "min=677.394, mean=677.394, max=677.394, sum=677.394 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "ada (350M)",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Wikipedia%20%28en%29&runSpecs=%5B%22the_pile%3Asubset%3DWikipedia%20%28en%29%2Cmodel%3Dopenai_ada%22%5D",
          "markdown": false
        },
        {
          "value": 0.8753049580454825,
          "description": "min=0.875, mean=0.875, max=0.875, sum=0.875 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.14050905037100497,
          "description": "min=0.141, mean=0.141, max=0.141, sum=0.141 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 677.393607305936,
          "description": "min=677.394, mean=677.394, max=677.394, sum=677.394 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-003",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Wikipedia%20%28en%29&runSpecs=%5B%22the_pile%3Asubset%3DWikipedia%20%28en%29%2Cmodel%3Dopenai_text-davinci-003%22%5D",
          "markdown": false
        },
        {
          "value": 0.5573198707460081,
          "description": "min=0.557, mean=0.557, max=0.557, sum=0.557 (1)",
          "style": {},
          "markdown": false
        },
        {
          "description": "1 matching runs, but no matching metrics",
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 689.6634146341463,
          "description": "min=689.663, mean=689.663, max=689.663, sum=689.663 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-davinci-002",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Wikipedia%20%28en%29&runSpecs=%5B%22the_pile%3Asubset%3DWikipedia%20%28en%29%2Cmodel%3Dopenai_text-davinci-002%22%5D",
          "markdown": false
        },
        {
          "value": 0.5807336813994477,
          "description": "min=0.581, mean=0.581, max=0.581, sum=0.581 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.20095383003048778,
          "description": "min=0.201, mean=0.201, max=0.201, sum=0.201 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 689.6634146341463,
          "description": "min=689.663, mean=689.663, max=689.663, sum=689.663 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-curie-001",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Wikipedia%20%28en%29&runSpecs=%5B%22the_pile%3Asubset%3DWikipedia%20%28en%29%2Cmodel%3Dopenai_text-curie-001%22%5D",
          "markdown": false
        },
        {
          "value": 0.8602829938615569,
          "description": "min=0.86, mean=0.86, max=0.86, sum=0.86 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.1364976253329529,
          "description": "min=0.136, mean=0.136, max=0.136, sum=0.136 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 677.393607305936,
          "description": "min=677.394, mean=677.394, max=677.394, sum=677.394 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-babbage-001",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Wikipedia%20%28en%29&runSpecs=%5B%22the_pile%3Asubset%3DWikipedia%20%28en%29%2Cmodel%3Dopenai_text-babbage-001%22%5D",
          "markdown": false
        },
        {
          "value": 0.9991420735424653,
          "description": "min=0.999, mean=0.999, max=0.999, sum=0.999 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.13779047754946727,
          "description": "min=0.138, mean=0.138, max=0.138, sum=0.138 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 677.393607305936,
          "description": "min=677.394, mean=677.394, max=677.394, sum=677.394 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ],
      [
        {
          "value": "text-ada-001",
          "description": "",
          "href": "?group=the_pile&subgroup=subset%3A%20Wikipedia%20%28en%29&runSpecs=%5B%22the_pile%3Asubset%3DWikipedia%20%28en%29%2Cmodel%3Dopenai_text-ada-001%22%5D",
          "markdown": false
        },
        {
          "value": 1.5019691433663551,
          "description": "min=1.502, mean=1.502, max=1.502, sum=1.502 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.09194275114155268,
          "description": "min=0.092, mean=0.092, max=0.092, sum=0.092 (1)",
          "style": {
            "font-weight": "bold"
          },
          "markdown": false
        },
        {
          "value": 1000.0,
          "description": "min=1000, mean=1000, max=1000, sum=1000 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 677.393607305936,
          "description": "min=677.394, mean=677.394, max=677.394, sum=677.394 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 0.0,
          "description": "min=0, mean=0, max=0, sum=0 (1)",
          "style": {},
          "markdown": false
        },
        {
          "value": 1.0,
          "description": "min=1, mean=1, max=1, sum=1 (1)",
          "style": {},
          "markdown": false
        }
      ]
    ],
    "links": [
      {
        "text": "LaTeX",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/the_pile_the_pile_subset:Wikipedia(en).tex"
      },
      {
        "text": "JSON",
        "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/the_pile_the_pile_subset:Wikipedia(en).json"
      }
    ],
    "name": "the_pile_subset:Wikipedia(en)"
  }
]