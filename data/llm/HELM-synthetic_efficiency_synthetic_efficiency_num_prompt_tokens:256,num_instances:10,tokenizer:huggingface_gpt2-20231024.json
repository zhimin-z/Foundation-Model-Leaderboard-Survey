{
  "title": "num_prompt_tokens: 256, num_instances: 10, tokenizer: huggingface/gpt2",
  "header": [
    {
      "value": "Model/adapter",
      "markdown": false,
      "metadata": {}
    },
    {
      "value": "# eval",
      "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# eval: Number of evaluation instances.",
      "markdown": false,
      "metadata": {
        "metric": "# eval",
        "run_group": "Synthetic efficiency"
      }
    },
    {
      "value": "# train",
      "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# train: Number of training instances (e.g., in-context examples).",
      "markdown": false,
      "metadata": {
        "metric": "# train",
        "run_group": "Synthetic efficiency"
      }
    },
    {
      "value": "truncated",
      "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
      "markdown": false,
      "metadata": {
        "metric": "truncated",
        "run_group": "Synthetic efficiency"
      }
    },
    {
      "value": "# prompt tokens",
      "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# prompt tokens: Number of tokens in the prompt.",
      "markdown": false,
      "metadata": {
        "metric": "# prompt tokens",
        "run_group": "Synthetic efficiency"
      }
    },
    {
      "value": "# output tokens",
      "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# output tokens: Actual number of output tokens.",
      "markdown": false,
      "metadata": {
        "metric": "# output tokens",
        "run_group": "Synthetic efficiency"
      }
    },
    {
      "value": "# trials",
      "description": "Scenario introduced in this work to better understand inference runtime performance of various models.\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
      "markdown": false,
      "metadata": {
        "metric": "# trials",
        "run_group": "Synthetic efficiency"
      }
    }
  ],
  "rows": [
    [
      {
        "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 1]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 16]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 16.0,
        "description": "min=16, mean=16, max=16, sum=16 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 2]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 2.0,
        "description": "min=2, mean=2, max=2, sum=2 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 32]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 32.0,
        "description": "min=32, mean=32, max=32, sum=32 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 4]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 4.0,
        "description": "min=4, mean=4, max=4, sum=4 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 64]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 64.0,
        "description": "min=64, mean=64, max=64, sum=64 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "Anthropic-LM v4-s3 (52B) [max_tokens: 8]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Danthropic_stanford-online-all-v4-s3%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 8.0,
        "description": "min=8, mean=8, max=8, sum=8 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "TNLG v2 (530B) [max_tokens: 1]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "TNLG v2 (530B) [max_tokens: 16]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 16.0,
        "description": "min=16, mean=16, max=16, sum=16 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "TNLG v2 (530B) [max_tokens: 2]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 2.0,
        "description": "min=2, mean=2, max=2, sum=2 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "TNLG v2 (530B) [max_tokens: 32]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 32.0,
        "description": "min=32, mean=32, max=32, sum=32 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "TNLG v2 (530B) [max_tokens: 4]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 4.0,
        "description": "min=4, mean=4, max=4, sum=4 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "TNLG v2 (530B) [max_tokens: 64]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 64.0,
        "description": "min=64, mean=64, max=64, sum=64 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "TNLG v2 (530B) [max_tokens: 8]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_530B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 8.0,
        "description": "min=8, mean=8, max=8, sum=8 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "TNLG v2 (6.7B) [max_tokens: 1]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "TNLG v2 (6.7B) [max_tokens: 16]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 16.0,
        "description": "min=16, mean=16, max=16, sum=16 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "TNLG v2 (6.7B) [max_tokens: 2]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 2.0,
        "description": "min=2, mean=2, max=2, sum=2 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "TNLG v2 (6.7B) [max_tokens: 32]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 32.0,
        "description": "min=32, mean=32, max=32, sum=32 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "TNLG v2 (6.7B) [max_tokens: 4]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 4.0,
        "description": "min=4, mean=4, max=4, sum=4 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "TNLG v2 (6.7B) [max_tokens: 64]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 64.0,
        "description": "min=64, mean=64, max=64, sum=64 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "TNLG v2 (6.7B) [max_tokens: 8]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dmicrosoft_TNLGv2_7B%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 8.0,
        "description": "min=8, mean=8, max=8, sum=8 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "davinci (175B) [max_tokens: 1]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "davinci (175B) [max_tokens: 16]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 16.0,
        "description": "min=16, mean=16, max=16, sum=16 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "davinci (175B) [max_tokens: 2]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 2.0,
        "description": "min=2, mean=2, max=2, sum=2 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "davinci (175B) [max_tokens: 32]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 32.0,
        "description": "min=32, mean=32, max=32, sum=32 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "davinci (175B) [max_tokens: 4]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 4.0,
        "description": "min=4, mean=4, max=4, sum=4 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "davinci (175B) [max_tokens: 64]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 64.0,
        "description": "min=64, mean=64, max=64, sum=64 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "davinci (175B) [max_tokens: 8]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_davinci%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 8.0,
        "description": "min=8, mean=8, max=8, sum=8 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "curie (6.7B) [max_tokens: 1]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "curie (6.7B) [max_tokens: 16]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 16.0,
        "description": "min=16, mean=16, max=16, sum=16 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "curie (6.7B) [max_tokens: 2]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 2.0,
        "description": "min=2, mean=2, max=2, sum=2 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "curie (6.7B) [max_tokens: 32]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 32.0,
        "description": "min=32, mean=32, max=32, sum=32 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "curie (6.7B) [max_tokens: 4]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 4.0,
        "description": "min=4, mean=4, max=4, sum=4 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "curie (6.7B) [max_tokens: 64]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 64.0,
        "description": "min=64, mean=64, max=64, sum=64 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "curie (6.7B) [max_tokens: 8]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_curie%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 8.0,
        "description": "min=8, mean=8, max=8, sum=8 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "babbage (1.3B) [max_tokens: 1]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "babbage (1.3B) [max_tokens: 16]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 16.0,
        "description": "min=16, mean=16, max=16, sum=16 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "babbage (1.3B) [max_tokens: 2]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 2.0,
        "description": "min=2, mean=2, max=2, sum=2 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "babbage (1.3B) [max_tokens: 32]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 32.0,
        "description": "min=32, mean=32, max=32, sum=32 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "babbage (1.3B) [max_tokens: 4]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 4.0,
        "description": "min=4, mean=4, max=4, sum=4 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "babbage (1.3B) [max_tokens: 64]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 64.0,
        "description": "min=64, mean=64, max=64, sum=64 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "babbage (1.3B) [max_tokens: 8]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_babbage%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 8.0,
        "description": "min=8, mean=8, max=8, sum=8 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "ada (350M) [max_tokens: 1]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "ada (350M) [max_tokens: 16]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 16.0,
        "description": "min=16, mean=16, max=16, sum=16 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "ada (350M) [max_tokens: 2]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 2.0,
        "description": "min=2, mean=2, max=2, sum=2 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "ada (350M) [max_tokens: 32]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 32.0,
        "description": "min=32, mean=32, max=32, sum=32 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "ada (350M) [max_tokens: 4]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 4.0,
        "description": "min=4, mean=4, max=4, sum=4 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "ada (350M) [max_tokens: 64]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 64.0,
        "description": "min=64, mean=64, max=64, sum=64 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "ada (350M) [max_tokens: 8]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_ada%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 8.0,
        "description": "min=8, mean=8, max=8, sum=8 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-davinci-003 [max_tokens: 1]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-davinci-003 [max_tokens: 16]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 16.0,
        "description": "min=16, mean=16, max=16, sum=16 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-davinci-003 [max_tokens: 2]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 2.0,
        "description": "min=2, mean=2, max=2, sum=2 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-davinci-003 [max_tokens: 32]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 31.0,
        "description": "min=31, mean=31, max=31, sum=31 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-davinci-003 [max_tokens: 4]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 4.0,
        "description": "min=4, mean=4, max=4, sum=4 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-davinci-003 [max_tokens: 64]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 55.7,
        "description": "min=55.7, mean=55.7, max=55.7, sum=55.7 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-davinci-003 [max_tokens: 8]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-003%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 8.0,
        "description": "min=8, mean=8, max=8, sum=8 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-davinci-002 [max_tokens: 1]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-davinci-002 [max_tokens: 16]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 16.0,
        "description": "min=16, mean=16, max=16, sum=16 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-davinci-002 [max_tokens: 2]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 2.0,
        "description": "min=2, mean=2, max=2, sum=2 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-davinci-002 [max_tokens: 32]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 32.0,
        "description": "min=32, mean=32, max=32, sum=32 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-davinci-002 [max_tokens: 4]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 4.0,
        "description": "min=4, mean=4, max=4, sum=4 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-davinci-002 [max_tokens: 64]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 64.0,
        "description": "min=64, mean=64, max=64, sum=64 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-davinci-002 [max_tokens: 8]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 8.0,
        "description": "min=8, mean=8, max=8, sum=8 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-curie-001 [max_tokens: 1]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-curie-001 [max_tokens: 16]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 15.8,
        "description": "min=15.8, mean=15.8, max=15.8, sum=15.8 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-curie-001 [max_tokens: 2]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 2.0,
        "description": "min=2, mean=2, max=2, sum=2 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-curie-001 [max_tokens: 32]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 30.2,
        "description": "min=30.2, mean=30.2, max=30.2, sum=30.2 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-curie-001 [max_tokens: 4]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 4.0,
        "description": "min=4, mean=4, max=4, sum=4 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-curie-001 [max_tokens: 64]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 59.0,
        "description": "min=59, mean=59, max=59, sum=59 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-curie-001 [max_tokens: 8]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-curie-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 8.0,
        "description": "min=8, mean=8, max=8, sum=8 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-babbage-001 [max_tokens: 1]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-babbage-001 [max_tokens: 16]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 16.0,
        "description": "min=16, mean=16, max=16, sum=16 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-babbage-001 [max_tokens: 2]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 2.0,
        "description": "min=2, mean=2, max=2, sum=2 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-babbage-001 [max_tokens: 32]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 31.4,
        "description": "min=31.4, mean=31.4, max=31.4, sum=31.4 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-babbage-001 [max_tokens: 4]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 4.0,
        "description": "min=4, mean=4, max=4, sum=4 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-babbage-001 [max_tokens: 64]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 60.2,
        "description": "min=60.2, mean=60.2, max=60.2, sum=60.2 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-babbage-001 [max_tokens: 8]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-babbage-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 8.0,
        "description": "min=8, mean=8, max=8, sum=8 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-ada-001 [max_tokens: 1]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-ada-001 [max_tokens: 16]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 16.0,
        "description": "min=16, mean=16, max=16, sum=16 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-ada-001 [max_tokens: 2]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 2.0,
        "description": "min=2, mean=2, max=2, sum=2 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-ada-001 [max_tokens: 32]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 32.0,
        "description": "min=32, mean=32, max=32, sum=32 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-ada-001 [max_tokens: 4]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 4.0,
        "description": "min=4, mean=4, max=4, sum=4 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-ada-001 [max_tokens: 64]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 61.7,
        "description": "min=61.7, mean=61.7, max=61.7, sum=61.7 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "text-ada-001 [max_tokens: 8]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_text-ada-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 8.0,
        "description": "min=8, mean=8, max=8, sum=8 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "code-davinci-002 [max_tokens: 1]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "code-davinci-002 [max_tokens: 16]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 16.0,
        "description": "min=16, mean=16, max=16, sum=16 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "code-davinci-002 [max_tokens: 2]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 2.0,
        "description": "min=2, mean=2, max=2, sum=2 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "code-davinci-002 [max_tokens: 32]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 32.0,
        "description": "min=32, mean=32, max=32, sum=32 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "code-davinci-002 [max_tokens: 4]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 4.0,
        "description": "min=4, mean=4, max=4, sum=4 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "code-davinci-002 [max_tokens: 64]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 64.0,
        "description": "min=64, mean=64, max=64, sum=64 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "code-davinci-002 [max_tokens: 8]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-davinci-002%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 8.0,
        "description": "min=8, mean=8, max=8, sum=8 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "code-cushman-001 (12B) [max_tokens: 1]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D1%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "code-cushman-001 (12B) [max_tokens: 16]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D16%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 16.0,
        "description": "min=16, mean=16, max=16, sum=16 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "code-cushman-001 (12B) [max_tokens: 2]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D2%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 2.0,
        "description": "min=2, mean=2, max=2, sum=2 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "code-cushman-001 (12B) [max_tokens: 32]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D32%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 32.0,
        "description": "min=32, mean=32, max=32, sum=32 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "code-cushman-001 (12B) [max_tokens: 4]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D4%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 4.0,
        "description": "min=4, mean=4, max=4, sum=4 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "code-cushman-001 (12B) [max_tokens: 64]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D64%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 64.0,
        "description": "min=64, mean=64, max=64, sum=64 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ],
    [
      {
        "value": "code-cushman-001 (12B) [max_tokens: 8]",
        "description": "",
        "href": "?group=synthetic_efficiency&subgroup=num_prompt_tokens%3A%20256%2C%20num_instances%3A%2010%2C%20tokenizer%3A%20huggingface%2Fgpt2&runSpecs=%5B%22synthetic_efficiency%3Arandom%3DNone%2Cmodel%3Dopenai_code-cushman-001%2Ctokenizer%3Dhuggingface_gpt2%2Cnum_prompt_tokens%3D256%2Cnum_output_tokens%3D8%22%5D",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=10 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 256.0,
        "description": "min=256, mean=256, max=256, sum=256 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 8.0,
        "description": "min=8, mean=8, max=8, sum=8 (1)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=1 (1)",
        "style": {},
        "markdown": false
      }
    ]
  ],
  "links": [
    {
      "text": "LaTeX",
      "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/latex/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:huggingface_gpt2.tex"
    },
    {
      "text": "JSON",
      "href": "/nlp/scr4/nlp/crfm/yifanmai/helm-release/benchmark_output/releases/v0.3.0/groups/json/synthetic_efficiency_synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:huggingface_gpt2.json"
    }
  ],
  "name": "synthetic_efficiency_num_prompt_tokens:256,num_instances:10,tokenizer:huggingface_gpt2"
}