[
    {
        "table_id":22102,
        "row_id":114121,
        "rank":1,
        "Model":"Gemini Ultra",
        "mlmodel":{

        },
        "method_short":"Gemini Ultra",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-12-06",
        "metrics":{
            "1:1 Accuracy":"80.8"
        },
        "raw_metrics":{
            "1:1 Accuracy":80.8
        },
        "uses_additional_data":false,
        "paper":{
            "id":1336342,
            "title":"Gemini: A Family of Highly Capable Multimodal Models",
            "url":"\/paper\/gemini-a-family-of-highly-capable-multimodal",
            "published":"2023-12-06T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":22102,
        "row_id":110149,
        "rank":2,
        "Model":"DePlot+FlanPaLM+Codex (PoT Self-Consistency)",
        "mlmodel":{

        },
        "method_short":"DePlot+FlanPaLM+Codex ",
        "method_details":"PoT Self-Consistency",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-20",
        "metrics":{
            "1:1 Accuracy":"79.3"
        },
        "raw_metrics":{
            "1:1 Accuracy":79.3
        },
        "uses_additional_data":false,
        "paper":{
            "id":1131582,
            "title":"DePlot: One-shot visual language reasoning by plot-to-table translation",
            "url":"\/paper\/deplot-one-shot-visual-language-reasoning-by",
            "published":"2022-12-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/deplot-one-shot-visual-language-reasoning-by\/review\/?hl=110149"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":22102,
        "row_id":110148,
        "rank":3,
        "Model":"DePlot+Codex (PoT Self-Consistency)",
        "mlmodel":{

        },
        "method_short":"DePlot+Codex ",
        "method_details":"PoT Self-Consistency",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-20",
        "metrics":{
            "1:1 Accuracy":"76.7"
        },
        "raw_metrics":{
            "1:1 Accuracy":76.7
        },
        "uses_additional_data":false,
        "paper":{
            "id":1131582,
            "title":"DePlot: One-shot visual language reasoning by plot-to-table translation",
            "url":"\/paper\/deplot-one-shot-visual-language-reasoning-by",
            "published":"2022-12-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/deplot-one-shot-visual-language-reasoning-by\/review\/?hl=110148"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":22102,
        "row_id":114150,
        "rank":4,
        "Model":"SMoLA-PaLI-X Specialist Model",
        "mlmodel":{

        },
        "method_short":"SMoLA-PaLI-X Specialist Model",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-12-01",
        "metrics":{
            "1:1 Accuracy":"74.6"
        },
        "raw_metrics":{
            "1:1 Accuracy":74.6
        },
        "uses_additional_data":true,
        "paper":{
            "id":1335830,
            "title":"Omni-SMoLA: Boosting Generalist Multimodal Models with Soft Mixture of Low-rank Experts",
            "url":"\/paper\/omni-smola-boosting-generalist-multimodal",
            "published":"2023-12-01T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/omni-smola-boosting-generalist-multimodal\/review\/?hl=114150"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":22102,
        "row_id":114149,
        "rank":5,
        "Model":"SMoLA-PaLI-X Generalist Model",
        "mlmodel":{

        },
        "method_short":"SMoLA-PaLI-X Generalist Model",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-12-01",
        "metrics":{
            "1:1 Accuracy":"73.8"
        },
        "raw_metrics":{
            "1:1 Accuracy":73.8
        },
        "uses_additional_data":true,
        "paper":{
            "id":1335830,
            "title":"Omni-SMoLA: Boosting Generalist Multimodal Models with Soft Mixture of Low-rank Experts",
            "url":"\/paper\/omni-smola-boosting-generalist-multimodal",
            "published":"2023-12-01T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/omni-smola-boosting-generalist-multimodal\/review\/?hl=114149"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":22102,
        "row_id":110122,
        "rank":6,
        "Model":"PaLI-X (Single-task FT w\/ OCR)",
        "mlmodel":{

        },
        "method_short":"PaLI-X ",
        "method_details":"Single-task FT w\/ OCR",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-29",
        "metrics":{
            "1:1 Accuracy":"72.3"
        },
        "raw_metrics":{
            "1:1 Accuracy":72.3
        },
        "uses_additional_data":true,
        "paper":{
            "id":1219485,
            "title":"PaLI-X: On Scaling up a Multilingual Vision and Language Model",
            "url":"\/paper\/pali-x-on-scaling-up-a-multilingual-vision",
            "published":"2023-05-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/pali-x-on-scaling-up-a-multilingual-vision\/review\/?hl=110122"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":22102,
        "row_id":110124,
        "rank":7,
        "Model":"PaLI-X (Single-task FT)",
        "mlmodel":{

        },
        "method_short":"PaLI-X ",
        "method_details":"Single-task FT",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-29",
        "metrics":{
            "1:1 Accuracy":"70.9"
        },
        "raw_metrics":{
            "1:1 Accuracy":70.9
        },
        "uses_additional_data":true,
        "paper":{
            "id":1219485,
            "title":"PaLI-X: On Scaling up a Multilingual Vision and Language Model",
            "url":"\/paper\/pali-x-on-scaling-up-a-multilingual-vision",
            "published":"2023-05-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/pali-x-on-scaling-up-a-multilingual-vision\/review\/?hl=110124"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":22102,
        "row_id":110126,
        "rank":8,
        "Model":"PaLI-X (Multi-task FT)",
        "mlmodel":{

        },
        "method_short":"PaLI-X ",
        "method_details":"Multi-task FT",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-29",
        "metrics":{
            "1:1 Accuracy":"70.6"
        },
        "raw_metrics":{
            "1:1 Accuracy":70.6
        },
        "uses_additional_data":true,
        "paper":{
            "id":1219485,
            "title":"PaLI-X: On Scaling up a Multilingual Vision and Language Model",
            "url":"\/paper\/pali-x-on-scaling-up-a-multilingual-vision",
            "published":"2023-05-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/pali-x-on-scaling-up-a-multilingual-vision\/review\/?hl=110126"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":22102,
        "row_id":110147,
        "rank":9,
        "Model":"DePlot+FlanPaLM (Self-Consistency)",
        "mlmodel":{

        },
        "method_short":"DePlot+FlanPaLM ",
        "method_details":"Self-Consistency",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-20",
        "metrics":{
            "1:1 Accuracy":"70.5"
        },
        "raw_metrics":{
            "1:1 Accuracy":70.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":1131582,
            "title":"DePlot: One-shot visual language reasoning by plot-to-table translation",
            "url":"\/paper\/deplot-one-shot-visual-language-reasoning-by",
            "published":"2022-12-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/deplot-one-shot-visual-language-reasoning-by\/review\/?hl=110147"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":22102,
        "row_id":110593,
        "rank":10,
        "Model":"PaLI-3",
        "mlmodel":{

        },
        "method_short":"PaLI-3",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-10-13",
        "metrics":{
            "1:1 Accuracy":"70"
        },
        "raw_metrics":{
            "1:1 Accuracy":70.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1300142,
            "title":"PaLI-3 Vision Language Models: Smaller, Faster, Stronger",
            "url":"\/paper\/pali-3-vision-language-models-smaller-faster",
            "published":"2023-10-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/pali-3-vision-language-models-smaller-faster\/review\/?hl=110593"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":22102,
        "row_id":110592,
        "rank":11,
        "Model":"PaLI-3 (w\/ OCR)",
        "mlmodel":{

        },
        "method_short":"PaLI-3 ",
        "method_details":"w\/ OCR",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-10-13",
        "metrics":{
            "1:1 Accuracy":"69.5"
        },
        "raw_metrics":{
            "1:1 Accuracy":69.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":1300142,
            "title":"PaLI-3 Vision Language Models: Smaller, Faster, Stronger",
            "url":"\/paper\/pali-3-vision-language-models-smaller-faster",
            "published":"2023-10-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/pali-3-vision-language-models-smaller-faster\/review\/?hl=110592"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":22102,
        "row_id":110146,
        "rank":12,
        "Model":"DePlot+FlanPaLM (CoT)",
        "mlmodel":{

        },
        "method_short":"DePlot+FlanPaLM ",
        "method_details":"CoT",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-20",
        "metrics":{
            "1:1 Accuracy":"67.3"
        },
        "raw_metrics":{
            "1:1 Accuracy":67.3
        },
        "uses_additional_data":false,
        "paper":{
            "id":1131582,
            "title":"DePlot: One-shot visual language reasoning by plot-to-table translation",
            "url":"\/paper\/deplot-one-shot-visual-language-reasoning-by",
            "published":"2022-12-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/deplot-one-shot-visual-language-reasoning-by\/review\/?hl=110146"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":22102,
        "row_id":110131,
        "rank":13,
        "Model":"Qwen-VL-Chat",
        "mlmodel":{

        },
        "method_short":"Qwen-VL-Chat",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-08-24",
        "metrics":{
            "1:1 Accuracy":"66.3"
        },
        "raw_metrics":{
            "1:1 Accuracy":66.3
        },
        "uses_additional_data":true,
        "paper":{
            "id":1269007,
            "title":"Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond",
            "url":"\/paper\/qwen-vl-a-frontier-large-vision-language",
            "published":"2023-08-24T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":22102,
        "row_id":110136,
        "rank":14,
        "Model":"UniChart",
        "mlmodel":{

        },
        "method_short":"UniChart",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-05-24",
        "metrics":{
            "1:1 Accuracy":"66.24"
        },
        "raw_metrics":{
            "1:1 Accuracy":66.24
        },
        "uses_additional_data":true,
        "paper":{
            "id":1215680,
            "title":"UniChart: A Universal Vision-language Pretrained Model for Chart Comprehension and Reasoning",
            "url":"\/paper\/unichart-a-universal-vision-language",
            "published":"2023-05-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/unichart-a-universal-vision-language\/review\/?hl=110136"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":22102,
        "row_id":110130,
        "rank":15,
        "Model":"Qwen-VL",
        "mlmodel":{

        },
        "method_short":"Qwen-VL",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-08-24",
        "metrics":{
            "1:1 Accuracy":"65.7"
        },
        "raw_metrics":{
            "1:1 Accuracy":65.7
        },
        "uses_additional_data":true,
        "paper":{
            "id":1269007,
            "title":"Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond",
            "url":"\/paper\/qwen-vl-a-frontier-large-vision-language",
            "published":"2023-08-24T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":22102,
        "row_id":110152,
        "rank":16,
        "Model":"StructChart+GPT3.5 (STR ChartQA+SimChart9K)",
        "mlmodel":{

        },
        "method_short":"StructChart+GPT3.5 ",
        "method_details":"STR ChartQA+SimChart9K",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-09-20",
        "metrics":{
            "1:1 Accuracy":"65.3"
        },
        "raw_metrics":{
            "1:1 Accuracy":65.3
        },
        "uses_additional_data":true,
        "paper":{
            "id":1284065,
            "title":"StructChart: Perception, Structuring, Reasoning for Visual Chart Understanding",
            "url":"\/paper\/structchart-perception-structuring-reasoning",
            "published":"2023-09-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/structchart-perception-structuring-reasoning\/review\/?hl=110152"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":22102,
        "row_id":87882,
        "rank":17,
        "Model":"MatCha",
        "mlmodel":{

        },
        "method_short":"MatCha",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-19",
        "metrics":{
            "1:1 Accuracy":"64.2"
        },
        "raw_metrics":{
            "1:1 Accuracy":64.2
        },
        "uses_additional_data":false,
        "paper":{
            "id":1130468,
            "title":"MatCha: Enhancing Visual Language Pretraining with Math Reasoning and Chart Derendering",
            "url":"\/paper\/matcha-enhancing-visual-language-pretraining",
            "published":"2022-12-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/matcha-enhancing-visual-language-pretraining\/review\/?hl=87882"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":22102,
        "row_id":110151,
        "rank":18,
        "Model":"StructChart+GPT3.5 (STR)",
        "mlmodel":{

        },
        "method_short":"StructChart+GPT3.5 ",
        "method_details":"STR",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-09-20",
        "metrics":{
            "1:1 Accuracy":"60.7"
        },
        "raw_metrics":{
            "1:1 Accuracy":60.7
        },
        "uses_additional_data":false,
        "paper":{
            "id":1284065,
            "title":"StructChart: Perception, Structuring, Reasoning for Visual Chart Understanding",
            "url":"\/paper\/structchart-perception-structuring-reasoning",
            "published":"2023-09-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/structchart-perception-structuring-reasoning\/review\/?hl=110151"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":22102,
        "row_id":87884,
        "rank":19,
        "Model":"Pix2Struct-large",
        "mlmodel":{

        },
        "method_short":"Pix2Struct-large",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-10-07",
        "metrics":{
            "1:1 Accuracy":"58.6"
        },
        "raw_metrics":{
            "1:1 Accuracy":58.6
        },
        "uses_additional_data":false,
        "paper":{
            "id":1088385,
            "title":"Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding",
            "url":"\/paper\/pix2struct-screenshot-parsing-as-pretraining",
            "published":"2022-10-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/pix2struct-screenshot-parsing-as-pretraining\/review\/?hl=87884"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":22102,
        "row_id":87883,
        "rank":20,
        "Model":"Pix2Struct-base",
        "mlmodel":{

        },
        "method_short":"Pix2Struct-base",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-10-07",
        "metrics":{
            "1:1 Accuracy":"56.0"
        },
        "raw_metrics":{
            "1:1 Accuracy":56.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1088385,
            "title":"Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding",
            "url":"\/paper\/pix2struct-screenshot-parsing-as-pretraining",
            "published":"2022-10-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/pix2struct-screenshot-parsing-as-pretraining\/review\/?hl=87883"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":22102,
        "row_id":87885,
        "rank":21,
        "Model":"VisionTapas-OCR",
        "mlmodel":{

        },
        "method_short":"VisionTapas-OCR",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-03-19",
        "metrics":{
            "1:1 Accuracy":"45.5"
        },
        "raw_metrics":{
            "1:1 Accuracy":45.5
        },
        "uses_additional_data":false,
        "paper":{
            "id":980225,
            "title":"ChartQA: A Benchmark for Question Answering about Charts with Visual and Logical Reasoning",
            "url":"\/paper\/chartqa-a-benchmark-for-question-answering",
            "published":"2022-03-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/chartqa-a-benchmark-for-question-answering\/review\/?hl=87885"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":22102,
        "row_id":110145,
        "rank":22,
        "Model":"DePlot+GPT3 (Self-Consistency)",
        "mlmodel":{

        },
        "method_short":"DePlot+GPT3 ",
        "method_details":"Self-Consistency",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-20",
        "metrics":{
            "1:1 Accuracy":"42.3"
        },
        "raw_metrics":{
            "1:1 Accuracy":42.3
        },
        "uses_additional_data":false,
        "paper":{
            "id":1131582,
            "title":"DePlot: One-shot visual language reasoning by plot-to-table translation",
            "url":"\/paper\/deplot-one-shot-visual-language-reasoning-by",
            "published":"2022-12-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/deplot-one-shot-visual-language-reasoning-by\/review\/?hl=110145"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":22102,
        "row_id":110150,
        "rank":23,
        "Model":"DePlot+GPT3 (CoT)",
        "mlmodel":{

        },
        "method_short":"DePlot+GPT3 ",
        "method_details":"CoT",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-20",
        "metrics":{
            "1:1 Accuracy":"36.9"
        },
        "raw_metrics":{
            "1:1 Accuracy":36.9
        },
        "uses_additional_data":false,
        "paper":{
            "id":1131582,
            "title":"DePlot: One-shot visual language reasoning by plot-to-table translation",
            "url":"\/paper\/deplot-one-shot-visual-language-reasoning-by",
            "published":"2022-12-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/deplot-one-shot-visual-language-reasoning-by\/review\/?hl=110150"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]