[
    {
        "Model":"InfiMM (Zephyr-7B)",
        "Yes-or-No":61.31,
        "What":56.61,
        "How":49.58,
        "Distortion":47.79,
        "Other":62.05,
        "In-context Distortion":51.71,
        "In-context Other":67.68,
        "Overall":56.05
    },
    {
        "Model":"Emu2-Chat (LLaMA-33B)",
        "Yes-or-No":70.09,
        "What":65.12,
        "How":54.11,
        "Distortion":66.22,
        "Other":62.96,
        "In-context Distortion":63.47,
        "In-context Other":73.21,
        "Overall":64.32
    },
    {
        "Model":"Fuyu-8B (Persimmon-8B)",
        "Yes-or-No":62.22,
        "What":35.79,
        "How":36.62,
        "Distortion":41.07,
        "Other":49.4,
        "In-context Distortion":45.89,
        "In-context Other":49.04,
        "Overall":45.75
    },
    {
        "Model":"BakLLava (Mistral-7B)",
        "Yes-or-No":66.46,
        "What":61.48,
        "How":54.83,
        "Distortion":51.33,
        "Other":63.76,
        "In-context Distortion":56.52,
        "In-context Other":78.16,
        "Overall":61.02
    },
    {
        "Model":"SPHINX",
        "Yes-or-No":74.45,
        "What":65.5,
        "How":62.13,
        "Distortion":59.11,
        "Other":73.26,
        "In-context Distortion":66.09,
        "In-context Other":77.56,
        "Overall":67.69
    },
    {
        "Model":"mPLUG-Owl2 (LLaMA-7B)",
        "Yes-or-No":72.26,
        "What":55.53,
        "How":58.64,
        "Distortion":52.59,
        "Other":71.36,
        "In-context Distortion":58.9,
        "In-context Other":73.0,
        "Overall":62.68
    },
    {
        "Model":"LLaVA-v1.5 (Vicuna-v1.5-7B)",
        "Yes-or-No":64.6,
        "What":59.22,
        "How":55.76,
        "Distortion":47.98,
        "Other":67.3,
        "In-context Distortion":58.9,
        "In-context Other":73.76,
        "Overall":60.07
    },
    {
        "Model":"LLaVA-v1.5 (Vicuna-v1.5-13B)",
        "Yes-or-No":64.96,
        "What":64.86,
        "How":54.12,
        "Distortion":53.55,
        "Other":66.59,
        "In-context Distortion":58.9,
        "In-context Other":71.48,
        "Overall":61.4
    },
    {
        "Model":"InternLM-XComposer-VL (InternLM)",
        "Yes-or-No":68.43,
        "What":62.04,
        "How":61.93,
        "Distortion":56.81,
        "Other":70.41,
        "In-context Distortion":57.53,
        "In-context Other":77.19,
        "Overall":64.35
    },
    {
        "Model":"IDEFICS-Instruct (LLaMA-7B)",
        "Yes-or-No":60.04,
        "What":46.42,
        "How":46.71,
        "Distortion":40.38,
        "Other":59.9,
        "In-context Distortion":47.26,
        "In-context Other":64.77,
        "Overall":51.51
    },
    {
        "Model":"Qwen-VL (QwenLM)",
        "Yes-or-No":65.33,
        "What":60.74,
        "How":58.44,
        "Distortion":54.13,
        "Other":66.35,
        "In-context Distortion":58.22,
        "In-context Other":73.0,
        "Overall":61.67
    },
    {
        "Model":"Shikra (Vicuna-7B)",
        "Yes-or-No":69.09,
        "What":47.93,
        "How":46.71,
        "Distortion":47.31,
        "Other":60.86,
        "In-context Distortion":53.08,
        "In-context Other":64.77,
        "Overall":55.32
    },
    {
        "Model":"Otter-v1 (MPT-7B)",
        "Yes-or-No":57.66,
        "What":39.7,
        "How":42.59,
        "Distortion":42.12,
        "Other":48.93,
        "In-context Distortion":47.6,
        "In-context Other":54.17,
        "Overall":47.22
    },
    {
        "Model":"InstructBLIP (Flan-T5-XL)",
        "Yes-or-No":69.53,
        "What":59.0,
        "How":56.17,
        "Distortion":57.31,
        "Other":65.63,
        "In-context Distortion":56.51,
        "In-context Other":71.21,
        "Overall":61.94
    },
    {
        "Model":"InstructBLIP (Vicuna-7B)",
        "Yes-or-No":70.99,
        "What":51.41,
        "How":43.0,
        "Distortion":45.0,
        "Other":63.01,
        "In-context Distortion":57.19,
        "In-context Other":64.39,
        "Overall":55.85
    },
    {
        "Model":"VisualGLM-6B (GLM-6B)",
        "Yes-or-No":61.31,
        "What":53.58,
        "How":44.03,
        "Distortion":48.56,
        "Other":54.89,
        "In-context Distortion":55.48,
        "In-context Other":57.79,
        "Overall":53.31
    },
    {
        "Model":"mPLUG-Owl (LLaMA-7B)",
        "Yes-or-No":72.45,
        "What":54.88,
        "How":47.53,
        "Distortion":49.62,
        "Other":63.01,
        "In-context Distortion":62.67,
        "In-context Other":66.67,
        "Overall":58.93
    },
    {
        "Model":"LLaMA-Adapter-V2",
        "Yes-or-No":66.61,
        "What":54.66,
        "How":51.65,
        "Distortion":56.15,
        "Other":61.81,
        "In-context Distortion":59.25,
        "In-context Other":54.55,
        "Overall":58.06
    },
    {
        "Model":"LLaVA-v1 (Vicuna-13B)",
        "Yes-or-No":57.12,
        "What":54.88,
        "How":51.85,
        "Distortion":45.58,
        "Other":58.0,
        "In-context Distortion":57.19,
        "In-context Other":64.77,
        "Overall":54.72
    },
    {
        "Model":"MiniGPT-4 (Vicuna-13B)",
        "Yes-or-No":60.77,
        "What":50.33,
        "How":43.0,
        "Distortion":45.58,
        "Other":52.51,
        "In-context Distortion":53.42,
        "In-context Other":60.98,
        "Overall":51.77
    },
    {
        "Model":"Qwen-VL-Plus (Close-Source)",
        "Yes-or-No":75.74,
        "What":73.25,
        "How":57.33,
        "Distortion":64.88,
        "Other":73.24,
        "In-context Distortion":68.67,
        "In-context Other":70.56,
        "Overall":68.93
    },
    {
        "Model":"Qwen-VL-Max (Close-Source)",
        "Yes-or-No":73.2,
        "What":81.02,
        "How":68.39,
        "Distortion":70.84,
        "Other":74.57,
        "In-context Distortion":73.11,
        "In-context Other":80.44,
        "Overall":73.9
    },
    {
        "Model":"Gemini-Pro (Close-Source)",
        "Yes-or-No":71.26,
        "What":71.39,
        "How":65.59,
        "Distortion":67.3,
        "Other":73.04,
        "In-context Distortion":65.88,
        "In-context Other":73.6,
        "Overall":69.46
    },
    {
        "Model":"GPT-4V (Close-Source)",
        "Yes-or-No":77.72,
        "What":78.39,
        "How":66.45,
        "Distortion":71.01,
        "Other":71.07,
        "In-context Distortion":79.36,
        "In-context Other":78.91,
        "Overall":74.1
    }
]