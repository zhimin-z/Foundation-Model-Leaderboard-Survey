[
    {
        "Model":"InfiMM (Zephyr-7B)",
        "Completeness":0.77,
        "Precision":1.08,
        "Relevance":1.71,
        "Sum":3.58
    },
    {
        "Model":"Emu2-Chat (LLaMA-33B)",
        "Completeness":1.07,
        "Precision":1.24,
        "Relevance":1.88,
        "Sum":4.19
    },
    {
        "Model":"Fuyu-8B (Persimmon-8B)",
        "Completeness":0.88,
        "Precision":0.83,
        "Relevance":1.82,
        "Sum":3.53
    },
    {
        "Model":"BakLLava (Mistral-7B)",
        "Completeness":1.0,
        "Precision":0.77,
        "Relevance":1.61,
        "Sum":3.38
    },
    {
        "Model":"SPHINX",
        "Completeness":0.79,
        "Precision":1.14,
        "Relevance":1.72,
        "Sum":3.65
    },
    {
        "Model":"mPLUG-Owl2 (LLaMA-7B)",
        "Completeness":1.06,
        "Precision":1.24,
        "Relevance":1.36,
        "Sum":3.67
    },
    {
        "Model":"LLaVA-v1.5 (Vicuna-v1.5-7B)",
        "Completeness":0.9,
        "Precision":1.13,
        "Relevance":1.18,
        "Sum":3.21
    },
    {
        "Model":"LLaVA-v1.5 (Vicuna-v1.5-13B)",
        "Completeness":0.91,
        "Precision":1.28,
        "Relevance":1.29,
        "Sum":3.47
    },
    {
        "Model":"InternLM-XComposer-VL (InternLM)",
        "Completeness":1.08,
        "Precision":1.26,
        "Relevance":1.87,
        "Sum":4.21
    },
    {
        "Model":"IDEFICS-Instruct (LLaMA-7B)",
        "Completeness":0.83,
        "Precision":1.03,
        "Relevance":1.33,
        "Sum":3.18
    },
    {
        "Model":"Qwen-VL (QwenLM)",
        "Completeness":0.98,
        "Precision":0.75,
        "Relevance":1.63,
        "Sum":3.36
    },
    {
        "Model":"Shikra (Vicuna-7B)",
        "Completeness":0.89,
        "Precision":1.11,
        "Relevance":1.33,
        "Sum":3.34
    },
    {
        "Model":"Otter-v1 (MPT-7B)",
        "Completeness":0.96,
        "Precision":0.83,
        "Relevance":1.83,
        "Sum":3.61
    },
    {
        "Model":"Kosmos-2",
        "Completeness":1.12,
        "Precision":1.06,
        "Relevance":1.85,
        "Sum":4.03
    },
    {
        "Model":"InstructBLIP (Flan-T5-XL)",
        "Completeness":0.87,
        "Precision":1.04,
        "Relevance":1.11,
        "Sum":3.02
    },
    {
        "Model":"InstructBLIP (Vicuna-7B)",
        "Completeness":0.79,
        "Precision":1.21,
        "Relevance":0.84,
        "Sum":2.84
    },
    {
        "Model":"VisualGLM-6B (GLM-6B)",
        "Completeness":0.82,
        "Precision":0.97,
        "Relevance":1.21,
        "Sum":2.99
    },
    {
        "Model":"mPLUG-Owl (LLaMA-7B)",
        "Completeness":1.06,
        "Precision":1.28,
        "Relevance":1.6,
        "Sum":3.94
    },
    {
        "Model":"LLaMA-Adapter-V2",
        "Completeness":0.85,
        "Precision":1.15,
        "Relevance":1.44,
        "Sum":3.45
    },
    {
        "Model":"LLaVA-v1 (Vicuna-13B)",
        "Completeness":0.91,
        "Precision":1.25,
        "Relevance":1.6,
        "Sum":3.76
    },
    {
        "Model":"MiniGPT-4 (Vicuna-13B)",
        "Completeness":1.0,
        "Precision":1.26,
        "Relevance":1.41,
        "Sum":3.67
    }
]