[
    {
        "Model":"Qwen-VL-Max",
        "Version":"-",
        "Score":184.12
    },
    {
        "Model":"Qwen-VL-Plus",
        "Version":"-",
        "Score":184.12
    },
    {
        "Model":"PureMM",
        "Version":"Vicuna-13B",
        "Score":182.35
    },
    {
        "Model":"WeMM",
        "Version":"InternLM-7B",
        "Score":179.12
    },
    {
        "Model":"SPHINX",
        "Version":"LLaMA2-13B",
        "Score":177.94
    },
    {
        "Model":"ChatTruth-7B",
        "Version":"Qwen-7B",
        "Score":177.65
    },
    {
        "Model":"Honeybee",
        "Version":"Vicuna-13B",
        "Score":177.06
    },
    {
        "Model":"Otter",
        "Version":"OTTER-Image-MPT7B",
        "Score":172.65
    },
    {
        "Model":"OmniLMM",
        "Version":"Zephyr-7B-beta",
        "Score":172.06
    },
    {
        "Model":"RBDash",
        "Version":"Vicuna-13B",
        "Score":170.0
    },
    {
        "Model":"InfMLLM",
        "Version":"Vicuna-13B",
        "Score":164.41
    },
    {
        "Model":"mPLUG-Owl2",
        "Version":"LLaMA2-7B",
        "Score":164.41
    },
    {
        "Model":"Cheetor",
        "Version":"Vicuna-7B",
        "Score":164.12
    },
    {
        "Model":"LVIS-INSTRUCT4V",
        "Version":"Vicuna-13B",
        "Score":161.47
    },
    {
        "Model":"LLaVA-1.6",
        "Version":"Vicuna-34B",
        "Score":160.0
    },
    {
        "Model":"DataOptim-LLaVA",
        "Version":"Vicuna-13B",
        "Score":159.41
    },
    {
        "Model":"MiniCPM",
        "Version":"MiniCPM-2B",
        "Score":155.59
    },
    {
        "Model":"InternVL-Chat-V1.1",
        "Version":"LLaMA2-13B",
        "Score":154.71
    },
    {
        "Model":"ShareGPT4V",
        "Version":"Vicuna-13B",
        "Score":153.82
    },
    {
        "Model":"InternLM-XComposer2-VL",
        "Version":"InternLM2-7B",
        "Score":153.82
    },
    {
        "Model":"LLaVA",
        "Version":"Vicuna-13B",
        "Score":152.94
    },
    {
        "Model":"InternLM-XComposer-VL",
        "Version":"InternLM-7B",
        "Score":150.29
    },
    {
        "Model":"CogAgent",
        "Version":"Vicuna-7B",
        "Score":147.94
    },
    {
        "Model":"MoE-LLaVA",
        "Version":"Phi-2.7B\u00d74",
        "Score":147.94
    },
    {
        "Model":"Gemini Pro",
        "Version":"-",
        "Score":147.35
    },
    {
        "Model":"GIT2",
        "Version":"VQAv2-finetuned",
        "Score":145.88
    },
    {
        "Model":"TransCore-M",
        "Version":"PCITransGPT-13B",
        "Score":145.29
    },
    {
        "Model":"Monkey-Chat",
        "Version":"Qwen-7B",
        "Score":142.65
    },
    {
        "Model":"MMICL",
        "Version":"FlanT5xxl",
        "Score":141.76
    },
    {
        "Model":"BLIVA",
        "Version":"FlanT5xxl",
        "Score":140.88
    },
    {
        "Model":"BELLE-VL",
        "Version":"Qwen-14B",
        "Score":136.76
    },
    {
        "Model":"LLaMA-Adapter V2",
        "Version":"LLaMA-Adapter-v2.1-7B",
        "Score":136.76
    },
    {
        "Model":"Bunny-3B",
        "Version":"Phi-2",
        "Score":130.88
    },
    {
        "Model":"Qwen-VL-Chat",
        "Version":"Qwen-7B",
        "Score":120.59
    },
    {
        "Model":"Lynx",
        "Version":"Vicuna-7B",
        "Score":118.24
    },
    {
        "Model":"CogVLM",
        "Version":"Vicuna-7B",
        "Score":115.29
    },
    {
        "Model":"LRV-Instruction",
        "Version":"LRV-7B",
        "Score":112.65
    },
    {
        "Model":"BLIP-2",
        "Version":"Flant5xxl",
        "Score":105.59
    },
    {
        "Model":"InstructBLIP",
        "Version":"FlanT5xxl",
        "Score":101.18
    },
    {
        "Model":"mPLUG-Owl",
        "Version":"LLaMA-7B",
        "Score":100.29
    },
    {
        "Model":"Muffin",
        "Version":"Vicuna-13B",
        "Score":81.76
    },
    {
        "Model":"ImageBind_LLM",
        "Version":"LLaMA-7B",
        "Score":76.47
    },
    {
        "Model":"Multimodal-GPT",
        "Version":"Multimodal-GPT-9B",
        "Score":73.82
    },
    {
        "Model":"PandaGPT",
        "Version":"Vicuna-7B",
        "Score":57.06
    },
    {
        "Model":"MiniGPT-4",
        "Version":"Vicuna-13B",
        "Score":54.41
    },
    {
        "Model":"VPGTrans",
        "Version":"Vicuna-7B",
        "Score":53.53
    },
    {
        "Model":"VisualGLM-6B",
        "Version":"VisualGLM-6B",
        "Score":53.24
    },
    {
        "Model":"LaVIN",
        "Version":"LAVIN-13B",
        "Score":47.35
    },
    {
        "Model":"GPT-4V",
        "Version":"-",
        "Score":0.0
    }
]