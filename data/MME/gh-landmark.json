[
    {
        "Model":"PureMM",
        "Version":"Vicuna-13B",
        "Score":"192.50"
    },
    {
        "Model":"Qwen-VL-Plus",
        "Version":"-",
        "Score":"191.00"
    },
    {
        "Model":"Monkey-Chat",
        "Version":"Qwen-7B",
        "Score":"176.50"
    },
    {
        "Model":"RBDash",
        "Version":"Vicuna-13B",
        "Score":"174.25"
    },
    {
        "Model":"ShareGPT4V",
        "Version":"Vicuna-13B",
        "Score":"174.00"
    },
    {
        "Model":"BELLE-VL",
        "Version":"Qwen-14B",
        "Score":"174.00"
    },
    {
        "Model":"WeMM",
        "Version":"InternLM-7B",
        "Score":"172.25"
    },
    {
        "Model":"Honeybee",
        "Version":"Vicuna-13B",
        "Score":"172.25"
    },
    {
        "Model":"LLaVA",
        "Version":"Vicuna-13B",
        "Score":"170.50"
    },
    {
        "Model":"SPHINX",
        "Version":"LLaMA2-13B",
        "Score":"168.09"
    },
    {
        "Model":"LLaMA-Adapter V2",
        "Version":"LLaMA-Adapter-v2.1-7B",
        "Score":"167.84"
    },
    {
        "Model":"InfMLLM",
        "Version":"Vicuna-13B",
        "Score":"166.75"
    },
    {
        "Model":"InternLM-XComposer-VL",
        "Version":"InternLM-7B",
        "Score":"165.25"
    },
    {
        "Model":"Qwen-VL-Chat",
        "Version":"Qwen-7B",
        "Score":"164.00"
    },
    {
        "Model":"Lynx",
        "Version":"Vicuna-7B",
        "Score":"162.00"
    },
    {
        "Model":"LVIS-INSTRUCT4V",
        "Version":"Vicuna-13B",
        "Score":"161.50"
    },
    {
        "Model":"LRV-Instruction",
        "Version":"LRV-7B",
        "Score":"160.53"
    },
    {
        "Model":"DataOptim-LLaVA",
        "Version":"Vicuna-13B",
        "Score":"160.00"
    },
    {
        "Model":"mPLUG-Owl",
        "Version":"LLaMA-7B",
        "Score":"159.25"
    },
    {
        "Model":"TransCore-M",
        "Version":"PCITransGPT-13B",
        "Score":"159.25"
    },
    {
        "Model":"Gemini Pro",
        "Version":"-",
        "Score":"158.75"
    },
    {
        "Model":"mPLUG-Owl2",
        "Version":"LLaMA2-7B",
        "Score":"157.25"
    },
    {
        "Model":"Muffin",
        "Version":"Vicuna-13B",
        "Score":"146.25"
    },
    {
        "Model":"Cheetor",
        "Version":"Vicuna-7B",
        "Score":"145.73"
    },
    {
        "Model":"GIT2",
        "Version":"VQAv2-finetuned",
        "Score":"140.50"
    },
    {
        "Model":"GPT-4V",
        "Version":"-",
        "Score":"138.25"
    },
    {
        "Model":"BLIP-2",
        "Version":"Flant5xxl",
        "Score":"138.00"
    },
    {
        "Model":"Otter",
        "Version":"OTTER-Image-MPT7B",
        "Score":"137.25"
    },
    {
        "Model":"MMICL",
        "Version":"FlanT5xxl",
        "Score":"136.13"
    },
    {
        "Model":"LaVIN",
        "Version":"LAVIN-13B",
        "Score":"93.50"
    },
    {
        "Model":"BLIVA",
        "Version":"FlanT5xxl",
        "Score":"89.50"
    },
    {
        "Model":"VisualGLM-6B",
        "Version":"VisualGLM-6B",
        "Score":"83.75"
    },
    {
        "Model":"InstructBLIP",
        "Version":"FlanT5xxl",
        "Score":"79.75"
    },
    {
        "Model":"Multimodal-GPT",
        "Version":"Multimodal-GPT-9B",
        "Score":"69.75"
    },
    {
        "Model":"PandaGPT",
        "Version":"Vicuna-7B",
        "Score":"69.75"
    },
    {
        "Model":"VPGTrans",
        "Version":"Vicuna-7B",
        "Score":"64.75"
    },
    {
        "Model":"ImageBind_LLM",
        "Version":"LLaMA-7B",
        "Score":"62.00"
    },
    {
        "Model":"MiniGPT-4",
        "Version":"Vicuna-13B",
        "Score":"54.00"
    }
]