[
    {
        "Model":"InfMLLM",
        "Version":"Vicuna-13B",
        "Score":176.75
    },
    {
        "Model":"WeMM",
        "Version":"InternLM-7B",
        "Score":176.25
    },
    {
        "Model":"Qwen-VL-Max",
        "Version":"-",
        "Score":173.0
    },
    {
        "Model":"ShareGPT4V",
        "Version":"Vicuna-13B",
        "Score":168.0
    },
    {
        "Model":"ChatTruth-7B",
        "Version":"Qwen-7B",
        "Score":167.75
    },
    {
        "Model":"DataOptim-LLaVA",
        "Version":"Vicuna-13B",
        "Score":166.5
    },
    {
        "Model":"InternLM-XComposer2-VL",
        "Version":"InternLM2-7B",
        "Score":164.75
    },
    {
        "Model":"Lynx",
        "Version":"Vicuna-7B",
        "Score":164.5
    },
    {
        "Model":"LLaVA-1.6",
        "Version":"Vicuna-34B",
        "Score":164.5
    },
    {
        "Model":"LVIS-INSTRUCT4V",
        "Version":"Vicuna-13B",
        "Score":163.25
    },
    {
        "Model":"PureMM",
        "Version":"Vicuna-13B",
        "Score":162.75
    },
    {
        "Model":"Honeybee",
        "Version":"Vicuna-13B",
        "Score":162.0
    },
    {
        "Model":"Monkey-Chat",
        "Version":"Qwen-7B",
        "Score":161.75
    },
    {
        "Model":"LLaVA",
        "Version":"Vicuna-13B",
        "Score":161.25
    },
    {
        "Model":"TransCore-M",
        "Version":"PCITransGPT-13B",
        "Score":161.0
    },
    {
        "Model":"RBDash",
        "Version":"Vicuna-13B",
        "Score":160.25
    },
    {
        "Model":"SPHINX",
        "Version":"LLaMA2-13B",
        "Score":160.0
    },
    {
        "Model":"InternLM-XComposer-VL",
        "Version":"InternLM-7B",
        "Score":159.75
    },
    {
        "Model":"CogVLM",
        "Version":"Vicuna-7B",
        "Score":159.25
    },
    {
        "Model":"Otter",
        "Version":"OTTER-Image-MPT7B",
        "Score":158.75
    },
    {
        "Model":"GIT2",
        "Version":"VQAv2-finetuned",
        "Score":158.5
    },
    {
        "Model":"Bunny-3B",
        "Version":"Phi-2",
        "Score":158.5
    },
    {
        "Model":"MiniCPM",
        "Version":"MiniCPM-2B",
        "Score":157.75
    },
    {
        "Model":"LLaMA-Adapter V2",
        "Version":"LLaMA-Adapter-v2.1-7B",
        "Score":156.25
    },
    {
        "Model":"BELLE-VL",
        "Version":"Qwen-14B",
        "Score":156.25
    },
    {
        "Model":"Cheetor",
        "Version":"Vicuna-7B",
        "Score":156.0
    },
    {
        "Model":"InternVL-Chat-V1.1",
        "Version":"LLaMA2-13B",
        "Score":155.75
    },
    {
        "Model":"MoE-LLaVA",
        "Version":"Phi-2.7B\u00d74",
        "Score":154.5
    },
    {
        "Model":"CogAgent",
        "Version":"Vicuna-7B",
        "Score":154.25
    },
    {
        "Model":"MMICL",
        "Version":"FlanT5xxl",
        "Score":153.75
    },
    {
        "Model":"mPLUG-Owl2",
        "Version":"LLaMA2-7B",
        "Score":153.25
    },
    {
        "Model":"InstructBLIP",
        "Version":"FlanT5xxl",
        "Score":153.0
    },
    {
        "Model":"Qwen-VL-Chat",
        "Version":"Qwen-7B",
        "Score":152.25
    },
    {
        "Model":"BLIVA",
        "Version":"FlanT5xxl",
        "Score":151.5
    },
    {
        "Model":"Muffin",
        "Version":"Vicuna-13B",
        "Score":151.25
    },
    {
        "Model":"GPT-4V",
        "Version":"-",
        "Score":151.0
    },
    {
        "Model":"Qwen-VL-Plus",
        "Version":"-",
        "Score":151.0
    },
    {
        "Model":"LRV-Instruction",
        "Version":"LRV-7B",
        "Score":147.98
    },
    {
        "Model":"VisualGLM-6B",
        "Version":"VisualGLM-6B",
        "Score":146.25
    },
    {
        "Model":"OmniLMM",
        "Version":"Zephyr-7B-beta",
        "Score":146.25
    },
    {
        "Model":"BLIP-2",
        "Version":"Flant5xxl",
        "Score":145.25
    },
    {
        "Model":"Gemini Pro",
        "Version":"-",
        "Score":144.75
    },
    {
        "Model":"VPGTrans",
        "Version":"Vicuna-7B",
        "Score":141.75
    },
    {
        "Model":"LaVIN",
        "Version":"LAVIN-13B",
        "Score":136.75
    },
    {
        "Model":"mPLUG-Owl",
        "Version":"LLaMA-7B",
        "Score":135.5
    },
    {
        "Model":"PandaGPT",
        "Version":"Vicuna-7B",
        "Score":118.0
    },
    {
        "Model":"ImageBind_LLM",
        "Version":"LLaMA-7B",
        "Score":113.25
    },
    {
        "Model":"MiniGPT-4",
        "Version":"Vicuna-13B",
        "Score":71.75
    },
    {
        "Model":"Multimodal-GPT",
        "Version":"Multimodal-GPT-9B",
        "Score":68.0
    }
]