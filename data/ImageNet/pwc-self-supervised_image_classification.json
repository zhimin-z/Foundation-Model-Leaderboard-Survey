[
    {
        "table_id":1714,
        "row_id":101329,
        "rank":1,
        "method":"DINOv2 (ViT-g\/14 @448)",
        "mlmodel":{

        },
        "Model":"DINOv2 ",
        "method_details":"ViT-g\/14 @448",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-04-14",
        "metrics":{
            "Top 1 Accuracy":"86.7%",
            "Top 5 Accuracy":null,
            "Number of Params":"1100M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":86.7,
            "Top 5 Accuracy":null,
            "Number of Params":1100000000.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1191620,
            "title":"DINOv2: Learning Robust Visual Features without Supervision",
            "url":"\/paper\/dinov2-learning-robust-visual-features",
            "published":"2023-04-14T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":101336,
        "rank":2,
        "method":"DINOv2 (ViT-g\/14)",
        "mlmodel":{

        },
        "Model":"DINOv2 ",
        "method_details":"ViT-g\/14",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-04-14",
        "metrics":{
            "Top 1 Accuracy":"86.5%",
            "Top 5 Accuracy":null,
            "Number of Params":"1100M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":86.5,
            "Top 5 Accuracy":null,
            "Number of Params":1100000000.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1191620,
            "title":"DINOv2: Learning Robust Visual Features without Supervision",
            "url":"\/paper\/dinov2-learning-robust-visual-features",
            "published":"2023-04-14T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":101337,
        "rank":3,
        "method":"DINOv2 distilled (ViT-L\/14)",
        "mlmodel":{

        },
        "Model":"DINOv2 distilled ",
        "method_details":"ViT-L\/14",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-04-14",
        "metrics":{
            "Top 1 Accuracy":"86.3%",
            "Top 5 Accuracy":null,
            "Number of Params":"307M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":86.3,
            "Top 5 Accuracy":null,
            "Number of Params":307000000.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1191620,
            "title":"DINOv2: Learning Robust Visual Features without Supervision",
            "url":"\/paper\/dinov2-learning-robust-visual-features",
            "published":"2023-04-14T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":101338,
        "rank":4,
        "method":"DINOv2 distilled (ViT-B\/14)",
        "mlmodel":{

        },
        "Model":"DINOv2 distilled ",
        "method_details":"ViT-B\/14",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-04-14",
        "metrics":{
            "Top 1 Accuracy":"84.5%",
            "Top 5 Accuracy":null,
            "Number of Params":"85M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":84.5,
            "Top 5 Accuracy":null,
            "Number of Params":85000000.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":1191620,
            "title":"DINOv2: Learning Robust Visual Features without Supervision",
            "url":"\/paper\/dinov2-learning-robust-visual-features",
            "published":"2023-04-14T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":101656,
        "rank":5,
        "method":"Unicom (ViT-L\/14@336px)",
        "mlmodel":{

        },
        "Model":"Unicom ",
        "method_details":"ViT-L\/14@336px",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-04-12",
        "metrics":{
            "Top 1 Accuracy":"82.7%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":82.7,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":1190273,
            "title":"Unicom: Universal and Compact Representation Learning for Image Retrieval",
            "url":"\/paper\/unicom-universal-and-compact-representation",
            "published":"2023-04-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/unicom-universal-and-compact-representation\/review\/?hl=101656"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":426,
                "name":"Train without ImageNet1K",
                "color":"#27b6d3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":64542,
        "rank":6,
        "method":"iBOT (ViT-L\/16) (IN22k)",
        "mlmodel":{

        },
        "Model":"iBOT ",
        "method_details":"ViT-L\/16",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-11-15",
        "metrics":{
            "Top 1 Accuracy":"82.3%",
            "Top 5 Accuracy":null,
            "Number of Params":"307M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":82.3,
            "Top 5 Accuracy":null,
            "Number of Params":307000000.0
        },
        "uses_additional_data":true,
        "paper":{
            "id":909858,
            "title":"iBOT: Image BERT Pre-Training with Online Tokenizer",
            "url":"\/paper\/ibot-image-bert-pre-training-with-online",
            "published":"2021-11-15T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":108712,
        "rank":7,
        "method":"MAE-CT (ViT-H\/16)",
        "mlmodel":{

        },
        "Model":"MAE-CT ",
        "method_details":"ViT-H\/16",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-04-20",
        "metrics":{
            "Top 1 Accuracy":"82.2%",
            "Top 5 Accuracy":null,
            "Number of Params":"632M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":82.2,
            "Top 5 Accuracy":null,
            "Number of Params":632000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1194752,
            "title":"Contrastive Tuning: A Little Help to Make Masked Autoencoders Forget",
            "url":"\/paper\/contrastive-tuning-a-little-help-to-make",
            "published":"2023-04-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/contrastive-tuning-a-little-help-to-make\/review\/?hl=108712"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":64402,
        "rank":8,
        "method":"Mugs (VIT-L\/16)",
        "mlmodel":{

        },
        "Model":"Mugs ",
        "method_details":"VIT-L\/16",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-03-27",
        "metrics":{
            "Top 1 Accuracy":"82.1%",
            "Top 5 Accuracy":null,
            "Number of Params":"307M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":82.1,
            "Top 5 Accuracy":null,
            "Number of Params":307000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":984107,
            "title":"Mugs: A Multi-Granular Self-Supervised Learning Framework",
            "url":"\/paper\/mugs-a-multi-granular-self-supervised",
            "published":"2022-03-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/mugs-a-multi-granular-self-supervised\/review\/?hl=64402"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":101655,
        "rank":9,
        "method":"Unicom (ViT-L\/14)",
        "mlmodel":{

        },
        "Model":"Unicom ",
        "method_details":"ViT-L\/14",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-04-12",
        "metrics":{
            "Top 1 Accuracy":"81.8%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":81.8,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":1190273,
            "title":"Unicom: Universal and Compact Representation Learning for Image Retrieval",
            "url":"\/paper\/unicom-universal-and-compact-representation",
            "published":"2023-04-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/unicom-universal-and-compact-representation\/review\/?hl=101655"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":426,
                "name":"Train without ImageNet1K",
                "color":"#27b6d3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":108713,
        "rank":10,
        "method":"MAE-CT (ViT-L\/16",
        "mlmodel":{

        },
        "Model":"MAE-CT ",
        "method_details":"ViT-L\/16",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-04-20",
        "metrics":{
            "Top 1 Accuracy":"81.5%",
            "Top 5 Accuracy":null,
            "Number of Params":"307M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":81.5,
            "Top 5 Accuracy":null,
            "Number of Params":307000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1194752,
            "title":"Contrastive Tuning: A Little Help to Make Masked Autoencoders Forget",
            "url":"\/paper\/contrastive-tuning-a-little-help-to-make",
            "published":"2023-04-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/contrastive-tuning-a-little-help-to-make\/review\/?hl=108713"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":35305,
        "rank":11,
        "method":"EsViT (Swin-B)",
        "mlmodel":{

        },
        "Model":"EsViT ",
        "method_details":"Swin-B",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-06-17",
        "metrics":{
            "Top 1 Accuracy":"81.3%",
            "Top 5 Accuracy":"95.5%",
            "Number of Params":"87M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":81.3,
            "Top 5 Accuracy":95.5,
            "Number of Params":87000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":821124,
            "title":"Efficient Self-supervised Vision Transformers for Representation Learning",
            "url":"\/paper\/efficient-self-supervised-vision-transformers",
            "published":"2021-06-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/efficient-self-supervised-vision-transformers\/review\/?hl=35305"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":45184,
        "rank":12,
        "method":"iBOT (ViT-L\/16)",
        "mlmodel":{

        },
        "Model":"iBOT ",
        "method_details":"ViT-L\/16",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-11-15",
        "metrics":{
            "Top 1 Accuracy":"81.3%",
            "Top 5 Accuracy":null,
            "Number of Params":"307M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":81.3,
            "Top 5 Accuracy":null,
            "Number of Params":307000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":909858,
            "title":"iBOT: Image BERT Pre-Training with Online Tokenizer",
            "url":"\/paper\/ibot-image-bert-pre-training-with-online",
            "published":"2021-11-15T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":29406,
        "rank":13,
        "method":"MoCo v3 (ViT-BN-L\/7)",
        "mlmodel":{

        },
        "Model":"MoCo v3 ",
        "method_details":"ViT-BN-L\/7",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-05",
        "metrics":{
            "Top 1 Accuracy":"81.0%",
            "Top 5 Accuracy":null,
            "Number of Params":"304M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":81.0,
            "Top 5 Accuracy":null,
            "Number of Params":304000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":774854,
            "title":"An Empirical Study of Training Self-Supervised Vision Transformers",
            "url":"\/paper\/an-empirical-study-of-training-self",
            "published":"2021-04-05T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/an-empirical-study-of-training-self\/review\/?hl=29406"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":35306,
        "rank":14,
        "method":"EsViT(Swin-S)",
        "mlmodel":{

        },
        "Model":"EsViT",
        "method_details":"Swin-S",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-06-17",
        "metrics":{
            "Top 1 Accuracy":"80.8%",
            "Top 5 Accuracy":null,
            "Number of Params":"49M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":80.8,
            "Top 5 Accuracy":null,
            "Number of Params":49000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":821124,
            "title":"Efficient Self-supervised Vision Transformers for Representation Learning",
            "url":"\/paper\/efficient-self-supervised-vision-transformers",
            "published":"2021-06-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/efficient-self-supervised-vision-transformers\/review\/?hl=35306"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":98605,
        "rank":15,
        "method":"MSN (ViT-L\/7)",
        "mlmodel":{

        },
        "Model":"MSN ",
        "method_details":"ViT-L\/7",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-04-14",
        "metrics":{
            "Top 1 Accuracy":"80.7%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":80.7,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":994421,
            "title":"Masked Siamese Networks for Label-Efficient Learning",
            "url":"\/paper\/masked-siamese-networks-for-label-efficient",
            "published":"2022-04-14T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/masked-siamese-networks-for-label-efficient\/review\/?hl=98605"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":73367,
        "rank":16,
        "method":"ReLICv2 (ResNet-200 x2)",
        "mlmodel":{

        },
        "Model":"ReLICv2 ",
        "method_details":"ResNet-200 x2",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-01-13",
        "metrics":{
            "Top 1 Accuracy":"80.6%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":80.6,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":944970,
            "title":"Pushing the limits of self-supervised ResNets: Can we outperform supervised learning without labels on ImageNet?",
            "url":"\/paper\/pushing-the-limits-of-self-supervised-resnets",
            "published":"2022-01-13T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/pushing-the-limits-of-self-supervised-resnets\/review\/?hl=73367"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":79356,
        "rank":17,
        "method":"MR BarTwins (MR BarTwins)",
        "mlmodel":{

        },
        "Model":"MR BarTwins ",
        "method_details":"MR BarTwins",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-15",
        "metrics":{
            "Top 1 Accuracy":"80.4%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":80.4,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1112656,
            "title":"Masked Reconstruction Contrastive Learning with Information Bottleneck Principle",
            "url":"\/paper\/masked-reconstruction-contrastive-learning",
            "published":"2022-11-15T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/masked-reconstruction-contrastive-learning\/review\/?hl=79356"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":64543,
        "rank":18,
        "method":"DINO (xcit_medium_24_p8)",
        "mlmodel":{

        },
        "Model":"DINO ",
        "method_details":"xcit_medium_24_p8",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-29",
        "metrics":{
            "Top 1 Accuracy":"80.3%",
            "Top 5 Accuracy":null,
            "Number of Params":"84M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":80.3,
            "Top 5 Accuracy":null,
            "Number of Params":84000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":789002,
            "title":"Emerging Properties in Self-Supervised Vision Transformers",
            "url":"\/paper\/emerging-properties-in-self-supervised-vision",
            "published":"2021-04-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/emerging-properties-in-self-supervised-vision\/review\/?hl=64543"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":112978,
        "rank":19,
        "method":"PGT (PGT-B w\/ Flow)",
        "mlmodel":{

        },
        "Model":"PGT ",
        "method_details":"PGT-B w\/ Flow",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-11-30",
        "metrics":{
            "Top 1 Accuracy":"80.3%",
            "Top 5 Accuracy":null,
            "Number of Params":"70M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":80.3,
            "Top 5 Accuracy":null,
            "Number of Params":70000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":1333230,
            "title":"Perceptual Group Tokenizer: Building Perception with Iterative Grouping",
            "url":"\/paper\/perceptual-group-tokenizer-building",
            "published":"2023-11-30T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/perceptual-group-tokenizer-building\/review\/?hl=112978"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":31087,
        "rank":20,
        "method":"DINO (ViT-B\/8)",
        "mlmodel":{

        },
        "Model":"DINO ",
        "method_details":"ViT-B\/8",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-29",
        "metrics":{
            "Top 1 Accuracy":"80.1%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":80.1,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":789002,
            "title":"Emerging Properties in Self-Supervised Vision Transformers",
            "url":"\/paper\/emerging-properties-in-self-supervised-vision",
            "published":"2021-04-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/emerging-properties-in-self-supervised-vision\/review\/?hl=31087"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":17366,
        "rank":21,
        "method":"SimCLRv2 (ResNet-152 x3, SK)",
        "mlmodel":{

        },
        "Model":"SimCLRv2 ",
        "method_details":"ResNet-152 x3, SK",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-06-17",
        "metrics":{
            "Top 1 Accuracy":"79.8%",
            "Top 5 Accuracy":"94.9%",
            "Number of Params":"795M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":79.8,
            "Top 5 Accuracy":94.9,
            "Number of Params":795000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":202875,
            "title":"Big Self-Supervised Models are Strong Semi-Supervised Learners",
            "url":"\/paper\/big-self-supervised-models-are-strong-semi",
            "published":"2020-06-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/big-self-supervised-models-are-strong-semi\/review\/?hl=17366"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":73358,
        "rank":22,
        "method":"ReLICv2 (ResNet200)",
        "mlmodel":{

        },
        "Model":"ReLICv2 ",
        "method_details":"ResNet200",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-01-13",
        "metrics":{
            "Top 1 Accuracy":"79.8%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":79.8,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":944970,
            "title":"Pushing the limits of self-supervised ResNets: Can we outperform supervised learning without labels on ImageNet?",
            "url":"\/paper\/pushing-the-limits-of-self-supervised-resnets",
            "published":"2022-01-13T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/pushing-the-limits-of-self-supervised-resnets\/review\/?hl=73358"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":103622,
        "rank":23,
        "method":"PercMAE (ViT-B, dVAE)",
        "mlmodel":{

        },
        "Model":"PercMAE ",
        "method_details":"ViT-B, dVAE",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-30",
        "metrics":{
            "Top 1 Accuracy":"79.8%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":79.8,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":1136076,
            "title":"Improving Visual Representation Learning through Perceptual Understanding",
            "url":"\/paper\/improving-visual-representation-learning",
            "published":"2022-12-30T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/improving-visual-representation-learning\/review\/?hl=103622"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":31086,
        "rank":24,
        "method":"DINO (ViT-S\/8)",
        "mlmodel":{

        },
        "Model":"DINO ",
        "method_details":"ViT-S\/8",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-29",
        "metrics":{
            "Top 1 Accuracy":"79.7%",
            "Top 5 Accuracy":null,
            "Number of Params":"21M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":79.7,
            "Top 5 Accuracy":null,
            "Number of Params":21000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":789002,
            "title":"Emerging Properties in Self-Supervised Vision Transformers",
            "url":"\/paper\/emerging-properties-in-self-supervised-vision",
            "published":"2021-04-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/emerging-properties-in-self-supervised-vision\/review\/?hl=31086"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":17307,
        "rank":25,
        "method":"BYOL (ResNet-200 x2)",
        "mlmodel":{

        },
        "Model":"BYOL ",
        "method_details":"ResNet-200 x2",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-06-13",
        "metrics":{
            "Top 1 Accuracy":"79.6%",
            "Top 5 Accuracy":"94.8%",
            "Number of Params":"250M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":79.6,
            "Top 5 Accuracy":94.8,
            "Number of Params":250000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":202435,
            "title":"Bootstrap your own latent: A new approach to self-supervised Learning",
            "url":"\/paper\/bootstrap-your-own-latent-a-new-approach-to",
            "published":"2020-06-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/bootstrap-your-own-latent-a-new-approach-to\/review\/?hl=17307"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":73361,
        "rank":26,
        "method":"ReLICv2 (ResNet-50 4x)",
        "mlmodel":{

        },
        "Model":"ReLICv2 ",
        "method_details":"ResNet-50 4x",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-01-13",
        "metrics":{
            "Top 1 Accuracy":"79.4%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":79.4,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":944970,
            "title":"Pushing the limits of self-supervised ResNets: Can we outperform supervised learning without labels on ImageNet?",
            "url":"\/paper\/pushing-the-limits-of-self-supervised-resnets",
            "published":"2022-01-13T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/pushing-the-limits-of-self-supervised-resnets\/review\/?hl=73361"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":73355,
        "rank":27,
        "method":"ReLICv2 (ResNet152)",
        "mlmodel":{

        },
        "Model":"ReLICv2 ",
        "method_details":"ResNet152",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-01-13",
        "metrics":{
            "Top 1 Accuracy":"79.3%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":79.3,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":944970,
            "title":"Pushing the limits of self-supervised ResNets: Can we outperform supervised learning without labels on ImageNet?",
            "url":"\/paper\/pushing-the-limits-of-self-supervised-resnets",
            "published":"2022-01-13T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/pushing-the-limits-of-self-supervised-resnets\/review\/?hl=73355"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            },
            {
                "id":81,
                "name":"ResNet-152",
                "color":"#598ac9"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":29405,
        "rank":28,
        "method":"MoCo v3 (ViT-BN-H)",
        "mlmodel":{

        },
        "Model":"MoCo v3 ",
        "method_details":"ViT-BN-H",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-05",
        "metrics":{
            "Top 1 Accuracy":"79.1%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":79.1,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":774854,
            "title":"An Empirical Study of Training Self-Supervised Vision Transformers",
            "url":"\/paper\/an-empirical-study-of-training-self",
            "published":"2021-04-05T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/an-empirical-study-of-training-self\/review\/?hl=29405"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":101654,
        "rank":29,
        "method":"Unicom (ViT-B\/16)",
        "mlmodel":{

        },
        "Model":"Unicom ",
        "method_details":"ViT-B\/16",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-04-12",
        "metrics":{
            "Top 1 Accuracy":"79.1%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":79.1,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":1190273,
            "title":"Unicom: Universal and Compact Representation Learning for Image Retrieval",
            "url":"\/paper\/unicom-universal-and-compact-representation",
            "published":"2023-04-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/unicom-universal-and-compact-representation\/review\/?hl=101654"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":426,
                "name":"Train without ImageNet1K",
                "color":"#27b6d3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":70885,
        "rank":30,
        "method":"SMoG (ResNet-50 x4)",
        "mlmodel":{

        },
        "Model":"SMoG ",
        "method_details":"ResNet-50 x4",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-07-13",
        "metrics":{
            "Top 1 Accuracy":"79.0%",
            "Top 5 Accuracy":"94.4",
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":79.0,
            "Top 5 Accuracy":94.4,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1043136,
            "title":"Unsupervised Visual Representation Learning by Synchronous Momentum Grouping",
            "url":"\/paper\/unsupervised-visual-representation-learning-4",
            "published":"2022-07-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/unsupervised-visual-representation-learning-4\/review\/?hl=70885"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":73360,
        "rank":31,
        "method":"ReLICv2 (ResNet-50 x2)",
        "mlmodel":{

        },
        "Model":"ReLICv2 ",
        "method_details":"ResNet-50 x2",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-01-13",
        "metrics":{
            "Top 1 Accuracy":"79%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":79.0,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":944970,
            "title":"Pushing the limits of self-supervised ResNets: Can we outperform supervised learning without labels on ImageNet?",
            "url":"\/paper\/pushing-the-limits-of-self-supervised-resnets",
            "published":"2022-01-13T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/pushing-the-limits-of-self-supervised-resnets\/review\/?hl=73360"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":39971,
        "rank":32,
        "method":"C-BYOL (ResNet-50 2x, 1000 epochs)",
        "mlmodel":{

        },
        "Model":"C-BYOL ",
        "method_details":"ResNet-50 2x, 1000 epochs",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-09-27",
        "metrics":{
            "Top 1 Accuracy":"78.8%",
            "Top 5 Accuracy":"94.5%",
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":78.8,
            "Top 5 Accuracy":94.5,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":873900,
            "title":"Compressive Visual Representations",
            "url":"\/paper\/compressive-visual-representations",
            "published":"2021-09-27T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":73354,
        "rank":33,
        "method":"ReLICv2 (ResNet101)",
        "mlmodel":{

        },
        "Model":"ReLICv2 ",
        "method_details":"ResNet101",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-01-13",
        "metrics":{
            "Top 1 Accuracy":"78.7%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":78.7,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":944970,
            "title":"Pushing the limits of self-supervised ResNets: Can we outperform supervised learning without labels on ImageNet?",
            "url":"\/paper\/pushing-the-limits-of-self-supervised-resnets",
            "published":"2022-01-13T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/pushing-the-limits-of-self-supervised-resnets\/review\/?hl=73354"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            },
            {
                "id":54,
                "name":"ResNet-101",
                "color":"#cc1e1e"
            },
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":17306,
        "rank":34,
        "method":"BYOL (ResNet-50 x4)",
        "mlmodel":{

        },
        "Model":"BYOL ",
        "method_details":"ResNet-50 x4",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-06-13",
        "metrics":{
            "Top 1 Accuracy":"78.6%",
            "Top 5 Accuracy":"94.2%",
            "Number of Params":"375M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":78.6,
            "Top 5 Accuracy":94.2,
            "Number of Params":375000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":202435,
            "title":"Bootstrap your own latent: A new approach to self-supervised Learning",
            "url":"\/paper\/bootstrap-your-own-latent-a-new-approach-to",
            "published":"2020-06-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/bootstrap-your-own-latent-a-new-approach-to\/review\/?hl=17306"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":18586,
        "rank":35,
        "method":"SwAV (ResNet-50 x4)",
        "mlmodel":{

        },
        "Model":"SwAV ",
        "method_details":"ResNet-50 x4",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-06-17",
        "metrics":{
            "Top 1 Accuracy":"78.5%",
            "Top 5 Accuracy":null,
            "Number of Params":"586M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":78.5,
            "Top 5 Accuracy":null,
            "Number of Params":586000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":202916,
            "title":"Unsupervised Learning of Visual Features by Contrasting Cluster Assignments",
            "url":"\/paper\/unsupervised-learning-of-visual-features-by",
            "published":"2020-06-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/unsupervised-learning-of-visual-features-by\/review\/?hl=18586"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":31085,
        "rank":36,
        "method":"DINO (ViT-B\/16)",
        "mlmodel":{

        },
        "Model":"DINO ",
        "method_details":"ViT-B\/16",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-29",
        "metrics":{
            "Top 1 Accuracy":"78.2%",
            "Top 5 Accuracy":null,
            "Number of Params":"85M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":78.2,
            "Top 5 Accuracy":null,
            "Number of Params":85000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":789002,
            "title":"Emerging Properties in Self-Supervised Vision Transformers",
            "url":"\/paper\/emerging-properties-in-self-supervised-vision",
            "published":"2021-04-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/emerging-properties-in-self-supervised-vision\/review\/?hl=31085"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":29404,
        "rank":37,
        "method":"MoCo v3 (ViT-H)",
        "mlmodel":{

        },
        "Model":"MoCo v3 ",
        "method_details":"ViT-H",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-05",
        "metrics":{
            "Top 1 Accuracy":"78.1%",
            "Top 5 Accuracy":null,
            "Number of Params":"632M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":78.1,
            "Top 5 Accuracy":null,
            "Number of Params":632000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":774854,
            "title":"An Empirical Study of Training Self-Supervised Vision Transformers",
            "url":"\/paper\/an-empirical-study-of-training-self",
            "published":"2021-04-05T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/an-empirical-study-of-training-self\/review\/?hl=29404"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":103620,
        "rank":38,
        "method":"PercMAE (ViT-B)",
        "mlmodel":{

        },
        "Model":"PercMAE ",
        "method_details":"ViT-B",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-12-30",
        "metrics":{
            "Top 1 Accuracy":"78.1%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":78.1,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1136076,
            "title":"Improving Visual Representation Learning through Perceptual Understanding",
            "url":"\/paper\/improving-visual-representation-learning",
            "published":"2022-12-30T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/improving-visual-representation-learning\/review\/?hl=103620"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":70886,
        "rank":39,
        "method":"SMoG (ResNet-50 x2)",
        "mlmodel":{

        },
        "Model":"SMoG ",
        "method_details":"ResNet-50 x2",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-07-13",
        "metrics":{
            "Top 1 Accuracy":"78.0%",
            "Top 5 Accuracy":"93.9",
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":78.0,
            "Top 5 Accuracy":93.9,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1043136,
            "title":"Unsupervised Visual Representation Learning by Synchronous Momentum Grouping",
            "url":"\/paper\/unsupervised-visual-representation-learning-4",
            "published":"2022-07-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/unsupervised-visual-representation-learning-4\/review\/?hl=70886"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":29403,
        "rank":40,
        "method":"MoCo v3 (ViT-L)",
        "mlmodel":{

        },
        "Model":"MoCo v3 ",
        "method_details":"ViT-L",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-05",
        "metrics":{
            "Top 1 Accuracy":"77.6%",
            "Top 5 Accuracy":null,
            "Number of Params":"307M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":77.6,
            "Top 5 Accuracy":null,
            "Number of Params":307000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":774854,
            "title":"An Empirical Study of Training Self-Supervised Vision Transformers",
            "url":"\/paper\/an-empirical-study-of-training-self",
            "published":"2021-04-05T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/an-empirical-study-of-training-self\/review\/?hl=29403"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":17305,
        "rank":41,
        "method":"BYOL (ResNet-50 x2)",
        "mlmodel":{

        },
        "Model":"BYOL ",
        "method_details":"ResNet-50 x2",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-06-13",
        "metrics":{
            "Top 1 Accuracy":"77.4%",
            "Top 5 Accuracy":"93.6%",
            "Number of Params":"94M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":77.4,
            "Top 5 Accuracy":93.6,
            "Number of Params":94000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":202435,
            "title":"Bootstrap your own latent: A new approach to self-supervised Learning",
            "url":"\/paper\/bootstrap-your-own-latent-a-new-approach-to",
            "published":"2020-06-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/bootstrap-your-own-latent-a-new-approach-to\/review\/?hl=17305"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":18585,
        "rank":42,
        "method":"SwAV (ResNet-50 x2)",
        "mlmodel":{

        },
        "Model":"SwAV ",
        "method_details":"ResNet-50 x2",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-06-17",
        "metrics":{
            "Top 1 Accuracy":"77.3%",
            "Top 5 Accuracy":null,
            "Number of Params":"94M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":77.3,
            "Top 5 Accuracy":null,
            "Number of Params":94000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":202916,
            "title":"Unsupervised Learning of Visual Features by Contrasting Cluster Assignments",
            "url":"\/paper\/unsupervised-learning-of-visual-features-by",
            "published":"2020-06-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/unsupervised-learning-of-visual-features-by\/review\/?hl=18585"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":73353,
        "rank":43,
        "method":"ReLICv2 (ResNet-50)",
        "mlmodel":{

        },
        "Model":"ReLICv2 ",
        "method_details":"ResNet-50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-01-13",
        "metrics":{
            "Top 1 Accuracy":"77.1%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":77.1,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":944970,
            "title":"Pushing the limits of self-supervised ResNets: Can we outperform supervised learning without labels on ImageNet?",
            "url":"\/paper\/pushing-the-limits-of-self-supervised-resnets",
            "published":"2022-01-13T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/pushing-the-limits-of-self-supervised-resnets\/review\/?hl=73353"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":95,
                "name":"ResNet-50x1",
                "color":"#2771D3"
            },
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":31084,
        "rank":44,
        "method":"DINO (ViT-S\/16)",
        "mlmodel":{

        },
        "Model":"DINO ",
        "method_details":"ViT-S\/16",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-29",
        "metrics":{
            "Top 1 Accuracy":"77.0%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":77.0,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":789002,
            "title":"Emerging Properties in Self-Supervised Vision Transformers",
            "url":"\/paper\/emerging-properties-in-self-supervised-vision",
            "published":"2021-04-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/emerging-properties-in-self-supervised-vision\/review\/?hl=31084"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":29402,
        "rank":45,
        "method":"MoCo v3 (ViT-L\/16)",
        "mlmodel":{

        },
        "Model":"MoCo v3 ",
        "method_details":"ViT-L\/16",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-05",
        "metrics":{
            "Top 1 Accuracy":"76.7%",
            "Top 5 Accuracy":null,
            "Number of Params":"86M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":76.7,
            "Top 5 Accuracy":null,
            "Number of Params":86000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":774854,
            "title":"An Empirical Study of Training Self-Supervised Vision Transformers",
            "url":"\/paper\/an-empirical-study-of-training-self",
            "published":"2021-04-05T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/an-empirical-study-of-training-self\/review\/?hl=29402"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":44083,
        "rank":46,
        "method":"MAE (ViT-H)",
        "mlmodel":{

        },
        "Model":"MAE ",
        "method_details":"ViT-H",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-11-11",
        "metrics":{
            "Top 1 Accuracy":"76.6%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":76.6,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":908690,
            "title":"Masked Autoencoders Are Scalable Vision Learners",
            "url":"\/paper\/masked-autoencoders-are-scalable-vision",
            "published":"2021-11-11T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/masked-autoencoders-are-scalable-vision\/review\/?hl=44083"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":9939,
        "rank":47,
        "method":"SimCLR (ResNet-50 4x)",
        "mlmodel":{

        },
        "Model":"SimCLR ",
        "method_details":"ResNet-50 4x",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-02-13",
        "metrics":{
            "Top 1 Accuracy":"76.5%",
            "Top 5 Accuracy":"93.2%",
            "Number of Params":"375M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":76.5,
            "Top 5 Accuracy":93.2,
            "Number of Params":375000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":183167,
            "title":"A Simple Framework for Contrastive Learning of Visual Representations",
            "url":"\/paper\/a-simple-framework-for-contrastive-learning",
            "published":"2020-02-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/a-simple-framework-for-contrastive-learning\/review\/?hl=9939"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":63797,
        "rank":48,
        "method":"CoKe (ResNet-50)",
        "mlmodel":{

        },
        "Model":"CoKe ",
        "method_details":"ResNet-50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-05-24",
        "metrics":{
            "Top 1 Accuracy":"76.4%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":76.4,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":805156,
            "title":"Unsupervised Visual Representation Learning by Online Constrained K-Means",
            "url":"\/paper\/unsupervised-visual-representation-learning-3",
            "published":"2021-05-24T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/unsupervised-visual-representation-learning-3\/review\/?hl=63797"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":70887,
        "rank":49,
        "method":"SMoG (ResNet-50)",
        "mlmodel":{

        },
        "Model":"SMoG ",
        "method_details":"ResNet-50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-07-13",
        "metrics":{
            "Top 1 Accuracy":"76.4%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":76.4,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1043136,
            "title":"Unsupervised Visual Representation Learning by Synchronous Momentum Grouping",
            "url":"\/paper\/unsupervised-visual-representation-learning-4",
            "published":"2022-07-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/unsupervised-visual-representation-learning-4\/review\/?hl=70887"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":65628,
        "rank":50,
        "method":"ReSSL (ResNet-50 w\/ Predictor and Stronger Aug)",
        "mlmodel":{

        },
        "Model":"ReSSL ",
        "method_details":"ResNet-50 w\/ Predictor and Stronger Aug",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-03-16",
        "metrics":{
            "Top 1 Accuracy":"76.3%",
            "Top 5 Accuracy":null,
            "Number of Params":"24M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":76.3,
            "Top 5 Accuracy":null,
            "Number of Params":24000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":978227,
            "title":"Relational Self-Supervised Learning",
            "url":"\/paper\/relational-self-supervised-learning",
            "published":"2022-03-16T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/relational-self-supervised-learning\/review\/?hl=65628"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":65629,
        "rank":51,
        "method":"ReSSL (ResNet-50 w\/ Predictor)",
        "mlmodel":{

        },
        "Model":"ReSSL ",
        "method_details":"ResNet-50 w\/ Predictor",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-03-16",
        "metrics":{
            "Top 1 Accuracy":"76.0%",
            "Top 5 Accuracy":null,
            "Number of Params":"24M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":76.0,
            "Top 5 Accuracy":null,
            "Number of Params":24000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":978227,
            "title":"Relational Self-Supervised Learning",
            "url":"\/paper\/relational-self-supervised-learning",
            "published":"2022-03-16T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/relational-self-supervised-learning\/review\/?hl=65629"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":39619,
        "rank":52,
        "method":"Triplet  (ResNet-50)",
        "mlmodel":{

        },
        "Model":"Triplet  ",
        "method_details":"ResNet-50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-18",
        "metrics":{
            "Top 1 Accuracy":"75.9%",
            "Top 5 Accuracy":null,
            "Number of Params":"23.56M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":75.9,
            "Top 5 Accuracy":null,
            "Number of Params":23560000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":784287,
            "title":"Solving Inefficiency of Self-supervised Representation Learning",
            "url":"\/paper\/solving-inefficiency-of-self-supervised",
            "published":"2021-04-18T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/solving-inefficiency-of-self-supervised\/review\/?hl=39619"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":95,
                "name":"ResNet-50x1",
                "color":"#2771D3"
            },
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":46873,
        "rank":53,
        "method":"DnC (ResNet-50)",
        "mlmodel":{

        },
        "Model":"DnC ",
        "method_details":"ResNet-50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-05-17",
        "metrics":{
            "Top 1 Accuracy":"75.8%",
            "Top 5 Accuracy":null,
            "Number of Params":"24M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":75.8,
            "Top 5 Accuracy":null,
            "Number of Params":24000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":800164,
            "title":"Divide and Contrast: Self-supervised Learning from Uncurated Data",
            "url":"\/paper\/divide-and-contrast-self-supervised-learning",
            "published":"2021-05-17T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            },
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":44082,
        "rank":54,
        "method":"MAE (ViT-L)",
        "mlmodel":{

        },
        "Model":"MAE ",
        "method_details":"ViT-L",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-11-11",
        "metrics":{
            "Top 1 Accuracy":"75.8%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":75.8,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":908690,
            "title":"Masked Autoencoders Are Scalable Vision Learners",
            "url":"\/paper\/masked-autoencoders-are-scalable-vision",
            "published":"2021-11-11T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/masked-autoencoders-are-scalable-vision\/review\/?hl=44082"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":51046,
        "rank":55,
        "method":"CaCo (ResNet-50)",
        "mlmodel":{

        },
        "Model":"CaCo ",
        "method_details":"ResNet-50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-01-03",
        "metrics":{
            "Top 1 Accuracy":"75.7%",
            "Top 5 Accuracy":null,
            "Number of Params":"24M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":75.7,
            "Top 5 Accuracy":null,
            "Number of Params":24000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":984112,
            "title":"CaCo: Both Positive and Negative Samples are Directly Learnable via Cooperative-adversarial Contrastive Learning",
            "url":"\/paper\/caco-both-positive-and-negative-samples-are",
            "published":"2022-03-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/caco-both-positive-and-negative-samples-are\/review\/?hl=51046"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":17365,
        "rank":56,
        "method":"SimCLRv2 (ResNet-50 x2)",
        "mlmodel":{

        },
        "Model":"SimCLRv2 ",
        "method_details":"ResNet-50 x2",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-06-17",
        "metrics":{
            "Top 1 Accuracy":"75.6%",
            "Top 5 Accuracy":"92.7%",
            "Number of Params":"94M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":75.6,
            "Top 5 Accuracy":92.7,
            "Number of Params":94000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":202875,
            "title":"Big Self-Supervised Models are Strong Semi-Supervised Learners",
            "url":"\/paper\/big-self-supervised-models-are-strong-semi",
            "published":"2020-06-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/big-self-supervised-models-are-strong-semi\/review\/?hl=17365"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":39972,
        "rank":57,
        "method":"C-BYOL (ResNet-50, 1000 epochs)",
        "mlmodel":{

        },
        "Model":"C-BYOL ",
        "method_details":"ResNet-50, 1000 epochs",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-09-27",
        "metrics":{
            "Top 1 Accuracy":"75.6%",
            "Top 5 Accuracy":"92.7%",
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":75.6,
            "Top 5 Accuracy":92.7,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":873900,
            "title":"Compressive Visual Representations",
            "url":"\/paper\/compressive-visual-representations",
            "published":"2021-09-27T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":31440,
        "rank":58,
        "method":"NNCLR (ResNet-50, multi-crop)",
        "mlmodel":{

        },
        "Model":"NNCLR ",
        "method_details":"ResNet-50, multi-crop",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-29",
        "metrics":{
            "Top 1 Accuracy":"75.6%",
            "Top 5 Accuracy":"92.4",
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":75.6,
            "Top 5 Accuracy":92.4,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":788988,
            "title":"With a Little Help from My Friends: Nearest-Neighbor Contrastive Learning of Visual Representations",
            "url":"\/paper\/with-a-little-help-from-my-friends-nearest",
            "published":"2021-04-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/with-a-little-help-from-my-friends-nearest\/review\/?hl=31440"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":35040,
        "rank":59,
        "method":"HEXA",
        "mlmodel":{

        },
        "Model":"HEXA",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-12-25",
        "metrics":{
            "Top 1 Accuracy":"75.5%",
            "Top 5 Accuracy":null,
            "Number of Params":"24M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":75.5,
            "Top 5 Accuracy":null,
            "Number of Params":24000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":732057,
            "title":"Self-supervised Pre-training with Hard Examples Improves Visual Representations",
            "url":"\/paper\/self-supervised-pre-training-with-hard",
            "published":"2020-12-25T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/self-supervised-pre-training-with-hard\/review\/?hl=35040"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":95530,
        "rank":60,
        "method":"SCE (ResNet-50, multi-crop)",
        "mlmodel":{

        },
        "Model":"SCE ",
        "method_details":"ResNet-50, multi-crop",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-11-29",
        "metrics":{
            "Top 1 Accuracy":"75.4%",
            "Top 5 Accuracy":null,
            "Number of Params":"24M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":75.4,
            "Top 5 Accuracy":null,
            "Number of Params":24000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":921779,
            "title":"Similarity Contrastive Estimation for Self-Supervised Soft Contrastive Learning",
            "url":"\/paper\/similarity-contrastive-estimation-for-self",
            "published":"2021-11-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/similarity-contrastive-estimation-for-self\/review\/?hl=95530"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            },
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":17643,
        "rank":61,
        "method":"SwAV (ResNet-50)",
        "mlmodel":{

        },
        "Model":"SwAV ",
        "method_details":"ResNet-50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-06-17",
        "metrics":{
            "Top 1 Accuracy":"75.3%",
            "Top 5 Accuracy":null,
            "Number of Params":"24M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":75.3,
            "Top 5 Accuracy":null,
            "Number of Params":24000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":202916,
            "title":"Unsupervised Learning of Visual Features by Contrasting Cluster Assignments",
            "url":"\/paper\/unsupervised-learning-of-visual-features-by",
            "published":"2020-06-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/unsupervised-learning-of-visual-features-by\/review\/?hl=17643"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            },
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":31083,
        "rank":62,
        "method":"DINO (ResNet-50)",
        "mlmodel":{

        },
        "Model":"DINO ",
        "method_details":"ResNet-50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-29",
        "metrics":{
            "Top 1 Accuracy":"75.3%",
            "Top 5 Accuracy":null,
            "Number of Params":"24M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":75.3,
            "Top 5 Accuracy":null,
            "Number of Params":24000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":789002,
            "title":"Emerging Properties in Self-Supervised Vision Transformers",
            "url":"\/paper\/emerging-properties-in-self-supervised-vision",
            "published":"2021-04-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/emerging-properties-in-self-supervised-vision\/review\/?hl=31083"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":17574,
        "rank":63,
        "method":"InfoMin (ResNeXt-152)",
        "mlmodel":{

        },
        "Model":"InfoMin ",
        "method_details":"ResNeXt-152",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-20",
        "metrics":{
            "Top 1 Accuracy":"75.2%",
            "Top 5 Accuracy":null,
            "Number of Params":"120M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":75.2,
            "Top 5 Accuracy":null,
            "Number of Params":120000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":195774,
            "title":"What Makes for Good Views for Contrastive Learning?",
            "url":"\/paper\/what-makes-for-good-views-for-contrastive",
            "published":"2020-05-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/what-makes-for-good-views-for-contrastive\/review\/?hl=17574"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":6,
                "name":"ResNeXt",
                "color":"#86960b"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":21010,
        "rank":64,
        "method":"DeepCluster-v2 (ResNet-50)",
        "mlmodel":{

        },
        "Model":"DeepCluster-v2 ",
        "method_details":"ResNet-50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-06-17",
        "metrics":{
            "Top 1 Accuracy":"75.2%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":75.2,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":202916,
            "title":"Unsupervised Learning of Visual Features by Contrasting Cluster Assignments",
            "url":"\/paper\/unsupervised-learning-of-visual-features-by",
            "published":"2020-06-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/unsupervised-learning-of-visual-features-by\/review\/?hl=21010"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":32072,
        "rank":65,
        "method":"MoBY (Swin-T)",
        "mlmodel":{

        },
        "Model":"MoBY ",
        "method_details":"Swin-T",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-05-10",
        "metrics":{
            "Top 1 Accuracy":"75%",
            "Top 5 Accuracy":null,
            "Number of Params":"29M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":75.0,
            "Top 5 Accuracy":null,
            "Number of Params":29000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":796086,
            "title":"Self-Supervised Learning with Swin Transformers",
            "url":"\/paper\/self-supervised-learning-with-swin",
            "published":"2021-05-10T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/self-supervised-learning-with-swin\/review\/?hl=32072"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":101653,
        "rank":66,
        "method":"Unicom (ViT-B\/32)",
        "mlmodel":{

        },
        "Model":"Unicom ",
        "method_details":"ViT-B\/32",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-04-12",
        "metrics":{
            "Top 1 Accuracy":"75.0%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":75.0,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":1190273,
            "title":"Unicom: Universal and Compact Representation Learning for Image Retrieval",
            "url":"\/paper\/unicom-universal-and-compact-representation",
            "published":"2023-04-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/unicom-universal-and-compact-representation\/review\/?hl=101653"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":426,
                "name":"Train without ImageNet1K",
                "color":"#27b6d3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":35270,
        "rank":67,
        "method":"ReLIC (ResNet-50)",
        "mlmodel":{

        },
        "Model":"ReLIC ",
        "method_details":"ResNet-50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-10-15",
        "metrics":{
            "Top 1 Accuracy":"74.8%",
            "Top 5 Accuracy":null,
            "Number of Params":"24M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":74.8,
            "Top 5 Accuracy":null,
            "Number of Params":24000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":227823,
            "title":"Representation Learning via Invariant Causal Mechanisms",
            "url":"\/paper\/representation-learning-via-invariant-causal-1",
            "published":"2020-10-15T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/representation-learning-via-invariant-causal-1\/review\/?hl=35270"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":37641,
        "rank":68,
        "method":"ReSSL(ResNet-50)  200ep",
        "mlmodel":{

        },
        "Model":"ReSSL",
        "method_details":"ResNet-50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-07-20",
        "metrics":{
            "Top 1 Accuracy":"74.7%",
            "Top 5 Accuracy":"92.3%",
            "Number of Params":"24M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":74.7,
            "Top 5 Accuracy":92.3,
            "Number of Params":24000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":838589,
            "title":"ReSSL: Relational Self-Supervised Learning with Weak Augmentation",
            "url":"\/paper\/ressl-relational-self-supervised-learning",
            "published":"2021-07-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/ressl-relational-self-supervised-learning\/review\/?hl=37641"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":41143,
        "rank":69,
        "method":"WCL (ResNet-50)",
        "mlmodel":{

        },
        "Model":"WCL ",
        "method_details":"ResNet-50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-10-10",
        "metrics":{
            "Top 1 Accuracy":"74.7%",
            "Top 5 Accuracy":null,
            "Number of Params":"24M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":74.7,
            "Top 5 Accuracy":null,
            "Number of Params":24000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":885979,
            "title":"Weakly Supervised Contrastive Learning",
            "url":"\/paper\/weakly-supervised-contrastive-learning-1",
            "published":"2021-10-10T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/weakly-supervised-contrastive-learning-1\/review\/?hl=41143"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":22035,
        "rank":70,
        "method":"FNC (ResNet-50)",
        "mlmodel":{

        },
        "Model":"FNC ",
        "method_details":"ResNet-50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-11-23",
        "metrics":{
            "Top 1 Accuracy":"74.4%",
            "Top 5 Accuracy":"91.8%",
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":74.4,
            "Top 5 Accuracy":91.8,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":237224,
            "title":"Boosting Contrastive Self-Supervised Learning with False Negative Cancellation",
            "url":"\/paper\/boosting-contrastive-self-supervised-learning",
            "published":"2020-11-23T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/boosting-contrastive-self-supervised-learning\/review\/?hl=22035"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            },
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":17304,
        "rank":71,
        "method":"BYOL (ResNet-50)",
        "mlmodel":{

        },
        "Model":"BYOL ",
        "method_details":"ResNet-50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-06-13",
        "metrics":{
            "Top 1 Accuracy":"74.3%",
            "Top 5 Accuracy":"91.6%",
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":74.3,
            "Top 5 Accuracy":91.6,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":202435,
            "title":"Bootstrap your own latent: A new approach to self-supervised Learning",
            "url":"\/paper\/bootstrap-your-own-latent-a-new-approach-to",
            "published":"2020-06-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/bootstrap-your-own-latent-a-new-approach-to\/review\/?hl=17304"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            },
            {
                "id":95,
                "name":"ResNet-50x1",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":9940,
        "rank":72,
        "method":"SimCLR (ResNet-50 2x)",
        "mlmodel":{

        },
        "Model":"SimCLR ",
        "method_details":"ResNet-50 2x",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-02-13",
        "metrics":{
            "Top 1 Accuracy":"74.2%",
            "Top 5 Accuracy":"92.0%",
            "Number of Params":"94M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":74.2,
            "Top 5 Accuracy":92.0,
            "Number of Params":94000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":183167,
            "title":"A Simple Framework for Contrastive Learning of Visual Representations",
            "url":"\/paper\/a-simple-framework-for-contrastive-learning",
            "published":"2020-02-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/a-simple-framework-for-contrastive-learning\/review\/?hl=9940"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":73384,
        "rank":73,
        "method":"Self-Classifier (ResNet-50)",
        "mlmodel":{

        },
        "Model":"Self-Classifier ",
        "method_details":"ResNet-50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-03-19",
        "metrics":{
            "Top 1 Accuracy":"74.2%",
            "Top 5 Accuracy":null,
            "Number of Params":"24M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":74.2,
            "Top 5 Accuracy":null,
            "Number of Params":24000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":755954,
            "title":"Self-Supervised Classification Network",
            "url":"\/paper\/self-supervised-classification-network",
            "published":"2021-03-19T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/self-supervised-classification-network\/review\/?hl=73384"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            },
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":23612,
        "rank":74,
        "method":"OBoW (ResNet-50)",
        "mlmodel":{

        },
        "Model":"OBoW ",
        "method_details":"ResNet-50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-11-30",
        "metrics":{
            "Top 1 Accuracy":"73.8%",
            "Top 5 Accuracy":"92.2%",
            "Number of Params":"24M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":73.8,
            "Top 5 Accuracy":92.2,
            "Number of Params":24000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":729820,
            "title":"OBoW: Online Bag-of-Visual-Words Generation for Self-Supervised Learning",
            "url":"\/paper\/online-bag-of-visual-words-generation-for",
            "published":"2020-12-21T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":46847,
        "rank":75,
        "method":"VICReg (ResNet50)",
        "mlmodel":{

        },
        "Model":"VICReg ",
        "method_details":"ResNet50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-05-11",
        "metrics":{
            "Top 1 Accuracy":"73.2",
            "Top 5 Accuracy":"91.1",
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":73.2,
            "Top 5 Accuracy":91.1,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":797293,
            "title":"VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning",
            "url":"\/paper\/vicreg-variance-invariance-covariance",
            "published":"2021-05-11T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/vicreg-variance-invariance-covariance\/review\/?hl=46847"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":28369,
        "rank":76,
        "method":"Barlow Twins (ResNet-50)",
        "mlmodel":{

        },
        "Model":"Barlow Twins ",
        "method_details":"ResNet-50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-03-04",
        "metrics":{
            "Top 1 Accuracy":"73.2%",
            "Top 5 Accuracy":"91%",
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":73.2,
            "Top 5 Accuracy":91.0,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":750717,
            "title":"Barlow Twins: Self-Supervised Learning via Redundancy Reduction",
            "url":"\/paper\/barlow-twins-self-supervised-learning-via",
            "published":"2021-03-04T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/barlow-twins-self-supervised-learning-via\/review\/?hl=28369"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            },
            {
                "id":95,
                "name":"ResNet-50x1",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":16616,
        "rank":77,
        "method":"InfoMin (ResNet-50)",
        "mlmodel":{

        },
        "Model":"InfoMin ",
        "method_details":"ResNet-50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-20",
        "metrics":{
            "Top 1 Accuracy":"73.0%",
            "Top 5 Accuracy":"91.1%",
            "Number of Params":"24M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":73.0,
            "Top 5 Accuracy":91.1,
            "Number of Params":24000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":195774,
            "title":"What Makes for Good Views for Contrastive Learning?",
            "url":"\/paper\/what-makes-for-good-views-for-contrastive",
            "published":"2020-05-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/what-makes-for-good-views-for-contrastive\/review\/?hl=16616"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            },
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":34967,
        "rank":78,
        "method":"DINO (ResMLP-24)",
        "mlmodel":{

        },
        "Model":"DINO ",
        "method_details":"ResMLP-24",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-05-07",
        "metrics":{
            "Top 1 Accuracy":"72.8%",
            "Top 5 Accuracy":null,
            "Number of Params":"30M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":72.8,
            "Top 5 Accuracy":null,
            "Number of Params":30000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":795412,
            "title":"ResMLP: Feedforward networks for image classification with data-efficient training",
            "url":"\/paper\/resmlp-feedforward-networks-for-image",
            "published":"2021-05-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/resmlp-feedforward-networks-for-image\/review\/?hl=34967"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":32074,
        "rank":79,
        "method":"MoBY (DeiT-S)",
        "mlmodel":{

        },
        "Model":"MoBY ",
        "method_details":"DeiT-S",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-05-10",
        "metrics":{
            "Top 1 Accuracy":"72.8%",
            "Top 5 Accuracy":null,
            "Number of Params":"22M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":72.8,
            "Top 5 Accuracy":null,
            "Number of Params":22000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":796086,
            "title":"Self-Supervised Learning with Swin Transformers",
            "url":"\/paper\/self-supervised-learning-with-swin",
            "published":"2021-05-10T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/self-supervised-learning-with-swin\/review\/?hl=32074"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":100674,
        "rank":80,
        "method":"I-VNE+ (ResNet-50)",
        "mlmodel":{

        },
        "Model":"I-VNE+ ",
        "method_details":"ResNet-50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-04",
        "metrics":{
            "Top 1 Accuracy":"72.1",
            "Top 5 Accuracy":"91.0",
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":72.1,
            "Top 5 Accuracy":91.0,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1185949,
            "title":"VNE: An Effective Method for Improving Deep Representation by Manipulating Eigenvalue Distribution",
            "url":"\/paper\/vne-an-effective-method-for-improving-deep",
            "published":"2023-04-04T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/vne-an-effective-method-for-improving-deep\/review\/?hl=100674"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":17379,
        "rank":81,
        "method":"iGPT-XL (64x64, 15360 features)",
        "mlmodel":{

        },
        "Model":"iGPT-XL ",
        "method_details":"64x64, 15360 features",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-07-17",
        "metrics":{
            "Top 1 Accuracy":"72.0%",
            "Top 5 Accuracy":null,
            "Number of Params":"6801M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":72.0,
            "Top 5 Accuracy":null,
            "Number of Params":6801000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":203073,
            "title":"Generative Pretraining from Pixels",
            "url":"\/paper\/generative-pretraining-from-pixels",
            "published":"2020-07-17T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":17364,
        "rank":82,
        "method":"SimCLRv2 (ResNet-50)",
        "mlmodel":{

        },
        "Model":"SimCLRv2 ",
        "method_details":"ResNet-50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-06-17",
        "metrics":{
            "Top 1 Accuracy":"71.7%",
            "Top 5 Accuracy":"90.4%",
            "Number of Params":"24M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":71.7,
            "Top 5 Accuracy":90.4,
            "Number of Params":24000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":202875,
            "title":"Big Self-Supervised Models are Strong Semi-Supervised Learners",
            "url":"\/paper\/big-self-supervised-models-are-strong-semi",
            "published":"2020-06-17T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/big-self-supervised-models-are-strong-semi\/review\/?hl=17364"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            },
            {
                "id":95,
                "name":"ResNet-50x1",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":9943,
        "rank":83,
        "method":"CPC v2 (ResNet-161)",
        "mlmodel":{

        },
        "Model":"CPC v2 ",
        "method_details":"ResNet-161",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-05-22",
        "metrics":{
            "Top 1 Accuracy":"71.5%",
            "Top 5 Accuracy":"90.1",
            "Number of Params":"305M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":71.5,
            "Top 5 Accuracy":90.1,
            "Number of Params":305000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":116646,
            "title":"Data-Efficient Image Recognition with Contrastive Predictive Coding",
            "url":"\/paper\/data-efficient-image-recognition-with",
            "published":"2019-05-22T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/data-efficient-image-recognition-with\/review\/?hl=9943"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":35366,
        "rank":84,
        "method":"SimSiam (ResNet-50)",
        "mlmodel":{

        },
        "Model":"SimSiam ",
        "method_details":"ResNet-50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-11-20",
        "metrics":{
            "Top 1 Accuracy":"71.3%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":71.3,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":236645,
            "title":"Exploring Simple Siamese Representation Learning",
            "url":"\/paper\/exploring-simple-siamese-representation",
            "published":"2020-11-20T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/exploring-simple-siamese-representation\/review\/?hl=35366"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":95,
                "name":"ResNet-50x1",
                "color":"#2771D3"
            },
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":10270,
        "rank":85,
        "method":"MoCo v2 (ResNet-50)",
        "mlmodel":{

        },
        "Model":"MoCo v2 ",
        "method_details":"ResNet-50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-03-09",
        "metrics":{
            "Top 1 Accuracy":"71.1%",
            "Top 5 Accuracy":"90.1%",
            "Number of Params":"24M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":71.1,
            "Top 5 Accuracy":90.1,
            "Number of Params":24000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":186308,
            "title":"Improved Baselines with Momentum Contrastive Learning",
            "url":"\/paper\/improved-baselines-with-momentum-contrastive",
            "published":"2020-03-09T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/improved-baselines-with-momentum-contrastive\/review\/?hl=10270"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            },
            {
                "id":95,
                "name":"ResNet-50x1",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":9949,
        "rank":86,
        "method":"CMC (ResNet-50 x2)",
        "mlmodel":{

        },
        "Model":"CMC ",
        "method_details":"ResNet-50 x2",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-06-13",
        "metrics":{
            "Top 1 Accuracy":"70.6%",
            "Top 5 Accuracy":"89.7%",
            "Number of Params":"188M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":70.6,
            "Top 5 Accuracy":89.7,
            "Number of Params":188000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":142555,
            "title":"Contrastive Multiview Coding",
            "url":"\/paper\/contrastive-multiview-coding",
            "published":"2019-06-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/contrastive-multiview-coding\/review\/?hl=9949"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":9941,
        "rank":87,
        "method":"SimCLR (ResNet-50)",
        "mlmodel":{

        },
        "Model":"SimCLR ",
        "method_details":"ResNet-50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-02-13",
        "metrics":{
            "Top 1 Accuracy":"69.3%",
            "Top 5 Accuracy":"89.0%",
            "Number of Params":"24M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":69.3,
            "Top 5 Accuracy":89.0,
            "Number of Params":24000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":183167,
            "title":"A Simple Framework for Contrastive Learning of Visual Representations",
            "url":"\/paper\/a-simple-framework-for-contrastive-learning",
            "published":"2020-02-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/a-simple-framework-for-contrastive-learning\/review\/?hl=9941"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            },
            {
                "id":95,
                "name":"ResNet-50x1",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":17378,
        "rank":88,
        "method":"iGPT-XL (64x64, 3072 features)",
        "mlmodel":{

        },
        "Model":"iGPT-XL ",
        "method_details":"64x64, 3072 features",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-07-17",
        "metrics":{
            "Top 1 Accuracy":"68.7%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":68.7,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":203073,
            "title":"Generative Pretraining from Pixels",
            "url":"\/paper\/generative-pretraining-from-pixels",
            "published":"2020-07-17T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":9944,
        "rank":89,
        "method":"MoCo (ResNet-50 4x)",
        "mlmodel":{

        },
        "Model":"MoCo ",
        "method_details":"ResNet-50 4x",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-11-13",
        "metrics":{
            "Top 1 Accuracy":"68.6%",
            "Top 5 Accuracy":null,
            "Number of Params":"375M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":68.6,
            "Top 5 Accuracy":null,
            "Number of Params":375000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":172144,
            "title":"Momentum Contrast for Unsupervised Visual Representation Learning",
            "url":"\/paper\/momentum-contrast-for-unsupervised-visual",
            "published":"2019-11-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/momentum-contrast-for-unsupervised-visual\/review\/?hl=9944"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":9950,
        "rank":90,
        "method":"AMDIM (large)",
        "mlmodel":{

        },
        "Model":"AMDIM ",
        "method_details":"large",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-06-03",
        "metrics":{
            "Top 1 Accuracy":"68.1%",
            "Top 5 Accuracy":null,
            "Number of Params":"626M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":68.1,
            "Top 5 Accuracy":null,
            "Number of Params":626000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":118410,
            "title":"Learning Representations by Maximizing Mutual Information Across Views",
            "url":"\/paper\/190600910",
            "published":"2019-06-03T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":44092,
        "rank":91,
        "method":"MAE (ViT-B)",
        "mlmodel":{

        },
        "Model":"MAE ",
        "method_details":"ViT-B",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-11-11",
        "metrics":{
            "Top 1 Accuracy":"68.0%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":68.0,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":908690,
            "title":"Masked Autoencoders Are Scalable Vision Learners",
            "url":"\/paper\/masked-autoencoders-are-scalable-vision",
            "published":"2021-11-11T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/masked-autoencoders-are-scalable-vision\/review\/?hl=44092"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":34966,
        "rank":92,
        "method":"DINO (ResMLP-12)",
        "mlmodel":{

        },
        "Model":"DINO ",
        "method_details":"ResMLP-12",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-05-07",
        "metrics":{
            "Top 1 Accuracy":"67.5%",
            "Top 5 Accuracy":null,
            "Number of Params":"15M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":67.5,
            "Top 5 Accuracy":null,
            "Number of Params":15000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":795412,
            "title":"ResMLP: Feedforward networks for image classification with data-efficient training",
            "url":"\/paper\/resmlp-feedforward-networks-for-image",
            "published":"2021-05-07T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/resmlp-feedforward-networks-for-image\/review\/?hl=34966"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":9947,
        "rank":93,
        "method":"CMC (ResNet-50)",
        "mlmodel":{

        },
        "Model":"CMC ",
        "method_details":"ResNet-50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-06-13",
        "metrics":{
            "Top 1 Accuracy":"66.2%",
            "Top 5 Accuracy":"87.0%",
            "Number of Params":"47M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":66.2,
            "Top 5 Accuracy":87.0,
            "Number of Params":47000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":142555,
            "title":"Contrastive Multiview Coding",
            "url":"\/paper\/contrastive-multiview-coding",
            "published":"2019-06-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/contrastive-multiview-coding\/review\/?hl=9947"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            },
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":16179,
        "rank":94,
        "method":"PCL (ResNet-50)",
        "mlmodel":{

        },
        "Model":"PCL ",
        "method_details":"ResNet-50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-05-11",
        "metrics":{
            "Top 1 Accuracy":"65.9%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":65.9,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":194453,
            "title":"Prototypical Contrastive Learning of Unsupervised Representations",
            "url":"\/paper\/prototypical-contrastive-learning-of",
            "published":"2020-05-11T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/prototypical-contrastive-learning-of\/review\/?hl=16179"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            },
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":9945,
        "rank":95,
        "method":"MoCo (ResNet-50 2x)",
        "mlmodel":{

        },
        "Model":"MoCo ",
        "method_details":"ResNet-50 2x",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-11-13",
        "metrics":{
            "Top 1 Accuracy":"65.4%",
            "Top 5 Accuracy":null,
            "Number of Params":"94M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":65.4,
            "Top 5 Accuracy":null,
            "Number of Params":94000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":172144,
            "title":"Momentum Contrast for Unsupervised Visual Representation Learning",
            "url":"\/paper\/momentum-contrast-for-unsupervised-visual",
            "published":"2019-11-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/momentum-contrast-for-unsupervised-visual\/review\/?hl=9945"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":17377,
        "rank":96,
        "method":"iGPT-L (48x48)",
        "mlmodel":{

        },
        "Model":"iGPT-L ",
        "method_details":"48x48",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-07-17",
        "metrics":{
            "Top 1 Accuracy":"65.2%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":65.2,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":203073,
            "title":"Generative Pretraining from Pixels",
            "url":"\/paper\/generative-pretraining-from-pixels",
            "published":"2020-07-17T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":9948,
        "rank":97,
        "method":"CMC (ResNet-101)-deprecated",
        "mlmodel":{

        },
        "Model":"CMC ",
        "method_details":"ResNet-101",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-06-13",
        "metrics":{
            "Top 1 Accuracy":"65.0%",
            "Top 5 Accuracy":"86.0%",
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":65.0,
            "Top 5 Accuracy":86.0,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":142555,
            "title":"Contrastive Multiview Coding",
            "url":"\/paper\/contrastive-multiview-coding",
            "published":"2019-06-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/contrastive-multiview-coding\/review\/?hl=9948"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":9942,
        "rank":98,
        "method":"CPC v2 (ResNet-50)",
        "mlmodel":{

        },
        "Model":"CPC v2 ",
        "method_details":"ResNet-50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-05-22",
        "metrics":{
            "Top 1 Accuracy":"63.8%",
            "Top 5 Accuracy":"85.3%",
            "Number of Params":"24M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":63.8,
            "Top 5 Accuracy":85.3,
            "Number of Params":24000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":116646,
            "title":"Data-Efficient Image Recognition with Contrastive Predictive Coding",
            "url":"\/paper\/data-efficient-image-recognition-with",
            "published":"2019-05-22T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/data-efficient-image-recognition-with\/review\/?hl=9942"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":95,
                "name":"ResNet-50x1",
                "color":"#2771D3"
            },
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":53648,
        "rank":99,
        "method":"MMCL (100 epoch, 256 batch size)",
        "mlmodel":{

        },
        "Model":"MMCL ",
        "method_details":"100 epoch, 256 batch size",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-12-21",
        "metrics":{
            "Top 1 Accuracy":"63.8%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":63.8,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":932445,
            "title":"Max-Margin Contrastive Learning",
            "url":"\/paper\/max-margin-contrastive-learning",
            "published":"2021-12-21T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            },
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":9956,
        "rank":100,
        "method":"PIRL",
        "mlmodel":{

        },
        "Model":"PIRL",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-12-04",
        "metrics":{
            "Top 1 Accuracy":"63.6%",
            "Top 5 Accuracy":null,
            "Number of Params":"24M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":63.6,
            "Top 5 Accuracy":null,
            "Number of Params":24000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":175424,
            "title":"Self-Supervised Learning of Pretext-Invariant Representations",
            "url":"\/paper\/self-supervised-learning-of-pretext-invariant",
            "published":"2019-12-04T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/self-supervised-learning-of-pretext-invariant\/review\/?hl=9956"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":9951,
        "rank":101,
        "method":"AMDIM (small)",
        "mlmodel":{

        },
        "Model":"AMDIM ",
        "method_details":"small",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-06-03",
        "metrics":{
            "Top 1 Accuracy":"63.5%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":63.5,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":118410,
            "title":"Learning Representations by Maximizing Mutual Information Across Views",
            "url":"\/paper\/190600910",
            "published":"2019-06-03T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":17837,
        "rank":102,
        "method":"SeLa",
        "mlmodel":{

        },
        "Model":"SeLa",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-11-13",
        "metrics":{
            "Top 1 Accuracy":"61.5%",
            "Top 5 Accuracy":"84.0%",
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":61.5,
            "Top 5 Accuracy":84.0,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":172188,
            "title":"Self-labelling via simultaneous clustering and representation learning",
            "url":"\/paper\/self-labelling-via-simultaneous-clustering-1",
            "published":"2019-11-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/self-labelling-via-simultaneous-clustering-1\/review\/?hl=17837"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":9955,
        "rank":103,
        "method":"BigBiGAN (RevNet-50 \u00d74, BN+CReLU)",
        "mlmodel":{

        },
        "Model":"BigBiGAN ",
        "method_details":"RevNet-50 \u00d74, BN+CReLU",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-07-04",
        "metrics":{
            "Top 1 Accuracy":"61.3%",
            "Top 5 Accuracy":"81.9%",
            "Number of Params":"86M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":61.3,
            "Top 5 Accuracy":81.9,
            "Number of Params":86000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":145004,
            "title":"Large Scale Adversarial Representation Learning",
            "url":"\/paper\/large-scale-adversarial-representation",
            "published":"2019-07-04T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/large-scale-adversarial-representation\/review\/?hl=9955"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":23,
                "name":"GAN",
                "color":"#9d27d3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":9954,
        "rank":104,
        "method":"BigBiGAN (RevNet-50 \u00d74)",
        "mlmodel":{

        },
        "Model":"BigBiGAN ",
        "method_details":"RevNet-50 \u00d74",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-07-04",
        "metrics":{
            "Top 1 Accuracy":"60.8%",
            "Top 5 Accuracy":"81.4%",
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":60.8,
            "Top 5 Accuracy":81.4,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":145004,
            "title":"Large Scale Adversarial Representation Learning",
            "url":"\/paper\/large-scale-adversarial-representation",
            "published":"2019-07-04T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/large-scale-adversarial-representation\/review\/?hl=9954"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":23,
                "name":"GAN",
                "color":"#9d27d3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":9946,
        "rank":105,
        "method":"MoCo (ResNet-50)",
        "mlmodel":{

        },
        "Model":"MoCo ",
        "method_details":"ResNet-50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-11-13",
        "metrics":{
            "Top 1 Accuracy":"60.6%",
            "Top 5 Accuracy":null,
            "Number of Params":"24M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":60.6,
            "Top 5 Accuracy":null,
            "Number of Params":24000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":172144,
            "title":"Momentum Contrast for Unsupervised Visual Representation Learning",
            "url":"\/paper\/momentum-contrast-for-unsupervised-visual",
            "published":"2019-11-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/momentum-contrast-for-unsupervised-visual\/review\/?hl=9946"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            },
            {
                "id":95,
                "name":"ResNet-50x1",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":17376,
        "rank":106,
        "method":"iGPT-L (32x32)",
        "mlmodel":{

        },
        "Model":"iGPT-L ",
        "method_details":"32x32",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2020-07-17",
        "metrics":{
            "Top 1 Accuracy":"60.3%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":60.3,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":203073,
            "title":"Generative Pretraining from Pixels",
            "url":"\/paper\/generative-pretraining-from-pixels",
            "published":"2020-07-17T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":4,
                "name":"Transformer",
                "color":"#0037CC"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":16180,
        "rank":107,
        "method":"LocalAgg (ResNet-50)",
        "mlmodel":{

        },
        "Model":"LocalAgg ",
        "method_details":"ResNet-50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-03-29",
        "metrics":{
            "Top 1 Accuracy":"60.2%",
            "Top 5 Accuracy":null,
            "Number of Params":"24M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":60.2,
            "Top 5 Accuracy":null,
            "Number of Params":24000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":109861,
            "title":"Local Aggregation for Unsupervised Learning of Visual Embeddings",
            "url":"\/paper\/local-aggregation-for-unsupervised-learning",
            "published":"2019-03-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/local-aggregation-for-unsupervised-learning\/review\/?hl=16180"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":9953,
        "rank":108,
        "method":"BigBiGAN (ResNet-50, BN+CReLU)",
        "mlmodel":{

        },
        "Model":"BigBiGAN ",
        "method_details":"ResNet-50, BN+CReLU",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-07-04",
        "metrics":{
            "Top 1 Accuracy":"56.6%",
            "Top 5 Accuracy":"78.6%",
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":56.6,
            "Top 5 Accuracy":78.6,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":145004,
            "title":"Large Scale Adversarial Representation Learning",
            "url":"\/paper\/large-scale-adversarial-representation",
            "published":"2019-07-04T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/large-scale-adversarial-representation\/review\/?hl=9953"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":23,
                "name":"GAN",
                "color":"#9d27d3"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":10624,
        "rank":109,
        "method":"Revisited Rotation (RevNet-50 \u00d74)",
        "mlmodel":{

        },
        "Model":"Revisited Rotation ",
        "method_details":"RevNet-50 \u00d74",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-01-25",
        "metrics":{
            "Top 1 Accuracy":"55.4%",
            "Top 5 Accuracy":"77.9%",
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":55.4,
            "Top 5 Accuracy":77.9,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":88377,
            "title":"Revisiting Self-Supervised Visual Representation Learning",
            "url":"\/paper\/revisiting-self-supervised-visual",
            "published":"2019-01-25T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/revisiting-self-supervised-visual\/review\/?hl=10624"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":9952,
        "rank":110,
        "method":"BigBiGAN (ResNet-50)",
        "mlmodel":{

        },
        "Model":"BigBiGAN ",
        "method_details":"ResNet-50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-07-04",
        "metrics":{
            "Top 1 Accuracy":"55.4%",
            "Top 5 Accuracy":"77.4%",
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":55.4,
            "Top 5 Accuracy":77.4,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":145004,
            "title":"Large Scale Adversarial Representation Learning",
            "url":"\/paper\/large-scale-adversarial-representation",
            "published":"2019-07-04T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/large-scale-adversarial-representation\/review\/?hl=9952"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            },
            {
                "id":23,
                "name":"GAN",
                "color":"#9d27d3"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":16181,
        "rank":111,
        "method":"InstDisc (ResNet-50)",
        "mlmodel":{

        },
        "Model":"InstDisc ",
        "method_details":"ResNet-50",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-06-01",
        "metrics":{
            "Top 1 Accuracy":"54.0%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":54.0,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":81384,
            "title":"Unsupervised Feature Learning via Non-Parametric Instance Discrimination",
            "url":"\/paper\/unsupervised-feature-learning-via-non-1",
            "published":"2018-06-01T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[
            {
                "id":33,
                "name":"ResNet-50",
                "color":"#c17b9b"
            },
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":10626,
        "rank":112,
        "method":"Revisited Rel.Patch.Loc (ResNet50v1 \u00d72)",
        "mlmodel":{

        },
        "Model":"Revisited Rel.Patch.Loc ",
        "method_details":"ResNet50v1 \u00d72",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-01-25",
        "metrics":{
            "Top 1 Accuracy":"51.4%",
            "Top 5 Accuracy":"74.0%",
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":51.4,
            "Top 5 Accuracy":74.0,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":88377,
            "title":"Revisiting Self-Supervised Visual Representation Learning",
            "url":"\/paper\/revisiting-self-supervised-visual",
            "published":"2019-01-25T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/revisiting-self-supervised-visual\/review\/?hl=10626"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":9957,
        "rank":113,
        "method":"CPC (ResNet-101 V2)",
        "mlmodel":{

        },
        "Model":"CPC ",
        "method_details":"ResNet-101 V2",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-07-10",
        "metrics":{
            "Top 1 Accuracy":"48.7%",
            "Top 5 Accuracy":"73.6%",
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":48.7,
            "Top 5 Accuracy":73.6,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":52310,
            "title":"Representation Learning with Contrastive Predictive Coding",
            "url":"\/paper\/representation-learning-with-contrastive",
            "published":"2018-07-10T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/representation-learning-with-contrastive\/review\/?hl=9957"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":25,
                "name":"Contrastive",
                "color":"#995d0b"
            },
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":17838,
        "rank":114,
        "method":"SeLa (AlexNet)",
        "mlmodel":{

        },
        "Model":"SeLa ",
        "method_details":"AlexNet",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-11-13",
        "metrics":{
            "Top 1 Accuracy":"48.4%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":48.4,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":172188,
            "title":"Self-labelling via simultaneous clustering and representation learning",
            "url":"\/paper\/self-labelling-via-simultaneous-clustering-1",
            "published":"2019-11-13T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/self-labelling-via-simultaneous-clustering-1\/review\/?hl=17838"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":7,
                "name":"AlexNet",
                "color":"#ffb005"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":10625,
        "rank":115,
        "method":"Revisited Exemplar (ResNet-50v1 \u00d73)",
        "mlmodel":{

        },
        "Model":"Revisited Exemplar ",
        "method_details":"ResNet-50v1 \u00d73",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-01-25",
        "metrics":{
            "Top 1 Accuracy":"46.0%",
            "Top 5 Accuracy":"68.8%",
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":46.0,
            "Top 5 Accuracy":68.8,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":88377,
            "title":"Revisiting Self-Supervised Visual Representation Learning",
            "url":"\/paper\/revisiting-self-supervised-visual",
            "published":"2019-01-25T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/revisiting-self-supervised-visual\/review\/?hl=10625"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":10627,
        "rank":116,
        "method":"Revisited Jigsaw (ResNet50v1 \u00d72)",
        "mlmodel":{

        },
        "Model":"Revisited Jigsaw ",
        "method_details":"ResNet50v1 \u00d72",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2019-01-25",
        "metrics":{
            "Top 1 Accuracy":"44.6%",
            "Top 5 Accuracy":"68.0%",
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":44.6,
            "Top 5 Accuracy":68.0,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":88377,
            "title":"Revisiting Self-Supervised Visual Representation Learning",
            "url":"\/paper\/revisiting-self-supervised-visual",
            "published":"2019-01-25T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/revisiting-self-supervised-visual\/review\/?hl=10627"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":3,
                "name":"ResNet",
                "color":"#2771D3"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":27540,
        "rank":117,
        "method":"Rotation (RevNet50-4w)",
        "mlmodel":{

        },
        "Model":"Rotation ",
        "method_details":"RevNet50-4w",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2018-03-21",
        "metrics":{
            "Top 1 Accuracy":"36.5",
            "Top 5 Accuracy":null,
            "Number of Params":"86M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":36.5,
            "Top 5 Accuracy":null,
            "Number of Params":86000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":7859,
            "title":"Unsupervised Representation Learning by Predicting Image Rotations",
            "url":"\/paper\/unsupervised-representation-learning-by-1",
            "published":"2018-03-21T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/unsupervised-representation-learning-by-1\/review\/?hl=27540"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":72998,
        "rank":118,
        "method":"Split-Brain (AlexNet)",
        "mlmodel":{

        },
        "Model":"Split-Brain ",
        "method_details":"AlexNet",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2016-11-29",
        "metrics":{
            "Top 1 Accuracy":"35.4%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":35.4,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":23842,
            "title":"Split-Brain Autoencoders: Unsupervised Learning by Cross-Channel Prediction",
            "url":"\/paper\/split-brain-autoencoders-unsupervised",
            "published":"2016-11-29T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/split-brain-autoencoders-unsupervised\/review\/?hl=72998"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":13258,
        "rank":119,
        "method":"Colorization (AlexNet)",
        "mlmodel":{

        },
        "Model":"Colorization ",
        "method_details":"AlexNet",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2016-03-28",
        "metrics":{
            "Top 1 Accuracy":"32.6%",
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "raw_metrics":{
            "Top 1 Accuracy":32.6,
            "Top 5 Accuracy":null,
            "Number of Params":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":29941,
            "title":"Colorful Image Colorization",
            "url":"\/paper\/colorful-image-colorization",
            "published":"2016-03-28T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/colorful-image-colorization\/review\/?hl=13258"
        },
        "external_source_url":null,
        "tags":[
            {
                "id":7,
                "name":"AlexNet",
                "color":"#ffb005"
            }
        ],
        "reports":[

        ]
    },
    {
        "table_id":1714,
        "row_id":40869,
        "rank":120,
        "method":"MoCo v3 (ViT-H\uff09",
        "mlmodel":{

        },
        "Model":"MoCo v3 ",
        "method_details":"ViT-H\uff09",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-04-05",
        "metrics":{
            "Top 1 Accuracy":null,
            "Top 5 Accuracy":null,
            "Number of Params":"632M"
        },
        "raw_metrics":{
            "Top 1 Accuracy":null,
            "Top 5 Accuracy":null,
            "Number of Params":632000000.0
        },
        "uses_additional_data":false,
        "paper":{
            "id":774854,
            "title":"An Empirical Study of Training Self-Supervised Vision Transformers",
            "url":"\/paper\/an-empirical-study-of-training-self",
            "published":"2021-04-05T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/an-empirical-study-of-training-self\/review\/?hl=40869"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]