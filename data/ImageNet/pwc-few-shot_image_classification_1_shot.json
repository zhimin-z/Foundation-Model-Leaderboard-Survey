[
    {
        "table_id":9955,
        "row_id":34963,
        "rank":1,
        "Model":"ViT-MoE-15B (Every-2)",
        "mlmodel":{

        },
        "method_short":"ViT-MoE-15B ",
        "method_details":"Every-2",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-06-10",
        "metrics":{
            "Top 1 Accuracy":"68.66"
        },
        "raw_metrics":{
            "Top 1 Accuracy":68.66
        },
        "uses_additional_data":false,
        "paper":{
            "id":816109,
            "title":"Scaling Vision with Sparse Mixture of Experts",
            "url":"\/paper\/scaling-vision-with-sparse-mixture-of-experts",
            "published":"2021-06-10T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/scaling-vision-with-sparse-mixture-of-experts\/review\/?hl=34963"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":9955,
        "row_id":34959,
        "rank":2,
        "Model":"V-MoE-H\/14 (Every-2)",
        "mlmodel":{

        },
        "method_short":"V-MoE-H\/14 ",
        "method_details":"Every-2",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-06-10",
        "metrics":{
            "Top 1 Accuracy":"63.38"
        },
        "raw_metrics":{
            "Top 1 Accuracy":63.38
        },
        "uses_additional_data":false,
        "paper":{
            "id":816109,
            "title":"Scaling Vision with Sparse Mixture of Experts",
            "url":"\/paper\/scaling-vision-with-sparse-mixture-of-experts",
            "published":"2021-06-10T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/scaling-vision-with-sparse-mixture-of-experts\/review\/?hl=34959"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":9955,
        "row_id":34954,
        "rank":3,
        "Model":"V-MoE-H\/14 (Last-5)",
        "mlmodel":{

        },
        "method_short":"V-MoE-H\/14 ",
        "method_details":"Last-5",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-06-10",
        "metrics":{
            "Top 1 Accuracy":"62.95"
        },
        "raw_metrics":{
            "Top 1 Accuracy":62.95
        },
        "uses_additional_data":false,
        "paper":{
            "id":816109,
            "title":"Scaling Vision with Sparse Mixture of Experts",
            "url":"\/paper\/scaling-vision-with-sparse-mixture-of-experts",
            "published":"2021-06-10T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/scaling-vision-with-sparse-mixture-of-experts\/review\/?hl=34954"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":9955,
        "row_id":34949,
        "rank":4,
        "Model":"V-MoE-L\/16 (Every-2)",
        "mlmodel":{

        },
        "method_short":"V-MoE-L\/16 ",
        "method_details":"Every-2",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-06-10",
        "metrics":{
            "Top 1 Accuracy":"62.41"
        },
        "raw_metrics":{
            "Top 1 Accuracy":62.41
        },
        "uses_additional_data":false,
        "paper":{
            "id":816109,
            "title":"Scaling Vision with Sparse Mixture of Experts",
            "url":"\/paper\/scaling-vision-with-sparse-mixture-of-experts",
            "published":"2021-06-10T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/scaling-vision-with-sparse-mixture-of-experts\/review\/?hl=34949"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":9955,
        "row_id":34944,
        "rank":5,
        "Model":"VIT-H\/14",
        "mlmodel":{

        },
        "method_short":"VIT-H\/14",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-06-10",
        "metrics":{
            "Top 1 Accuracy":"62.34"
        },
        "raw_metrics":{
            "Top 1 Accuracy":62.34
        },
        "uses_additional_data":false,
        "paper":{
            "id":816109,
            "title":"Scaling Vision with Sparse Mixture of Experts",
            "url":"\/paper\/scaling-vision-with-sparse-mixture-of-experts",
            "published":"2021-06-10T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/scaling-vision-with-sparse-mixture-of-experts\/review\/?hl=34944"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":9955,
        "row_id":100967,
        "rank":6,
        "Model":"MAWS (ViT-2B)",
        "mlmodel":{

        },
        "method_short":"MAWS ",
        "method_details":"ViT-2B",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-23",
        "metrics":{
            "Top 1 Accuracy":"62.1"
        },
        "raw_metrics":{
            "Top 1 Accuracy":62.1
        },
        "uses_additional_data":true,
        "paper":{
            "id":1179156,
            "title":"The effectiveness of MAE pre-pretraining for billion-scale pretraining",
            "url":"\/paper\/the-effectiveness-of-mae-pre-pretraining-for",
            "published":"2023-03-23T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]