[
    {
        "table_id":9957,
        "row_id":34965,
        "rank":1,
        "method":"ViT-MoE-15B (Every-2)",
        "mlmodel":{

        },
        "Model":"ViT-MoE-15B ",
        "method_details":"Every-2",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-06-10",
        "metrics":{
            "Top 1 Accuracy":"84.29"
        },
        "raw_metrics":{
            "Top 1 Accuracy":84.29
        },
        "uses_additional_data":false,
        "paper":{
            "id":816109,
            "title":"Scaling Vision with Sparse Mixture of Experts",
            "url":"\/paper\/scaling-vision-with-sparse-mixture-of-experts",
            "published":"2021-06-10T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/scaling-vision-with-sparse-mixture-of-experts\/review\/?hl=34965"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":9957,
        "row_id":100969,
        "rank":2,
        "method":"MAWS (ViT-2B)",
        "mlmodel":{

        },
        "Model":"MAWS ",
        "method_details":"ViT-2B",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-23",
        "metrics":{
            "Top 1 Accuracy":"83.7"
        },
        "raw_metrics":{
            "Top 1 Accuracy":83.7
        },
        "uses_additional_data":true,
        "paper":{
            "id":1179156,
            "title":"The effectiveness of MAE pre-pretraining for billion-scale pretraining",
            "url":"\/paper\/the-effectiveness-of-mae-pre-pretraining-for",
            "published":"2023-03-23T00:00:00.000000",
            "code":true,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":9957,
        "row_id":34961,
        "rank":3,
        "method":"V-MoE-H\/14 (Every-2)",
        "mlmodel":{

        },
        "Model":"V-MoE-H\/14 ",
        "method_details":"Every-2",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-06-10",
        "metrics":{
            "Top 1 Accuracy":"80.33"
        },
        "raw_metrics":{
            "Top 1 Accuracy":80.33
        },
        "uses_additional_data":false,
        "paper":{
            "id":816109,
            "title":"Scaling Vision with Sparse Mixture of Experts",
            "url":"\/paper\/scaling-vision-with-sparse-mixture-of-experts",
            "published":"2021-06-10T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/scaling-vision-with-sparse-mixture-of-experts\/review\/?hl=34961"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":9957,
        "row_id":34956,
        "rank":4,
        "method":"V-MoE-H\/14 (Last-5)",
        "mlmodel":{

        },
        "Model":"V-MoE-H\/14 ",
        "method_details":"Last-5",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-06-10",
        "metrics":{
            "Top 1 Accuracy":"80.1"
        },
        "raw_metrics":{
            "Top 1 Accuracy":80.1
        },
        "uses_additional_data":false,
        "paper":{
            "id":816109,
            "title":"Scaling Vision with Sparse Mixture of Experts",
            "url":"\/paper\/scaling-vision-with-sparse-mixture-of-experts",
            "published":"2021-06-10T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/scaling-vision-with-sparse-mixture-of-experts\/review\/?hl=34956"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":9957,
        "row_id":34946,
        "rank":5,
        "method":"VIT-H\/14",
        "mlmodel":{

        },
        "Model":"VIT-H\/14",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-06-10",
        "metrics":{
            "Top 1 Accuracy":"79.01"
        },
        "raw_metrics":{
            "Top 1 Accuracy":79.01
        },
        "uses_additional_data":false,
        "paper":{
            "id":816109,
            "title":"Scaling Vision with Sparse Mixture of Experts",
            "url":"\/paper\/scaling-vision-with-sparse-mixture-of-experts",
            "published":"2021-06-10T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/scaling-vision-with-sparse-mixture-of-experts\/review\/?hl=34946"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]