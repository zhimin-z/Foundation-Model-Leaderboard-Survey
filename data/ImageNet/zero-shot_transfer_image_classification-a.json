[
    {
        "table_id":13784,
        "row_id":54008,
        "rank":1,
        "method":"CoCa",
        "mlmodel":{

        },
        "method_short":"CoCa",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-05-04",
        "metrics":{
            "Accuracy (Private)":"90.2",
            "Accuracy (Public)":null
        },
        "raw_metrics":{
            "Accuracy (Private)":90.2,
            "Accuracy (Public)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1004211,
            "title":"CoCa: Contrastive Captioners are Image-Text Foundation Models",
            "url":"\/paper\/coca-contrastive-captioners-are-image-text",
            "published":"2022-05-04T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/coca-contrastive-captioners-are-image-text\/review\/?hl=54008"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":13784,
        "row_id":97013,
        "rank":2,
        "method":"LiT-22B",
        "mlmodel":{

        },
        "method_short":"LiT-22B",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-02-10",
        "metrics":{
            "Accuracy (Private)":"90.1",
            "Accuracy (Public)":null
        },
        "raw_metrics":{
            "Accuracy (Private)":90.1,
            "Accuracy (Public)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1155994,
            "title":"Scaling Vision Transformers to 22 Billion Parameters",
            "url":"\/paper\/scaling-vision-transformers-to-22-billion",
            "published":"2023-02-10T00:00:00.000000",
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":13784,
        "row_id":70431,
        "rank":3,
        "method":"LiT ViT-e",
        "mlmodel":{

        },
        "method_short":"LiT ViT-e",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-09-14",
        "metrics":{
            "Accuracy (Private)":"88.0",
            "Accuracy (Public)":null
        },
        "raw_metrics":{
            "Accuracy (Private)":88.0,
            "Accuracy (Public)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1074922,
            "title":"PaLI: A Jointly-Scaled Multilingual Language-Image Model",
            "url":"\/paper\/pali-a-jointly-scaled-multilingual-language",
            "published":"2022-09-14T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/pali-a-jointly-scaled-multilingual-language\/review\/?hl=70431"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":13784,
        "row_id":97334,
        "rank":4,
        "method":"BASIC (Lion)",
        "mlmodel":{

        },
        "method_short":"BASIC ",
        "method_details":"Lion",
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":null,
        "metrics":{
            "Accuracy (Private)":"86.4",
            "Accuracy (Public)":null
        },
        "raw_metrics":{
            "Accuracy (Private)":86.4,
            "Accuracy (Public)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":null,
            "title":null,
            "url":null,
            "published":null,
            "code":false,
            "review_url":null
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":13784,
        "row_id":43083,
        "rank":5,
        "method":"BASIC",
        "mlmodel":{

        },
        "method_short":"BASIC",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-11-19",
        "metrics":{
            "Accuracy (Private)":"85.6",
            "Accuracy (Public)":null
        },
        "raw_metrics":{
            "Accuracy (Private)":85.6,
            "Accuracy (Public)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":912981,
            "title":"Combined Scaling for Zero-shot Transfer Learning",
            "url":"\/paper\/combined-scaling-for-zero-shot-transfer",
            "published":"2021-11-19T00:00:00.000000",
            "code":false,
            "review_url":"\/paper\/combined-scaling-for-zero-shot-transfer\/review\/?hl=43083"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":13784,
        "row_id":111665,
        "rank":6,
        "method":"EVA-CLIP-E\/14+",
        "mlmodel":{

        },
        "method_short":"EVA-CLIP-E\/14+",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2023-03-27",
        "metrics":{
            "Accuracy (Private)":"82.1",
            "Accuracy (Public)":null
        },
        "raw_metrics":{
            "Accuracy (Private)":82.1,
            "Accuracy (Public)":null
        },
        "uses_additional_data":true,
        "paper":{
            "id":1180718,
            "title":"EVA-CLIP: Improved Training Techniques for CLIP at Scale",
            "url":"\/paper\/eva-clip-improved-training-techniques-for",
            "published":"2023-03-27T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/eva-clip-improved-training-techniques-for\/review\/?hl=111665"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":13784,
        "row_id":42564,
        "rank":7,
        "method":"LiT-tuning",
        "mlmodel":{

        },
        "method_short":"LiT-tuning",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-11-15",
        "metrics":{
            "Accuracy (Private)":"79.4",
            "Accuracy (Public)":" 37.8"
        },
        "raw_metrics":{
            "Accuracy (Private)":79.4,
            "Accuracy (Public)":37.8
        },
        "uses_additional_data":false,
        "paper":{
            "id":909846,
            "title":"LiT: Zero-Shot Transfer with Locked-image text Tuning",
            "url":"\/paper\/lit-zero-shot-transfer-with-locked-image-text",
            "published":"2021-11-15T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/lit-zero-shot-transfer-with-locked-image-text\/review\/?hl=42564"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":13784,
        "row_id":42566,
        "rank":8,
        "method":"CLIP",
        "mlmodel":{

        },
        "method_short":"CLIP",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-02-26",
        "metrics":{
            "Accuracy (Private)":"77.2",
            "Accuracy (Public)":"-"
        },
        "raw_metrics":{
            "Accuracy (Private)":77.2,
            "Accuracy (Public)":0
        },
        "uses_additional_data":false,
        "paper":{
            "id":749733,
            "title":"Learning Transferable Visual Models From Natural Language Supervision",
            "url":"\/paper\/learning-transferable-visual-models-from",
            "published":"2021-02-26T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/learning-transferable-visual-models-from\/review\/?hl=42566"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":13784,
        "row_id":42565,
        "rank":9,
        "method":"ALIGN",
        "mlmodel":{

        },
        "method_short":"ALIGN",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2021-02-11",
        "metrics":{
            "Accuracy (Private)":"75.8",
            "Accuracy (Public)":"-"
        },
        "raw_metrics":{
            "Accuracy (Private)":75.8,
            "Accuracy (Public)":0
        },
        "uses_additional_data":false,
        "paper":{
            "id":744362,
            "title":"Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision",
            "url":"\/paper\/scaling-up-visual-and-vision-language",
            "published":"2021-02-11T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/scaling-up-visual-and-vision-language\/review\/?hl=42565"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":13784,
        "row_id":79791,
        "rank":10,
        "method":"AltCLIP",
        "mlmodel":{

        },
        "method_short":"AltCLIP",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-11-12",
        "metrics":{
            "Accuracy (Private)":"69.5",
            "Accuracy (Public)":null
        },
        "raw_metrics":{
            "Accuracy (Private)":69.5,
            "Accuracy (Public)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1110840,
            "title":"AltCLIP: Altering the Language Encoder in CLIP for Extended Language Capabilities",
            "url":"\/paper\/altclip-altering-the-language-encoder-in-clip",
            "published":"2022-11-12T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/altclip-altering-the-language-encoder-in-clip\/review\/?hl=79791"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    },
    {
        "table_id":13784,
        "row_id":70424,
        "rank":11,
        "method":"PaLI",
        "mlmodel":{

        },
        "method_short":"PaLI",
        "method_details":null,
        "mlmodel_short":null,
        "mlmodeldetails":null,
        "evaluation_date":"2022-09-14",
        "metrics":{
            "Accuracy (Private)":"44.7",
            "Accuracy (Public)":null
        },
        "raw_metrics":{
            "Accuracy (Private)":44.7,
            "Accuracy (Public)":null
        },
        "uses_additional_data":false,
        "paper":{
            "id":1074922,
            "title":"PaLI: A Jointly-Scaled Multilingual Language-Image Model",
            "url":"\/paper\/pali-a-jointly-scaled-multilingual-language",
            "published":"2022-09-14T00:00:00.000000",
            "code":true,
            "review_url":"\/paper\/pali-a-jointly-scaled-multilingual-language\/review\/?hl=70424"
        },
        "external_source_url":null,
        "tags":[

        ],
        "reports":[

        ]
    }
]