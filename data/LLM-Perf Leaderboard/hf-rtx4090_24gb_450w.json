[
    {
        "Model":"rishiraj\/CatPPT-base",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.24,
        "Open LLM Score (%)":"72.25 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0314,
        "Decode Throughput (tokens\/s)":49.5,
        "Allocated Memory (MB)":15171,
        "Energy (tokens\/kWh)":657894,
        "E2E Latency (s)":5.18,
        "E2E Throughput (tokens\/s)":49.4,
        "Reserved Memory (MB)":15374,
        "Used Memory (MB)":16232
    },
    {
        "Model":"upstage\/SOLAR-10.7B-v1.0",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":10.73,
        "Open LLM Score (%)":"66.04 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0452,
        "Decode Throughput (tokens\/s)":33.4,
        "Allocated Memory (MB)":21781,
        "Energy (tokens\/kWh)":454545,
        "E2E Latency (s)":7.69,
        "E2E Throughput (tokens\/s)":33.3,
        "Reserved Memory (MB)":22047,
        "Used Memory (MB)":22906
    },
    {
        "Model":"Deci\/DeciLM-7B",
        "Arch":"\ud83d\udd35 deci",
        "Params (B)":7.04,
        "Open LLM Score (%)":"61.55 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0305,
        "Decode Throughput (tokens\/s)":51.3,
        "Allocated Memory (MB)":14290,
        "Energy (tokens\/kWh)":709219,
        "E2E Latency (s)":5.0,
        "E2E Throughput (tokens\/s)":51.2,
        "Reserved Memory (MB)":14357,
        "Used Memory (MB)":15215
    },
    {
        "Model":"microsoft\/phi-2",
        "Arch":"phi",
        "Params (B)":2.78,
        "Open LLM Score (%)":"61.33 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0436,
        "Decode Throughput (tokens\/s)":69.9,
        "Allocated Memory (MB)":11951,
        "Energy (tokens\/kWh)":990099,
        "E2E Latency (s)":3.69,
        "E2E Throughput (tokens\/s)":69.4,
        "Reserved Memory (MB)":11978,
        "Used Memory (MB)":12831
    },
    {
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.24,
        "Open LLM Score (%)":"60.97 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0315,
        "Decode Throughput (tokens\/s)":49.2,
        "Allocated Memory (MB)":15171,
        "Energy (tokens\/kWh)":689655,
        "E2E Latency (s)":5.21,
        "E2E Throughput (tokens\/s)":49.1,
        "Reserved Memory (MB)":15374,
        "Used Memory (MB)":16232
    },
    {
        "Model":"scb10x\/typhoon-7b",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.0,
        "Open LLM Score (%)":"58.05 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0318,
        "Decode Throughput (tokens\/s)":49.3,
        "Allocated Memory (MB)":15225,
        "Energy (tokens\/kWh)":680272,
        "E2E Latency (s)":5.2,
        "E2E Throughput (tokens\/s)":49.2,
        "Reserved Memory (MB)":15430,
        "Used Memory (MB)":16289
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.06,
        "Open LLM Score (%)":"54.08 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0866,
        "Decode Throughput (tokens\/s)":33.8,
        "Allocated Memory (MB)":24537,
        "Energy (tokens\/kWh)":456621,
        "E2E Latency (s)":7.64,
        "E2E Throughput (tokens\/s)":33.5,
        "Reserved Memory (MB)":24672,
        "Used Memory (MB)":25525
    },
    {
        "Model":"augmxnt\/shisa-base-7b-v1",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.96,
        "Open LLM Score (%)":"51.64 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0328,
        "Decode Throughput (tokens\/s)":47.4,
        "Allocated Memory (MB)":16692,
        "Energy (tokens\/kWh)":636942,
        "E2E Latency (s)":5.41,
        "E2E Throughput (tokens\/s)":47.3,
        "Reserved Memory (MB)":16972,
        "Used Memory (MB)":17830
    },
    {
        "Model":"vishesht27\/22-Neuro_Model",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.24,
        "Open LLM Score (%)":"50.23 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0314,
        "Decode Throughput (tokens\/s)":49.2,
        "Allocated Memory (MB)":15171,
        "Energy (tokens\/kWh)":680272,
        "E2E Latency (s)":5.21,
        "E2E Throughput (tokens\/s)":49.1,
        "Reserved Memory (MB)":15374,
        "Used Memory (MB)":16232
    },
    {
        "Model":"itsliupeng\/openllama-7b-icl",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"47.93 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0282,
        "Decode Throughput (tokens\/s)":52.8,
        "Allocated Memory (MB)":14056,
        "Energy (tokens\/kWh)":704225,
        "E2E Latency (s)":4.86,
        "E2E Throughput (tokens\/s)":52.7,
        "Reserved Memory (MB)":14092,
        "Used Memory (MB)":14951
    },
    {
        "Model":"microsoft\/phi-1_5",
        "Arch":"phi",
        "Params (B)":0.0,
        "Open LLM Score (%)":"47.69*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00986,
        "Decode Throughput (tokens\/s)":116.0,
        "Allocated Memory (MB)":1304,
        "Energy (tokens\/kWh)":2915451,
        "E2E Latency (s)":2.2,
        "E2E Throughput (tokens\/s)":116.0,
        "Reserved Memory (MB)":1402,
        "Used Memory (MB)":2263
    },
    {
        "Model":"microsoft\/phi-1_5",
        "Arch":"phi",
        "Params (B)":0.0,
        "Open LLM Score (%)":"47.69 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0102,
        "Decode Throughput (tokens\/s)":111.0,
        "Allocated Memory (MB)":3057,
        "Energy (tokens\/kWh)":2247191,
        "E2E Latency (s)":2.3,
        "E2E Throughput (tokens\/s)":111.0,
        "Reserved Memory (MB)":3229,
        "Used Memory (MB)":4088
    },
    {
        "Model":"microsoft\/phi-1_5",
        "Arch":"phi",
        "Params (B)":0.0,
        "Open LLM Score (%)":"47.69*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0141,
        "Decode Throughput (tokens\/s)":105.0,
        "Allocated Memory (MB)":1269,
        "Energy (tokens\/kWh)":1766784,
        "E2E Latency (s)":2.45,
        "E2E Throughput (tokens\/s)":104.0,
        "Reserved Memory (MB)":1354,
        "Used Memory (MB)":2213
    },
    {
        "Model":"microsoft\/phi-1_5",
        "Arch":"phi",
        "Params (B)":0.0,
        "Open LLM Score (%)":"47.69 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0227,
        "Decode Throughput (tokens\/s)":123.0,
        "Allocated Memory (MB)":6098,
        "Energy (tokens\/kWh)":1754385,
        "E2E Latency (s)":2.1,
        "E2E Throughput (tokens\/s)":122.0,
        "Reserved Memory (MB)":6142,
        "Used Memory (MB)":6994
    },
    {
        "Model":"microsoft\/phi-1_5",
        "Arch":"phi",
        "Params (B)":0.0,
        "Open LLM Score (%)":"47.69*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0311,
        "Decode Throughput (tokens\/s)":32.6,
        "Allocated Memory (MB)":1848,
        "Energy (tokens\/kWh)":1081081,
        "E2E Latency (s)":7.86,
        "E2E Throughput (tokens\/s)":32.6,
        "Reserved Memory (MB)":1944,
        "Used Memory (MB)":2811
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.0,
        "Open LLM Score (%)":"47.64 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0287,
        "Decode Throughput (tokens\/s)":51.9,
        "Allocated Memory (MB)":14653,
        "Energy (tokens\/kWh)":704225,
        "E2E Latency (s)":4.94,
        "E2E Throughput (tokens\/s)":51.8,
        "Reserved Memory (MB)":14682,
        "Used Memory (MB)":15540
    },
    {
        "Model":"itsliupeng\/openllama-7b-base",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"47.09 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0282,
        "Decode Throughput (tokens\/s)":52.7,
        "Allocated Memory (MB)":14056,
        "Energy (tokens\/kWh)":724637,
        "E2E Latency (s)":4.87,
        "E2E Throughput (tokens\/s)":52.6,
        "Reserved Memory (MB)":14092,
        "Used Memory (MB)":14951
    },
    {
        "Model":"stabilityai\/stablelm-3b-4e1t",
        "Arch":"\ud83d\udd34 StableLM-Epoch",
        "Params (B)":2.8,
        "Open LLM Score (%)":"46.58 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0413,
        "Decode Throughput (tokens\/s)":68.4,
        "Allocated Memory (MB)":12068,
        "Energy (tokens\/kWh)":917431,
        "E2E Latency (s)":3.77,
        "E2E Throughput (tokens\/s)":67.9,
        "Reserved Memory (MB)":12117,
        "Used Memory (MB)":12969
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.61,
        "Open LLM Score (%)":"45.62 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0279,
        "Decode Throughput (tokens\/s)":52.9,
        "Allocated Memory (MB)":14056,
        "Energy (tokens\/kWh)":724637,
        "E2E Latency (s)":4.85,
        "E2E Throughput (tokens\/s)":52.8,
        "Reserved Memory (MB)":14092,
        "Used Memory (MB)":14951
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"44.26 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0283,
        "Decode Throughput (tokens\/s)":52.7,
        "Allocated Memory (MB)":14056,
        "Energy (tokens\/kWh)":719424,
        "E2E Latency (s)":4.87,
        "E2E Throughput (tokens\/s)":52.6,
        "Reserved Memory (MB)":14092,
        "Used Memory (MB)":14951
    },
    {
        "Model":"tiiuae\/falcon-7b",
        "Arch":"\ud83e\udd85 Falcon",
        "Params (B)":7.0,
        "Open LLM Score (%)":"44.17 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0343,
        "Decode Throughput (tokens\/s)":43.2,
        "Allocated Memory (MB)":13945,
        "Energy (tokens\/kWh)":636942,
        "E2E Latency (s)":5.93,
        "E2E Throughput (tokens\/s)":43.2,
        "Reserved Memory (MB)":14061,
        "Used Memory (MB)":14920
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"42.31 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0282,
        "Decode Throughput (tokens\/s)":52.9,
        "Allocated Memory (MB)":14056,
        "Energy (tokens\/kWh)":729927,
        "E2E Latency (s)":4.85,
        "E2E Throughput (tokens\/s)":52.8,
        "Reserved Memory (MB)":14092,
        "Used Memory (MB)":14951
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"GPT-NeoX",
        "Params (B)":7.0,
        "Open LLM Score (%)":"41.49 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0294,
        "Decode Throughput (tokens\/s)":50.9,
        "Allocated Memory (MB)":14429,
        "Energy (tokens\/kWh)":680272,
        "E2E Latency (s)":5.04,
        "E2E Throughput (tokens\/s)":50.8,
        "Reserved Memory (MB)":14470,
        "Used Memory (MB)":15329
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.02,
        "Open LLM Score (%)":"41.44 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0159,
        "Decode Throughput (tokens\/s)":102.0,
        "Allocated Memory (MB)":6401,
        "Energy (tokens\/kWh)":1536098,
        "E2E Latency (s)":2.52,
        "E2E Throughput (tokens\/s)":102.0,
        "Reserved Memory (MB)":6452,
        "Used Memory (MB)":7311
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.02,
        "Open LLM Score (%)":"41.44 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0427,
        "Decode Throughput (tokens\/s)":60.6,
        "Allocated Memory (MB)":12793,
        "Energy (tokens\/kWh)":833333,
        "E2E Latency (s)":4.25,
        "E2E Throughput (tokens\/s)":60.2,
        "Reserved Memory (MB)":12893,
        "Used Memory (MB)":13745
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"GPT-NeoX",
        "Params (B)":6.65,
        "Open LLM Score (%)":"41.25 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0293,
        "Decode Throughput (tokens\/s)":51.0,
        "Allocated Memory (MB)":14429,
        "Energy (tokens\/kWh)":675675,
        "E2E Latency (s)":5.03,
        "E2E Throughput (tokens\/s)":50.9,
        "Reserved Memory (MB)":14470,
        "Used Memory (MB)":15329
    },
    {
        "Model":"openlm-research\/open_llama_3b_v2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"40.28 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0185,
        "Decode Throughput (tokens\/s)":90.1,
        "Allocated Memory (MB)":7280,
        "Energy (tokens\/kWh)":1297016,
        "E2E Latency (s)":2.85,
        "E2E Throughput (tokens\/s)":89.8,
        "Reserved Memory (MB)":7440,
        "Used Memory (MB)":8299
    },
    {
        "Model":"openlm-research\/open_llama_3b_v2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"40.28 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.054,
        "Decode Throughput (tokens\/s)":52.7,
        "Allocated Memory (MB)":14582,
        "Energy (tokens\/kWh)":735294,
        "E2E Latency (s)":4.89,
        "E2E Throughput (tokens\/s)":52.4,
        "Reserved Memory (MB)":14677,
        "Used Memory (MB)":15530
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"GPT-J",
        "Params (B)":6.0,
        "Open LLM Score (%)":"40.10 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0263,
        "Decode Throughput (tokens\/s)":53.8,
        "Allocated Memory (MB)":12721,
        "Energy (tokens\/kWh)":757575,
        "E2E Latency (s)":4.77,
        "E2E Throughput (tokens\/s)":53.7,
        "Reserved Memory (MB)":12769,
        "Used Memory (MB)":13628
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":6.0,
        "Open LLM Score (%)":"40.00 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0318,
        "Decode Throughput (tokens\/s)":45.8,
        "Allocated Memory (MB)":14855,
        "Energy (tokens\/kWh)":645161,
        "E2E Latency (s)":5.6,
        "E2E Throughput (tokens\/s)":45.7,
        "Reserved Memory (MB)":14902,
        "Used Memory (MB)":15761
    },
    {
        "Model":"EleutherAI\/pythia-12b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":12.0,
        "Open LLM Score (%)":"39.70 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0475,
        "Decode Throughput (tokens\/s)":32.6,
        "Allocated Memory (MB)":24619,
        "Energy (tokens\/kWh)":411522,
        "E2E Latency (s)":7.87,
        "E2E Throughput (tokens\/s)":32.5,
        "Reserved Memory (MB)":24647,
        "Used Memory (MB)":25506
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":6.9,
        "Open LLM Score (%)":"39.30 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0295,
        "Decode Throughput (tokens\/s)":50.9,
        "Allocated Memory (MB)":14403,
        "Energy (tokens\/kWh)":680272,
        "E2E Latency (s)":5.04,
        "E2E Throughput (tokens\/s)":50.8,
        "Reserved Memory (MB)":14445,
        "Used Memory (MB)":15303
    },
    {
        "Model":"bigscience\/bloom-7b1",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":7.07,
        "Open LLM Score (%)":"39.18 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0288,
        "Decode Throughput (tokens\/s)":56.0,
        "Allocated Memory (MB)":14651,
        "Energy (tokens\/kWh)":675675,
        "E2E Latency (s)":4.58,
        "E2E Throughput (tokens\/s)":55.9,
        "Reserved Memory (MB)":14690,
        "Used Memory (MB)":15549
    },
    {
        "Model":"EleutherAI\/pythia-12b",
        "Arch":"GPT-NeoX",
        "Params (B)":12.0,
        "Open LLM Score (%)":"38.82 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0483,
        "Decode Throughput (tokens\/s)":32.5,
        "Allocated Memory (MB)":24619,
        "Energy (tokens\/kWh)":403225,
        "E2E Latency (s)":7.9,
        "E2E Throughput (tokens\/s)":32.4,
        "Reserved Memory (MB)":24647,
        "Used Memory (MB)":25506
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"GPT-NeoX",
        "Params (B)":3.0,
        "Open LLM Score (%)":"38.54 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0174,
        "Decode Throughput (tokens\/s)":88.2,
        "Allocated Memory (MB)":6068,
        "Energy (tokens\/kWh)":1364256,
        "E2E Latency (s)":2.91,
        "E2E Throughput (tokens\/s)":88.0,
        "Reserved Memory (MB)":6144,
        "Used Memory (MB)":7003
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"GPT-NeoX",
        "Params (B)":3.0,
        "Open LLM Score (%)":"38.54 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0415,
        "Decode Throughput (tokens\/s)":60.7,
        "Allocated Memory (MB)":12028,
        "Energy (tokens\/kWh)":884955,
        "E2E Latency (s)":4.24,
        "E2E Throughput (tokens\/s)":60.4,
        "Reserved Memory (MB)":12069,
        "Used Memory (MB)":12921
    },
    {
        "Model":"openlm-research\/open_llama_3b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"38.26 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0185,
        "Decode Throughput (tokens\/s)":90.4,
        "Allocated Memory (MB)":7280,
        "Energy (tokens\/kWh)":1291989,
        "E2E Latency (s)":2.84,
        "E2E Throughput (tokens\/s)":90.1,
        "Reserved Memory (MB)":7440,
        "Used Memory (MB)":8299
    },
    {
        "Model":"openlm-research\/open_llama_3b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"38.26 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.054,
        "Decode Throughput (tokens\/s)":52.7,
        "Allocated Memory (MB)":14582,
        "Energy (tokens\/kWh)":729927,
        "E2E Latency (s)":4.89,
        "E2E Throughput (tokens\/s)":52.4,
        "Reserved Memory (MB)":14677,
        "Used Memory (MB)":15530
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"GPT-NeoX",
        "Params (B)":6.65,
        "Open LLM Score (%)":"38.06 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0287,
        "Decode Throughput (tokens\/s)":51.2,
        "Allocated Memory (MB)":14403,
        "Energy (tokens\/kWh)":684931,
        "E2E Latency (s)":5.01,
        "E2E Throughput (tokens\/s)":51.1,
        "Reserved Memory (MB)":14445,
        "Used Memory (MB)":15303
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"GPT-NeoX",
        "Params (B)":4.0,
        "Open LLM Score (%)":"37.31 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0599,
        "Decode Throughput (tokens\/s)":42.1,
        "Allocated Memory (MB)":17177,
        "Energy (tokens\/kWh)":636942,
        "E2E Latency (s)":6.11,
        "E2E Throughput (tokens\/s)":41.9,
        "Reserved Memory (MB)":17207,
        "Used Memory (MB)":18059
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"GPT-NeoX",
        "Params (B)":2.91,
        "Open LLM Score (%)":"37.09 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.017,
        "Decode Throughput (tokens\/s)":88.5,
        "Allocated Memory (MB)":6052,
        "Energy (tokens\/kWh)":1386962,
        "E2E Latency (s)":2.9,
        "E2E Throughput (tokens\/s)":88.3,
        "Reserved Memory (MB)":6123,
        "Used Memory (MB)":6982
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"GPT-NeoX",
        "Params (B)":2.91,
        "Open LLM Score (%)":"37.09 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0418,
        "Decode Throughput (tokens\/s)":61.2,
        "Allocated Memory (MB)":11995,
        "Energy (tokens\/kWh)":909090,
        "E2E Latency (s)":4.21,
        "E2E Throughput (tokens\/s)":60.8,
        "Reserved Memory (MB)":12043,
        "Used Memory (MB)":12896
    },
    {
        "Model":"tiiuae\/falcon-rw-1b",
        "Arch":"\ud83e\udd85 Falcon",
        "Params (B)":1.0,
        "Open LLM Score (%)":"37.07 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00885,
        "Decode Throughput (tokens\/s)":153.0,
        "Allocated Memory (MB)":2834,
        "Energy (tokens\/kWh)":2610966,
        "E2E Latency (s)":1.68,
        "E2E Throughput (tokens\/s)":152.0,
        "Reserved Memory (MB)":2858,
        "Used Memory (MB)":3717
    },
    {
        "Model":"tiiuae\/falcon-rw-1b",
        "Arch":"\ud83e\udd85 Falcon",
        "Params (B)":1.0,
        "Open LLM Score (%)":"37.07 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0204,
        "Decode Throughput (tokens\/s)":132.0,
        "Allocated Memory (MB)":5659,
        "Energy (tokens\/kWh)":1821493,
        "E2E Latency (s)":1.95,
        "E2E Throughput (tokens\/s)":131.0,
        "Reserved Memory (MB)":5700,
        "Used Memory (MB)":6552
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":2.91,
        "Open LLM Score (%)":"36.72 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0167,
        "Decode Throughput (tokens\/s)":90.1,
        "Allocated Memory (MB)":6052,
        "Energy (tokens\/kWh)":1400560,
        "E2E Latency (s)":2.85,
        "E2E Throughput (tokens\/s)":89.8,
        "Reserved Memory (MB)":6123,
        "Used Memory (MB)":6982
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":2.91,
        "Open LLM Score (%)":"36.72 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0419,
        "Decode Throughput (tokens\/s)":61.2,
        "Allocated Memory (MB)":11995,
        "Energy (tokens\/kWh)":900900,
        "E2E Latency (s)":4.21,
        "E2E Throughput (tokens\/s)":60.8,
        "Reserved Memory (MB)":12043,
        "Used Memory (MB)":12896
    },
    {
        "Model":"TinyLlama\/TinyLlama-1.1B-intermediate-step-1431k-3T",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"36.42 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00798,
        "Decode Throughput (tokens\/s)":121.0,
        "Allocated Memory (MB)":2279,
        "Energy (tokens\/kWh)":2444987,
        "E2E Latency (s)":2.11,
        "E2E Throughput (tokens\/s)":121.0,
        "Reserved Memory (MB)":2403,
        "Used Memory (MB)":3262
    },
    {
        "Model":"TinyLlama\/TinyLlama-1.1B-intermediate-step-1431k-3T",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"36.42 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0182,
        "Decode Throughput (tokens\/s)":128.0,
        "Allocated Memory (MB)":4492,
        "Energy (tokens\/kWh)":1968503,
        "E2E Latency (s)":2.02,
        "E2E Throughput (tokens\/s)":127.0,
        "Reserved Memory (MB)":4548,
        "Used Memory (MB)":5401
    },
    {
        "Model":"cerebras\/Cerebras-GPT-6.7B",
        "Arch":"GPT-2",
        "Params (B)":6.7,
        "Open LLM Score (%)":"36.27 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0268,
        "Decode Throughput (tokens\/s)":53.6,
        "Allocated Memory (MB)":13997,
        "Energy (tokens\/kWh)":729927,
        "E2E Latency (s)":4.79,
        "E2E Throughput (tokens\/s)":53.4,
        "Reserved Memory (MB)":14040,
        "Used Memory (MB)":14899
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"GPT-Neo",
        "Params (B)":2.72,
        "Open LLM Score (%)":"36.20 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0418,
        "Decode Throughput (tokens\/s)":63.4,
        "Allocated Memory (MB)":11555,
        "Energy (tokens\/kWh)":943396,
        "E2E Latency (s)":4.06,
        "E2E Throughput (tokens\/s)":63.1,
        "Reserved Memory (MB)":11593,
        "Used Memory (MB)":12445
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"GPT-NeoX",
        "Params (B)":4.0,
        "Open LLM Score (%)":"36.15 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0413,
        "Decode Throughput (tokens\/s)":60.9,
        "Allocated Memory (MB)":12028,
        "Energy (tokens\/kWh)":917431,
        "E2E Latency (s)":4.23,
        "E2E Throughput (tokens\/s)":60.5,
        "Reserved Memory (MB)":12069,
        "Used Memory (MB)":12921
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":3.0,
        "Open LLM Score (%)":"36.07 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0163,
        "Decode Throughput (tokens\/s)":108.0,
        "Allocated Memory (MB)":6365,
        "Energy (tokens\/kWh)":1443001,
        "E2E Latency (s)":2.39,
        "E2E Throughput (tokens\/s)":107.0,
        "Reserved Memory (MB)":6434,
        "Used Memory (MB)":7292
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":3.0,
        "Open LLM Score (%)":"36.07 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0441,
        "Decode Throughput (tokens\/s)":65.7,
        "Allocated Memory (MB)":12734,
        "Energy (tokens\/kWh)":884955,
        "E2E Latency (s)":3.92,
        "E2E Throughput (tokens\/s)":65.3,
        "Reserved Memory (MB)":12859,
        "Used Memory (MB)":13712
    },
    {
        "Model":"Dans-DiscountModels\/ShearedLlama-1.3b-FFT-Test1",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.3,
        "Open LLM Score (%)":"35.71 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00882,
        "Decode Throughput (tokens\/s)":131.0,
        "Allocated Memory (MB)":2991,
        "Energy (tokens\/kWh)":2386634,
        "E2E Latency (s)":1.95,
        "E2E Throughput (tokens\/s)":131.0,
        "Reserved Memory (MB)":3114,
        "Used Memory (MB)":3972
    },
    {
        "Model":"Dans-DiscountModels\/ShearedLlama-1.3b-FFT-Test1",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.3,
        "Open LLM Score (%)":"35.71 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0225,
        "Decode Throughput (tokens\/s)":105.0,
        "Allocated Memory (MB)":5969,
        "Energy (tokens\/kWh)":1709401,
        "E2E Latency (s)":2.46,
        "E2E Throughput (tokens\/s)":104.0,
        "Reserved Memory (MB)":5991,
        "Used Memory (MB)":6843
    },
    {
        "Model":"Writer\/palmyra-base",
        "Arch":"GPT-2",
        "Params (B)":0.0,
        "Open LLM Score (%)":"35.18 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0201,
        "Decode Throughput (tokens\/s)":70.6,
        "Allocated Memory (MB)":10607,
        "Energy (tokens\/kWh)":961538,
        "E2E Latency (s)":3.63,
        "E2E Throughput (tokens\/s)":70.5,
        "Reserved Memory (MB)":10649,
        "Used Memory (MB)":11508
    },
    {
        "Model":"Writer\/palmyra-base",
        "Arch":"GPT-2",
        "Params (B)":0.0,
        "Open LLM Score (%)":"35.18 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0553,
        "Decode Throughput (tokens\/s)":39.7,
        "Allocated Memory (MB)":21105,
        "Energy (tokens\/kWh)":440528,
        "E2E Latency (s)":6.48,
        "E2E Throughput (tokens\/s)":39.5,
        "Reserved Memory (MB)":21214,
        "Used Memory (MB)":22067
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":1.4,
        "Open LLM Score (%)":"35.00 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00996,
        "Decode Throughput (tokens\/s)":120.0,
        "Allocated Memory (MB)":3147,
        "Energy (tokens\/kWh)":2217294,
        "E2E Latency (s)":2.13,
        "E2E Throughput (tokens\/s)":120.0,
        "Reserved Memory (MB)":3202,
        "Used Memory (MB)":4061
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":1.4,
        "Open LLM Score (%)":"35.00 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0221,
        "Decode Throughput (tokens\/s)":104.0,
        "Allocated Memory (MB)":6186,
        "Energy (tokens\/kWh)":1718213,
        "E2E Latency (s)":2.48,
        "E2E Throughput (tokens\/s)":103.0,
        "Reserved Memory (MB)":6232,
        "Used Memory (MB)":7085
    },
    {
        "Model":"bn22\/tinyllama_frankenmerge",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.54,
        "Open LLM Score (%)":"34.64 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0112,
        "Decode Throughput (tokens\/s)":87.3,
        "Allocated Memory (MB)":3168,
        "Energy (tokens\/kWh)":1730103,
        "E2E Latency (s)":2.93,
        "E2E Throughput (tokens\/s)":87.4,
        "Reserved Memory (MB)":3342,
        "Used Memory (MB)":4201
    },
    {
        "Model":"bn22\/tinyllama_frankenmerge",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.54,
        "Open LLM Score (%)":"34.64 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0268,
        "Decode Throughput (tokens\/s)":89.5,
        "Allocated Memory (MB)":6279,
        "Energy (tokens\/kWh)":1438848,
        "E2E Latency (s)":2.88,
        "E2E Throughput (tokens\/s)":88.9,
        "Reserved Memory (MB)":6341,
        "Used Memory (MB)":7194
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"GPT-NeoX",
        "Params (B)":1.31,
        "Open LLM Score (%)":"34.46 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0099,
        "Decode Throughput (tokens\/s)":121.0,
        "Allocated Memory (MB)":3147,
        "Energy (tokens\/kWh)":2242152,
        "E2E Latency (s)":2.12,
        "E2E Throughput (tokens\/s)":121.0,
        "Reserved Memory (MB)":3202,
        "Used Memory (MB)":4061
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"GPT-NeoX",
        "Params (B)":1.31,
        "Open LLM Score (%)":"34.46 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0218,
        "Decode Throughput (tokens\/s)":105.0,
        "Allocated Memory (MB)":6186,
        "Energy (tokens\/kWh)":1700680,
        "E2E Latency (s)":2.44,
        "E2E Throughput (tokens\/s)":105.0,
        "Reserved Memory (MB)":6232,
        "Used Memory (MB)":7085
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"GPT-NeoX",
        "Params (B)":0.0,
        "Open LLM Score (%)":"34.42 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0306,
        "Decode Throughput (tokens\/s)":48.9,
        "Allocated Memory (MB)":16060,
        "Energy (tokens\/kWh)":649350,
        "E2E Latency (s)":5.24,
        "E2E Throughput (tokens\/s)":48.9,
        "Reserved Memory (MB)":16089,
        "Used Memory (MB)":16948
    },
    {
        "Model":"gpt2-xl",
        "Arch":"GPT-2",
        "Params (B)":1.61,
        "Open LLM Score (%)":"34.38 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0293,
        "Decode Throughput (tokens\/s)":69.5,
        "Allocated Memory (MB)":7061,
        "Energy (tokens\/kWh)":1197604,
        "E2E Latency (s)":3.7,
        "E2E Throughput (tokens\/s)":69.2,
        "Reserved Memory (MB)":7121,
        "Used Memory (MB)":7974
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.03,
        "Open LLM Score (%)":"34.37 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00796,
        "Decode Throughput (tokens\/s)":122.0,
        "Allocated Memory (MB)":2279,
        "Energy (tokens\/kWh)":2525252,
        "E2E Latency (s)":2.1,
        "E2E Throughput (tokens\/s)":122.0,
        "Reserved Memory (MB)":2403,
        "Used Memory (MB)":3262
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.03,
        "Open LLM Score (%)":"34.37 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0187,
        "Decode Throughput (tokens\/s)":126.0,
        "Allocated Memory (MB)":4492,
        "Energy (tokens\/kWh)":2061855,
        "E2E Latency (s)":2.05,
        "E2E Throughput (tokens\/s)":125.0,
        "Reserved Memory (MB)":4548,
        "Used Memory (MB)":5401
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-1.3b",
        "Arch":"GPT-2",
        "Params (B)":1.44,
        "Open LLM Score (%)":"34.31 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00882,
        "Decode Throughput (tokens\/s)":152.0,
        "Allocated Memory (MB)":2999,
        "Energy (tokens\/kWh)":2710027,
        "E2E Latency (s)":1.69,
        "E2E Throughput (tokens\/s)":151.0,
        "Reserved Memory (MB)":3045,
        "Used Memory (MB)":3903
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-1.3b",
        "Arch":"GPT-2",
        "Params (B)":1.44,
        "Open LLM Score (%)":"34.31 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0191,
        "Decode Throughput (tokens\/s)":103.0,
        "Allocated Memory (MB)":5888,
        "Energy (tokens\/kWh)":1474926,
        "E2E Latency (s)":2.49,
        "E2E Throughput (tokens\/s)":103.0,
        "Reserved Memory (MB)":5928,
        "Used Memory (MB)":6781
    },
    {
        "Model":"facebook\/xglm-4.5B",
        "Arch":"XGLM",
        "Params (B)":5.08,
        "Open LLM Score (%)":"34.31 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.063,
        "Decode Throughput (tokens\/s)":40.3,
        "Allocated Memory (MB)":19042,
        "Energy (tokens\/kWh)":568181,
        "E2E Latency (s)":6.39,
        "E2E Throughput (tokens\/s)":40.1,
        "Reserved Memory (MB)":19081,
        "Used Memory (MB)":19934
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"33.72 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00818,
        "Decode Throughput (tokens\/s)":118.0,
        "Allocated Memory (MB)":2279,
        "Energy (tokens\/kWh)":2506265,
        "E2E Latency (s)":2.18,
        "E2E Throughput (tokens\/s)":117.0,
        "Reserved Memory (MB)":2403,
        "Used Memory (MB)":3262
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"33.72 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0187,
        "Decode Throughput (tokens\/s)":126.0,
        "Allocated Memory (MB)":4492,
        "Energy (tokens\/kWh)":2057613,
        "E2E Latency (s)":2.04,
        "E2E Throughput (tokens\/s)":125.0,
        "Reserved Memory (MB)":4548,
        "Used Memory (MB)":5401
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"GPT-Neo",
        "Params (B)":1.37,
        "Open LLM Score (%)":"33.58 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0223,
        "Decode Throughput (tokens\/s)":110.0,
        "Allocated Memory (MB)":5775,
        "Energy (tokens\/kWh)":1689189,
        "E2E Latency (s)":2.33,
        "E2E Throughput (tokens\/s)":110.0,
        "Reserved Memory (MB)":5817,
        "Used Memory (MB)":6669
    },
    {
        "Model":"cerebras\/Cerebras-GPT-2.7B",
        "Arch":"GPT-2",
        "Params (B)":2.7,
        "Open LLM Score (%)":"33.25 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0158,
        "Decode Throughput (tokens\/s)":97.0,
        "Allocated Memory (MB)":5799,
        "Energy (tokens\/kWh)":1552795,
        "E2E Latency (s)":2.65,
        "E2E Throughput (tokens\/s)":96.6,
        "Reserved Memory (MB)":5869,
        "Used Memory (MB)":6728
    },
    {
        "Model":"cerebras\/Cerebras-GPT-2.7B",
        "Arch":"GPT-2",
        "Params (B)":2.7,
        "Open LLM Score (%)":"33.25 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0382,
        "Decode Throughput (tokens\/s)":61.9,
        "Allocated Memory (MB)":11488,
        "Energy (tokens\/kWh)":781250,
        "E2E Latency (s)":4.16,
        "E2E Throughput (tokens\/s)":61.5,
        "Reserved Memory (MB)":11525,
        "Used Memory (MB)":12378
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":1.08,
        "Open LLM Score (%)":"32.78 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00678,
        "Decode Throughput (tokens\/s)":175.0,
        "Allocated Memory (MB)":2243,
        "Energy (tokens\/kWh)":3300330,
        "E2E Latency (s)":1.47,
        "E2E Throughput (tokens\/s)":174.0,
        "Reserved Memory (MB)":2292,
        "Used Memory (MB)":3150
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":1.08,
        "Open LLM Score (%)":"32.78 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0155,
        "Decode Throughput (tokens\/s)":152.0,
        "Allocated Memory (MB)":4411,
        "Energy (tokens\/kWh)":2421307,
        "E2E Latency (s)":1.7,
        "E2E Throughput (tokens\/s)":151.0,
        "Reserved Memory (MB)":4445,
        "Used Memory (MB)":5298
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"GPT-NeoX",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.23 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0553,
        "Decode Throughput (tokens\/s)":47.1,
        "Allocated Memory (MB)":16325,
        "Energy (tokens\/kWh)":704225,
        "E2E Latency (s)":5.47,
        "E2E Throughput (tokens\/s)":46.8,
        "Reserved Memory (MB)":16601,
        "Used Memory (MB)":17453
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"GPT-NeoX",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.14 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0552,
        "Decode Throughput (tokens\/s)":47.4,
        "Allocated Memory (MB)":16325,
        "Energy (tokens\/kWh)":689655,
        "E2E Latency (s)":5.44,
        "E2E Throughput (tokens\/s)":47.1,
        "Reserved Memory (MB)":16601,
        "Used Memory (MB)":17453
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"31.86 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00823,
        "Decode Throughput (tokens\/s)":118.0,
        "Allocated Memory (MB)":2279,
        "Energy (tokens\/kWh)":2551020,
        "E2E Latency (s)":2.18,
        "E2E Throughput (tokens\/s)":117.0,
        "Reserved Memory (MB)":2403,
        "Used Memory (MB)":3262
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"31.86 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0185,
        "Decode Throughput (tokens\/s)":127.0,
        "Allocated Memory (MB)":4492,
        "Energy (tokens\/kWh)":2024291,
        "E2E Latency (s)":2.03,
        "E2E Throughput (tokens\/s)":126.0,
        "Reserved Memory (MB)":4548,
        "Used Memory (MB)":5401
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.55 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00899,
        "Decode Throughput (tokens\/s)":116.0,
        "Allocated Memory (MB)":1028,
        "Energy (tokens\/kWh)":3623188,
        "E2E Latency (s)":2.21,
        "E2E Throughput (tokens\/s)":116.0,
        "Reserved Memory (MB)":1121,
        "Used Memory (MB)":1980
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.55 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00953,
        "Decode Throughput (tokens\/s)":123.0,
        "Allocated Memory (MB)":1948,
        "Energy (tokens\/kWh)":2785515,
        "E2E Latency (s)":2.08,
        "E2E Throughput (tokens\/s)":123.0,
        "Reserved Memory (MB)":2006,
        "Used Memory (MB)":2859
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"GPT-NeoX",
        "Params (B)":3.0,
        "Open LLM Score (%)":"31.50 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0148,
        "Decode Throughput (tokens\/s)":98.8,
        "Allocated Memory (MB)":7829,
        "Energy (tokens\/kWh)":1312335,
        "E2E Latency (s)":2.59,
        "E2E Throughput (tokens\/s)":98.8,
        "Reserved Memory (MB)":7853,
        "Used Memory (MB)":8712
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"GPT-NeoX",
        "Params (B)":3.0,
        "Open LLM Score (%)":"31.50 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0457,
        "Decode Throughput (tokens\/s)":55.6,
        "Allocated Memory (MB)":15380,
        "Energy (tokens\/kWh)":704225,
        "E2E Latency (s)":4.64,
        "E2E Throughput (tokens\/s)":55.2,
        "Reserved Memory (MB)":15466,
        "Used Memory (MB)":16318
    },
    {
        "Model":"cerebras\/Cerebras-GPT-1.3B",
        "Arch":"GPT-2",
        "Params (B)":1.3,
        "Open LLM Score (%)":"31.30 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00891,
        "Decode Throughput (tokens\/s)":152.0,
        "Allocated Memory (MB)":2943,
        "Energy (tokens\/kWh)":2724795,
        "E2E Latency (s)":1.69,
        "E2E Throughput (tokens\/s)":151.0,
        "Reserved Memory (MB)":2984,
        "Used Memory (MB)":3842
    },
    {
        "Model":"cerebras\/Cerebras-GPT-1.3B",
        "Arch":"GPT-2",
        "Params (B)":1.3,
        "Open LLM Score (%)":"31.30 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0185,
        "Decode Throughput (tokens\/s)":106.0,
        "Allocated Memory (MB)":5776,
        "Energy (tokens\/kWh)":1468428,
        "E2E Latency (s)":2.43,
        "E2E Throughput (tokens\/s)":105.0,
        "Reserved Memory (MB)":5802,
        "Used Memory (MB)":6655
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.29 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00859,
        "Decode Throughput (tokens\/s)":120.0,
        "Allocated Memory (MB)":1028,
        "Energy (tokens\/kWh)":3610108,
        "E2E Latency (s)":2.13,
        "E2E Throughput (tokens\/s)":120.0,
        "Reserved Memory (MB)":1121,
        "Used Memory (MB)":1980
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.29 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00944,
        "Decode Throughput (tokens\/s)":120.0,
        "Allocated Memory (MB)":1948,
        "Energy (tokens\/kWh)":2865329,
        "E2E Latency (s)":2.14,
        "E2E Throughput (tokens\/s)":120.0,
        "Reserved Memory (MB)":2006,
        "Used Memory (MB)":2859
    },
    {
        "Model":"RWKV\/rwkv-4-430m-pile",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":0.43,
        "Open LLM Score (%)":"30.45 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0106,
        "Decode Throughput (tokens\/s)":101.0,
        "Allocated Memory (MB)":1784,
        "Energy (tokens\/kWh)":2624671,
        "E2E Latency (s)":2.54,
        "E2E Throughput (tokens\/s)":101.0,
        "Reserved Memory (MB)":1811,
        "Used Memory (MB)":2664
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-356m",
        "Arch":"GPT-2",
        "Params (B)":0.47,
        "Open LLM Score (%)":"30.41 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00851,
        "Decode Throughput (tokens\/s)":156.0,
        "Allocated Memory (MB)":1792,
        "Energy (tokens\/kWh)":3389830,
        "E2E Latency (s)":1.64,
        "E2E Throughput (tokens\/s)":156.0,
        "Reserved Memory (MB)":1828,
        "Used Memory (MB)":2681
    },
    {
        "Model":"robowaifudev\/megatron-gpt2-345m",
        "Arch":"GPT-2",
        "Params (B)":0.38,
        "Open LLM Score (%)":"30.40 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00741,
        "Decode Throughput (tokens\/s)":137.0,
        "Allocated Memory (MB)":844,
        "Energy (tokens\/kWh)":4149377,
        "E2E Latency (s)":1.87,
        "E2E Throughput (tokens\/s)":137.0,
        "Reserved Memory (MB)":935,
        "Used Memory (MB)":1794
    },
    {
        "Model":"robowaifudev\/megatron-gpt2-345m",
        "Arch":"GPT-2",
        "Params (B)":0.38,
        "Open LLM Score (%)":"30.40 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00882,
        "Decode Throughput (tokens\/s)":142.0,
        "Allocated Memory (MB)":1656,
        "Energy (tokens\/kWh)":3174603,
        "E2E Latency (s)":1.8,
        "E2E Throughput (tokens\/s)":142.0,
        "Reserved Memory (MB)":1696,
        "Used Memory (MB)":2549
    },
    {
        "Model":"ahxt\/LiteLlama-460M-1T",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.46,
        "Open LLM Score (%)":"30.16 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.01,
        "Decode Throughput (tokens\/s)":128.0,
        "Allocated Memory (MB)":1936,
        "Energy (tokens\/kWh)":2865329,
        "E2E Latency (s)":2.01,
        "E2E Throughput (tokens\/s)":127.0,
        "Reserved Memory (MB)":1986,
        "Used Memory (MB)":2838
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"GPT-Neo",
        "Params (B)":0.15,
        "Open LLM Score (%)":"29.47 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00429,
        "Decode Throughput (tokens\/s)":270.0,
        "Allocated Memory (MB)":658,
        "Energy (tokens\/kWh)":7246376,
        "E2E Latency (s)":0.948,
        "E2E Throughput (tokens\/s)":270.0,
        "Reserved Memory (MB)":746,
        "Used Memory (MB)":1599
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-220M-GQA",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.22,
        "Open LLM Score (%)":"29.44 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00388,
        "Decode Throughput (tokens\/s)":245.0,
        "Allocated Memory (MB)":500,
        "Energy (tokens\/kWh)":7352941,
        "E2E Latency (s)":1.04,
        "E2E Throughput (tokens\/s)":246.0,
        "Reserved Memory (MB)":549,
        "Used Memory (MB)":1408
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-220M-GQA",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.22,
        "Open LLM Score (%)":"29.44 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00439,
        "Decode Throughput (tokens\/s)":292.0,
        "Allocated Memory (MB)":932,
        "Energy (tokens\/kWh)":6578947,
        "E2E Latency (s)":0.878,
        "E2E Throughput (tokens\/s)":292.0,
        "Reserved Memory (MB)":968,
        "Used Memory (MB)":1821
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":0.16,
        "Open LLM Score (%)":"29.41 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0044,
        "Decode Throughput (tokens\/s)":243.0,
        "Allocated Memory (MB)":446,
        "Energy (tokens\/kWh)":7751937,
        "E2E Latency (s)":1.05,
        "E2E Throughput (tokens\/s)":244.0,
        "Reserved Memory (MB)":469,
        "Used Memory (MB)":1328
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":0.16,
        "Open LLM Score (%)":"29.41 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00443,
        "Decode Throughput (tokens\/s)":252.0,
        "Allocated Memory (MB)":804,
        "Energy (tokens\/kWh)":6134969,
        "E2E Latency (s)":1.01,
        "E2E Throughput (tokens\/s)":253.0,
        "Reserved Memory (MB)":870,
        "Used Memory (MB)":1722
    },
    {
        "Model":"cerebras\/Cerebras-GPT-256M",
        "Arch":"GPT-2",
        "Params (B)":0.26,
        "Open LLM Score (%)":"29.38 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00395,
        "Decode Throughput (tokens\/s)":266.0,
        "Allocated Memory (MB)":665,
        "Energy (tokens\/kWh)":7194244,
        "E2E Latency (s)":0.963,
        "E2E Throughput (tokens\/s)":266.0,
        "Reserved Memory (MB)":748,
        "Used Memory (MB)":1607
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.38 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00453,
        "Decode Throughput (tokens\/s)":230.0,
        "Allocated Memory (MB)":458,
        "Energy (tokens\/kWh)":7194244,
        "E2E Latency (s)":1.11,
        "E2E Throughput (tokens\/s)":231.0,
        "Reserved Memory (MB)":509,
        "Used Memory (MB)":1368
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.38 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00474,
        "Decode Throughput (tokens\/s)":230.0,
        "Allocated Memory (MB)":828,
        "Energy (tokens\/kWh)":6024096,
        "E2E Latency (s)":1.11,
        "E2E Throughput (tokens\/s)":231.0,
        "Reserved Memory (MB)":903,
        "Used Memory (MB)":1756
    },
    {
        "Model":"cerebras\/Cerebras-GPT-256M",
        "Arch":"GPT-2",
        "Params (B)":0.26,
        "Open LLM Score (%)":"29.38 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00598,
        "Decode Throughput (tokens\/s)":250.0,
        "Allocated Memory (MB)":1257,
        "Energy (tokens\/kWh)":5494505,
        "E2E Latency (s)":1.03,
        "E2E Throughput (tokens\/s)":249.0,
        "Reserved Memory (MB)":1321,
        "Used Memory (MB)":2173
    },
    {
        "Model":"chargoddard\/SmolLlamix-8x101M-take2",
        "Arch":"\u24c2\ufe0f Mixtral",
        "Params (B)":0.4,
        "Open LLM Score (%)":"29.35 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0119,
        "Decode Throughput (tokens\/s)":172.0,
        "Allocated Memory (MB)":894,
        "Energy (tokens\/kWh)":5813953,
        "E2E Latency (s)":1.49,
        "E2E Throughput (tokens\/s)":172.0,
        "Reserved Memory (MB)":945,
        "Used Memory (MB)":1804
    },
    {
        "Model":"chargoddard\/SmolLlamix-8x101M-take2",
        "Arch":"\u24c2\ufe0f Mixtral",
        "Params (B)":0.4,
        "Open LLM Score (%)":"29.35 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0127,
        "Decode Throughput (tokens\/s)":181.0,
        "Allocated Memory (MB)":1697,
        "Energy (tokens\/kWh)":5208333,
        "E2E Latency (s)":1.42,
        "E2E Throughput (tokens\/s)":180.0,
        "Reserved Memory (MB)":1895,
        "Used Memory (MB)":2748
    },
    {
        "Model":"bit-dny\/MindLLM",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.28 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0102,
        "Decode Throughput (tokens\/s)":126.0,
        "Allocated Memory (MB)":3048,
        "Energy (tokens\/kWh)":2331002,
        "E2E Latency (s)":2.04,
        "E2E Throughput (tokens\/s)":125.0,
        "Reserved Memory (MB)":3131,
        "Used Memory (MB)":3989
    },
    {
        "Model":"bit-dny\/MindLLM",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.28 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.023,
        "Decode Throughput (tokens\/s)":107.0,
        "Allocated Memory (MB)":5980,
        "Energy (tokens\/kWh)":1742160,
        "E2E Latency (s)":2.4,
        "E2E Throughput (tokens\/s)":107.0,
        "Reserved Memory (MB)":6025,
        "Used Memory (MB)":6877
    },
    {
        "Model":"BEE-spoke-data\/NanoLlama-GQA-L10-A32_KV8-v13-KI",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.22,
        "Open LLM Score (%)":"29.23 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00391,
        "Decode Throughput (tokens\/s)":245.0,
        "Allocated Memory (MB)":500,
        "Energy (tokens\/kWh)":7407407,
        "E2E Latency (s)":1.04,
        "E2E Throughput (tokens\/s)":246.0,
        "Reserved Memory (MB)":549,
        "Used Memory (MB)":1408
    },
    {
        "Model":"BEE-spoke-data\/NanoLlama-GQA-L10-A32_KV8-v13-KI",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.22,
        "Open LLM Score (%)":"29.23 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00439,
        "Decode Throughput (tokens\/s)":294.0,
        "Allocated Memory (MB)":932,
        "Energy (tokens\/kWh)":6578947,
        "E2E Latency (s)":0.871,
        "E2E Throughput (tokens\/s)":294.0,
        "Reserved Memory (MB)":968,
        "Used Memory (MB)":1821
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"29.15 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00226,
        "Decode Throughput (tokens\/s)":437.0,
        "Allocated Memory (MB)":221,
        "Energy (tokens\/kWh)":15082956,
        "E2E Latency (s)":0.586,
        "E2E Throughput (tokens\/s)":437.0,
        "Reserved Memory (MB)":236,
        "Used Memory (MB)":1089
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"29.15 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00237,
        "Decode Throughput (tokens\/s)":424.0,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":15822784,
        "E2E Latency (s)":0.603,
        "E2E Throughput (tokens\/s)":425.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1001
    },
    {
        "Model":"roneneldan\/TinyStories-1M",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.14 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00233,
        "Decode Throughput (tokens\/s)":409.0,
        "Allocated Memory (MB)":112,
        "Energy (tokens\/kWh)":14245014,
        "E2E Latency (s)":0.625,
        "E2E Throughput (tokens\/s)":410.0,
        "Reserved Memory (MB)":140,
        "Used Memory (MB)":992
    },
    {
        "Model":"roneneldan\/TinyStories-1M",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.14 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00255,
        "Decode Throughput (tokens\/s)":384.0,
        "Allocated Memory (MB)":77,
        "Energy (tokens\/kWh)":13869625,
        "E2E Latency (s)":0.667,
        "E2E Throughput (tokens\/s)":384.0,
        "Reserved Memory (MB)":96,
        "Used Memory (MB)":955
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.11 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00741,
        "Decode Throughput (tokens\/s)":142.0,
        "Allocated Memory (MB)":1939,
        "Energy (tokens\/kWh)":3058103,
        "E2E Latency (s)":1.8,
        "E2E Throughput (tokens\/s)":142.0,
        "Reserved Memory (MB)":2084,
        "Used Memory (MB)":2943
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.11*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.00998,
        "Decode Throughput (tokens\/s)":136.0,
        "Allocated Memory (MB)":942,
        "Energy (tokens\/kWh)":3389830,
        "E2E Latency (s)":1.89,
        "E2E Throughput (tokens\/s)":135.0,
        "Reserved Memory (MB)":1073,
        "Used Memory (MB)":1932
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.11*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.01,
        "Decode Throughput (tokens\/s)":151.0,
        "Allocated Memory (MB)":962,
        "Energy (tokens\/kWh)":3787878,
        "E2E Latency (s)":1.7,
        "E2E Throughput (tokens\/s)":151.0,
        "Reserved Memory (MB)":1090,
        "Used Memory (MB)":3897
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.11*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0153,
        "Decode Throughput (tokens\/s)":119.0,
        "Allocated Memory (MB)":943,
        "Energy (tokens\/kWh)":2985074,
        "E2E Latency (s)":2.16,
        "E2E Throughput (tokens\/s)":119.0,
        "Reserved Memory (MB)":1084,
        "Used Memory (MB)":1942
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.11 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0161,
        "Decode Throughput (tokens\/s)":147.0,
        "Allocated Memory (MB)":3893,
        "Energy (tokens\/kWh)":2421307,
        "E2E Latency (s)":1.75,
        "E2E Throughput (tokens\/s)":146.0,
        "Reserved Memory (MB)":3942,
        "Used Memory (MB)":4795
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.11*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0192,
        "Decode Throughput (tokens\/s)":68.5,
        "Allocated Memory (MB)":941,
        "Energy (tokens\/kWh)":2118644,
        "E2E Latency (s)":3.74,
        "E2E Throughput (tokens\/s)":68.4,
        "Reserved Memory (MB)":1113,
        "Used Memory (MB)":1972
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.02 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00468,
        "Decode Throughput (tokens\/s)":226.0,
        "Allocated Memory (MB)":828,
        "Energy (tokens\/kWh)":5882352,
        "E2E Latency (s)":1.13,
        "E2E Throughput (tokens\/s)":227.0,
        "Reserved Memory (MB)":903,
        "Used Memory (MB)":1756
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.02 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00468,
        "Decode Throughput (tokens\/s)":222.0,
        "Allocated Memory (MB)":458,
        "Energy (tokens\/kWh)":7299270,
        "E2E Latency (s)":1.15,
        "E2E Throughput (tokens\/s)":223.0,
        "Reserved Memory (MB)":509,
        "Used Memory (MB)":1368
    },
    {
        "Model":"chargoddard\/SmolLlamix-8x101M",
        "Arch":"\u24c2\ufe0f Mixtral",
        "Params (B)":0.4,
        "Open LLM Score (%)":"28.98 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0118,
        "Decode Throughput (tokens\/s)":168.0,
        "Allocated Memory (MB)":895,
        "Energy (tokens\/kWh)":5494505,
        "E2E Latency (s)":1.53,
        "E2E Throughput (tokens\/s)":167.0,
        "Reserved Memory (MB)":945,
        "Used Memory (MB)":1804
    },
    {
        "Model":"chargoddard\/SmolLlamix-8x101M",
        "Arch":"\u24c2\ufe0f Mixtral",
        "Params (B)":0.4,
        "Open LLM Score (%)":"28.98 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0126,
        "Decode Throughput (tokens\/s)":176.0,
        "Allocated Memory (MB)":1697,
        "Energy (tokens\/kWh)":4975124,
        "E2E Latency (s)":1.46,
        "E2E Throughput (tokens\/s)":175.0,
        "Reserved Memory (MB)":1895,
        "Used Memory (MB)":2750
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-101M-GQA",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.97 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00232,
        "Decode Throughput (tokens\/s)":401.0,
        "Allocated Memory (MB)":269,
        "Energy (tokens\/kWh)":12804097,
        "E2E Latency (s)":0.638,
        "E2E Throughput (tokens\/s)":401.0,
        "Reserved Memory (MB)":293,
        "Used Memory (MB)":1152
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-101M-GQA",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.97 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00249,
        "Decode Throughput (tokens\/s)":462.0,
        "Allocated Memory (MB)":456,
        "Energy (tokens\/kWh)":11261261,
        "E2E Latency (s)":0.554,
        "E2E Throughput (tokens\/s)":462.0,
        "Reserved Memory (MB)":513,
        "Used Memory (MB)":1366
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"GPT-NeoX",
        "Params (B)":0.0,
        "Open LLM Score (%)":"28.88 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00898,
        "Decode Throughput (tokens\/s)":118.0,
        "Allocated Memory (MB)":1976,
        "Energy (tokens\/kWh)":2754820,
        "E2E Latency (s)":2.18,
        "E2E Throughput (tokens\/s)":117.0,
        "Reserved Memory (MB)":2113,
        "Used Memory (MB)":2972
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"GPT-NeoX",
        "Params (B)":0.0,
        "Open LLM Score (%)":"28.88 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0152,
        "Decode Throughput (tokens\/s)":119.0,
        "Allocated Memory (MB)":3836,
        "Energy (tokens\/kWh)":2262443,
        "E2E Latency (s)":2.17,
        "E2E Throughput (tokens\/s)":118.0,
        "Reserved Memory (MB)":3915,
        "Used Memory (MB)":4767
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.85 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00229,
        "Decode Throughput (tokens\/s)":449.0,
        "Allocated Memory (MB)":221,
        "Energy (tokens\/kWh)":15503875,
        "E2E Latency (s)":0.57,
        "E2E Throughput (tokens\/s)":449.0,
        "Reserved Memory (MB)":236,
        "Used Memory (MB)":1089
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.85 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0023,
        "Decode Throughput (tokens\/s)":423.0,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":15527950,
        "E2E Latency (s)":0.605,
        "E2E Throughput (tokens\/s)":423.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1001
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.81 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00236,
        "Decode Throughput (tokens\/s)":431.0,
        "Allocated Memory (MB)":221,
        "Energy (tokens\/kWh)":14947683,
        "E2E Latency (s)":0.593,
        "E2E Throughput (tokens\/s)":432.0,
        "Reserved Memory (MB)":236,
        "Used Memory (MB)":1089
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.81 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00241,
        "Decode Throughput (tokens\/s)":416.0,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":15037593,
        "E2E Latency (s)":0.615,
        "E2E Throughput (tokens\/s)":416.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1001
    },
    {
        "Model":"Locutusque\/TinyMistral-248M-v2",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":0.25,
        "Open LLM Score (%)":"28.78 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00516,
        "Decode Throughput (tokens\/s)":204.0,
        "Allocated Memory (MB)":608,
        "Energy (tokens\/kWh)":5780346,
        "E2E Latency (s)":1.26,
        "E2E Throughput (tokens\/s)":203.0,
        "Reserved Memory (MB)":656,
        "Used Memory (MB)":1515
    },
    {
        "Model":"Locutusque\/TinyMistral-248M-v2",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":0.25,
        "Open LLM Score (%)":"28.78 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00552,
        "Decode Throughput (tokens\/s)":228.0,
        "Allocated Memory (MB)":1153,
        "Energy (tokens\/kWh)":5128205,
        "E2E Latency (s)":1.13,
        "E2E Throughput (tokens\/s)":227.0,
        "Reserved Memory (MB)":1199,
        "Used Memory (MB)":2051
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.06,
        "Open LLM Score (%)":"28.70 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00203,
        "Decode Throughput (tokens\/s)":494.0,
        "Allocated Memory (MB)":288,
        "Energy (tokens\/kWh)":13054830,
        "E2E Latency (s)":0.518,
        "E2E Throughput (tokens\/s)":494.0,
        "Reserved Memory (MB)":327,
        "Used Memory (MB)":1179
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.06,
        "Open LLM Score (%)":"28.70 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00214,
        "Decode Throughput (tokens\/s)":416.0,
        "Allocated Memory (MB)":180,
        "Energy (tokens\/kWh)":14749262,
        "E2E Latency (s)":0.615,
        "E2E Throughput (tokens\/s)":416.0,
        "Reserved Memory (MB)":209,
        "Used Memory (MB)":1068
    },
    {
        "Model":"RWKV\/rwkv-4-169m-pile",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":0.17,
        "Open LLM Score (%)":"28.64 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00568,
        "Decode Throughput (tokens\/s)":195.0,
        "Allocated Memory (MB)":740,
        "Energy (tokens\/kWh)":5319148,
        "E2E Latency (s)":1.32,
        "E2E Throughput (tokens\/s)":194.0,
        "Reserved Memory (MB)":815,
        "Used Memory (MB)":1668
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.61 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00229,
        "Decode Throughput (tokens\/s)":455.0,
        "Allocated Memory (MB)":221,
        "Energy (tokens\/kWh)":15797788,
        "E2E Latency (s)":0.562,
        "E2E Throughput (tokens\/s)":456.0,
        "Reserved Memory (MB)":236,
        "Used Memory (MB)":1089
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.61 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00233,
        "Decode Throughput (tokens\/s)":441.0,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":16103059,
        "E2E Latency (s)":0.58,
        "E2E Throughput (tokens\/s)":441.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1001
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.60 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00231,
        "Decode Throughput (tokens\/s)":440.0,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":16025641,
        "E2E Latency (s)":0.582,
        "E2E Throughput (tokens\/s)":440.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1001
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.60 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00234,
        "Decode Throughput (tokens\/s)":450.0,
        "Allocated Memory (MB)":221,
        "Energy (tokens\/kWh)":15220700,
        "E2E Latency (s)":0.569,
        "E2E Throughput (tokens\/s)":450.0,
        "Reserved Memory (MB)":236,
        "Used Memory (MB)":1089
    },
    {
        "Model":"gpt2",
        "Arch":"GPT-2",
        "Params (B)":0.14,
        "Open LLM Score (%)":"28.53 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00418,
        "Decode Throughput (tokens\/s)":252.0,
        "Allocated Memory (MB)":621,
        "Energy (tokens\/kWh)":6578947,
        "E2E Latency (s)":1.01,
        "E2E Throughput (tokens\/s)":253.0,
        "Reserved Memory (MB)":717,
        "Used Memory (MB)":1569
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":1.12,
        "Open LLM Score (%)":"28.49 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0176,
        "Decode Throughput (tokens\/s)":166.0,
        "Allocated Memory (MB)":4628,
        "Energy (tokens\/kWh)":2267573,
        "E2E Latency (s)":1.56,
        "E2E Throughput (tokens\/s)":164.0,
        "Reserved Memory (MB)":4708,
        "Used Memory (MB)":5560
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-126m",
        "Arch":"GPT-2",
        "Params (B)":0.19,
        "Open LLM Score (%)":"28.45 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00387,
        "Decode Throughput (tokens\/s)":287.0,
        "Allocated Memory (MB)":721,
        "Energy (tokens\/kWh)":6711409,
        "E2E Latency (s)":0.894,
        "E2E Throughput (tokens\/s)":286.0,
        "Reserved Memory (MB)":803,
        "Used Memory (MB)":1655
    },
    {
        "Model":"BEE-spoke-data\/Mixtral-GQA-400m-v2",
        "Arch":"\u24c2\ufe0f Mixtral",
        "Params (B)":2.01,
        "Open LLM Score (%)":"28.45 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0143,
        "Decode Throughput (tokens\/s)":159.0,
        "Allocated Memory (MB)":4083,
        "Energy (tokens\/kWh)":3816793,
        "E2E Latency (s)":1.61,
        "E2E Throughput (tokens\/s)":159.0,
        "Reserved Memory (MB)":4112,
        "Used Memory (MB)":4971
    },
    {
        "Model":"BEE-spoke-data\/Mixtral-GQA-400m-v2",
        "Arch":"\u24c2\ufe0f Mixtral",
        "Params (B)":2.01,
        "Open LLM Score (%)":"28.45 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0219,
        "Decode Throughput (tokens\/s)":143.0,
        "Allocated Memory (MB)":8095,
        "Energy (tokens\/kWh)":2801120,
        "E2E Latency (s)":1.8,
        "E2E Throughput (tokens\/s)":142.0,
        "Reserved Memory (MB)":8143,
        "Used Memory (MB)":8995
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.44 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00246,
        "Decode Throughput (tokens\/s)":421.0,
        "Allocated Memory (MB)":216,
        "Energy (tokens\/kWh)":15151515,
        "E2E Latency (s)":0.608,
        "E2E Throughput (tokens\/s)":421.0,
        "Reserved Memory (MB)":236,
        "Used Memory (MB)":1095
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.44 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00257,
        "Decode Throughput (tokens\/s)":431.0,
        "Allocated Memory (MB)":397,
        "Energy (tokens\/kWh)":12836970,
        "E2E Latency (s)":0.594,
        "E2E Throughput (tokens\/s)":431.0,
        "Reserved Memory (MB)":427,
        "Used Memory (MB)":1280
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"GPT-Neo",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.44 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00277,
        "Decode Throughput (tokens\/s)":405.0,
        "Allocated Memory (MB)":320,
        "Energy (tokens\/kWh)":12690355,
        "E2E Latency (s)":0.632,
        "E2E Throughput (tokens\/s)":405.0,
        "Reserved Memory (MB)":356,
        "Used Memory (MB)":1208
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.0,
        "Open LLM Score (%)":"28.44 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.004,
        "Decode Throughput (tokens\/s)":355.0,
        "Allocated Memory (MB)":2229,
        "Energy (tokens\/kWh)":5128205,
        "E2E Latency (s)":0.723,
        "E2E Throughput (tokens\/s)":354.0,
        "Reserved Memory (MB)":2250,
        "Used Memory (MB)":3108
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.0,
        "Open LLM Score (%)":"28.44 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0136,
        "Decode Throughput (tokens\/s)":206.0,
        "Allocated Memory (MB)":4446,
        "Energy (tokens\/kWh)":2680965,
        "E2E Latency (s)":1.25,
        "E2E Throughput (tokens\/s)":205.0,
        "Reserved Memory (MB)":4510,
        "Used Memory (MB)":5363
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"GPT-Neo",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.41 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00194,
        "Decode Throughput (tokens\/s)":651.0,
        "Allocated Memory (MB)":366,
        "Energy (tokens\/kWh)":15797788,
        "E2E Latency (s)":0.394,
        "E2E Throughput (tokens\/s)":650.0,
        "Reserved Memory (MB)":419,
        "Used Memory (MB)":1271
    },
    {
        "Model":"SaylorTwift\/gpt2_test",
        "Arch":"GPT-2",
        "Params (B)":0.14,
        "Open LLM Score (%)":"28.40 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00413,
        "Decode Throughput (tokens\/s)":257.0,
        "Allocated Memory (MB)":621,
        "Energy (tokens\/kWh)":6622516,
        "E2E Latency (s)":0.998,
        "E2E Throughput (tokens\/s)":257.0,
        "Reserved Memory (MB)":717,
        "Used Memory (MB)":1569
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"GPT-Neo",
        "Params (B)":0.01,
        "Open LLM Score (%)":"28.31 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00264,
        "Decode Throughput (tokens\/s)":397.0,
        "Allocated Memory (MB)":183,
        "Energy (tokens\/kWh)":13245033,
        "E2E Latency (s)":0.646,
        "E2E Throughput (tokens\/s)":396.0,
        "Reserved Memory (MB)":216,
        "Used Memory (MB)":1068
    },
    {
        "Model":"instructkr\/ko-wand-136M",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":0.14,
        "Open LLM Score (%)":"28.29 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00327,
        "Decode Throughput (tokens\/s)":303.0,
        "Allocated Memory (MB)":347,
        "Energy (tokens\/kWh)":8196721,
        "E2E Latency (s)":0.844,
        "E2E Throughput (tokens\/s)":303.0,
        "Reserved Memory (MB)":383,
        "Used Memory (MB)":1242
    },
    {
        "Model":"instructkr\/ko-wand-136M",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":0.14,
        "Open LLM Score (%)":"28.29 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00355,
        "Decode Throughput (tokens\/s)":311.0,
        "Allocated Memory (MB)":613,
        "Energy (tokens\/kWh)":7936507,
        "E2E Latency (s)":0.824,
        "E2E Throughput (tokens\/s)":311.0,
        "Reserved Memory (MB)":668,
        "Used Memory (MB)":1521
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.27 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00229,
        "Decode Throughput (tokens\/s)":436.0,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":15174506,
        "E2E Latency (s)":0.587,
        "E2E Throughput (tokens\/s)":436.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1001
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.27 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00232,
        "Decode Throughput (tokens\/s)":450.0,
        "Allocated Memory (MB)":221,
        "Energy (tokens\/kWh)":15037593,
        "E2E Latency (s)":0.569,
        "E2E Throughput (tokens\/s)":450.0,
        "Reserved Memory (MB)":236,
        "Used Memory (MB)":1089
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"28.19 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00238,
        "Decode Throughput (tokens\/s)":415.0,
        "Allocated Memory (MB)":132,
        "Energy (tokens\/kWh)":13698630,
        "E2E Latency (s)":0.617,
        "E2E Throughput (tokens\/s)":415.0,
        "Reserved Memory (MB)":161,
        "Used Memory (MB)":1013
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-81M-tied",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.08,
        "Open LLM Score (%)":"28.17 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00224,
        "Decode Throughput (tokens\/s)":409.0,
        "Allocated Memory (MB)":232,
        "Energy (tokens\/kWh)":13642564,
        "E2E Latency (s)":0.625,
        "E2E Throughput (tokens\/s)":410.0,
        "Reserved Memory (MB)":276,
        "Used Memory (MB)":1135
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-81M-tied",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.08,
        "Open LLM Score (%)":"28.17 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00255,
        "Decode Throughput (tokens\/s)":479.0,
        "Allocated Memory (MB)":387,
        "Energy (tokens\/kWh)":11273957,
        "E2E Latency (s)":0.535,
        "E2E Throughput (tokens\/s)":479.0,
        "Reserved Memory (MB)":438,
        "Used Memory (MB)":1290
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"27.95 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00383,
        "Decode Throughput (tokens\/s)":276.0,
        "Allocated Memory (MB)":480,
        "Energy (tokens\/kWh)":8264462,
        "E2E Latency (s)":0.927,
        "E2E Throughput (tokens\/s)":276.0,
        "Reserved Memory (MB)":553,
        "Used Memory (MB)":1412
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"27.95 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00447,
        "Decode Throughput (tokens\/s)":277.0,
        "Allocated Memory (MB)":934,
        "Energy (tokens\/kWh)":6369426,
        "E2E Latency (s)":0.924,
        "E2E Throughput (tokens\/s)":277.0,
        "Reserved Memory (MB)":1035,
        "Used Memory (MB)":1888
    },
    {
        "Model":"cerebras\/Cerebras-GPT-111M",
        "Arch":"GPT-2",
        "Params (B)":0.11,
        "Open LLM Score (%)":"27.75 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00294,
        "Decode Throughput (tokens\/s)":352.0,
        "Allocated Memory (MB)":332,
        "Energy (tokens\/kWh)":11061946,
        "E2E Latency (s)":0.727,
        "E2E Throughput (tokens\/s)":352.0,
        "Reserved Memory (MB)":381,
        "Used Memory (MB)":1240
    },
    {
        "Model":"cerebras\/Cerebras-GPT-111M",
        "Arch":"GPT-2",
        "Params (B)":0.11,
        "Open LLM Score (%)":"27.75 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00321,
        "Decode Throughput (tokens\/s)":357.0,
        "Allocated Memory (MB)":592,
        "Energy (tokens\/kWh)":8333333,
        "E2E Latency (s)":0.717,
        "E2E Throughput (tokens\/s)":357.0,
        "Reserved Memory (MB)":675,
        "Used Memory (MB)":1527
    },
    {
        "Model":"Locutusque\/TinyMistral-248m",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":0.25,
        "Open LLM Score (%)":"27.73 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00517,
        "Decode Throughput (tokens\/s)":201.0,
        "Allocated Memory (MB)":608,
        "Energy (tokens\/kWh)":5780346,
        "E2E Latency (s)":1.28,
        "E2E Throughput (tokens\/s)":200.0,
        "Reserved Memory (MB)":656,
        "Used Memory (MB)":1515
    },
    {
        "Model":"Locutusque\/TinyMistral-248m",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":0.25,
        "Open LLM Score (%)":"27.73 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00559,
        "Decode Throughput (tokens\/s)":222.0,
        "Allocated Memory (MB)":1153,
        "Energy (tokens\/kWh)":5263157,
        "E2E Latency (s)":1.16,
        "E2E Throughput (tokens\/s)":221.0,
        "Reserved Memory (MB)":1199,
        "Used Memory (MB)":2051
    },
    {
        "Model":"ai-forever\/mGPT",
        "Arch":"GPT-2",
        "Params (B)":0.0,
        "Open LLM Score (%)":"27.61 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00973,
        "Decode Throughput (tokens\/s)":133.0,
        "Allocated Memory (MB)":3147,
        "Energy (tokens\/kWh)":2469135,
        "E2E Latency (s)":1.93,
        "E2E Throughput (tokens\/s)":133.0,
        "Reserved Memory (MB)":3191,
        "Used Memory (MB)":4050
    },
    {
        "Model":"ai-forever\/mGPT",
        "Arch":"GPT-2",
        "Params (B)":0.0,
        "Open LLM Score (%)":"27.61 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0208,
        "Decode Throughput (tokens\/s)":99.2,
        "Allocated Memory (MB)":6184,
        "Energy (tokens\/kWh)":1345895,
        "E2E Latency (s)":2.59,
        "E2E Throughput (tokens\/s)":98.8,
        "Reserved Memory (MB)":6218,
        "Used Memory (MB)":7070
    },
    {
        "Model":"team-lucid\/mptk-1b",
        "Arch":"\ud83e\uddf1 MPT",
        "Params (B)":1.31,
        "Open LLM Score (%)":"20.84 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00773,
        "Decode Throughput (tokens\/s)":192.0,
        "Allocated Memory (MB)":2834,
        "Energy (tokens\/kWh)":3144654,
        "E2E Latency (s)":1.34,
        "E2E Throughput (tokens\/s)":191.0,
        "Reserved Memory (MB)":2856,
        "Used Memory (MB)":3715
    },
    {
        "Model":"team-lucid\/mptk-1b",
        "Arch":"\ud83e\uddf1 MPT",
        "Params (B)":1.31,
        "Open LLM Score (%)":"20.84 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0201,
        "Decode Throughput (tokens\/s)":142.0,
        "Allocated Memory (MB)":5657,
        "Energy (tokens\/kWh)":1968503,
        "E2E Latency (s)":1.82,
        "E2E Throughput (tokens\/s)":141.0,
        "Reserved Memory (MB)":5697,
        "Used Memory (MB)":6550
    }
]