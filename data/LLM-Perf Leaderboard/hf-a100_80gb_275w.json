[
    {
        "Model":"cloudyu\/Mixtral_11Bx2_MoE_19B",
        "Arch":"\u24c2\ufe0f Mixtral",
        "Params (B)":19.19,
        "Open LLM Score (%)":"74.41 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.116,
        "Decode Throughput (tokens\/s)":11.6,
        "Allocated Memory (MB)":38693,
        "Energy (tokens\/kWh)":143678,
        "E2E Latency (s)":22.1,
        "E2E Throughput (tokens\/s)":11.6,
        "Reserved Memory (MB)":38958,
        "Used Memory (MB)":40418
    },
    {
        "Model":"cloudyu\/Mixtral_11Bx2_MoE_19B",
        "Arch":"\u24c2\ufe0f Mixtral",
        "Params (B)":19.19,
        "Open LLM Score (%)":"74.41 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.866,
        "Decode Throughput (tokens\/s)":11.2,
        "Allocated Memory (MB)":77380,
        "Energy (tokens\/kWh)":105485,
        "E2E Latency (s)":23.6,
        "E2E Throughput (tokens\/s)":10.8,
        "Reserved Memory (MB)":77512,
        "Used Memory (MB)":78964
    },
    {
        "Model":"rishiraj\/CatPPT-base",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.24,
        "Open LLM Score (%)":"72.25 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0354,
        "Decode Throughput (tokens\/s)":34.7,
        "Allocated Memory (MB)":15171,
        "Energy (tokens\/kWh)":408163,
        "E2E Latency (s)":7.39,
        "E2E Throughput (tokens\/s)":34.6,
        "Reserved Memory (MB)":15374,
        "Used Memory (MB)":16833
    },
    {
        "Model":"rishiraj\/CatPPT-base",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.24,
        "Open LLM Score (%)":"72.25 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0413,
        "Decode Throughput (tokens\/s)":34.0,
        "Allocated Memory (MB)":15171,
        "Energy (tokens\/kWh)":387596,
        "E2E Latency (s)":7.53,
        "E2E Throughput (tokens\/s)":34.0,
        "Reserved Memory (MB)":15372,
        "Used Memory (MB)":16831
    },
    {
        "Model":"rishiraj\/CatPPT-base",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.24,
        "Open LLM Score (%)":"72.25*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0451,
        "Decode Throughput (tokens\/s)":32.2,
        "Allocated Memory (MB)":4963,
        "Energy (tokens\/kWh)":434782,
        "E2E Latency (s)":7.98,
        "E2E Throughput (tokens\/s)":32.1,
        "Reserved Memory (MB)":5161,
        "Used Memory (MB)":6622
    },
    {
        "Model":"rishiraj\/CatPPT-base",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.24,
        "Open LLM Score (%)":"72.25*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0461,
        "Decode Throughput (tokens\/s)":32.4,
        "Allocated Memory (MB)":5908,
        "Energy (tokens\/kWh)":465116,
        "E2E Latency (s)":7.92,
        "E2E Throughput (tokens\/s)":32.3,
        "Reserved Memory (MB)":6106,
        "Used Memory (MB)":7568
    },
    {
        "Model":"rishiraj\/CatPPT-base",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.24,
        "Open LLM Score (%)":"72.25*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0659,
        "Decode Throughput (tokens\/s)":33.5,
        "Allocated Memory (MB)":4838,
        "Energy (tokens\/kWh)":456621,
        "E2E Latency (s)":7.68,
        "E2E Throughput (tokens\/s)":33.3,
        "Reserved Memory (MB)":5052,
        "Used Memory (MB)":6511
    },
    {
        "Model":"rishiraj\/CatPPT-base",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.24,
        "Open LLM Score (%)":"72.25*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0766,
        "Decode Throughput (tokens\/s)":30.4,
        "Allocated Memory (MB)":4838,
        "Energy (tokens\/kWh)":427350,
        "E2E Latency (s)":8.47,
        "E2E Throughput (tokens\/s)":30.2,
        "Reserved Memory (MB)":5052,
        "Used Memory (MB)":6511
    },
    {
        "Model":"rishiraj\/CatPPT-base",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.24,
        "Open LLM Score (%)":"72.25*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.101,
        "Decode Throughput (tokens\/s)":9.88,
        "Allocated Memory (MB)":8197,
        "Energy (tokens\/kWh)":146412,
        "E2E Latency (s)":25.9,
        "E2E Throughput (tokens\/s)":9.88,
        "Reserved Memory (MB)":8399,
        "Used Memory (MB)":9867
    },
    {
        "Model":"rishiraj\/CatPPT-base",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.24,
        "Open LLM Score (%)":"72.25*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.103,
        "Decode Throughput (tokens\/s)":9.7,
        "Allocated Memory (MB)":8197,
        "Energy (tokens\/kWh)":143678,
        "E2E Latency (s)":26.4,
        "E2E Throughput (tokens\/s)":9.7,
        "Reserved Memory (MB)":8399,
        "Used Memory (MB)":9867
    },
    {
        "Model":"rishiraj\/CatPPT-base",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.24,
        "Open LLM Score (%)":"72.25 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.264,
        "Decode Throughput (tokens\/s)":37.2,
        "Allocated Memory (MB)":30334,
        "Energy (tokens\/kWh)":327868,
        "E2E Latency (s)":7.12,
        "E2E Throughput (tokens\/s)":36.0,
        "Reserved Memory (MB)":30431,
        "Used Memory (MB)":31883
    },
    {
        "Model":"rishiraj\/CatPPT-base",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.24,
        "Open LLM Score (%)":"72.25*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.289,
        "Decode Throughput (tokens\/s)":20.7,
        "Allocated Memory (MB)":5428,
        "Energy (tokens\/kWh)":274725,
        "E2E Latency (s)":12.6,
        "E2E Throughput (tokens\/s)":20.3,
        "Reserved Memory (MB)":5758,
        "Used Memory (MB)":7218
    },
    {
        "Model":"rishiraj\/CatPPT-base",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.24,
        "Open LLM Score (%)":"72.25*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.299,
        "Decode Throughput (tokens\/s)":20.7,
        "Allocated Memory (MB)":5428,
        "Energy (tokens\/kWh)":270270,
        "E2E Latency (s)":12.6,
        "E2E Throughput (tokens\/s)":20.3,
        "Reserved Memory (MB)":5758,
        "Used Memory (MB)":7218
    },
    {
        "Model":"chargoddard\/Yi-34B-Llama",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":34.39,
        "Open LLM Score (%)":"70.95 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.134,
        "Decode Throughput (tokens\/s)":18.5,
        "Allocated Memory (MB)":69165,
        "Energy (tokens\/kWh)":166112,
        "E2E Latency (s)":13.9,
        "E2E Throughput (tokens\/s)":18.4,
        "Reserved Memory (MB)":69331,
        "Used Memory (MB)":70791
    },
    {
        "Model":"chargoddard\/Yi-34B-Llama",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":34.39,
        "Open LLM Score (%)":"70.95*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.163,
        "Decode Throughput (tokens\/s)":19.6,
        "Allocated Memory (MB)":19971,
        "Energy (tokens\/kWh)":199203,
        "E2E Latency (s)":13.2,
        "E2E Throughput (tokens\/s)":19.4,
        "Reserved Memory (MB)":20336,
        "Used Memory (MB)":21797
    },
    {
        "Model":"chargoddard\/Yi-34B-Llama",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":34.39,
        "Open LLM Score (%)":"70.95*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.164,
        "Decode Throughput (tokens\/s)":19.6,
        "Allocated Memory (MB)":21328,
        "Energy (tokens\/kWh)":241545,
        "E2E Latency (s)":13.2,
        "E2E Throughput (tokens\/s)":19.4,
        "Reserved Memory (MB)":21695,
        "Used Memory (MB)":23156
    },
    {
        "Model":"chargoddard\/Yi-34B-Llama",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":34.39,
        "Open LLM Score (%)":"70.95*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.185,
        "Decode Throughput (tokens\/s)":5.41,
        "Allocated Memory (MB)":35851,
        "Energy (tokens\/kWh)":76923,
        "E2E Latency (s)":47.3,
        "E2E Throughput (tokens\/s)":5.41,
        "Reserved Memory (MB)":36383,
        "Used Memory (MB)":37851
    },
    {
        "Model":"chargoddard\/Yi-34B-Llama",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":34.39,
        "Open LLM Score (%)":"70.95*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.187,
        "Decode Throughput (tokens\/s)":5.47,
        "Allocated Memory (MB)":35836,
        "Energy (tokens\/kWh)":73529,
        "E2E Latency (s)":46.8,
        "E2E Throughput (tokens\/s)":5.47,
        "Reserved Memory (MB)":36383,
        "Used Memory (MB)":37851
    },
    {
        "Model":"chargoddard\/Yi-34B-Llama",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":34.39,
        "Open LLM Score (%)":"70.95*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.256,
        "Decode Throughput (tokens\/s)":20.2,
        "Allocated Memory (MB)":19654,
        "Energy (tokens\/kWh)":212314,
        "E2E Latency (s)":12.9,
        "E2E Throughput (tokens\/s)":19.8,
        "Reserved Memory (MB)":20076,
        "Used Memory (MB)":21535
    },
    {
        "Model":"chargoddard\/Yi-34B-Llama",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":34.39,
        "Open LLM Score (%)":"70.95*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.32,
        "Decode Throughput (tokens\/s)":18.3,
        "Allocated Memory (MB)":19654,
        "Energy (tokens\/kWh)":204081,
        "E2E Latency (s)":14.2,
        "E2E Throughput (tokens\/s)":18.0,
        "Reserved Memory (MB)":20076,
        "Used Memory (MB)":21535
    },
    {
        "Model":"chargoddard\/Yi-34B-Llama",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":34.39,
        "Open LLM Score (%)":"70.95*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":1.24,
        "Decode Throughput (tokens\/s)":11.5,
        "Allocated Memory (MB)":21798,
        "Energy (tokens\/kWh)":122850,
        "E2E Latency (s)":23.4,
        "E2E Throughput (tokens\/s)":10.9,
        "Reserved Memory (MB)":22802,
        "Used Memory (MB)":24261
    },
    {
        "Model":"chargoddard\/Yi-34B-Llama",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":34.39,
        "Open LLM Score (%)":"70.95*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":1.25,
        "Decode Throughput (tokens\/s)":11.8,
        "Allocated Memory (MB)":21798,
        "Energy (tokens\/kWh)":124533,
        "E2E Latency (s)":22.9,
        "E2E Throughput (tokens\/s)":11.2,
        "Reserved Memory (MB)":22802,
        "Used Memory (MB)":24261
    },
    {
        "Model":"01-ai\/Yi-34B-200K",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":34.39,
        "Open LLM Score (%)":"70.81 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.134,
        "Decode Throughput (tokens\/s)":18.2,
        "Allocated Memory (MB)":75184,
        "Energy (tokens\/kWh)":165562,
        "E2E Latency (s)":14.1,
        "E2E Throughput (tokens\/s)":18.2,
        "Reserved Memory (MB)":75803,
        "Used Memory (MB)":77263
    },
    {
        "Model":"01-ai\/Yi-34B-200K",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":34.39,
        "Open LLM Score (%)":"70.81*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.163,
        "Decode Throughput (tokens\/s)":19.3,
        "Allocated Memory (MB)":25989,
        "Energy (tokens\/kWh)":198807,
        "E2E Latency (s)":13.4,
        "E2E Throughput (tokens\/s)":19.1,
        "Reserved Memory (MB)":26501,
        "Used Memory (MB)":27963
    },
    {
        "Model":"01-ai\/Yi-34B-200K",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":34.39,
        "Open LLM Score (%)":"70.81*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.164,
        "Decode Throughput (tokens\/s)":19.6,
        "Allocated Memory (MB)":27347,
        "Energy (tokens\/kWh)":242718,
        "E2E Latency (s)":13.2,
        "E2E Throughput (tokens\/s)":19.4,
        "Reserved Memory (MB)":27862,
        "Used Memory (MB)":29324
    },
    {
        "Model":"01-ai\/Yi-34B-200K",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":34.39,
        "Open LLM Score (%)":"70.81*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.186,
        "Decode Throughput (tokens\/s)":5.45,
        "Allocated Memory (MB)":41854,
        "Energy (tokens\/kWh)":74074,
        "E2E Latency (s)":47.0,
        "E2E Throughput (tokens\/s)":5.45,
        "Reserved Memory (MB)":42549,
        "Used Memory (MB)":44017
    },
    {
        "Model":"01-ai\/Yi-34B-200K",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":34.39,
        "Open LLM Score (%)":"70.81*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.189,
        "Decode Throughput (tokens\/s)":5.43,
        "Allocated Memory (MB)":41869,
        "Energy (tokens\/kWh)":76335,
        "E2E Latency (s)":47.2,
        "E2E Throughput (tokens\/s)":5.42,
        "Reserved Memory (MB)":42549,
        "Used Memory (MB)":44017
    },
    {
        "Model":"01-ai\/Yi-34B-200K",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":34.39,
        "Open LLM Score (%)":"70.81*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.254,
        "Decode Throughput (tokens\/s)":20.7,
        "Allocated Memory (MB)":25673,
        "Energy (tokens\/kWh)":212314,
        "E2E Latency (s)":12.6,
        "E2E Throughput (tokens\/s)":20.3,
        "Reserved Memory (MB)":26241,
        "Used Memory (MB)":27701
    },
    {
        "Model":"01-ai\/Yi-34B-200K",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":34.39,
        "Open LLM Score (%)":"70.81*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.313,
        "Decode Throughput (tokens\/s)":18.2,
        "Allocated Memory (MB)":25673,
        "Energy (tokens\/kWh)":204498,
        "E2E Latency (s)":14.3,
        "E2E Throughput (tokens\/s)":17.9,
        "Reserved Memory (MB)":26241,
        "Used Memory (MB)":27701
    },
    {
        "Model":"01-ai\/Yi-34B-200K",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":34.39,
        "Open LLM Score (%)":"70.81*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":1.24,
        "Decode Throughput (tokens\/s)":11.5,
        "Allocated Memory (MB)":27816,
        "Energy (tokens\/kWh)":123609,
        "E2E Latency (s)":23.4,
        "E2E Throughput (tokens\/s)":10.9,
        "Reserved Memory (MB)":28967,
        "Used Memory (MB)":30427
    },
    {
        "Model":"01-ai\/Yi-34B-200K",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":34.39,
        "Open LLM Score (%)":"70.81*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":1.25,
        "Decode Throughput (tokens\/s)":11.8,
        "Allocated Memory (MB)":27816,
        "Energy (tokens\/kWh)":124533,
        "E2E Latency (s)":22.9,
        "E2E Throughput (tokens\/s)":11.2,
        "Reserved Memory (MB)":28967,
        "Used Memory (MB)":30427
    },
    {
        "Model":"01-ai\/Yi-34B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":34.39,
        "Open LLM Score (%)":"69.42 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.134,
        "Decode Throughput (tokens\/s)":18.5,
        "Allocated Memory (MB)":69165,
        "Energy (tokens\/kWh)":166112,
        "E2E Latency (s)":13.9,
        "E2E Throughput (tokens\/s)":18.4,
        "Reserved Memory (MB)":69331,
        "Used Memory (MB)":70791
    },
    {
        "Model":"01-ai\/Yi-34B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":34.39,
        "Open LLM Score (%)":"69.42*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.164,
        "Decode Throughput (tokens\/s)":19.2,
        "Allocated Memory (MB)":21328,
        "Energy (tokens\/kWh)":239234,
        "E2E Latency (s)":13.5,
        "E2E Throughput (tokens\/s)":19.0,
        "Reserved Memory (MB)":21695,
        "Used Memory (MB)":23156
    },
    {
        "Model":"01-ai\/Yi-34B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":34.39,
        "Open LLM Score (%)":"69.42*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.166,
        "Decode Throughput (tokens\/s)":19.6,
        "Allocated Memory (MB)":19971,
        "Energy (tokens\/kWh)":198019,
        "E2E Latency (s)":13.2,
        "E2E Throughput (tokens\/s)":19.4,
        "Reserved Memory (MB)":20336,
        "Used Memory (MB)":21797
    },
    {
        "Model":"01-ai\/Yi-34B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":34.39,
        "Open LLM Score (%)":"69.42*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.182,
        "Decode Throughput (tokens\/s)":5.39,
        "Allocated Memory (MB)":35836,
        "Energy (tokens\/kWh)":74626,
        "E2E Latency (s)":47.5,
        "E2E Throughput (tokens\/s)":5.39,
        "Reserved Memory (MB)":36383,
        "Used Memory (MB)":37851
    },
    {
        "Model":"01-ai\/Yi-34B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":34.39,
        "Open LLM Score (%)":"69.42*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.184,
        "Decode Throughput (tokens\/s)":5.37,
        "Allocated Memory (MB)":35851,
        "Energy (tokens\/kWh)":76335,
        "E2E Latency (s)":47.7,
        "E2E Throughput (tokens\/s)":5.37,
        "Reserved Memory (MB)":36383,
        "Used Memory (MB)":37851
    },
    {
        "Model":"01-ai\/Yi-34B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":34.39,
        "Open LLM Score (%)":"69.42*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.254,
        "Decode Throughput (tokens\/s)":20.2,
        "Allocated Memory (MB)":19654,
        "Energy (tokens\/kWh)":215053,
        "E2E Latency (s)":12.9,
        "E2E Throughput (tokens\/s)":19.8,
        "Reserved Memory (MB)":20076,
        "Used Memory (MB)":21535
    },
    {
        "Model":"01-ai\/Yi-34B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":34.39,
        "Open LLM Score (%)":"69.42*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.314,
        "Decode Throughput (tokens\/s)":18.1,
        "Allocated Memory (MB)":19654,
        "Energy (tokens\/kWh)":200803,
        "E2E Latency (s)":14.4,
        "E2E Throughput (tokens\/s)":17.8,
        "Reserved Memory (MB)":20076,
        "Used Memory (MB)":21535
    },
    {
        "Model":"01-ai\/Yi-34B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":34.39,
        "Open LLM Score (%)":"69.42*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":1.24,
        "Decode Throughput (tokens\/s)":11.5,
        "Allocated Memory (MB)":21798,
        "Energy (tokens\/kWh)":123456,
        "E2E Latency (s)":23.3,
        "E2E Throughput (tokens\/s)":11.0,
        "Reserved Memory (MB)":22802,
        "Used Memory (MB)":24261
    },
    {
        "Model":"01-ai\/Yi-34B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":34.39,
        "Open LLM Score (%)":"69.42*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":1.25,
        "Decode Throughput (tokens\/s)":11.7,
        "Allocated Memory (MB)":21798,
        "Energy (tokens\/kWh)":123915,
        "E2E Latency (s)":23.0,
        "E2E Throughput (tokens\/s)":11.1,
        "Reserved Memory (MB)":22802,
        "Used Memory (MB)":24261
    },
    {
        "Model":"deepseek-ai\/deepseek-llm-67b-base",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":67.0,
        "Open LLM Score (%)":"69.38*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.295,
        "Decode Throughput (tokens\/s)":3.38,
        "Allocated Memory (MB)":69753,
        "Energy (tokens\/kWh)":47619,
        "E2E Latency (s)":75.7,
        "E2E Throughput (tokens\/s)":3.38,
        "Reserved Memory (MB)":70380,
        "Used Memory (MB)":71848
    },
    {
        "Model":"deepseek-ai\/deepseek-llm-67b-base",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":67.0,
        "Open LLM Score (%)":"69.38*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.296,
        "Decode Throughput (tokens\/s)":3.4,
        "Allocated Memory (MB)":69737,
        "Energy (tokens\/kWh)":45045,
        "E2E Latency (s)":75.4,
        "E2E Throughput (tokens\/s)":3.4,
        "Reserved Memory (MB)":70380,
        "Used Memory (MB)":71848
    },
    {
        "Model":"deepseek-ai\/deepseek-llm-67b-base",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":67.0,
        "Open LLM Score (%)":"69.38*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.308,
        "Decode Throughput (tokens\/s)":12.3,
        "Allocated Memory (MB)":40008,
        "Energy (tokens\/kWh)":146842,
        "E2E Latency (s)":21.1,
        "E2E Throughput (tokens\/s)":12.1,
        "Reserved Memory (MB)":40376,
        "Used Memory (MB)":41838
    },
    {
        "Model":"deepseek-ai\/deepseek-llm-67b-base",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":67.0,
        "Open LLM Score (%)":"69.38*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.312,
        "Decode Throughput (tokens\/s)":12.1,
        "Allocated Memory (MB)":38539,
        "Energy (tokens\/kWh)":117647,
        "E2E Latency (s)":21.3,
        "E2E Throughput (tokens\/s)":12.0,
        "Reserved Memory (MB)":38904,
        "Used Memory (MB)":40365
    },
    {
        "Model":"deepseek-ai\/deepseek-llm-67b-base",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":67.0,
        "Open LLM Score (%)":"69.38*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.591,
        "Decode Throughput (tokens\/s)":11.5,
        "Allocated Memory (MB)":38138,
        "Energy (tokens\/kWh)":123001,
        "E2E Latency (s)":22.8,
        "E2E Throughput (tokens\/s)":11.2,
        "Reserved Memory (MB)":38541,
        "Used Memory (MB)":40001
    },
    {
        "Model":"deepseek-ai\/deepseek-llm-67b-base",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":67.0,
        "Open LLM Score (%)":"69.38*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":2.57,
        "Decode Throughput (tokens\/s)":6.39,
        "Allocated Memory (MB)":41781,
        "Energy (tokens\/kWh)":68493,
        "E2E Latency (s)":42.5,
        "E2E Throughput (tokens\/s)":6.02,
        "Reserved Memory (MB)":42941,
        "Used Memory (MB)":44400
    },
    {
        "Model":"deepseek-ai\/deepseek-llm-67b-base",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":67.0,
        "Open LLM Score (%)":"69.38*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":2.58,
        "Decode Throughput (tokens\/s)":6.27,
        "Allocated Memory (MB)":41781,
        "Energy (tokens\/kWh)":66225,
        "E2E Latency (s)":43.3,
        "E2E Throughput (tokens\/s)":5.91,
        "Reserved Memory (MB)":42941,
        "Used Memory (MB)":44400
    },
    {
        "Model":"cloudyu\/Mixtral_7Bx4_MOE_24B",
        "Arch":"\u24c2\ufe0f Mixtral",
        "Params (B)":24.15,
        "Open LLM Score (%)":"68.85 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.114,
        "Decode Throughput (tokens\/s)":15.8,
        "Allocated Memory (MB)":48995,
        "Energy (tokens\/kWh)":200400,
        "E2E Latency (s)":16.2,
        "E2E Throughput (tokens\/s)":15.8,
        "Reserved Memory (MB)":49197,
        "Used Memory (MB)":50656
    },
    {
        "Model":"cloudyu\/Mixtral_7Bx4_MOE_24B",
        "Arch":"\u24c2\ufe0f Mixtral",
        "Params (B)":24.15,
        "Open LLM Score (%)":"68.85 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.121,
        "Decode Throughput (tokens\/s)":15.6,
        "Allocated Memory (MB)":48995,
        "Energy (tokens\/kWh)":193423,
        "E2E Latency (s)":16.4,
        "E2E Throughput (tokens\/s)":15.6,
        "Reserved Memory (MB)":49197,
        "Used Memory (MB)":50656
    },
    {
        "Model":"cloudyu\/Mixtral_7Bx4_MOE_24B",
        "Arch":"\u24c2\ufe0f Mixtral",
        "Params (B)":24.15,
        "Open LLM Score (%)":"68.85*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.177,
        "Decode Throughput (tokens\/s)":5.92,
        "Allocated Memory (MB)":25125,
        "Energy (tokens\/kWh)":88495,
        "E2E Latency (s)":43.3,
        "E2E Throughput (tokens\/s)":5.91,
        "Reserved Memory (MB)":25337,
        "Used Memory (MB)":26805
    },
    {
        "Model":"cloudyu\/Mixtral_7Bx4_MOE_24B",
        "Arch":"\u24c2\ufe0f Mixtral",
        "Params (B)":24.15,
        "Open LLM Score (%)":"68.85*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.181,
        "Decode Throughput (tokens\/s)":5.73,
        "Allocated Memory (MB)":25125,
        "Energy (tokens\/kWh)":78740,
        "E2E Latency (s)":44.7,
        "E2E Throughput (tokens\/s)":5.73,
        "Reserved Memory (MB)":25333,
        "Used Memory (MB)":26801
    },
    {
        "Model":"cloudyu\/Mixtral_7Bx4_MOE_24B",
        "Arch":"\u24c2\ufe0f Mixtral",
        "Params (B)":24.15,
        "Open LLM Score (%)":"68.85*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.553,
        "Decode Throughput (tokens\/s)":10.4,
        "Allocated Memory (MB)":14970,
        "Energy (tokens\/kWh)":141843,
        "E2E Latency (s)":25.1,
        "E2E Throughput (tokens\/s)":10.2,
        "Reserved Memory (MB)":15325,
        "Used Memory (MB)":16785
    },
    {
        "Model":"cloudyu\/Mixtral_7Bx4_MOE_24B",
        "Arch":"\u24c2\ufe0f Mixtral",
        "Params (B)":24.15,
        "Open LLM Score (%)":"68.85*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.562,
        "Decode Throughput (tokens\/s)":10.5,
        "Allocated Memory (MB)":14970,
        "Energy (tokens\/kWh)":142857,
        "E2E Latency (s)":24.9,
        "E2E Throughput (tokens\/s)":10.3,
        "Reserved Memory (MB)":15328,
        "Used Memory (MB)":16787
    },
    {
        "Model":"mistralai\/Mixtral-8x7B-v0.1",
        "Arch":"\u24c2\ufe0f Mixtral",
        "Params (B)":46.7,
        "Open LLM Score (%)":"68.42*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.185,
        "Decode Throughput (tokens\/s)":5.41,
        "Allocated Memory (MB)":47691,
        "Energy (tokens\/kWh)":78740,
        "E2E Latency (s)":47.3,
        "E2E Throughput (tokens\/s)":5.41,
        "Reserved Memory (MB)":47867,
        "Used Memory (MB)":49335
    },
    {
        "Model":"mistralai\/Mixtral-8x7B-v0.1",
        "Arch":"\u24c2\ufe0f Mixtral",
        "Params (B)":46.7,
        "Open LLM Score (%)":"68.42*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.188,
        "Decode Throughput (tokens\/s)":5.57,
        "Allocated Memory (MB)":47691,
        "Energy (tokens\/kWh)":84033,
        "E2E Latency (s)":46.0,
        "E2E Throughput (tokens\/s)":5.57,
        "Reserved Memory (MB)":47880,
        "Used Memory (MB)":49348
    },
    {
        "Model":"mistralai\/Mixtral-8x7B-v0.1",
        "Arch":"\u24c2\ufe0f Mixtral",
        "Params (B)":46.7,
        "Open LLM Score (%)":"68.42*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.561,
        "Decode Throughput (tokens\/s)":9.62,
        "Allocated Memory (MB)":27662,
        "Energy (tokens\/kWh)":133689,
        "E2E Latency (s)":27.1,
        "E2E Throughput (tokens\/s)":9.45,
        "Reserved Memory (MB)":28196,
        "Used Memory (MB)":29655
    },
    {
        "Model":"mistralai\/Mixtral-8x7B-v0.1",
        "Arch":"\u24c2\ufe0f Mixtral",
        "Params (B)":46.7,
        "Open LLM Score (%)":"68.42*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.569,
        "Decode Throughput (tokens\/s)":9.85,
        "Allocated Memory (MB)":27662,
        "Energy (tokens\/kWh)":136612,
        "E2E Latency (s)":26.5,
        "E2E Throughput (tokens\/s)":9.66,
        "Reserved Memory (MB)":28194,
        "Used Memory (MB)":29653
    },
    {
        "Model":"meta-llama\/Llama-2-70b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":68.98,
        "Open LLM Score (%)":"67.87*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.244,
        "Decode Throughput (tokens\/s)":4.0,
        "Allocated Memory (MB)":70040,
        "Energy (tokens\/kWh)":52083,
        "E2E Latency (s)":64.0,
        "E2E Throughput (tokens\/s)":4.0,
        "Reserved Memory (MB)":70506,
        "Used Memory (MB)":71974
    },
    {
        "Model":"meta-llama\/Llama-2-70b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":68.98,
        "Open LLM Score (%)":"67.87*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.31,
        "Decode Throughput (tokens\/s)":14.6,
        "Allocated Memory (MB)":39553,
        "Energy (tokens\/kWh)":163934,
        "E2E Latency (s)":17.8,
        "E2E Throughput (tokens\/s)":14.4,
        "Reserved Memory (MB)":39795,
        "Used Memory (MB)":41257
    },
    {
        "Model":"meta-llama\/Llama-2-70b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":68.98,
        "Open LLM Score (%)":"67.87*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.315,
        "Decode Throughput (tokens\/s)":13.2,
        "Allocated Memory (MB)":37649,
        "Energy (tokens\/kWh)":123152,
        "E2E Latency (s)":19.6,
        "E2E Throughput (tokens\/s)":13.1,
        "Reserved Memory (MB)":37889,
        "Used Memory (MB)":39350
    },
    {
        "Model":"meta-llama\/Llama-2-70b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":68.98,
        "Open LLM Score (%)":"67.87*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.497,
        "Decode Throughput (tokens\/s)":15.4,
        "Allocated Memory (MB)":37141,
        "Energy (tokens\/kWh)":140056,
        "E2E Latency (s)":17.1,
        "E2E Throughput (tokens\/s)":15.0,
        "Reserved Memory (MB)":37453,
        "Used Memory (MB)":38912
    },
    {
        "Model":"meta-llama\/Llama-2-70b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":68.98,
        "Open LLM Score (%)":"67.87*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.602,
        "Decode Throughput (tokens\/s)":13.9,
        "Allocated Memory (MB)":37141,
        "Energy (tokens\/kWh)":137551,
        "E2E Latency (s)":19.0,
        "E2E Throughput (tokens\/s)":13.5,
        "Reserved Memory (MB)":37453,
        "Used Memory (MB)":38912
    },
    {
        "Model":"upstage\/SOLAR-10.7B-v1.0",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":10.73,
        "Open LLM Score (%)":"66.04 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0497,
        "Decode Throughput (tokens\/s)":25.6,
        "Allocated Memory (MB)":21781,
        "Energy (tokens\/kWh)":301204,
        "E2E Latency (s)":10.0,
        "E2E Throughput (tokens\/s)":25.6,
        "Reserved Memory (MB)":22047,
        "Used Memory (MB)":23506
    },
    {
        "Model":"upstage\/SOLAR-10.7B-v1.0",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":10.73,
        "Open LLM Score (%)":"66.04 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0509,
        "Decode Throughput (tokens\/s)":26.6,
        "Allocated Memory (MB)":21773,
        "Energy (tokens\/kWh)":286532,
        "E2E Latency (s)":9.65,
        "E2E Throughput (tokens\/s)":26.5,
        "Reserved Memory (MB)":22047,
        "Used Memory (MB)":23506
    },
    {
        "Model":"upstage\/SOLAR-10.7B-v1.0",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":10.73,
        "Open LLM Score (%)":"66.04*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0628,
        "Decode Throughput (tokens\/s)":24.5,
        "Allocated Memory (MB)":6411,
        "Energy (tokens\/kWh)":317460,
        "E2E Latency (s)":10.5,
        "E2E Throughput (tokens\/s)":24.4,
        "Reserved Memory (MB)":6494,
        "Used Memory (MB)":7956
    },
    {
        "Model":"upstage\/SOLAR-10.7B-v1.0",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":10.73,
        "Open LLM Score (%)":"66.04*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0664,
        "Decode Throughput (tokens\/s)":24.3,
        "Allocated Memory (MB)":7358,
        "Energy (tokens\/kWh)":344827,
        "E2E Latency (s)":10.6,
        "E2E Throughput (tokens\/s)":24.2,
        "Reserved Memory (MB)":7442,
        "Used Memory (MB)":8904
    },
    {
        "Model":"upstage\/SOLAR-10.7B-v1.0",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":10.73,
        "Open LLM Score (%)":"66.04*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0957,
        "Decode Throughput (tokens\/s)":25.2,
        "Allocated Memory (MB)":6282,
        "Energy (tokens\/kWh)":337837,
        "E2E Latency (s)":10.2,
        "E2E Throughput (tokens\/s)":25.1,
        "Reserved Memory (MB)":6381,
        "Used Memory (MB)":7841
    },
    {
        "Model":"upstage\/SOLAR-10.7B-v1.0",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":10.73,
        "Open LLM Score (%)":"66.04*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.113,
        "Decode Throughput (tokens\/s)":22.4,
        "Allocated Memory (MB)":6282,
        "Energy (tokens\/kWh)":316455,
        "E2E Latency (s)":11.5,
        "E2E Throughput (tokens\/s)":22.3,
        "Reserved Memory (MB)":6381,
        "Used Memory (MB)":7841
    },
    {
        "Model":"upstage\/SOLAR-10.7B-v1.0",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":10.73,
        "Open LLM Score (%)":"66.04*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.144,
        "Decode Throughput (tokens\/s)":6.84,
        "Allocated Memory (MB)":11312,
        "Energy (tokens\/kWh)":102459,
        "E2E Latency (s)":37.4,
        "E2E Throughput (tokens\/s)":6.84,
        "Reserved Memory (MB)":11421,
        "Used Memory (MB)":12889
    },
    {
        "Model":"upstage\/SOLAR-10.7B-v1.0",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":10.73,
        "Open LLM Score (%)":"66.04*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.149,
        "Decode Throughput (tokens\/s)":6.76,
        "Allocated Memory (MB)":11320,
        "Energy (tokens\/kWh)":100300,
        "E2E Latency (s)":37.8,
        "E2E Throughput (tokens\/s)":6.77,
        "Reserved Memory (MB)":11421,
        "Used Memory (MB)":12889
    },
    {
        "Model":"upstage\/SOLAR-10.7B-v1.0",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":10.73,
        "Open LLM Score (%)":"66.04 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.39,
        "Decode Throughput (tokens\/s)":26.5,
        "Allocated Memory (MB)":43555,
        "Energy (tokens\/kWh)":231481,
        "E2E Latency (s)":10.0,
        "E2E Throughput (tokens\/s)":25.6,
        "Reserved Memory (MB)":43673,
        "Used Memory (MB)":45124
    },
    {
        "Model":"upstage\/SOLAR-10.7B-v1.0",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":10.73,
        "Open LLM Score (%)":"66.04*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.43,
        "Decode Throughput (tokens\/s)":14.7,
        "Allocated Memory (MB)":6980,
        "Energy (tokens\/kWh)":195694,
        "E2E Latency (s)":17.8,
        "E2E Throughput (tokens\/s)":14.4,
        "Reserved Memory (MB)":7266,
        "Used Memory (MB)":8726
    },
    {
        "Model":"upstage\/SOLAR-10.7B-v1.0",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":10.73,
        "Open LLM Score (%)":"66.04*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.434,
        "Decode Throughput (tokens\/s)":14.7,
        "Allocated Memory (MB)":6980,
        "Energy (tokens\/kWh)":191938,
        "E2E Latency (s)":17.7,
        "E2E Throughput (tokens\/s)":14.5,
        "Reserved Memory (MB)":7266,
        "Used Memory (MB)":8726
    },
    {
        "Model":"huggyllama\/llama-65b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":65.29,
        "Open LLM Score (%)":"62.79*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.239,
        "Decode Throughput (tokens\/s)":4.14,
        "Allocated Memory (MB)":68608,
        "Energy (tokens\/kWh)":56497,
        "E2E Latency (s)":61.8,
        "E2E Throughput (tokens\/s)":4.14,
        "Reserved Memory (MB)":69396,
        "Used Memory (MB)":70864
    },
    {
        "Model":"huggyllama\/llama-65b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":65.29,
        "Open LLM Score (%)":"62.79*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.241,
        "Decode Throughput (tokens\/s)":4.04,
        "Allocated Memory (MB)":68608,
        "Energy (tokens\/kWh)":52356,
        "E2E Latency (s)":63.3,
        "E2E Throughput (tokens\/s)":4.04,
        "Reserved Memory (MB)":69396,
        "Used Memory (MB)":70864
    },
    {
        "Model":"huggyllama\/llama-65b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":65.29,
        "Open LLM Score (%)":"62.79*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.296,
        "Decode Throughput (tokens\/s)":16.3,
        "Allocated Memory (MB)":39328,
        "Energy (tokens\/kWh)":181159,
        "E2E Latency (s)":15.9,
        "E2E Throughput (tokens\/s)":16.1,
        "Reserved Memory (MB)":40185,
        "Used Memory (MB)":41647
    },
    {
        "Model":"huggyllama\/llama-65b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":65.29,
        "Open LLM Score (%)":"62.79*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.296,
        "Decode Throughput (tokens\/s)":13.7,
        "Allocated Memory (MB)":37862,
        "Energy (tokens\/kWh)":128865,
        "E2E Latency (s)":18.9,
        "E2E Throughput (tokens\/s)":13.5,
        "Reserved Memory (MB)":38717,
        "Used Memory (MB)":40179
    },
    {
        "Model":"huggyllama\/llama-65b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":65.29,
        "Open LLM Score (%)":"62.79*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.575,
        "Decode Throughput (tokens\/s)":15.2,
        "Allocated Memory (MB)":37465,
        "Energy (tokens\/kWh)":145348,
        "E2E Latency (s)":17.4,
        "E2E Throughput (tokens\/s)":14.7,
        "Reserved Memory (MB)":38128,
        "Used Memory (MB)":39587
    },
    {
        "Model":"huggyllama\/llama-65b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":65.29,
        "Open LLM Score (%)":"62.79*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":2.5,
        "Decode Throughput (tokens\/s)":6.57,
        "Allocated Memory (MB)":40249,
        "Energy (tokens\/kWh)":70422,
        "E2E Latency (s)":41.3,
        "E2E Throughput (tokens\/s)":6.2,
        "Reserved Memory (MB)":40793,
        "Used Memory (MB)":42253
    },
    {
        "Model":"huggyllama\/llama-65b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":65.29,
        "Open LLM Score (%)":"62.79*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":2.5,
        "Decode Throughput (tokens\/s)":6.57,
        "Allocated Memory (MB)":40249,
        "Energy (tokens\/kWh)":70422,
        "E2E Latency (s)":41.3,
        "E2E Throughput (tokens\/s)":6.2,
        "Reserved Memory (MB)":40793,
        "Used Memory (MB)":42253
    },
    {
        "Model":"Deci\/DeciLM-7B",
        "Arch":"\ud83d\udd35 deci",
        "Params (B)":7.04,
        "Open LLM Score (%)":"61.55 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0341,
        "Decode Throughput (tokens\/s)":38.9,
        "Allocated Memory (MB)":14290,
        "Energy (tokens\/kWh)":452488,
        "E2E Latency (s)":6.59,
        "E2E Throughput (tokens\/s)":38.8,
        "Reserved Memory (MB)":14357,
        "Used Memory (MB)":15816
    },
    {
        "Model":"Deci\/DeciLM-7B",
        "Arch":"\ud83d\udd35 deci",
        "Params (B)":7.04,
        "Open LLM Score (%)":"61.55 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0353,
        "Decode Throughput (tokens\/s)":39.1,
        "Allocated Memory (MB)":14290,
        "Energy (tokens\/kWh)":429184,
        "E2E Latency (s)":6.57,
        "E2E Throughput (tokens\/s)":39.0,
        "Reserved Memory (MB)":14357,
        "Used Memory (MB)":15816
    },
    {
        "Model":"Deci\/DeciLM-7B",
        "Arch":"\ud83d\udd35 deci",
        "Params (B)":7.04,
        "Open LLM Score (%)":"61.55*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.065,
        "Decode Throughput (tokens\/s)":38.5,
        "Allocated Memory (MB)":4281,
        "Energy (tokens\/kWh)":526315,
        "E2E Latency (s)":6.7,
        "E2E Throughput (tokens\/s)":38.2,
        "Reserved Memory (MB)":4334,
        "Used Memory (MB)":5794
    },
    {
        "Model":"Deci\/DeciLM-7B",
        "Arch":"\ud83d\udd35 deci",
        "Params (B)":7.04,
        "Open LLM Score (%)":"61.55*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0765,
        "Decode Throughput (tokens\/s)":34.7,
        "Allocated Memory (MB)":4281,
        "Energy (tokens\/kWh)":471698,
        "E2E Latency (s)":7.42,
        "E2E Throughput (tokens\/s)":34.5,
        "Reserved Memory (MB)":4334,
        "Used Memory (MB)":5794
    },
    {
        "Model":"Deci\/DeciLM-7B",
        "Arch":"\ud83d\udd35 deci",
        "Params (B)":7.04,
        "Open LLM Score (%)":"61.55*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.102,
        "Decode Throughput (tokens\/s)":10.2,
        "Allocated Memory (MB)":7514,
        "Energy (tokens\/kWh)":152207,
        "E2E Latency (s)":25.1,
        "E2E Throughput (tokens\/s)":10.2,
        "Reserved Memory (MB)":7589,
        "Used Memory (MB)":9057
    },
    {
        "Model":"Deci\/DeciLM-7B",
        "Arch":"\ud83d\udd35 deci",
        "Params (B)":7.04,
        "Open LLM Score (%)":"61.55*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.104,
        "Decode Throughput (tokens\/s)":10.2,
        "Allocated Memory (MB)":7514,
        "Energy (tokens\/kWh)":152905,
        "E2E Latency (s)":25.1,
        "E2E Throughput (tokens\/s)":10.2,
        "Reserved Memory (MB)":7589,
        "Used Memory (MB)":9057
    },
    {
        "Model":"Deci\/DeciLM-7B",
        "Arch":"\ud83d\udd35 deci",
        "Params (B)":7.04,
        "Open LLM Score (%)":"61.55 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.255,
        "Decode Throughput (tokens\/s)":41.2,
        "Allocated Memory (MB)":28538,
        "Energy (tokens\/kWh)":359712,
        "E2E Latency (s)":6.44,
        "E2E Throughput (tokens\/s)":39.8,
        "Reserved Memory (MB)":28638,
        "Used Memory (MB)":30089
    },
    {
        "Model":"Deci\/DeciLM-7B",
        "Arch":"\ud83d\udd35 deci",
        "Params (B)":7.04,
        "Open LLM Score (%)":"61.55*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.284,
        "Decode Throughput (tokens\/s)":22.2,
        "Allocated Memory (MB)":4884,
        "Energy (tokens\/kWh)":291545,
        "E2E Latency (s)":11.8,
        "E2E Throughput (tokens\/s)":21.7,
        "Reserved Memory (MB)":5066,
        "Used Memory (MB)":6526
    },
    {
        "Model":"Deci\/DeciLM-7B",
        "Arch":"\ud83d\udd35 deci",
        "Params (B)":7.04,
        "Open LLM Score (%)":"61.55*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.284,
        "Decode Throughput (tokens\/s)":21.8,
        "Allocated Memory (MB)":4884,
        "Energy (tokens\/kWh)":284900,
        "E2E Latency (s)":12.0,
        "E2E Throughput (tokens\/s)":21.3,
        "Reserved Memory (MB)":5064,
        "Used Memory (MB)":6524
    },
    {
        "Model":"microsoft\/phi-2",
        "Arch":"phi",
        "Params (B)":2.78,
        "Open LLM Score (%)":"61.33 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0354,
        "Decode Throughput (tokens\/s)":27.2,
        "Allocated Memory (MB)":6339,
        "Energy (tokens\/kWh)":381679,
        "E2E Latency (s)":9.42,
        "E2E Throughput (tokens\/s)":27.2,
        "Reserved Memory (MB)":6429,
        "Used Memory (MB)":7889
    },
    {
        "Model":"microsoft\/phi-2",
        "Arch":"phi",
        "Params (B)":2.78,
        "Open LLM Score (%)":"61.33 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.04,
        "Decode Throughput (tokens\/s)":27.1,
        "Allocated Memory (MB)":6339,
        "Energy (tokens\/kWh)":387596,
        "E2E Latency (s)":9.45,
        "E2E Throughput (tokens\/s)":27.1,
        "Reserved Memory (MB)":6429,
        "Used Memory (MB)":7889
    },
    {
        "Model":"microsoft\/phi-2",
        "Arch":"phi",
        "Params (B)":2.78,
        "Open LLM Score (%)":"61.33 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.107,
        "Decode Throughput (tokens\/s)":31.7,
        "Allocated Memory (MB)":12603,
        "Energy (tokens\/kWh)":421940,
        "E2E Latency (s)":8.15,
        "E2E Throughput (tokens\/s)":31.4,
        "Reserved Memory (MB)":12666,
        "Used Memory (MB)":14118
    },
    {
        "Model":"huggingface\/llama-65b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":65.29,
        "Open LLM Score (%)":"61.19*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.239,
        "Decode Throughput (tokens\/s)":4.09,
        "Allocated Memory (MB)":68608,
        "Energy (tokens\/kWh)":52910,
        "E2E Latency (s)":62.5,
        "E2E Throughput (tokens\/s)":4.1,
        "Reserved Memory (MB)":69396,
        "Used Memory (MB)":70864
    },
    {
        "Model":"huggingface\/llama-65b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":65.29,
        "Open LLM Score (%)":"61.19*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.295,
        "Decode Throughput (tokens\/s)":15.8,
        "Allocated Memory (MB)":39328,
        "Energy (tokens\/kWh)":178890,
        "E2E Latency (s)":16.4,
        "E2E Throughput (tokens\/s)":15.6,
        "Reserved Memory (MB)":40185,
        "Used Memory (MB)":41647
    },
    {
        "Model":"huggingface\/llama-65b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":65.29,
        "Open LLM Score (%)":"61.19*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.295,
        "Decode Throughput (tokens\/s)":13.7,
        "Allocated Memory (MB)":37862,
        "Energy (tokens\/kWh)":129366,
        "E2E Latency (s)":18.9,
        "E2E Throughput (tokens\/s)":13.5,
        "Reserved Memory (MB)":38717,
        "Used Memory (MB)":40179
    },
    {
        "Model":"huggingface\/llama-65b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":65.29,
        "Open LLM Score (%)":"61.19*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.577,
        "Decode Throughput (tokens\/s)":14.9,
        "Allocated Memory (MB)":37465,
        "Energy (tokens\/kWh)":146412,
        "E2E Latency (s)":17.7,
        "E2E Throughput (tokens\/s)":14.5,
        "Reserved Memory (MB)":38128,
        "Used Memory (MB)":39587
    },
    {
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.24,
        "Open LLM Score (%)":"60.97 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0355,
        "Decode Throughput (tokens\/s)":34.9,
        "Allocated Memory (MB)":15171,
        "Energy (tokens\/kWh)":409836,
        "E2E Latency (s)":7.34,
        "E2E Throughput (tokens\/s)":34.9,
        "Reserved Memory (MB)":15374,
        "Used Memory (MB)":16833
    },
    {
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.24,
        "Open LLM Score (%)":"60.97 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0414,
        "Decode Throughput (tokens\/s)":34.1,
        "Allocated Memory (MB)":15171,
        "Energy (tokens\/kWh)":390625,
        "E2E Latency (s)":7.52,
        "E2E Throughput (tokens\/s)":34.0,
        "Reserved Memory (MB)":15372,
        "Used Memory (MB)":16831
    },
    {
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.24,
        "Open LLM Score (%)":"60.97*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0454,
        "Decode Throughput (tokens\/s)":31.8,
        "Allocated Memory (MB)":4963,
        "Energy (tokens\/kWh)":427350,
        "E2E Latency (s)":8.08,
        "E2E Throughput (tokens\/s)":31.7,
        "Reserved Memory (MB)":5161,
        "Used Memory (MB)":6622
    },
    {
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.24,
        "Open LLM Score (%)":"60.97*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.046,
        "Decode Throughput (tokens\/s)":32.8,
        "Allocated Memory (MB)":5908,
        "Energy (tokens\/kWh)":471698,
        "E2E Latency (s)":7.82,
        "E2E Throughput (tokens\/s)":32.7,
        "Reserved Memory (MB)":6106,
        "Used Memory (MB)":7568
    },
    {
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.24,
        "Open LLM Score (%)":"60.97*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0673,
        "Decode Throughput (tokens\/s)":32.9,
        "Allocated Memory (MB)":4838,
        "Energy (tokens\/kWh)":460829,
        "E2E Latency (s)":7.83,
        "E2E Throughput (tokens\/s)":32.7,
        "Reserved Memory (MB)":5052,
        "Used Memory (MB)":6511
    },
    {
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.24,
        "Open LLM Score (%)":"60.97*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.077,
        "Decode Throughput (tokens\/s)":31.1,
        "Allocated Memory (MB)":4838,
        "Energy (tokens\/kWh)":431034,
        "E2E Latency (s)":8.29,
        "E2E Throughput (tokens\/s)":30.9,
        "Reserved Memory (MB)":5052,
        "Used Memory (MB)":6511
    },
    {
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.24,
        "Open LLM Score (%)":"60.97*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.102,
        "Decode Throughput (tokens\/s)":9.85,
        "Allocated Memory (MB)":8197,
        "Energy (tokens\/kWh)":146627,
        "E2E Latency (s)":26.0,
        "E2E Throughput (tokens\/s)":9.85,
        "Reserved Memory (MB)":8399,
        "Used Memory (MB)":9867
    },
    {
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.24,
        "Open LLM Score (%)":"60.97*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.104,
        "Decode Throughput (tokens\/s)":9.77,
        "Allocated Memory (MB)":8197,
        "Energy (tokens\/kWh)":144508,
        "E2E Latency (s)":26.2,
        "E2E Throughput (tokens\/s)":9.77,
        "Reserved Memory (MB)":8399,
        "Used Memory (MB)":9867
    },
    {
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.24,
        "Open LLM Score (%)":"60.97 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.265,
        "Decode Throughput (tokens\/s)":38.5,
        "Allocated Memory (MB)":30334,
        "Energy (tokens\/kWh)":334448,
        "E2E Latency (s)":6.89,
        "E2E Throughput (tokens\/s)":37.2,
        "Reserved Memory (MB)":30431,
        "Used Memory (MB)":31883
    },
    {
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.24,
        "Open LLM Score (%)":"60.97*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.29,
        "Decode Throughput (tokens\/s)":20.9,
        "Allocated Memory (MB)":5428,
        "Energy (tokens\/kWh)":274725,
        "E2E Latency (s)":12.5,
        "E2E Throughput (tokens\/s)":20.5,
        "Reserved Memory (MB)":5758,
        "Used Memory (MB)":7218
    },
    {
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.24,
        "Open LLM Score (%)":"60.97*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.299,
        "Decode Throughput (tokens\/s)":20.2,
        "Allocated Memory (MB)":5428,
        "Energy (tokens\/kWh)":270270,
        "E2E Latency (s)":12.9,
        "E2E Throughput (tokens\/s)":19.8,
        "Reserved Memory (MB)":5758,
        "Used Memory (MB)":7218
    },
    {
        "Model":"internlm\/internlm-20b",
        "Arch":"\ud83e\uddd1\u200d\ud83c\udf93 InternLM \u4e66\u751f",
        "Params (B)":20.0,
        "Open LLM Score (%)":"59.55 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0803,
        "Decode Throughput (tokens\/s)":18.8,
        "Allocated Memory (MB)":41901,
        "Energy (tokens\/kWh)":189035,
        "E2E Latency (s)":13.7,
        "E2E Throughput (tokens\/s)":18.7,
        "Reserved Memory (MB)":41934,
        "Used Memory (MB)":43394
    },
    {
        "Model":"internlm\/internlm-20b",
        "Arch":"\ud83e\uddd1\u200d\ud83c\udf93 InternLM \u4e66\u751f",
        "Params (B)":20.0,
        "Open LLM Score (%)":"59.55*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.104,
        "Decode Throughput (tokens\/s)":17.3,
        "Allocated Memory (MB)":13828,
        "Energy (tokens\/kWh)":209643,
        "E2E Latency (s)":14.8,
        "E2E Throughput (tokens\/s)":17.3,
        "Reserved Memory (MB)":13964,
        "Used Memory (MB)":15426
    },
    {
        "Model":"internlm\/internlm-20b",
        "Arch":"\ud83e\uddd1\u200d\ud83c\udf93 InternLM \u4e66\u751f",
        "Params (B)":20.0,
        "Open LLM Score (%)":"59.55*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.163,
        "Decode Throughput (tokens\/s)":18.0,
        "Allocated Memory (MB)":13668,
        "Energy (tokens\/kWh)":219780,
        "E2E Latency (s)":14.4,
        "E2E Throughput (tokens\/s)":17.8,
        "Reserved Memory (MB)":13845,
        "Used Memory (MB)":15305
    },
    {
        "Model":"internlm\/internlm-20b",
        "Arch":"\ud83e\uddd1\u200d\ud83c\udf93 InternLM \u4e66\u751f",
        "Params (B)":20.0,
        "Open LLM Score (%)":"59.55*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.19,
        "Decode Throughput (tokens\/s)":5.21,
        "Allocated Memory (MB)":23038,
        "Energy (tokens\/kWh)":74626,
        "E2E Latency (s)":49.1,
        "E2E Throughput (tokens\/s)":5.21,
        "Reserved Memory (MB)":23068,
        "Used Memory (MB)":24536
    },
    {
        "Model":"internlm\/internlm-20b",
        "Arch":"\ud83e\uddd1\u200d\ud83c\udf93 InternLM \u4e66\u751f",
        "Params (B)":20.0,
        "Open LLM Score (%)":"59.55*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.203,
        "Decode Throughput (tokens\/s)":15.9,
        "Allocated Memory (MB)":13667,
        "Energy (tokens\/kWh)":204498,
        "E2E Latency (s)":16.2,
        "E2E Throughput (tokens\/s)":15.8,
        "Reserved Memory (MB)":13845,
        "Used Memory (MB)":15305
    },
    {
        "Model":"internlm\/internlm-20b",
        "Arch":"\ud83e\uddd1\u200d\ud83c\udf93 InternLM \u4e66\u751f",
        "Params (B)":20.0,
        "Open LLM Score (%)":"59.55 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.699,
        "Decode Throughput (tokens\/s)":15.8,
        "Allocated Memory (MB)":83163,
        "Energy (tokens\/kWh)":138504,
        "E2E Latency (s)":16.8,
        "E2E Throughput (tokens\/s)":15.2,
        "Reserved Memory (MB)":83443,
        "Used Memory (MB)":84894
    },
    {
        "Model":"internlm\/internlm-20b",
        "Arch":"\ud83e\uddd1\u200d\ud83c\udf93 InternLM \u4e66\u751f",
        "Params (B)":20.0,
        "Open LLM Score (%)":"59.55*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.749,
        "Decode Throughput (tokens\/s)":10.5,
        "Allocated Memory (MB)":14401,
        "Energy (tokens\/kWh)":131061,
        "E2E Latency (s)":24.9,
        "E2E Throughput (tokens\/s)":10.3,
        "Reserved Memory (MB)":14933,
        "Used Memory (MB)":16393
    },
    {
        "Model":"tiiuae\/falcon-40b",
        "Arch":"\ud83e\udd85 Falcon",
        "Params (B)":40.0,
        "Open LLM Score (%)":"58.07*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.137,
        "Decode Throughput (tokens\/s)":8.04,
        "Allocated Memory (MB)":43877,
        "Energy (tokens\/kWh)":106723,
        "E2E Latency (s)":31.8,
        "E2E Throughput (tokens\/s)":8.05,
        "Reserved Memory (MB)":44300,
        "Used Memory (MB)":45768
    },
    {
        "Model":"tiiuae\/falcon-40b",
        "Arch":"\ud83e\udd85 Falcon",
        "Params (B)":40.0,
        "Open LLM Score (%)":"58.07*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.193,
        "Decode Throughput (tokens\/s)":15.3,
        "Allocated Memory (MB)":24846,
        "Energy (tokens\/kWh)":162074,
        "E2E Latency (s)":16.9,
        "E2E Throughput (tokens\/s)":15.1,
        "Reserved Memory (MB)":25228,
        "Used Memory (MB)":26690
    },
    {
        "Model":"tiiuae\/falcon-40b",
        "Arch":"\ud83e\udd85 Falcon",
        "Params (B)":40.0,
        "Open LLM Score (%)":"58.07*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.296,
        "Decode Throughput (tokens\/s)":17.7,
        "Allocated Memory (MB)":24289,
        "Energy (tokens\/kWh)":190839,
        "E2E Latency (s)":14.7,
        "E2E Throughput (tokens\/s)":17.4,
        "Reserved Memory (MB)":24687,
        "Used Memory (MB)":26147
    },
    {
        "Model":"tiiuae\/falcon-40b",
        "Arch":"\ud83e\udd85 Falcon",
        "Params (B)":40.0,
        "Open LLM Score (%)":"58.07*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.367,
        "Decode Throughput (tokens\/s)":16.5,
        "Allocated Memory (MB)":24290,
        "Energy (tokens\/kWh)":185528,
        "E2E Latency (s)":15.9,
        "E2E Throughput (tokens\/s)":16.1,
        "Reserved Memory (MB)":24687,
        "Used Memory (MB)":26147
    },
    {
        "Model":"tiiuae\/falcon-40b",
        "Arch":"\ud83e\udd85 Falcon",
        "Params (B)":40.0,
        "Open LLM Score (%)":"58.07*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":1.63,
        "Decode Throughput (tokens\/s)":8.23,
        "Allocated Memory (MB)":26201,
        "Energy (tokens\/kWh)":94339,
        "E2E Latency (s)":32.6,
        "E2E Throughput (tokens\/s)":7.85,
        "Reserved Memory (MB)":26344,
        "Used Memory (MB)":27803
    },
    {
        "Model":"scb10x\/typhoon-7b",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.0,
        "Open LLM Score (%)":"58.05 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0363,
        "Decode Throughput (tokens\/s)":34.5,
        "Allocated Memory (MB)":15225,
        "Energy (tokens\/kWh)":404858,
        "E2E Latency (s)":7.43,
        "E2E Throughput (tokens\/s)":34.5,
        "Reserved Memory (MB)":15430,
        "Used Memory (MB)":16890
    },
    {
        "Model":"scb10x\/typhoon-7b",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.0,
        "Open LLM Score (%)":"58.05 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0368,
        "Decode Throughput (tokens\/s)":34.4,
        "Allocated Memory (MB)":15225,
        "Energy (tokens\/kWh)":390625,
        "E2E Latency (s)":7.45,
        "E2E Throughput (tokens\/s)":34.4,
        "Reserved Memory (MB)":15430,
        "Used Memory (MB)":16890
    },
    {
        "Model":"scb10x\/typhoon-7b",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.0,
        "Open LLM Score (%)":"58.05 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0423,
        "Decode Throughput (tokens\/s)":33.7,
        "Allocated Memory (MB)":15225,
        "Energy (tokens\/kWh)":389105,
        "E2E Latency (s)":7.6,
        "E2E Throughput (tokens\/s)":33.7,
        "Reserved Memory (MB)":15430,
        "Used Memory (MB)":16890
    },
    {
        "Model":"scb10x\/typhoon-7b",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.0,
        "Open LLM Score (%)":"58.05*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0464,
        "Decode Throughput (tokens\/s)":32.1,
        "Allocated Memory (MB)":5018,
        "Energy (tokens\/kWh)":432900,
        "E2E Latency (s)":8.0,
        "E2E Throughput (tokens\/s)":32.0,
        "Reserved Memory (MB)":5219,
        "Used Memory (MB)":6681
    },
    {
        "Model":"scb10x\/typhoon-7b",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.0,
        "Open LLM Score (%)":"58.05*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0466,
        "Decode Throughput (tokens\/s)":32.3,
        "Allocated Memory (MB)":5962,
        "Energy (tokens\/kWh)":465116,
        "E2E Latency (s)":7.94,
        "E2E Throughput (tokens\/s)":32.2,
        "Reserved Memory (MB)":6165,
        "Used Memory (MB)":7627
    },
    {
        "Model":"scb10x\/typhoon-7b",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.0,
        "Open LLM Score (%)":"58.05*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0687,
        "Decode Throughput (tokens\/s)":34.0,
        "Allocated Memory (MB)":4893,
        "Energy (tokens\/kWh)":458715,
        "E2E Latency (s)":7.56,
        "E2E Throughput (tokens\/s)":33.9,
        "Reserved Memory (MB)":5106,
        "Used Memory (MB)":6566
    },
    {
        "Model":"scb10x\/typhoon-7b",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.0,
        "Open LLM Score (%)":"58.05*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.102,
        "Decode Throughput (tokens\/s)":10.0,
        "Allocated Memory (MB)":8252,
        "Energy (tokens\/kWh)":146842,
        "E2E Latency (s)":25.6,
        "E2E Throughput (tokens\/s)":10.0,
        "Reserved Memory (MB)":8457,
        "Used Memory (MB)":9925
    },
    {
        "Model":"scb10x\/typhoon-7b",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.0,
        "Open LLM Score (%)":"58.05*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.104,
        "Decode Throughput (tokens\/s)":9.81,
        "Allocated Memory (MB)":8252,
        "Energy (tokens\/kWh)":148148,
        "E2E Latency (s)":26.1,
        "E2E Throughput (tokens\/s)":9.81,
        "Reserved Memory (MB)":8457,
        "Used Memory (MB)":9925
    },
    {
        "Model":"scb10x\/typhoon-7b",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.0,
        "Open LLM Score (%)":"58.05 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.264,
        "Decode Throughput (tokens\/s)":38.1,
        "Allocated Memory (MB)":30440,
        "Energy (tokens\/kWh)":333333,
        "E2E Latency (s)":6.96,
        "E2E Throughput (tokens\/s)":36.8,
        "Reserved Memory (MB)":30524,
        "Used Memory (MB)":31975
    },
    {
        "Model":"scb10x\/typhoon-7b",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.0,
        "Open LLM Score (%)":"58.05*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.295,
        "Decode Throughput (tokens\/s)":20.6,
        "Allocated Memory (MB)":5483,
        "Energy (tokens\/kWh)":263157,
        "E2E Latency (s)":12.7,
        "E2E Throughput (tokens\/s)":20.2,
        "Reserved Memory (MB)":5815,
        "Used Memory (MB)":7274
    },
    {
        "Model":"scb10x\/typhoon-7b",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.0,
        "Open LLM Score (%)":"58.05*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.3,
        "Decode Throughput (tokens\/s)":20.6,
        "Allocated Memory (MB)":5483,
        "Energy (tokens\/kWh)":268817,
        "E2E Latency (s)":12.7,
        "E2E Throughput (tokens\/s)":20.2,
        "Reserved Memory (MB)":5815,
        "Used Memory (MB)":7274
    },
    {
        "Model":"huggingface\/llama-30b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":32.53,
        "Open LLM Score (%)":"56.94*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.153,
        "Decode Throughput (tokens\/s)":21.6,
        "Allocated Memory (MB)":19768,
        "Energy (tokens\/kWh)":215982,
        "E2E Latency (s)":12.0,
        "E2E Throughput (tokens\/s)":21.3,
        "Reserved Memory (MB)":20006,
        "Used Memory (MB)":21468
    },
    {
        "Model":"huggingface\/llama-30b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":32.53,
        "Open LLM Score (%)":"56.94*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.155,
        "Decode Throughput (tokens\/s)":21.6,
        "Allocated Memory (MB)":20957,
        "Energy (tokens\/kWh)":259740,
        "E2E Latency (s)":12.0,
        "E2E Throughput (tokens\/s)":21.3,
        "Reserved Memory (MB)":21214,
        "Used Memory (MB)":22676
    },
    {
        "Model":"huggingface\/llama-30b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":32.53,
        "Open LLM Score (%)":"56.94*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.178,
        "Decode Throughput (tokens\/s)":5.57,
        "Allocated Memory (MB)":34766,
        "Energy (tokens\/kWh)":75757,
        "E2E Latency (s)":46.0,
        "E2E Throughput (tokens\/s)":5.57,
        "Reserved Memory (MB)":35257,
        "Used Memory (MB)":36725
    },
    {
        "Model":"huggingface\/llama-30b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":32.53,
        "Open LLM Score (%)":"56.94*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.241,
        "Decode Throughput (tokens\/s)":22.0,
        "Allocated Memory (MB)":19528,
        "Energy (tokens\/kWh)":230414,
        "E2E Latency (s)":11.8,
        "E2E Throughput (tokens\/s)":21.7,
        "Reserved Memory (MB)":19868,
        "Used Memory (MB)":21328
    },
    {
        "Model":"huggingface\/llama-30b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":32.53,
        "Open LLM Score (%)":"56.94*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.302,
        "Decode Throughput (tokens\/s)":19.8,
        "Allocated Memory (MB)":19494,
        "Energy (tokens\/kWh)":216450,
        "E2E Latency (s)":13.2,
        "E2E Throughput (tokens\/s)":19.4,
        "Reserved Memory (MB)":19820,
        "Used Memory (MB)":21279
    },
    {
        "Model":"01-ai\/Yi-6B-200K",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.06,
        "Open LLM Score (%)":"56.69 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0275,
        "Decode Throughput (tokens\/s)":39.8,
        "Allocated Memory (MB)":15525,
        "Energy (tokens\/kWh)":467289,
        "E2E Latency (s)":6.44,
        "E2E Throughput (tokens\/s)":39.8,
        "Reserved Memory (MB)":16791,
        "Used Memory (MB)":18251
    },
    {
        "Model":"01-ai\/Yi-6B-200K",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.06,
        "Open LLM Score (%)":"56.69 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.029,
        "Decode Throughput (tokens\/s)":39.8,
        "Allocated Memory (MB)":15525,
        "Energy (tokens\/kWh)":467289,
        "E2E Latency (s)":6.43,
        "E2E Throughput (tokens\/s)":39.8,
        "Reserved Memory (MB)":16791,
        "Used Memory (MB)":18251
    },
    {
        "Model":"01-ai\/Yi-6B-200K",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.06,
        "Open LLM Score (%)":"56.69 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0312,
        "Decode Throughput (tokens\/s)":38.5,
        "Allocated Memory (MB)":15525,
        "Energy (tokens\/kWh)":431034,
        "E2E Latency (s)":6.66,
        "E2E Throughput (tokens\/s)":38.4,
        "Reserved Memory (MB)":16791,
        "Used Memory (MB)":18251
    },
    {
        "Model":"01-ai\/Yi-6B-200K",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.06,
        "Open LLM Score (%)":"56.69*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0359,
        "Decode Throughput (tokens\/s)":36.6,
        "Allocated Memory (MB)":7476,
        "Energy (tokens\/kWh)":492610,
        "E2E Latency (s)":7.01,
        "E2E Throughput (tokens\/s)":36.5,
        "Reserved Memory (MB)":7776,
        "Used Memory (MB)":9237
    },
    {
        "Model":"01-ai\/Yi-6B-200K",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.06,
        "Open LLM Score (%)":"56.69*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0379,
        "Decode Throughput (tokens\/s)":36.2,
        "Allocated Memory (MB)":8202,
        "Energy (tokens\/kWh)":537634,
        "E2E Latency (s)":7.09,
        "E2E Throughput (tokens\/s)":36.1,
        "Reserved Memory (MB)":8503,
        "Used Memory (MB)":9965
    },
    {
        "Model":"01-ai\/Yi-6B-200K",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.06,
        "Open LLM Score (%)":"56.69*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0548,
        "Decode Throughput (tokens\/s)":37.8,
        "Allocated Memory (MB)":7378,
        "Energy (tokens\/kWh)":518134,
        "E2E Latency (s)":6.8,
        "E2E Throughput (tokens\/s)":37.6,
        "Reserved Memory (MB)":7696,
        "Used Memory (MB)":9156
    },
    {
        "Model":"01-ai\/Yi-6B-200K",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.06,
        "Open LLM Score (%)":"56.69*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0627,
        "Decode Throughput (tokens\/s)":34.3,
        "Allocated Memory (MB)":7378,
        "Energy (tokens\/kWh)":483091,
        "E2E Latency (s)":7.49,
        "E2E Throughput (tokens\/s)":34.2,
        "Reserved Memory (MB)":7696,
        "Used Memory (MB)":9156
    },
    {
        "Model":"01-ai\/Yi-6B-200K",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.06,
        "Open LLM Score (%)":"56.69*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0965,
        "Decode Throughput (tokens\/s)":10.4,
        "Allocated Memory (MB)":10093,
        "Energy (tokens\/kWh)":156006,
        "E2E Latency (s)":24.6,
        "E2E Throughput (tokens\/s)":10.4,
        "Reserved Memory (MB)":10242,
        "Used Memory (MB)":11710
    },
    {
        "Model":"01-ai\/Yi-6B-200K",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.06,
        "Open LLM Score (%)":"56.69*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.101,
        "Decode Throughput (tokens\/s)":10.1,
        "Allocated Memory (MB)":10093,
        "Energy (tokens\/kWh)":147928,
        "E2E Latency (s)":25.3,
        "E2E Throughput (tokens\/s)":10.1,
        "Reserved Memory (MB)":10246,
        "Used Memory (MB)":11714
    },
    {
        "Model":"01-ai\/Yi-6B-200K",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.06,
        "Open LLM Score (%)":"56.69*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.143,
        "Decode Throughput (tokens\/s)":25.2,
        "Allocated Memory (MB)":7524,
        "Energy (tokens\/kWh)":369003,
        "E2E Latency (s)":10.2,
        "E2E Throughput (tokens\/s)":25.1,
        "Reserved Memory (MB)":7826,
        "Used Memory (MB)":9286
    },
    {
        "Model":"01-ai\/Yi-6B-200K",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.06,
        "Open LLM Score (%)":"56.69 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.212,
        "Decode Throughput (tokens\/s)":41.5,
        "Allocated Memory (MB)":30980,
        "Energy (tokens\/kWh)":380228,
        "E2E Latency (s)":6.35,
        "E2E Throughput (tokens\/s)":40.3,
        "Reserved Memory (MB)":31616,
        "Used Memory (MB)":33067
    },
    {
        "Model":"01-ai\/Yi-6B-200K",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.06,
        "Open LLM Score (%)":"56.69*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.235,
        "Decode Throughput (tokens\/s)":22.0,
        "Allocated Memory (MB)":7811,
        "Energy (tokens\/kWh)":291545,
        "E2E Latency (s)":11.8,
        "E2E Throughput (tokens\/s)":21.7,
        "Reserved Memory (MB)":8118,
        "Used Memory (MB)":9577
    },
    {
        "Model":"01-ai\/Yi-6B-200K",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.06,
        "Open LLM Score (%)":"56.69*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.238,
        "Decode Throughput (tokens\/s)":22.6,
        "Allocated Memory (MB)":7811,
        "Energy (tokens\/kWh)":296735,
        "E2E Latency (s)":11.5,
        "E2E Throughput (tokens\/s)":22.3,
        "Reserved Memory (MB)":8120,
        "Used Memory (MB)":9579
    },
    {
        "Model":"meta-llama\/Llama-2-13b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"55.69 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0505,
        "Decode Throughput (tokens\/s)":33.6,
        "Allocated Memory (MB)":27089,
        "Energy (tokens\/kWh)":322580,
        "E2E Latency (s)":7.65,
        "E2E Throughput (tokens\/s)":33.5,
        "Reserved Memory (MB)":27118,
        "Used Memory (MB)":28577
    },
    {
        "Model":"meta-llama\/Llama-2-13b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"55.69*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0667,
        "Decode Throughput (tokens\/s)":31.9,
        "Allocated Memory (MB)":8420,
        "Energy (tokens\/kWh)":375939,
        "E2E Latency (s)":8.06,
        "E2E Throughput (tokens\/s)":31.8,
        "Reserved Memory (MB)":8514,
        "Used Memory (MB)":9976
    },
    {
        "Model":"meta-llama\/Llama-2-13b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"55.69*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0681,
        "Decode Throughput (tokens\/s)":32.1,
        "Allocated Memory (MB)":9334,
        "Energy (tokens\/kWh)":434782,
        "E2E Latency (s)":8.02,
        "E2E Throughput (tokens\/s)":31.9,
        "Reserved Memory (MB)":9426,
        "Used Memory (MB)":10888
    },
    {
        "Model":"meta-llama\/Llama-2-13b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"55.69*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.105,
        "Decode Throughput (tokens\/s)":32.6,
        "Allocated Memory (MB)":8267,
        "Energy (tokens\/kWh)":403225,
        "E2E Latency (s)":7.93,
        "E2E Throughput (tokens\/s)":32.3,
        "Reserved Memory (MB)":8394,
        "Used Memory (MB)":9854
    },
    {
        "Model":"meta-llama\/Llama-2-13b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"55.69*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.119,
        "Decode Throughput (tokens\/s)":8.36,
        "Allocated Memory (MB)":14514,
        "Energy (tokens\/kWh)":120772,
        "E2E Latency (s)":30.6,
        "E2E Throughput (tokens\/s)":8.37,
        "Reserved Memory (MB)":14550,
        "Used Memory (MB)":16017
    },
    {
        "Model":"meta-llama\/Llama-2-13b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"55.69*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.132,
        "Decode Throughput (tokens\/s)":28.8,
        "Allocated Memory (MB)":8267,
        "Energy (tokens\/kWh)":369003,
        "E2E Latency (s)":8.98,
        "E2E Throughput (tokens\/s)":28.5,
        "Reserved Memory (MB)":8394,
        "Used Memory (MB)":9854
    },
    {
        "Model":"meta-llama\/Llama-2-13b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"55.69*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.307,
        "Decode Throughput (tokens\/s)":23.8,
        "Allocated Memory (MB)":8279,
        "Energy (tokens\/kWh)":290697,
        "E2E Latency (s)":11.0,
        "E2E Throughput (tokens\/s)":23.3,
        "Reserved Memory (MB)":8522,
        "Used Memory (MB)":9982
    },
    {
        "Model":"meta-llama\/Llama-2-13b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"55.69 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.454,
        "Decode Throughput (tokens\/s)":24.5,
        "Allocated Memory (MB)":53918,
        "Energy (tokens\/kWh)":215053,
        "E2E Latency (s)":10.9,
        "E2E Throughput (tokens\/s)":23.5,
        "Reserved Memory (MB)":54123,
        "Used Memory (MB)":55574
    },
    {
        "Model":"codellama\/CodeLlama-34b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":33.74,
        "Open LLM Score (%)":"55.28*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.241,
        "Decode Throughput (tokens\/s)":24.8,
        "Allocated Memory (MB)":18941,
        "Energy (tokens\/kWh)":246305,
        "E2E Latency (s)":10.5,
        "E2E Throughput (tokens\/s)":24.4,
        "Reserved Memory (MB)":19232,
        "Used Memory (MB)":20692
    },
    {
        "Model":"codellama\/CodeLlama-34b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":33.74,
        "Open LLM Score (%)":"55.28*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.305,
        "Decode Throughput (tokens\/s)":23.2,
        "Allocated Memory (MB)":18937,
        "Energy (tokens\/kWh)":238663,
        "E2E Latency (s)":11.3,
        "E2E Throughput (tokens\/s)":22.7,
        "Reserved Memory (MB)":19230,
        "Used Memory (MB)":20690
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.06,
        "Open LLM Score (%)":"54.08 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0276,
        "Decode Throughput (tokens\/s)":39.1,
        "Allocated Memory (MB)":12315,
        "Energy (tokens\/kWh)":467289,
        "E2E Latency (s)":6.55,
        "E2E Throughput (tokens\/s)":39.1,
        "Reserved Memory (MB)":12406,
        "Used Memory (MB)":13866
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.06,
        "Open LLM Score (%)":"54.08 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0284,
        "Decode Throughput (tokens\/s)":39.5,
        "Allocated Memory (MB)":12315,
        "Energy (tokens\/kWh)":462962,
        "E2E Latency (s)":6.49,
        "E2E Throughput (tokens\/s)":39.4,
        "Reserved Memory (MB)":12406,
        "Used Memory (MB)":13866
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.06,
        "Open LLM Score (%)":"54.08 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0298,
        "Decode Throughput (tokens\/s)":38.0,
        "Allocated Memory (MB)":12315,
        "Energy (tokens\/kWh)":416666,
        "E2E Latency (s)":6.74,
        "E2E Throughput (tokens\/s)":38.0,
        "Reserved Memory (MB)":12406,
        "Used Memory (MB)":13866
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.06,
        "Open LLM Score (%)":"54.08*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0368,
        "Decode Throughput (tokens\/s)":36.8,
        "Allocated Memory (MB)":4266,
        "Energy (tokens\/kWh)":495049,
        "E2E Latency (s)":6.97,
        "E2E Throughput (tokens\/s)":36.7,
        "Reserved Memory (MB)":4487,
        "Used Memory (MB)":5949
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.06,
        "Open LLM Score (%)":"54.08*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0379,
        "Decode Throughput (tokens\/s)":37.1,
        "Allocated Memory (MB)":4992,
        "Energy (tokens\/kWh)":546448,
        "E2E Latency (s)":6.92,
        "E2E Throughput (tokens\/s)":37.0,
        "Reserved Memory (MB)":5215,
        "Used Memory (MB)":6677
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.06,
        "Open LLM Score (%)":"54.08*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0553,
        "Decode Throughput (tokens\/s)":38.8,
        "Allocated Memory (MB)":4169,
        "Energy (tokens\/kWh)":526315,
        "E2E Latency (s)":6.63,
        "E2E Throughput (tokens\/s)":38.6,
        "Reserved Memory (MB)":4408,
        "Used Memory (MB)":5867
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.06,
        "Open LLM Score (%)":"54.08*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0646,
        "Decode Throughput (tokens\/s)":33.6,
        "Allocated Memory (MB)":4168,
        "Energy (tokens\/kWh)":467289,
        "E2E Latency (s)":7.64,
        "E2E Throughput (tokens\/s)":33.5,
        "Reserved Memory (MB)":4408,
        "Used Memory (MB)":5867
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.06,
        "Open LLM Score (%)":"54.08*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0956,
        "Decode Throughput (tokens\/s)":10.4,
        "Allocated Memory (MB)":6883,
        "Energy (tokens\/kWh)":156006,
        "E2E Latency (s)":24.6,
        "E2E Throughput (tokens\/s)":10.4,
        "Reserved Memory (MB)":6954,
        "Used Memory (MB)":8422
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.06,
        "Open LLM Score (%)":"54.08*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0996,
        "Decode Throughput (tokens\/s)":10.0,
        "Allocated Memory (MB)":6883,
        "Energy (tokens\/kWh)":146412,
        "E2E Latency (s)":25.5,
        "E2E Throughput (tokens\/s)":10.0,
        "Reserved Memory (MB)":6958,
        "Used Memory (MB)":8426
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.06,
        "Open LLM Score (%)":"54.08*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.144,
        "Decode Throughput (tokens\/s)":27.3,
        "Allocated Memory (MB)":4314,
        "Energy (tokens\/kWh)":377358,
        "E2E Latency (s)":9.49,
        "E2E Throughput (tokens\/s)":27.0,
        "Reserved Memory (MB)":4538,
        "Used Memory (MB)":5997
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.06,
        "Open LLM Score (%)":"54.08 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.213,
        "Decode Throughput (tokens\/s)":41.3,
        "Allocated Memory (MB)":24537,
        "Energy (tokens\/kWh)":380228,
        "E2E Latency (s)":6.39,
        "E2E Throughput (tokens\/s)":40.1,
        "Reserved Memory (MB)":24672,
        "Used Memory (MB)":26124
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.06,
        "Open LLM Score (%)":"54.08*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.238,
        "Decode Throughput (tokens\/s)":22.6,
        "Allocated Memory (MB)":4602,
        "Energy (tokens\/kWh)":299401,
        "E2E Latency (s)":11.5,
        "E2E Throughput (tokens\/s)":22.3,
        "Reserved Memory (MB)":4829,
        "Used Memory (MB)":6289
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.06,
        "Open LLM Score (%)":"54.08*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.239,
        "Decode Throughput (tokens\/s)":22.0,
        "Allocated Memory (MB)":4602,
        "Energy (tokens\/kWh)":290697,
        "E2E Latency (s)":11.8,
        "E2E Throughput (tokens\/s)":21.7,
        "Reserved Memory (MB)":4829,
        "Used Memory (MB)":6289
    },
    {
        "Model":"TheBloke\/Llama-2-13B-fp16",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.0,
        "Open LLM Score (%)":"53.67 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0499,
        "Decode Throughput (tokens\/s)":34.8,
        "Allocated Memory (MB)":27089,
        "Energy (tokens\/kWh)":335570,
        "E2E Latency (s)":7.37,
        "E2E Throughput (tokens\/s)":34.7,
        "Reserved Memory (MB)":27118,
        "Used Memory (MB)":28577
    },
    {
        "Model":"TheBloke\/Llama-2-13B-fp16",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.0,
        "Open LLM Score (%)":"53.67 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0517,
        "Decode Throughput (tokens\/s)":31.8,
        "Allocated Memory (MB)":27089,
        "Energy (tokens\/kWh)":295857,
        "E2E Latency (s)":8.08,
        "E2E Throughput (tokens\/s)":31.7,
        "Reserved Memory (MB)":27118,
        "Used Memory (MB)":28577
    },
    {
        "Model":"TheBloke\/Llama-2-13B-fp16",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.0,
        "Open LLM Score (%)":"53.67*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0675,
        "Decode Throughput (tokens\/s)":31.8,
        "Allocated Memory (MB)":8420,
        "Energy (tokens\/kWh)":380228,
        "E2E Latency (s)":8.1,
        "E2E Throughput (tokens\/s)":31.6,
        "Reserved Memory (MB)":8514,
        "Used Memory (MB)":9976
    },
    {
        "Model":"TheBloke\/Llama-2-13B-fp16",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.0,
        "Open LLM Score (%)":"53.67*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0685,
        "Decode Throughput (tokens\/s)":31.7,
        "Allocated Memory (MB)":9334,
        "Energy (tokens\/kWh)":431034,
        "E2E Latency (s)":8.11,
        "E2E Throughput (tokens\/s)":31.6,
        "Reserved Memory (MB)":9426,
        "Used Memory (MB)":10888
    },
    {
        "Model":"TheBloke\/Llama-2-13B-fp16",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.0,
        "Open LLM Score (%)":"53.67*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.105,
        "Decode Throughput (tokens\/s)":33.4,
        "Allocated Memory (MB)":8267,
        "Energy (tokens\/kWh)":401606,
        "E2E Latency (s)":7.74,
        "E2E Throughput (tokens\/s)":33.1,
        "Reserved Memory (MB)":8394,
        "Used Memory (MB)":9854
    },
    {
        "Model":"TheBloke\/Llama-2-13B-fp16",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.0,
        "Open LLM Score (%)":"53.67*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.119,
        "Decode Throughput (tokens\/s)":8.28,
        "Allocated Memory (MB)":14514,
        "Energy (tokens\/kWh)":118764,
        "E2E Latency (s)":30.9,
        "E2E Throughput (tokens\/s)":8.28,
        "Reserved Memory (MB)":14550,
        "Used Memory (MB)":16017
    },
    {
        "Model":"TheBloke\/Llama-2-13B-fp16",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.0,
        "Open LLM Score (%)":"53.67*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.122,
        "Decode Throughput (tokens\/s)":8.25,
        "Allocated Memory (MB)":14514,
        "Energy (tokens\/kWh)":117647,
        "E2E Latency (s)":31.0,
        "E2E Throughput (tokens\/s)":8.26,
        "Reserved Memory (MB)":14550,
        "Used Memory (MB)":16017
    },
    {
        "Model":"TheBloke\/Llama-2-13B-fp16",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.0,
        "Open LLM Score (%)":"53.67*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.132,
        "Decode Throughput (tokens\/s)":29.2,
        "Allocated Memory (MB)":8267,
        "Energy (tokens\/kWh)":364963,
        "E2E Latency (s)":8.86,
        "E2E Throughput (tokens\/s)":28.9,
        "Reserved Memory (MB)":8394,
        "Used Memory (MB)":9854
    },
    {
        "Model":"TheBloke\/Llama-2-13B-fp16",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.0,
        "Open LLM Score (%)":"53.67*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.307,
        "Decode Throughput (tokens\/s)":23.0,
        "Allocated Memory (MB)":8279,
        "Energy (tokens\/kWh)":282485,
        "E2E Latency (s)":11.4,
        "E2E Throughput (tokens\/s)":22.5,
        "Reserved Memory (MB)":8522,
        "Used Memory (MB)":9982
    },
    {
        "Model":"TheBloke\/Llama-2-13B-fp16",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.0,
        "Open LLM Score (%)":"53.67 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.452,
        "Decode Throughput (tokens\/s)":24.5,
        "Allocated Memory (MB)":53918,
        "Energy (tokens\/kWh)":215517,
        "E2E Latency (s)":10.9,
        "E2E Throughput (tokens\/s)":23.5,
        "Reserved Memory (MB)":54123,
        "Used Memory (MB)":55574
    },
    {
        "Model":"TheBloke\/Llama-2-13B-fp16",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.0,
        "Open LLM Score (%)":"53.67*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.503,
        "Decode Throughput (tokens\/s)":18.2,
        "Allocated Memory (MB)":8754,
        "Energy (tokens\/kWh)":218818,
        "E2E Latency (s)":14.5,
        "E2E Throughput (tokens\/s)":17.7,
        "Reserved Memory (MB)":9156,
        "Used Memory (MB)":10615
    },
    {
        "Model":"TheBloke\/Llama-2-13B-fp16",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.0,
        "Open LLM Score (%)":"53.67*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.51,
        "Decode Throughput (tokens\/s)":18.9,
        "Allocated Memory (MB)":8754,
        "Energy (tokens\/kWh)":230946,
        "E2E Latency (s)":14.0,
        "E2E Throughput (tokens\/s)":18.3,
        "Reserved Memory (MB)":9156,
        "Used Memory (MB)":10615
    },
    {
        "Model":"TigerResearch\/tigerbot-13b-base",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.0,
        "Open LLM Score (%)":"53.42 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0654,
        "Decode Throughput (tokens\/s)":20.4,
        "Allocated Memory (MB)":27641,
        "Energy (tokens\/kWh)":228310,
        "E2E Latency (s)":12.6,
        "E2E Throughput (tokens\/s)":20.3,
        "Reserved Memory (MB)":27694,
        "Used Memory (MB)":29154
    },
    {
        "Model":"TigerResearch\/tigerbot-13b-base",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.0,
        "Open LLM Score (%)":"53.42 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0695,
        "Decode Throughput (tokens\/s)":19.6,
        "Allocated Memory (MB)":27641,
        "Energy (tokens\/kWh)":212765,
        "E2E Latency (s)":13.1,
        "E2E Throughput (tokens\/s)":19.5,
        "Reserved Memory (MB)":27694,
        "Used Memory (MB)":29154
    },
    {
        "Model":"TigerResearch\/tigerbot-13b-base",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.0,
        "Open LLM Score (%)":"53.42 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.507,
        "Decode Throughput (tokens\/s)":21.1,
        "Allocated Memory (MB)":55017,
        "Energy (tokens\/kWh)":180180,
        "E2E Latency (s)":12.6,
        "E2E Throughput (tokens\/s)":20.3,
        "Reserved Memory (MB)":55192,
        "Used Memory (MB)":56644
    },
    {
        "Model":"mosaicml\/mpt-30b",
        "Arch":"\ud83e\uddf1 MPT",
        "Params (B)":30.0,
        "Open LLM Score (%)":"52.77*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0895,
        "Decode Throughput (tokens\/s)":11.5,
        "Allocated Memory (MB)":31849,
        "Energy (tokens\/kWh)":151745,
        "E2E Latency (s)":22.3,
        "E2E Throughput (tokens\/s)":11.5,
        "Reserved Memory (MB)":32193,
        "Used Memory (MB)":33661
    },
    {
        "Model":"mosaicml\/mpt-30b",
        "Arch":"\ud83e\uddf1 MPT",
        "Params (B)":30.0,
        "Open LLM Score (%)":"52.77*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.213,
        "Decode Throughput (tokens\/s)":39.6,
        "Allocated Memory (MB)":17553,
        "Energy (tokens\/kWh)":346020,
        "E2E Latency (s)":6.65,
        "E2E Throughput (tokens\/s)":38.5,
        "Reserved Memory (MB)":17960,
        "Used Memory (MB)":19419
    },
    {
        "Model":"mosaicml\/mpt-30b",
        "Arch":"\ud83e\uddf1 MPT",
        "Params (B)":30.0,
        "Open LLM Score (%)":"52.77*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.264,
        "Decode Throughput (tokens\/s)":35.0,
        "Allocated Memory (MB)":17553,
        "Energy (tokens\/kWh)":328947,
        "E2E Latency (s)":7.55,
        "E2E Throughput (tokens\/s)":33.9,
        "Reserved Memory (MB)":17960,
        "Used Memory (MB)":19419
    },
    {
        "Model":"mosaicml\/mpt-30b",
        "Arch":"\ud83e\uddf1 MPT",
        "Params (B)":30.0,
        "Open LLM Score (%)":"52.77*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":1.14,
        "Decode Throughput (tokens\/s)":14.6,
        "Allocated Memory (MB)":19236,
        "Energy (tokens\/kWh)":156739,
        "E2E Latency (s)":18.6,
        "E2E Throughput (tokens\/s)":13.8,
        "Reserved Memory (MB)":19782,
        "Used Memory (MB)":21241
    },
    {
        "Model":"augmxnt\/shisa-base-7b-v1",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.96,
        "Open LLM Score (%)":"51.64 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0377,
        "Decode Throughput (tokens\/s)":34.2,
        "Allocated Memory (MB)":16692,
        "Energy (tokens\/kWh)":401606,
        "E2E Latency (s)":7.49,
        "E2E Throughput (tokens\/s)":34.2,
        "Reserved Memory (MB)":16972,
        "Used Memory (MB)":18431
    },
    {
        "Model":"augmxnt\/shisa-base-7b-v1",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.96,
        "Open LLM Score (%)":"51.64 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0428,
        "Decode Throughput (tokens\/s)":33.5,
        "Allocated Memory (MB)":16692,
        "Energy (tokens\/kWh)":371747,
        "E2E Latency (s)":7.66,
        "E2E Throughput (tokens\/s)":33.4,
        "Reserved Memory (MB)":16974,
        "Used Memory (MB)":18433
    },
    {
        "Model":"augmxnt\/shisa-base-7b-v1",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.96,
        "Open LLM Score (%)":"51.64*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0464,
        "Decode Throughput (tokens\/s)":32.4,
        "Allocated Memory (MB)":6485,
        "Energy (tokens\/kWh)":432900,
        "E2E Latency (s)":7.91,
        "E2E Throughput (tokens\/s)":32.4,
        "Reserved Memory (MB)":6761,
        "Used Memory (MB)":8222
    },
    {
        "Model":"augmxnt\/shisa-base-7b-v1",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.96,
        "Open LLM Score (%)":"51.64*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0468,
        "Decode Throughput (tokens\/s)":32.5,
        "Allocated Memory (MB)":7429,
        "Energy (tokens\/kWh)":462962,
        "E2E Latency (s)":7.89,
        "E2E Throughput (tokens\/s)":32.4,
        "Reserved Memory (MB)":7709,
        "Used Memory (MB)":9170
    },
    {
        "Model":"augmxnt\/shisa-base-7b-v1",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.96,
        "Open LLM Score (%)":"51.64*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0671,
        "Decode Throughput (tokens\/s)":34.3,
        "Allocated Memory (MB)":6360,
        "Energy (tokens\/kWh)":458715,
        "E2E Latency (s)":7.5,
        "E2E Throughput (tokens\/s)":34.1,
        "Reserved Memory (MB)":6685,
        "Used Memory (MB)":8145
    },
    {
        "Model":"augmxnt\/shisa-base-7b-v1",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.96,
        "Open LLM Score (%)":"51.64*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.078,
        "Decode Throughput (tokens\/s)":29.6,
        "Allocated Memory (MB)":6360,
        "Energy (tokens\/kWh)":420168,
        "E2E Latency (s)":8.69,
        "E2E Throughput (tokens\/s)":29.5,
        "Reserved Memory (MB)":6685,
        "Used Memory (MB)":8145
    },
    {
        "Model":"augmxnt\/shisa-base-7b-v1",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.96,
        "Open LLM Score (%)":"51.64*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.104,
        "Decode Throughput (tokens\/s)":9.85,
        "Allocated Memory (MB)":9718,
        "Energy (tokens\/kWh)":144927,
        "E2E Latency (s)":26.0,
        "E2E Throughput (tokens\/s)":9.85,
        "Reserved Memory (MB)":10009,
        "Used Memory (MB)":11477
    },
    {
        "Model":"augmxnt\/shisa-base-7b-v1",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.96,
        "Open LLM Score (%)":"51.64*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.105,
        "Decode Throughput (tokens\/s)":9.85,
        "Allocated Memory (MB)":9718,
        "Energy (tokens\/kWh)":144927,
        "E2E Latency (s)":26.0,
        "E2E Throughput (tokens\/s)":9.85,
        "Reserved Memory (MB)":10020,
        "Used Memory (MB)":11488
    },
    {
        "Model":"augmxnt\/shisa-base-7b-v1",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.96,
        "Open LLM Score (%)":"51.64*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.183,
        "Decode Throughput (tokens\/s)":24.5,
        "Allocated Memory (MB)":6491,
        "Energy (tokens\/kWh)":318471,
        "E2E Latency (s)":10.6,
        "E2E Throughput (tokens\/s)":24.2,
        "Reserved Memory (MB)":6750,
        "Used Memory (MB)":8210
    },
    {
        "Model":"augmxnt\/shisa-base-7b-v1",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.96,
        "Open LLM Score (%)":"51.64 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.276,
        "Decode Throughput (tokens\/s)":37.2,
        "Allocated Memory (MB)":33224,
        "Energy (tokens\/kWh)":321543,
        "E2E Latency (s)":7.14,
        "E2E Throughput (tokens\/s)":35.9,
        "Reserved Memory (MB)":33327,
        "Used Memory (MB)":34779
    },
    {
        "Model":"augmxnt\/shisa-base-7b-v1",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.96,
        "Open LLM Score (%)":"51.64*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.29,
        "Decode Throughput (tokens\/s)":20.7,
        "Allocated Memory (MB)":6871,
        "Energy (tokens\/kWh)":270270,
        "E2E Latency (s)":12.6,
        "E2E Throughput (tokens\/s)":20.3,
        "Reserved Memory (MB)":7207,
        "Used Memory (MB)":8667
    },
    {
        "Model":"augmxnt\/shisa-base-7b-v1",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":7.96,
        "Open LLM Score (%)":"51.64*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.302,
        "Decode Throughput (tokens\/s)":20.4,
        "Allocated Memory (MB)":6871,
        "Energy (tokens\/kWh)":264550,
        "E2E Latency (s)":12.8,
        "E2E Throughput (tokens\/s)":20.0,
        "Reserved Memory (MB)":7207,
        "Used Memory (MB)":8667
    },
    {
        "Model":"huggingface\/llama-13b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"51.36 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.051,
        "Decode Throughput (tokens\/s)":33.8,
        "Allocated Memory (MB)":27047,
        "Energy (tokens\/kWh)":323624,
        "E2E Latency (s)":7.6,
        "E2E Throughput (tokens\/s)":33.7,
        "Reserved Memory (MB)":27078,
        "Used Memory (MB)":28538
    },
    {
        "Model":"huggingface\/llama-13b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"51.36*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0673,
        "Decode Throughput (tokens\/s)":31.4,
        "Allocated Memory (MB)":8379,
        "Energy (tokens\/kWh)":378787,
        "E2E Latency (s)":8.19,
        "E2E Throughput (tokens\/s)":31.3,
        "Reserved Memory (MB)":8472,
        "Used Memory (MB)":9934
    },
    {
        "Model":"huggingface\/llama-13b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"51.36*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0683,
        "Decode Throughput (tokens\/s)":32.3,
        "Allocated Memory (MB)":9292,
        "Energy (tokens\/kWh)":423728,
        "E2E Latency (s)":7.96,
        "E2E Throughput (tokens\/s)":32.2,
        "Reserved Memory (MB)":9384,
        "Used Memory (MB)":10846
    },
    {
        "Model":"huggingface\/llama-13b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"51.36*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.105,
        "Decode Throughput (tokens\/s)":33.0,
        "Allocated Memory (MB)":8225,
        "Energy (tokens\/kWh)":403225,
        "E2E Latency (s)":7.83,
        "E2E Throughput (tokens\/s)":32.7,
        "Reserved Memory (MB)":8355,
        "Used Memory (MB)":9814
    },
    {
        "Model":"huggingface\/llama-13b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"51.36*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.122,
        "Decode Throughput (tokens\/s)":7.99,
        "Allocated Memory (MB)":14472,
        "Energy (tokens\/kWh)":118343,
        "E2E Latency (s)":32.0,
        "E2E Throughput (tokens\/s)":8.0,
        "Reserved Memory (MB)":14508,
        "Used Memory (MB)":15976
    },
    {
        "Model":"huggingface\/llama-13b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"51.36*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.132,
        "Decode Throughput (tokens\/s)":28.8,
        "Allocated Memory (MB)":8225,
        "Energy (tokens\/kWh)":363636,
        "E2E Latency (s)":8.97,
        "E2E Throughput (tokens\/s)":28.5,
        "Reserved Memory (MB)":8352,
        "Used Memory (MB)":9812
    },
    {
        "Model":"huggingface\/llama-13b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"51.36*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.307,
        "Decode Throughput (tokens\/s)":23.4,
        "Allocated Memory (MB)":8237,
        "Energy (tokens\/kWh)":287356,
        "E2E Latency (s)":11.2,
        "E2E Throughput (tokens\/s)":22.9,
        "Reserved Memory (MB)":8480,
        "Used Memory (MB)":9940
    },
    {
        "Model":"huggingface\/llama-13b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"51.36 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.453,
        "Decode Throughput (tokens\/s)":24.5,
        "Allocated Memory (MB)":53834,
        "Energy (tokens\/kWh)":216450,
        "E2E Latency (s)":10.9,
        "E2E Throughput (tokens\/s)":23.5,
        "Reserved Memory (MB)":54045,
        "Used Memory (MB)":55496
    },
    {
        "Model":"huggyllama\/llama-13b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"51.33 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0498,
        "Decode Throughput (tokens\/s)":34.6,
        "Allocated Memory (MB)":27047,
        "Energy (tokens\/kWh)":337837,
        "E2E Latency (s)":7.41,
        "E2E Throughput (tokens\/s)":34.5,
        "Reserved Memory (MB)":27078,
        "Used Memory (MB)":28537
    },
    {
        "Model":"huggyllama\/llama-13b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"51.33 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.052,
        "Decode Throughput (tokens\/s)":32.6,
        "Allocated Memory (MB)":27047,
        "Energy (tokens\/kWh)":304878,
        "E2E Latency (s)":7.87,
        "E2E Throughput (tokens\/s)":32.5,
        "Reserved Memory (MB)":27078,
        "Used Memory (MB)":28537
    },
    {
        "Model":"huggyllama\/llama-13b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"51.33*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0665,
        "Decode Throughput (tokens\/s)":31.4,
        "Allocated Memory (MB)":8379,
        "Energy (tokens\/kWh)":367647,
        "E2E Latency (s)":8.18,
        "E2E Throughput (tokens\/s)":31.3,
        "Reserved Memory (MB)":8472,
        "Used Memory (MB)":9934
    },
    {
        "Model":"huggyllama\/llama-13b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"51.33*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0685,
        "Decode Throughput (tokens\/s)":32.2,
        "Allocated Memory (MB)":9292,
        "Energy (tokens\/kWh)":434782,
        "E2E Latency (s)":7.98,
        "E2E Throughput (tokens\/s)":32.1,
        "Reserved Memory (MB)":9384,
        "Used Memory (MB)":10846
    },
    {
        "Model":"huggyllama\/llama-13b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"51.33*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.105,
        "Decode Throughput (tokens\/s)":32.1,
        "Allocated Memory (MB)":8225,
        "Energy (tokens\/kWh)":401606,
        "E2E Latency (s)":8.05,
        "E2E Throughput (tokens\/s)":31.8,
        "Reserved Memory (MB)":8355,
        "Used Memory (MB)":9814
    },
    {
        "Model":"huggyllama\/llama-13b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"51.33*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.119,
        "Decode Throughput (tokens\/s)":8.31,
        "Allocated Memory (MB)":14472,
        "Energy (tokens\/kWh)":119617,
        "E2E Latency (s)":30.8,
        "E2E Throughput (tokens\/s)":8.31,
        "Reserved Memory (MB)":14508,
        "Used Memory (MB)":15976
    },
    {
        "Model":"huggyllama\/llama-13b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"51.33*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.122,
        "Decode Throughput (tokens\/s)":7.16,
        "Allocated Memory (MB)":14472,
        "Energy (tokens\/kWh)":117233,
        "E2E Latency (s)":35.7,
        "E2E Throughput (tokens\/s)":7.17,
        "Reserved Memory (MB)":14508,
        "Used Memory (MB)":15976
    },
    {
        "Model":"huggyllama\/llama-13b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"51.33*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.132,
        "Decode Throughput (tokens\/s)":29.3,
        "Allocated Memory (MB)":8225,
        "Energy (tokens\/kWh)":370370,
        "E2E Latency (s)":8.82,
        "E2E Throughput (tokens\/s)":29.0,
        "Reserved Memory (MB)":8352,
        "Used Memory (MB)":9812
    },
    {
        "Model":"huggyllama\/llama-13b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"51.33 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.454,
        "Decode Throughput (tokens\/s)":24.5,
        "Allocated Memory (MB)":53834,
        "Energy (tokens\/kWh)":212765,
        "E2E Latency (s)":10.9,
        "E2E Throughput (tokens\/s)":23.5,
        "Reserved Memory (MB)":54045,
        "Used Memory (MB)":55496
    },
    {
        "Model":"huggyllama\/llama-13b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"51.33*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.5,
        "Decode Throughput (tokens\/s)":18.9,
        "Allocated Memory (MB)":8713,
        "Energy (tokens\/kWh)":231481,
        "E2E Latency (s)":14.0,
        "E2E Throughput (tokens\/s)":18.3,
        "Reserved Memory (MB)":9114,
        "Used Memory (MB)":10573
    },
    {
        "Model":"huggyllama\/llama-13b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"51.33*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.515,
        "Decode Throughput (tokens\/s)":18.5,
        "Allocated Memory (MB)":8713,
        "Energy (tokens\/kWh)":218818,
        "E2E Latency (s)":14.3,
        "E2E Throughput (tokens\/s)":17.9,
        "Reserved Memory (MB)":9114,
        "Used Memory (MB)":10573
    },
    {
        "Model":"chargoddard\/llama-2-26b-trenchcoat-stack",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":25.7,
        "Open LLM Score (%)":"51.13 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.1,
        "Decode Throughput (tokens\/s)":17.3,
        "Allocated Memory (MB)":53514,
        "Energy (tokens\/kWh)":165837,
        "E2E Latency (s)":14.8,
        "E2E Throughput (tokens\/s)":17.3,
        "Reserved Memory (MB)":53544,
        "Used Memory (MB)":55004
    },
    {
        "Model":"chargoddard\/llama-2-26b-trenchcoat-stack",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":25.7,
        "Open LLM Score (%)":"51.13 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.105,
        "Decode Throughput (tokens\/s)":15.6,
        "Allocated Memory (MB)":53514,
        "Energy (tokens\/kWh)":151515,
        "E2E Latency (s)":16.4,
        "E2E Throughput (tokens\/s)":15.6,
        "Reserved Memory (MB)":53544,
        "Used Memory (MB)":55004
    },
    {
        "Model":"chargoddard\/llama-2-26b-trenchcoat-stack",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":25.7,
        "Open LLM Score (%)":"51.13*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.134,
        "Decode Throughput (tokens\/s)":16.0,
        "Allocated Memory (MB)":16955,
        "Energy (tokens\/kWh)":219298,
        "E2E Latency (s)":16.0,
        "E2E Throughput (tokens\/s)":16.0,
        "Reserved Memory (MB)":17110,
        "Used Memory (MB)":18572
    },
    {
        "Model":"chargoddard\/llama-2-26b-trenchcoat-stack",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":25.7,
        "Open LLM Score (%)":"51.13*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.134,
        "Decode Throughput (tokens\/s)":15.7,
        "Allocated Memory (MB)":16035,
        "Energy (tokens\/kWh)":189393,
        "E2E Latency (s)":16.3,
        "E2E Throughput (tokens\/s)":15.7,
        "Reserved Memory (MB)":16190,
        "Used Memory (MB)":17651
    },
    {
        "Model":"chargoddard\/llama-2-26b-trenchcoat-stack",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":25.7,
        "Open LLM Score (%)":"51.13*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.211,
        "Decode Throughput (tokens\/s)":16.3,
        "Allocated Memory (MB)":15869,
        "Energy (tokens\/kWh)":199203,
        "E2E Latency (s)":15.8,
        "E2E Throughput (tokens\/s)":16.2,
        "Reserved Memory (MB)":16059,
        "Used Memory (MB)":17519
    },
    {
        "Model":"chargoddard\/llama-2-26b-trenchcoat-stack",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":25.7,
        "Open LLM Score (%)":"51.13*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.242,
        "Decode Throughput (tokens\/s)":4.13,
        "Allocated Memory (MB)":28365,
        "Energy (tokens\/kWh)":59880,
        "E2E Latency (s)":62.0,
        "E2E Throughput (tokens\/s)":4.13,
        "Reserved Memory (MB)":28380,
        "Used Memory (MB)":29848
    },
    {
        "Model":"chargoddard\/llama-2-26b-trenchcoat-stack",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":25.7,
        "Open LLM Score (%)":"51.13*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.242,
        "Decode Throughput (tokens\/s)":4.03,
        "Allocated Memory (MB)":28365,
        "Energy (tokens\/kWh)":57471,
        "E2E Latency (s)":63.4,
        "E2E Throughput (tokens\/s)":4.04,
        "Reserved Memory (MB)":28380,
        "Used Memory (MB)":29848
    },
    {
        "Model":"chargoddard\/llama-2-26b-trenchcoat-stack",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":25.7,
        "Open LLM Score (%)":"51.13*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.265,
        "Decode Throughput (tokens\/s)":14.9,
        "Allocated Memory (MB)":15869,
        "Energy (tokens\/kWh)":183486,
        "E2E Latency (s)":17.4,
        "E2E Throughput (tokens\/s)":14.7,
        "Reserved Memory (MB)":16057,
        "Used Memory (MB)":17517
    },
    {
        "Model":"chargoddard\/llama-2-26b-trenchcoat-stack",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":25.7,
        "Open LLM Score (%)":"51.13*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.995,
        "Decode Throughput (tokens\/s)":9.44,
        "Allocated Memory (MB)":16846,
        "Energy (tokens\/kWh)":113765,
        "E2E Latency (s)":28.0,
        "E2E Throughput (tokens\/s)":9.14,
        "Reserved Memory (MB)":17504,
        "Used Memory (MB)":18964
    },
    {
        "Model":"chargoddard\/llama-2-26b-trenchcoat-stack",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":25.7,
        "Open LLM Score (%)":"51.13*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":1.0,
        "Decode Throughput (tokens\/s)":9.24,
        "Allocated Memory (MB)":16846,
        "Energy (tokens\/kWh)":111111,
        "E2E Latency (s)":28.6,
        "E2E Throughput (tokens\/s)":8.95,
        "Reserved Memory (MB)":17504,
        "Used Memory (MB)":18964
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.74,
        "Open LLM Score (%)":"50.97 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0311,
        "Decode Throughput (tokens\/s)":41.5,
        "Allocated Memory (MB)":14089,
        "Energy (tokens\/kWh)":473933,
        "E2E Latency (s)":6.18,
        "E2E Throughput (tokens\/s)":41.4,
        "Reserved Memory (MB)":14124,
        "Used Memory (MB)":15583
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.74,
        "Open LLM Score (%)":"50.97 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0322,
        "Decode Throughput (tokens\/s)":42.0,
        "Allocated Memory (MB)":14089,
        "Energy (tokens\/kWh)":458715,
        "E2E Latency (s)":6.1,
        "E2E Throughput (tokens\/s)":42.0,
        "Reserved Memory (MB)":14124,
        "Used Memory (MB)":15583
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.74,
        "Open LLM Score (%)":"50.97*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0398,
        "Decode Throughput (tokens\/s)":40.2,
        "Allocated Memory (MB)":4649,
        "Energy (tokens\/kWh)":526315,
        "E2E Latency (s)":6.38,
        "E2E Throughput (tokens\/s)":40.1,
        "Reserved Memory (MB)":4680,
        "Used Memory (MB)":6142
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.74,
        "Open LLM Score (%)":"50.97*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.041,
        "Decode Throughput (tokens\/s)":39.8,
        "Allocated Memory (MB)":5375,
        "Energy (tokens\/kWh)":578034,
        "E2E Latency (s)":6.45,
        "E2E Throughput (tokens\/s)":39.7,
        "Reserved Memory (MB)":5408,
        "Used Memory (MB)":6870
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.74,
        "Open LLM Score (%)":"50.97*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0632,
        "Decode Throughput (tokens\/s)":40.2,
        "Allocated Memory (MB)":4553,
        "Energy (tokens\/kWh)":537634,
        "E2E Latency (s)":6.4,
        "E2E Throughput (tokens\/s)":40.0,
        "Reserved Memory (MB)":4586,
        "Used Memory (MB)":6046
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.74,
        "Open LLM Score (%)":"50.97*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0721,
        "Decode Throughput (tokens\/s)":36.5,
        "Allocated Memory (MB)":4552,
        "Energy (tokens\/kWh)":502512,
        "E2E Latency (s)":7.05,
        "E2E Throughput (tokens\/s)":36.3,
        "Reserved Memory (MB)":4586,
        "Used Memory (MB)":6046
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.74,
        "Open LLM Score (%)":"50.97*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0975,
        "Decode Throughput (tokens\/s)":10.2,
        "Allocated Memory (MB)":7719,
        "Energy (tokens\/kWh)":154559,
        "E2E Latency (s)":25.0,
        "E2E Throughput (tokens\/s)":10.2,
        "Reserved Memory (MB)":7757,
        "Used Memory (MB)":9225
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.74,
        "Open LLM Score (%)":"50.97*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.167,
        "Decode Throughput (tokens\/s)":28.9,
        "Allocated Memory (MB)":4561,
        "Energy (tokens\/kWh)":378787,
        "E2E Latency (s)":8.99,
        "E2E Throughput (tokens\/s)":28.5,
        "Reserved Memory (MB)":4607,
        "Used Memory (MB)":6066
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.74,
        "Open LLM Score (%)":"50.97 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.238,
        "Decode Throughput (tokens\/s)":41.6,
        "Allocated Memory (MB)":28167,
        "Energy (tokens\/kWh)":362318,
        "E2E Latency (s)":6.37,
        "E2E Throughput (tokens\/s)":40.2,
        "Reserved Memory (MB)":28527,
        "Used Memory (MB)":29978
    },
    {
        "Model":"itsliupeng\/openllama-7b-icl",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"47.93 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0303,
        "Decode Throughput (tokens\/s)":42.5,
        "Allocated Memory (MB)":14056,
        "Energy (tokens\/kWh)":476190,
        "E2E Latency (s)":6.03,
        "E2E Throughput (tokens\/s)":42.5,
        "Reserved Memory (MB)":14092,
        "Used Memory (MB)":15552
    },
    {
        "Model":"itsliupeng\/openllama-7b-icl",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"47.93 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0319,
        "Decode Throughput (tokens\/s)":39.0,
        "Allocated Memory (MB)":14056,
        "Energy (tokens\/kWh)":446428,
        "E2E Latency (s)":6.57,
        "E2E Throughput (tokens\/s)":39.0,
        "Reserved Memory (MB)":14092,
        "Used Memory (MB)":15552
    },
    {
        "Model":"itsliupeng\/openllama-7b-icl",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"47.93*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0398,
        "Decode Throughput (tokens\/s)":39.1,
        "Allocated Memory (MB)":4616,
        "Energy (tokens\/kWh)":512820,
        "E2E Latency (s)":6.57,
        "E2E Throughput (tokens\/s)":39.0,
        "Reserved Memory (MB)":4647,
        "Used Memory (MB)":6108
    },
    {
        "Model":"itsliupeng\/openllama-7b-icl",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"47.93*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.041,
        "Decode Throughput (tokens\/s)":39.7,
        "Allocated Memory (MB)":5342,
        "Energy (tokens\/kWh)":561797,
        "E2E Latency (s)":6.46,
        "E2E Throughput (tokens\/s)":39.6,
        "Reserved Memory (MB)":5375,
        "Used Memory (MB)":6836
    },
    {
        "Model":"itsliupeng\/openllama-7b-icl",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"47.93*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0613,
        "Decode Throughput (tokens\/s)":39.6,
        "Allocated Memory (MB)":4519,
        "Energy (tokens\/kWh)":549450,
        "E2E Latency (s)":6.5,
        "E2E Throughput (tokens\/s)":39.4,
        "Reserved Memory (MB)":4548,
        "Used Memory (MB)":6008
    },
    {
        "Model":"itsliupeng\/openllama-7b-icl",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"47.93*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0716,
        "Decode Throughput (tokens\/s)":37.0,
        "Allocated Memory (MB)":4519,
        "Energy (tokens\/kWh)":497512,
        "E2E Latency (s)":6.97,
        "E2E Throughput (tokens\/s)":36.7,
        "Reserved Memory (MB)":4548,
        "Used Memory (MB)":6008
    },
    {
        "Model":"itsliupeng\/openllama-7b-icl",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"47.93*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0933,
        "Decode Throughput (tokens\/s)":10.5,
        "Allocated Memory (MB)":7686,
        "Energy (tokens\/kWh)":157728,
        "E2E Latency (s)":24.4,
        "E2E Throughput (tokens\/s)":10.5,
        "Reserved Memory (MB)":7728,
        "Used Memory (MB)":9195
    },
    {
        "Model":"itsliupeng\/openllama-7b-icl",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"47.93*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0955,
        "Decode Throughput (tokens\/s)":10.3,
        "Allocated Memory (MB)":7686,
        "Energy (tokens\/kWh)":155763,
        "E2E Latency (s)":24.8,
        "E2E Throughput (tokens\/s)":10.3,
        "Reserved Memory (MB)":7728,
        "Used Memory (MB)":9195
    },
    {
        "Model":"itsliupeng\/openllama-7b-icl",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"47.93 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.238,
        "Decode Throughput (tokens\/s)":41.7,
        "Allocated Memory (MB)":28100,
        "Energy (tokens\/kWh)":367647,
        "E2E Latency (s)":6.35,
        "E2E Throughput (tokens\/s)":40.3,
        "Reserved Memory (MB)":28458,
        "Used Memory (MB)":29909
    },
    {
        "Model":"itsliupeng\/openllama-7b-icl",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"47.93*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.268,
        "Decode Throughput (tokens\/s)":23.4,
        "Allocated Memory (MB)":4795,
        "Energy (tokens\/kWh)":302114,
        "E2E Latency (s)":11.2,
        "E2E Throughput (tokens\/s)":22.9,
        "Reserved Memory (MB)":4995,
        "Used Memory (MB)":6454
    },
    {
        "Model":"itsliupeng\/openllama-7b-icl",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"47.93*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.268,
        "Decode Throughput (tokens\/s)":23.0,
        "Allocated Memory (MB)":4796,
        "Energy (tokens\/kWh)":292397,
        "E2E Latency (s)":11.4,
        "E2E Throughput (tokens\/s)":22.5,
        "Reserved Memory (MB)":4949,
        "Used Memory (MB)":6408
    },
    {
        "Model":"microsoft\/phi-1_5",
        "Arch":"phi",
        "Params (B)":0.0,
        "Open LLM Score (%)":"47.69*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0203,
        "Decode Throughput (tokens\/s)":52.5,
        "Allocated Memory (MB)":1280,
        "Energy (tokens\/kWh)":799999,
        "E2E Latency (s)":4.88,
        "E2E Throughput (tokens\/s)":52.5,
        "Reserved Memory (MB)":1331,
        "Used Memory (MB)":2791
    },
    {
        "Model":"microsoft\/phi-1_5",
        "Arch":"phi",
        "Params (B)":0.0,
        "Open LLM Score (%)":"47.69*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0208,
        "Decode Throughput (tokens\/s)":49.1,
        "Allocated Memory (MB)":1280,
        "Energy (tokens\/kWh)":769230,
        "E2E Latency (s)":5.21,
        "E2E Throughput (tokens\/s)":49.1,
        "Reserved Memory (MB)":1331,
        "Used Memory (MB)":2791
    },
    {
        "Model":"microsoft\/phi-1_5",
        "Arch":"phi",
        "Params (B)":0.0,
        "Open LLM Score (%)":"47.69 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0268,
        "Decode Throughput (tokens\/s)":36.4,
        "Allocated Memory (MB)":3329,
        "Energy (tokens\/kWh)":546448,
        "E2E Latency (s)":7.04,
        "E2E Throughput (tokens\/s)":36.4,
        "Reserved Memory (MB)":3521,
        "Used Memory (MB)":4980
    },
    {
        "Model":"microsoft\/phi-1_5",
        "Arch":"phi",
        "Params (B)":0.0,
        "Open LLM Score (%)":"47.69 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0273,
        "Decode Throughput (tokens\/s)":36.4,
        "Allocated Memory (MB)":3329,
        "Energy (tokens\/kWh)":568181,
        "E2E Latency (s)":7.04,
        "E2E Throughput (tokens\/s)":36.4,
        "Reserved Memory (MB)":3521,
        "Used Memory (MB)":4980
    },
    {
        "Model":"microsoft\/phi-1_5",
        "Arch":"phi",
        "Params (B)":0.0,
        "Open LLM Score (%)":"47.69 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0549,
        "Decode Throughput (tokens\/s)":41.1,
        "Allocated Memory (MB)":6550,
        "Energy (tokens\/kWh)":588235,
        "E2E Latency (s)":6.26,
        "E2E Throughput (tokens\/s)":40.9,
        "Reserved Memory (MB)":6603,
        "Used Memory (MB)":8055
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.0,
        "Open LLM Score (%)":"47.64 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.031,
        "Decode Throughput (tokens\/s)":43.3,
        "Allocated Memory (MB)":14653,
        "Energy (tokens\/kWh)":485436,
        "E2E Latency (s)":5.92,
        "E2E Throughput (tokens\/s)":43.2,
        "Reserved Memory (MB)":14682,
        "Used Memory (MB)":16141
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.0,
        "Open LLM Score (%)":"47.64 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0326,
        "Decode Throughput (tokens\/s)":42.6,
        "Allocated Memory (MB)":14653,
        "Energy (tokens\/kWh)":458715,
        "E2E Latency (s)":6.01,
        "E2E Throughput (tokens\/s)":42.6,
        "Reserved Memory (MB)":14682,
        "Used Memory (MB)":16141
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.0,
        "Open LLM Score (%)":"47.64 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0329,
        "Decode Throughput (tokens\/s)":40.5,
        "Allocated Memory (MB)":14653,
        "Energy (tokens\/kWh)":442477,
        "E2E Latency (s)":6.33,
        "E2E Throughput (tokens\/s)":40.4,
        "Reserved Memory (MB)":14682,
        "Used Memory (MB)":16141
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.0,
        "Open LLM Score (%)":"47.64*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0405,
        "Decode Throughput (tokens\/s)":39.2,
        "Allocated Memory (MB)":5213,
        "Energy (tokens\/kWh)":512820,
        "E2E Latency (s)":6.55,
        "E2E Throughput (tokens\/s)":39.1,
        "Reserved Memory (MB)":5236,
        "Used Memory (MB)":6698
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.0,
        "Open LLM Score (%)":"47.64*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0418,
        "Decode Throughput (tokens\/s)":38.9,
        "Allocated Memory (MB)":5939,
        "Energy (tokens\/kWh)":561797,
        "E2E Latency (s)":6.59,
        "E2E Throughput (tokens\/s)":38.8,
        "Reserved Memory (MB)":5964,
        "Used Memory (MB)":7426
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.0,
        "Open LLM Score (%)":"47.64*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0619,
        "Decode Throughput (tokens\/s)":38.8,
        "Allocated Memory (MB)":5117,
        "Energy (tokens\/kWh)":543478,
        "E2E Latency (s)":6.63,
        "E2E Throughput (tokens\/s)":38.6,
        "Reserved Memory (MB)":5156,
        "Used Memory (MB)":6616
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.0,
        "Open LLM Score (%)":"47.64*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0714,
        "Decode Throughput (tokens\/s)":36.6,
        "Allocated Memory (MB)":5116,
        "Energy (tokens\/kWh)":492610,
        "E2E Latency (s)":7.03,
        "E2E Throughput (tokens\/s)":36.4,
        "Reserved Memory (MB)":5156,
        "Used Memory (MB)":6616
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.0,
        "Open LLM Score (%)":"47.64*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0956,
        "Decode Throughput (tokens\/s)":10.5,
        "Allocated Memory (MB)":8283,
        "Energy (tokens\/kWh)":155763,
        "E2E Latency (s)":24.4,
        "E2E Throughput (tokens\/s)":10.5,
        "Reserved Memory (MB)":8321,
        "Used Memory (MB)":9789
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.0,
        "Open LLM Score (%)":"47.64*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0991,
        "Decode Throughput (tokens\/s)":10.1,
        "Allocated Memory (MB)":8283,
        "Energy (tokens\/kWh)":152207,
        "E2E Latency (s)":25.4,
        "E2E Throughput (tokens\/s)":10.1,
        "Reserved Memory (MB)":8321,
        "Used Memory (MB)":9789
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.0,
        "Open LLM Score (%)":"47.64*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.169,
        "Decode Throughput (tokens\/s)":29.2,
        "Allocated Memory (MB)":5124,
        "Energy (tokens\/kWh)":387596,
        "E2E Latency (s)":8.89,
        "E2E Throughput (tokens\/s)":28.8,
        "Reserved Memory (MB)":5173,
        "Used Memory (MB)":6633
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.0,
        "Open LLM Score (%)":"47.64 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.242,
        "Decode Throughput (tokens\/s)":41.0,
        "Allocated Memory (MB)":29295,
        "Energy (tokens\/kWh)":358422,
        "E2E Latency (s)":6.46,
        "E2E Throughput (tokens\/s)":39.6,
        "Reserved Memory (MB)":29628,
        "Used Memory (MB)":31079
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.0,
        "Open LLM Score (%)":"47.64*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.268,
        "Decode Throughput (tokens\/s)":23.2,
        "Allocated Memory (MB)":5393,
        "Energy (tokens\/kWh)":294117,
        "E2E Latency (s)":11.3,
        "E2E Throughput (tokens\/s)":22.7,
        "Reserved Memory (MB)":5549,
        "Used Memory (MB)":7008
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.0,
        "Open LLM Score (%)":"47.64*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.27,
        "Decode Throughput (tokens\/s)":22.8,
        "Allocated Memory (MB)":5393,
        "Energy (tokens\/kWh)":280112,
        "E2E Latency (s)":11.5,
        "E2E Throughput (tokens\/s)":22.3,
        "Reserved Memory (MB)":5595,
        "Used Memory (MB)":7054
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.0,
        "Open LLM Score (%)":"47.26 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0504,
        "Decode Throughput (tokens\/s)":33.5,
        "Allocated Memory (MB)":27047,
        "Energy (tokens\/kWh)":332225,
        "E2E Latency (s)":7.66,
        "E2E Throughput (tokens\/s)":33.4,
        "Reserved Memory (MB)":27078,
        "Used Memory (MB)":28537
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.0,
        "Open LLM Score (%)":"47.26 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0522,
        "Decode Throughput (tokens\/s)":32.5,
        "Allocated Memory (MB)":27047,
        "Energy (tokens\/kWh)":300300,
        "E2E Latency (s)":7.9,
        "E2E Throughput (tokens\/s)":32.4,
        "Reserved Memory (MB)":27078,
        "Used Memory (MB)":28537
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.0,
        "Open LLM Score (%)":"47.26*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0661,
        "Decode Throughput (tokens\/s)":31.3,
        "Allocated Memory (MB)":8379,
        "Energy (tokens\/kWh)":377358,
        "E2E Latency (s)":8.22,
        "E2E Throughput (tokens\/s)":31.1,
        "Reserved Memory (MB)":8472,
        "Used Memory (MB)":9934
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.0,
        "Open LLM Score (%)":"47.26*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0679,
        "Decode Throughput (tokens\/s)":31.5,
        "Allocated Memory (MB)":9292,
        "Energy (tokens\/kWh)":431034,
        "E2E Latency (s)":8.16,
        "E2E Throughput (tokens\/s)":31.4,
        "Reserved Memory (MB)":9384,
        "Used Memory (MB)":10846
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.0,
        "Open LLM Score (%)":"47.26*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.105,
        "Decode Throughput (tokens\/s)":32.9,
        "Allocated Memory (MB)":8225,
        "Energy (tokens\/kWh)":396825,
        "E2E Latency (s)":7.85,
        "E2E Throughput (tokens\/s)":32.6,
        "Reserved Memory (MB)":8355,
        "Used Memory (MB)":9814
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.0,
        "Open LLM Score (%)":"47.26*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.12,
        "Decode Throughput (tokens\/s)":8.25,
        "Allocated Memory (MB)":14472,
        "Energy (tokens\/kWh)":117096,
        "E2E Latency (s)":31.0,
        "E2E Throughput (tokens\/s)":8.26,
        "Reserved Memory (MB)":14508,
        "Used Memory (MB)":15976
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.0,
        "Open LLM Score (%)":"47.26*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.126,
        "Decode Throughput (tokens\/s)":8.02,
        "Allocated Memory (MB)":14472,
        "Energy (tokens\/kWh)":117508,
        "E2E Latency (s)":31.9,
        "E2E Throughput (tokens\/s)":8.03,
        "Reserved Memory (MB)":14508,
        "Used Memory (MB)":15976
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.0,
        "Open LLM Score (%)":"47.26*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.132,
        "Decode Throughput (tokens\/s)":29.1,
        "Allocated Memory (MB)":8225,
        "Energy (tokens\/kWh)":363636,
        "E2E Latency (s)":8.89,
        "E2E Throughput (tokens\/s)":28.8,
        "Reserved Memory (MB)":8352,
        "Used Memory (MB)":9812
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.0,
        "Open LLM Score (%)":"47.26*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.307,
        "Decode Throughput (tokens\/s)":23.2,
        "Allocated Memory (MB)":8237,
        "Energy (tokens\/kWh)":286532,
        "E2E Latency (s)":11.3,
        "E2E Throughput (tokens\/s)":22.7,
        "Reserved Memory (MB)":8480,
        "Used Memory (MB)":9940
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.0,
        "Open LLM Score (%)":"47.26 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.451,
        "Decode Throughput (tokens\/s)":24.5,
        "Allocated Memory (MB)":53834,
        "Energy (tokens\/kWh)":213675,
        "E2E Latency (s)":10.9,
        "E2E Throughput (tokens\/s)":23.5,
        "Reserved Memory (MB)":54045,
        "Used Memory (MB)":55496
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.0,
        "Open LLM Score (%)":"47.26*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.498,
        "Decode Throughput (tokens\/s)":18.9,
        "Allocated Memory (MB)":8713,
        "Energy (tokens\/kWh)":229885,
        "E2E Latency (s)":14.0,
        "E2E Throughput (tokens\/s)":18.3,
        "Reserved Memory (MB)":9114,
        "Used Memory (MB)":10573
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.0,
        "Open LLM Score (%)":"47.26*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.507,
        "Decode Throughput (tokens\/s)":18.5,
        "Allocated Memory (MB)":8713,
        "Energy (tokens\/kWh)":220264,
        "E2E Latency (s)":14.3,
        "E2E Throughput (tokens\/s)":17.9,
        "Reserved Memory (MB)":9114,
        "Used Memory (MB)":10573
    },
    {
        "Model":"itsliupeng\/openllama-7b-base",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"47.09 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0301,
        "Decode Throughput (tokens\/s)":42.4,
        "Allocated Memory (MB)":14056,
        "Energy (tokens\/kWh)":490196,
        "E2E Latency (s)":6.05,
        "E2E Throughput (tokens\/s)":42.3,
        "Reserved Memory (MB)":14092,
        "Used Memory (MB)":15552
    },
    {
        "Model":"itsliupeng\/openllama-7b-base",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"47.09 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0323,
        "Decode Throughput (tokens\/s)":41.4,
        "Allocated Memory (MB)":14056,
        "Energy (tokens\/kWh)":454545,
        "E2E Latency (s)":6.19,
        "E2E Throughput (tokens\/s)":41.4,
        "Reserved Memory (MB)":14092,
        "Used Memory (MB)":15552
    },
    {
        "Model":"itsliupeng\/openllama-7b-base",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"47.09*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0407,
        "Decode Throughput (tokens\/s)":39.7,
        "Allocated Memory (MB)":4616,
        "Energy (tokens\/kWh)":526315,
        "E2E Latency (s)":6.47,
        "E2E Throughput (tokens\/s)":39.6,
        "Reserved Memory (MB)":4647,
        "Used Memory (MB)":6108
    },
    {
        "Model":"itsliupeng\/openllama-7b-base",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"47.09*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0408,
        "Decode Throughput (tokens\/s)":38.0,
        "Allocated Memory (MB)":5342,
        "Energy (tokens\/kWh)":574712,
        "E2E Latency (s)":6.75,
        "E2E Throughput (tokens\/s)":37.9,
        "Reserved Memory (MB)":5375,
        "Used Memory (MB)":6836
    },
    {
        "Model":"itsliupeng\/openllama-7b-base",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"47.09*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0617,
        "Decode Throughput (tokens\/s)":41.2,
        "Allocated Memory (MB)":4519,
        "Energy (tokens\/kWh)":540540,
        "E2E Latency (s)":6.25,
        "E2E Throughput (tokens\/s)":41.0,
        "Reserved Memory (MB)":4548,
        "Used Memory (MB)":6008
    },
    {
        "Model":"itsliupeng\/openllama-7b-base",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"47.09*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0735,
        "Decode Throughput (tokens\/s)":35.6,
        "Allocated Memory (MB)":4519,
        "Energy (tokens\/kWh)":476190,
        "E2E Latency (s)":7.24,
        "E2E Throughput (tokens\/s)":35.4,
        "Reserved Memory (MB)":4548,
        "Used Memory (MB)":6008
    },
    {
        "Model":"itsliupeng\/openllama-7b-base",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"47.09*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0936,
        "Decode Throughput (tokens\/s)":10.5,
        "Allocated Memory (MB)":7686,
        "Energy (tokens\/kWh)":157232,
        "E2E Latency (s)":24.3,
        "E2E Throughput (tokens\/s)":10.5,
        "Reserved Memory (MB)":7728,
        "Used Memory (MB)":9195
    },
    {
        "Model":"itsliupeng\/openllama-7b-base",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"47.09*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0966,
        "Decode Throughput (tokens\/s)":10.5,
        "Allocated Memory (MB)":7686,
        "Energy (tokens\/kWh)":154320,
        "E2E Latency (s)":24.4,
        "E2E Throughput (tokens\/s)":10.5,
        "Reserved Memory (MB)":7728,
        "Used Memory (MB)":9195
    },
    {
        "Model":"itsliupeng\/openllama-7b-base",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"47.09*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.168,
        "Decode Throughput (tokens\/s)":28.7,
        "Allocated Memory (MB)":4527,
        "Energy (tokens\/kWh)":381679,
        "E2E Latency (s)":9.04,
        "E2E Throughput (tokens\/s)":28.3,
        "Reserved Memory (MB)":4573,
        "Used Memory (MB)":6033
    },
    {
        "Model":"itsliupeng\/openllama-7b-base",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"47.09 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.238,
        "Decode Throughput (tokens\/s)":41.8,
        "Allocated Memory (MB)":28100,
        "Energy (tokens\/kWh)":364963,
        "E2E Latency (s)":6.34,
        "E2E Throughput (tokens\/s)":40.4,
        "Reserved Memory (MB)":28458,
        "Used Memory (MB)":29909
    },
    {
        "Model":"itsliupeng\/openllama-7b-base",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"47.09*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.268,
        "Decode Throughput (tokens\/s)":23.0,
        "Allocated Memory (MB)":4796,
        "Energy (tokens\/kWh)":294117,
        "E2E Latency (s)":11.4,
        "E2E Throughput (tokens\/s)":22.5,
        "Reserved Memory (MB)":4949,
        "Used Memory (MB)":6408
    },
    {
        "Model":"itsliupeng\/openllama-7b-base",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"47.09*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.273,
        "Decode Throughput (tokens\/s)":23.4,
        "Allocated Memory (MB)":4795,
        "Energy (tokens\/kWh)":291545,
        "E2E Latency (s)":11.2,
        "E2E Throughput (tokens\/s)":22.9,
        "Reserved Memory (MB)":4995,
        "Used Memory (MB)":6454
    },
    {
        "Model":"stabilityai\/stablelm-3b-4e1t",
        "Arch":"\ud83d\udd34 StableLM-Epoch",
        "Params (B)":2.8,
        "Open LLM Score (%)":"46.58 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0228,
        "Decode Throughput (tokens\/s)":42.4,
        "Allocated Memory (MB)":5972,
        "Energy (tokens\/kWh)":564971,
        "E2E Latency (s)":6.03,
        "E2E Throughput (tokens\/s)":42.5,
        "Reserved Memory (MB)":6205,
        "Used Memory (MB)":7665
    },
    {
        "Model":"stabilityai\/stablelm-3b-4e1t",
        "Arch":"\ud83d\udd34 StableLM-Epoch",
        "Params (B)":2.8,
        "Open LLM Score (%)":"46.58 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0234,
        "Decode Throughput (tokens\/s)":42.6,
        "Allocated Memory (MB)":5972,
        "Energy (tokens\/kWh)":568181,
        "E2E Latency (s)":6.01,
        "E2E Throughput (tokens\/s)":42.6,
        "Reserved Memory (MB)":6205,
        "Used Memory (MB)":7665
    },
    {
        "Model":"stabilityai\/stablelm-3b-4e1t",
        "Arch":"\ud83d\udd34 StableLM-Epoch",
        "Params (B)":2.8,
        "Open LLM Score (%)":"46.58*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0276,
        "Decode Throughput (tokens\/s)":40.5,
        "Allocated Memory (MB)":2230,
        "Energy (tokens\/kWh)":581395,
        "E2E Latency (s)":6.32,
        "E2E Throughput (tokens\/s)":40.5,
        "Reserved Memory (MB)":2334,
        "Used Memory (MB)":3795
    },
    {
        "Model":"stabilityai\/stablelm-3b-4e1t",
        "Arch":"\ud83d\udd34 StableLM-Epoch",
        "Params (B)":2.8,
        "Open LLM Score (%)":"46.58*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0371,
        "Decode Throughput (tokens\/s)":38.2,
        "Allocated Memory (MB)":2192,
        "Energy (tokens\/kWh)":578034,
        "E2E Latency (s)":6.71,
        "E2E Throughput (tokens\/s)":38.2,
        "Reserved Memory (MB)":2283,
        "Used Memory (MB)":3743
    },
    {
        "Model":"stabilityai\/stablelm-3b-4e1t",
        "Arch":"\ud83d\udd34 StableLM-Epoch",
        "Params (B)":2.8,
        "Open LLM Score (%)":"46.58*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0762,
        "Decode Throughput (tokens\/s)":29.9,
        "Allocated Memory (MB)":2195,
        "Energy (tokens\/kWh)":442477,
        "E2E Latency (s)":8.62,
        "E2E Throughput (tokens\/s)":29.7,
        "Reserved Memory (MB)":2300,
        "Used Memory (MB)":3760
    },
    {
        "Model":"stabilityai\/stablelm-3b-4e1t",
        "Arch":"\ud83d\udd34 StableLM-Epoch",
        "Params (B)":2.8,
        "Open LLM Score (%)":"46.58 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0944,
        "Decode Throughput (tokens\/s)":45.8,
        "Allocated Memory (MB)":12068,
        "Energy (tokens\/kWh)":546448,
        "E2E Latency (s)":5.66,
        "E2E Throughput (tokens\/s)":45.2,
        "Reserved Memory (MB)":12117,
        "Used Memory (MB)":13568
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b-v2",
        "Arch":"\ud83d\udd34 StableLM-Alpha",
        "Params (B)":6.89,
        "Open LLM Score (%)":"46.18 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0286,
        "Decode Throughput (tokens\/s)":43.5,
        "Allocated Memory (MB)":14353,
        "Energy (tokens\/kWh)":485436,
        "E2E Latency (s)":5.89,
        "E2E Throughput (tokens\/s)":43.5,
        "Reserved Memory (MB)":14392,
        "Used Memory (MB)":15852
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b-v2",
        "Arch":"\ud83d\udd34 StableLM-Alpha",
        "Params (B)":6.89,
        "Open LLM Score (%)":"46.18 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0303,
        "Decode Throughput (tokens\/s)":43.1,
        "Allocated Memory (MB)":14353,
        "Energy (tokens\/kWh)":450450,
        "E2E Latency (s)":5.95,
        "E2E Throughput (tokens\/s)":43.0,
        "Reserved Memory (MB)":14392,
        "Used Memory (MB)":15852
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b-v2",
        "Arch":"\ud83d\udd34 StableLM-Alpha",
        "Params (B)":6.89,
        "Open LLM Score (%)":"46.18*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0611,
        "Decode Throughput (tokens\/s)":41.7,
        "Allocated Memory (MB)":4816,
        "Energy (tokens\/kWh)":552486,
        "E2E Latency (s)":6.17,
        "E2E Throughput (tokens\/s)":41.5,
        "Reserved Memory (MB)":4894,
        "Used Memory (MB)":6354
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b-v2",
        "Arch":"\ud83d\udd34 StableLM-Alpha",
        "Params (B)":6.89,
        "Open LLM Score (%)":"46.18*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0643,
        "Decode Throughput (tokens\/s)":15.4,
        "Allocated Memory (MB)":7911,
        "Energy (tokens\/kWh)":224719,
        "E2E Latency (s)":16.7,
        "E2E Throughput (tokens\/s)":15.3,
        "Reserved Memory (MB)":7944,
        "Used Memory (MB)":9411
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b-v2",
        "Arch":"\ud83d\udd34 StableLM-Alpha",
        "Params (B)":6.89,
        "Open LLM Score (%)":"46.18*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0707,
        "Decode Throughput (tokens\/s)":38.9,
        "Allocated Memory (MB)":4815,
        "Energy (tokens\/kWh)":518134,
        "E2E Latency (s)":6.63,
        "E2E Throughput (tokens\/s)":38.6,
        "Reserved Memory (MB)":4894,
        "Used Memory (MB)":6354
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b-v2",
        "Arch":"\ud83d\udd34 StableLM-Alpha",
        "Params (B)":6.89,
        "Open LLM Score (%)":"46.18 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.239,
        "Decode Throughput (tokens\/s)":43.4,
        "Allocated Memory (MB)":28695,
        "Energy (tokens\/kWh)":378787,
        "E2E Latency (s)":6.11,
        "E2E Throughput (tokens\/s)":41.9,
        "Reserved Memory (MB)":29085,
        "Used Memory (MB)":30536
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b-v2",
        "Arch":"\ud83d\udd34 StableLM-Alpha",
        "Params (B)":6.89,
        "Open LLM Score (%)":"46.18*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.266,
        "Decode Throughput (tokens\/s)":27.4,
        "Allocated Memory (MB)":5398,
        "Energy (tokens\/kWh)":344827,
        "E2E Latency (s)":9.56,
        "E2E Throughput (tokens\/s)":26.8,
        "Reserved Memory (MB)":5695,
        "Used Memory (MB)":7155
    },
    {
        "Model":"huggingface\/llama-7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.74,
        "Open LLM Score (%)":"45.65 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0325,
        "Decode Throughput (tokens\/s)":42.2,
        "Allocated Memory (MB)":14056,
        "Energy (tokens\/kWh)":456621,
        "E2E Latency (s)":6.07,
        "E2E Throughput (tokens\/s)":42.2,
        "Reserved Memory (MB)":14092,
        "Used Memory (MB)":15552
    },
    {
        "Model":"huggingface\/llama-7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.74,
        "Open LLM Score (%)":"45.65*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0402,
        "Decode Throughput (tokens\/s)":38.1,
        "Allocated Memory (MB)":4616,
        "Energy (tokens\/kWh)":523560,
        "E2E Latency (s)":6.73,
        "E2E Throughput (tokens\/s)":38.0,
        "Reserved Memory (MB)":4647,
        "Used Memory (MB)":6108
    },
    {
        "Model":"huggingface\/llama-7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.74,
        "Open LLM Score (%)":"45.65*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0409,
        "Decode Throughput (tokens\/s)":39.5,
        "Allocated Memory (MB)":5342,
        "Energy (tokens\/kWh)":564971,
        "E2E Latency (s)":6.5,
        "E2E Throughput (tokens\/s)":39.4,
        "Reserved Memory (MB)":5375,
        "Used Memory (MB)":6836
    },
    {
        "Model":"huggingface\/llama-7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.74,
        "Open LLM Score (%)":"45.65*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0617,
        "Decode Throughput (tokens\/s)":40.2,
        "Allocated Memory (MB)":4519,
        "Energy (tokens\/kWh)":537634,
        "E2E Latency (s)":6.41,
        "E2E Throughput (tokens\/s)":39.9,
        "Reserved Memory (MB)":4548,
        "Used Memory (MB)":6008
    },
    {
        "Model":"huggingface\/llama-7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.74,
        "Open LLM Score (%)":"45.65*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0728,
        "Decode Throughput (tokens\/s)":36.3,
        "Allocated Memory (MB)":4519,
        "Energy (tokens\/kWh)":485436,
        "E2E Latency (s)":7.09,
        "E2E Throughput (tokens\/s)":36.1,
        "Reserved Memory (MB)":4548,
        "Used Memory (MB)":6008
    },
    {
        "Model":"huggingface\/llama-7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.74,
        "Open LLM Score (%)":"45.65*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.095,
        "Decode Throughput (tokens\/s)":10.5,
        "Allocated Memory (MB)":7686,
        "Energy (tokens\/kWh)":156739,
        "E2E Latency (s)":24.5,
        "E2E Throughput (tokens\/s)":10.4,
        "Reserved Memory (MB)":7728,
        "Used Memory (MB)":9195
    },
    {
        "Model":"huggingface\/llama-7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.74,
        "Open LLM Score (%)":"45.65*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.166,
        "Decode Throughput (tokens\/s)":28.6,
        "Allocated Memory (MB)":4527,
        "Energy (tokens\/kWh)":380228,
        "E2E Latency (s)":9.1,
        "E2E Throughput (tokens\/s)":28.1,
        "Reserved Memory (MB)":4573,
        "Used Memory (MB)":6033
    },
    {
        "Model":"huggingface\/llama-7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.74,
        "Open LLM Score (%)":"45.65 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.238,
        "Decode Throughput (tokens\/s)":41.7,
        "Allocated Memory (MB)":28100,
        "Energy (tokens\/kWh)":364963,
        "E2E Latency (s)":6.36,
        "E2E Throughput (tokens\/s)":40.3,
        "Reserved Memory (MB)":28458,
        "Used Memory (MB)":29909
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.61,
        "Open LLM Score (%)":"45.62 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0302,
        "Decode Throughput (tokens\/s)":44.0,
        "Allocated Memory (MB)":14056,
        "Energy (tokens\/kWh)":497512,
        "E2E Latency (s)":5.82,
        "E2E Throughput (tokens\/s)":44.0,
        "Reserved Memory (MB)":14092,
        "Used Memory (MB)":15552
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.61,
        "Open LLM Score (%)":"45.62 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0318,
        "Decode Throughput (tokens\/s)":40.5,
        "Allocated Memory (MB)":14056,
        "Energy (tokens\/kWh)":454545,
        "E2E Latency (s)":6.33,
        "E2E Throughput (tokens\/s)":40.4,
        "Reserved Memory (MB)":14092,
        "Used Memory (MB)":15552
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.61,
        "Open LLM Score (%)":"45.62 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.032,
        "Decode Throughput (tokens\/s)":42.4,
        "Allocated Memory (MB)":14056,
        "Energy (tokens\/kWh)":442477,
        "E2E Latency (s)":6.04,
        "E2E Throughput (tokens\/s)":42.4,
        "Reserved Memory (MB)":14092,
        "Used Memory (MB)":15552
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.61,
        "Open LLM Score (%)":"45.62*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0399,
        "Decode Throughput (tokens\/s)":39.2,
        "Allocated Memory (MB)":4616,
        "Energy (tokens\/kWh)":507614,
        "E2E Latency (s)":6.54,
        "E2E Throughput (tokens\/s)":39.1,
        "Reserved Memory (MB)":4647,
        "Used Memory (MB)":6108
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.61,
        "Open LLM Score (%)":"45.62*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0408,
        "Decode Throughput (tokens\/s)":39.7,
        "Allocated Memory (MB)":5342,
        "Energy (tokens\/kWh)":564971,
        "E2E Latency (s)":6.46,
        "E2E Throughput (tokens\/s)":39.6,
        "Reserved Memory (MB)":5375,
        "Used Memory (MB)":6836
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.61,
        "Open LLM Score (%)":"45.62*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0611,
        "Decode Throughput (tokens\/s)":41.5,
        "Allocated Memory (MB)":4519,
        "Energy (tokens\/kWh)":564971,
        "E2E Latency (s)":6.2,
        "E2E Throughput (tokens\/s)":41.3,
        "Reserved Memory (MB)":4548,
        "Used Memory (MB)":6008
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.61,
        "Open LLM Score (%)":"45.62*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0708,
        "Decode Throughput (tokens\/s)":37.3,
        "Allocated Memory (MB)":4519,
        "Energy (tokens\/kWh)":510204,
        "E2E Latency (s)":6.91,
        "E2E Throughput (tokens\/s)":37.0,
        "Reserved Memory (MB)":4548,
        "Used Memory (MB)":6008
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.61,
        "Open LLM Score (%)":"45.62*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0971,
        "Decode Throughput (tokens\/s)":10.4,
        "Allocated Memory (MB)":7686,
        "Energy (tokens\/kWh)":151285,
        "E2E Latency (s)":24.7,
        "E2E Throughput (tokens\/s)":10.4,
        "Reserved Memory (MB)":7728,
        "Used Memory (MB)":9195
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.61,
        "Open LLM Score (%)":"45.62*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0989,
        "Decode Throughput (tokens\/s)":10.2,
        "Allocated Memory (MB)":7686,
        "Energy (tokens\/kWh)":153609,
        "E2E Latency (s)":25.1,
        "E2E Throughput (tokens\/s)":10.2,
        "Reserved Memory (MB)":7728,
        "Used Memory (MB)":9195
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.61,
        "Open LLM Score (%)":"45.62*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.166,
        "Decode Throughput (tokens\/s)":28.8,
        "Allocated Memory (MB)":4527,
        "Energy (tokens\/kWh)":389105,
        "E2E Latency (s)":9.02,
        "E2E Throughput (tokens\/s)":28.4,
        "Reserved Memory (MB)":4573,
        "Used Memory (MB)":6033
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.61,
        "Open LLM Score (%)":"45.62 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.237,
        "Decode Throughput (tokens\/s)":41.8,
        "Allocated Memory (MB)":28100,
        "Energy (tokens\/kWh)":361010,
        "E2E Latency (s)":6.34,
        "E2E Throughput (tokens\/s)":40.4,
        "Reserved Memory (MB)":28458,
        "Used Memory (MB)":29909
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.61,
        "Open LLM Score (%)":"45.62*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.268,
        "Decode Throughput (tokens\/s)":22.8,
        "Allocated Memory (MB)":4796,
        "Energy (tokens\/kWh)":289017,
        "E2E Latency (s)":11.5,
        "E2E Throughput (tokens\/s)":22.3,
        "Reserved Memory (MB)":4949,
        "Used Memory (MB)":6408
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.61,
        "Open LLM Score (%)":"45.62*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.269,
        "Decode Throughput (tokens\/s)":23.4,
        "Allocated Memory (MB)":4795,
        "Energy (tokens\/kWh)":301204,
        "E2E Latency (s)":11.2,
        "E2E Throughput (tokens\/s)":22.9,
        "Reserved Memory (MB)":4995,
        "Used Memory (MB)":6454
    },
    {
        "Model":"KnutJaegersberg\/Qwen-1_8B-Llamafied",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.84,
        "Open LLM Score (%)":"44.75 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0196,
        "Decode Throughput (tokens\/s)":51.9,
        "Allocated Memory (MB)":4106,
        "Energy (tokens\/kWh)":729927,
        "E2E Latency (s)":4.93,
        "E2E Throughput (tokens\/s)":51.9,
        "Reserved Memory (MB)":4232,
        "Used Memory (MB)":5691
    },
    {
        "Model":"KnutJaegersberg\/Qwen-1_8B-Llamafied",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.84,
        "Open LLM Score (%)":"44.75 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0196,
        "Decode Throughput (tokens\/s)":51.6,
        "Allocated Memory (MB)":4106,
        "Energy (tokens\/kWh)":719424,
        "E2E Latency (s)":4.96,
        "E2E Throughput (tokens\/s)":51.6,
        "Reserved Memory (MB)":4232,
        "Used Memory (MB)":5691
    },
    {
        "Model":"KnutJaegersberg\/Qwen-1_8B-Llamafied",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.84,
        "Open LLM Score (%)":"44.75*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0205,
        "Decode Throughput (tokens\/s)":52.7,
        "Allocated Memory (MB)":2666,
        "Energy (tokens\/kWh)":787401,
        "E2E Latency (s)":4.86,
        "E2E Throughput (tokens\/s)":52.7,
        "Reserved Memory (MB)":2730,
        "Used Memory (MB)":4192
    },
    {
        "Model":"KnutJaegersberg\/Qwen-1_8B-Llamafied",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.84,
        "Open LLM Score (%)":"44.75*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0217,
        "Decode Throughput (tokens\/s)":50.7,
        "Allocated Memory (MB)":2279,
        "Energy (tokens\/kWh)":763358,
        "E2E Latency (s)":5.05,
        "E2E Throughput (tokens\/s)":50.7,
        "Reserved Memory (MB)":2365,
        "Used Memory (MB)":3825
    },
    {
        "Model":"KnutJaegersberg\/Qwen-1_8B-Llamafied",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.84,
        "Open LLM Score (%)":"44.75*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.023,
        "Decode Throughput (tokens\/s)":45.8,
        "Allocated Memory (MB)":2278,
        "Energy (tokens\/kWh)":684931,
        "E2E Latency (s)":5.59,
        "E2E Throughput (tokens\/s)":45.8,
        "Reserved Memory (MB)":2365,
        "Used Memory (MB)":3825
    },
    {
        "Model":"KnutJaegersberg\/Qwen-1_8B-Llamafied",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.84,
        "Open LLM Score (%)":"44.75 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0602,
        "Decode Throughput (tokens\/s)":54.8,
        "Allocated Memory (MB)":8039,
        "Energy (tokens\/kWh)":704225,
        "E2E Latency (s)":4.71,
        "E2E Throughput (tokens\/s)":54.4,
        "Reserved Memory (MB)":8080,
        "Used Memory (MB)":9531
    },
    {
        "Model":"mosaicml\/mpt-7b",
        "Arch":"\ud83e\uddf1 MPT",
        "Params (B)":7.0,
        "Open LLM Score (%)":"44.28*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0557,
        "Decode Throughput (tokens\/s)":62.2,
        "Allocated Memory (MB)":4308,
        "Energy (tokens\/kWh)":763358,
        "E2E Latency (s)":4.16,
        "E2E Throughput (tokens\/s)":61.5,
        "Reserved Memory (MB)":4362,
        "Used Memory (MB)":5821
    },
    {
        "Model":"mosaicml\/mpt-7b",
        "Arch":"\ud83e\uddf1 MPT",
        "Params (B)":7.0,
        "Open LLM Score (%)":"44.28*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0612,
        "Decode Throughput (tokens\/s)":17.1,
        "Allocated Memory (MB)":7406,
        "Energy (tokens\/kWh)":241545,
        "E2E Latency (s)":15.0,
        "E2E Throughput (tokens\/s)":17.1,
        "Reserved Memory (MB)":7446,
        "Used Memory (MB)":8914
    },
    {
        "Model":"mosaicml\/mpt-7b",
        "Arch":"\ud83e\uddf1 MPT",
        "Params (B)":7.0,
        "Open LLM Score (%)":"44.28*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0649,
        "Decode Throughput (tokens\/s)":56.0,
        "Allocated Memory (MB)":4308,
        "Energy (tokens\/kWh)":699300,
        "E2E Latency (s)":4.61,
        "E2E Throughput (tokens\/s)":55.5,
        "Reserved Memory (MB)":4362,
        "Used Memory (MB)":5821
    },
    {
        "Model":"mosaicml\/mpt-7b",
        "Arch":"\ud83e\uddf1 MPT",
        "Params (B)":7.0,
        "Open LLM Score (%)":"44.28*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.25,
        "Decode Throughput (tokens\/s)":34.0,
        "Allocated Memory (MB)":4721,
        "Energy (tokens\/kWh)":403225,
        "E2E Latency (s)":7.74,
        "E2E Throughput (tokens\/s)":33.1,
        "Reserved Memory (MB)":5012,
        "Used Memory (MB)":6471
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"44.26 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0303,
        "Decode Throughput (tokens\/s)":42.2,
        "Allocated Memory (MB)":14056,
        "Energy (tokens\/kWh)":478468,
        "E2E Latency (s)":6.07,
        "E2E Throughput (tokens\/s)":42.2,
        "Reserved Memory (MB)":14092,
        "Used Memory (MB)":15552
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"44.26 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0321,
        "Decode Throughput (tokens\/s)":40.0,
        "Allocated Memory (MB)":14056,
        "Energy (tokens\/kWh)":448430,
        "E2E Latency (s)":6.4,
        "E2E Throughput (tokens\/s)":40.0,
        "Reserved Memory (MB)":14092,
        "Used Memory (MB)":15552
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"44.26 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0328,
        "Decode Throughput (tokens\/s)":42.5,
        "Allocated Memory (MB)":14056,
        "Energy (tokens\/kWh)":450450,
        "E2E Latency (s)":6.03,
        "E2E Throughput (tokens\/s)":42.5,
        "Reserved Memory (MB)":14092,
        "Used Memory (MB)":15552
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"44.26*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.04,
        "Decode Throughput (tokens\/s)":37.4,
        "Allocated Memory (MB)":4616,
        "Energy (tokens\/kWh)":512820,
        "E2E Latency (s)":6.85,
        "E2E Throughput (tokens\/s)":37.4,
        "Reserved Memory (MB)":4647,
        "Used Memory (MB)":6108
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"44.26*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0409,
        "Decode Throughput (tokens\/s)":39.4,
        "Allocated Memory (MB)":5342,
        "Energy (tokens\/kWh)":558659,
        "E2E Latency (s)":6.52,
        "E2E Throughput (tokens\/s)":39.3,
        "Reserved Memory (MB)":5375,
        "Used Memory (MB)":6836
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"44.26*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0619,
        "Decode Throughput (tokens\/s)":39.9,
        "Allocated Memory (MB)":4519,
        "Energy (tokens\/kWh)":558659,
        "E2E Latency (s)":6.45,
        "E2E Throughput (tokens\/s)":39.7,
        "Reserved Memory (MB)":4548,
        "Used Memory (MB)":6008
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"44.26*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0714,
        "Decode Throughput (tokens\/s)":37.1,
        "Allocated Memory (MB)":4519,
        "Energy (tokens\/kWh)":492610,
        "E2E Latency (s)":6.94,
        "E2E Throughput (tokens\/s)":36.9,
        "Reserved Memory (MB)":4548,
        "Used Memory (MB)":6008
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"44.26*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0965,
        "Decode Throughput (tokens\/s)":10.4,
        "Allocated Memory (MB)":7686,
        "Energy (tokens\/kWh)":152439,
        "E2E Latency (s)":24.6,
        "E2E Throughput (tokens\/s)":10.4,
        "Reserved Memory (MB)":7728,
        "Used Memory (MB)":9195
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"44.26*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0994,
        "Decode Throughput (tokens\/s)":10.2,
        "Allocated Memory (MB)":7686,
        "Energy (tokens\/kWh)":155038,
        "E2E Latency (s)":25.2,
        "E2E Throughput (tokens\/s)":10.2,
        "Reserved Memory (MB)":7728,
        "Used Memory (MB)":9195
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"44.26*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.167,
        "Decode Throughput (tokens\/s)":28.7,
        "Allocated Memory (MB)":4527,
        "Energy (tokens\/kWh)":387596,
        "E2E Latency (s)":9.04,
        "E2E Throughput (tokens\/s)":28.3,
        "Reserved Memory (MB)":4573,
        "Used Memory (MB)":6033
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"44.26 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.237,
        "Decode Throughput (tokens\/s)":41.7,
        "Allocated Memory (MB)":28100,
        "Energy (tokens\/kWh)":367647,
        "E2E Latency (s)":6.35,
        "E2E Throughput (tokens\/s)":40.3,
        "Reserved Memory (MB)":28458,
        "Used Memory (MB)":29909
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"44.26*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.272,
        "Decode Throughput (tokens\/s)":23.6,
        "Allocated Memory (MB)":4795,
        "Energy (tokens\/kWh)":301204,
        "E2E Latency (s)":11.1,
        "E2E Throughput (tokens\/s)":23.1,
        "Reserved Memory (MB)":4995,
        "Used Memory (MB)":6454
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"44.26*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.273,
        "Decode Throughput (tokens\/s)":22.8,
        "Allocated Memory (MB)":4796,
        "Energy (tokens\/kWh)":290697,
        "E2E Latency (s)":11.5,
        "E2E Throughput (tokens\/s)":22.3,
        "Reserved Memory (MB)":4949,
        "Used Memory (MB)":6408
    },
    {
        "Model":"tiiuae\/falcon-7b",
        "Arch":"\ud83e\udd85 Falcon",
        "Params (B)":7.0,
        "Open LLM Score (%)":"44.17 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0345,
        "Decode Throughput (tokens\/s)":40.5,
        "Allocated Memory (MB)":13945,
        "Energy (tokens\/kWh)":471698,
        "E2E Latency (s)":6.32,
        "E2E Throughput (tokens\/s)":40.5,
        "Reserved Memory (MB)":14061,
        "Used Memory (MB)":15520
    },
    {
        "Model":"tiiuae\/falcon-7b",
        "Arch":"\ud83e\udd85 Falcon",
        "Params (B)":7.0,
        "Open LLM Score (%)":"44.17*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0645,
        "Decode Throughput (tokens\/s)":15.5,
        "Allocated Memory (MB)":7296,
        "Energy (tokens\/kWh)":229885,
        "E2E Latency (s)":16.6,
        "E2E Throughput (tokens\/s)":15.4,
        "Reserved Memory (MB)":7476,
        "Used Memory (MB)":8944
    },
    {
        "Model":"tiiuae\/falcon-7b",
        "Arch":"\ud83e\udd85 Falcon",
        "Params (B)":7.0,
        "Open LLM Score (%)":"44.17 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.247,
        "Decode Throughput (tokens\/s)":31.9,
        "Allocated Memory (MB)":27839,
        "Energy (tokens\/kWh)":314465,
        "E2E Latency (s)":8.24,
        "E2E Throughput (tokens\/s)":31.1,
        "Reserved Memory (MB)":28028,
        "Used Memory (MB)":29479
    },
    {
        "Model":"tiiuae\/falcon-7b",
        "Arch":"\ud83e\udd85 Falcon",
        "Params (B)":7.0,
        "Open LLM Score (%)":"44.17*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.272,
        "Decode Throughput (tokens\/s)":26.5,
        "Allocated Memory (MB)":4927,
        "Energy (tokens\/kWh)":331125,
        "E2E Latency (s)":9.9,
        "E2E Throughput (tokens\/s)":25.9,
        "Reserved Memory (MB)":5106,
        "Used Memory (MB)":6566
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-40b",
        "Arch":"GPT-2",
        "Params (B)":39.93,
        "Open LLM Score (%)":"43.42*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0988,
        "Decode Throughput (tokens\/s)":16.5,
        "Allocated Memory (MB)":80221,
        "Energy (tokens\/kWh)":173913,
        "E2E Latency (s)":15.6,
        "E2E Throughput (tokens\/s)":16.4,
        "Reserved Memory (MB)":80450,
        "Used Memory (MB)":81910
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-40b",
        "Arch":"GPT-2",
        "Params (B)":39.93,
        "Open LLM Score (%)":"43.42*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.101,
        "Decode Throughput (tokens\/s)":16.6,
        "Allocated Memory (MB)":80221,
        "Energy (tokens\/kWh)":173010,
        "E2E Latency (s)":15.5,
        "E2E Throughput (tokens\/s)":16.5,
        "Reserved Memory (MB)":80450,
        "Used Memory (MB)":81910
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-40b",
        "Arch":"GPT-2",
        "Params (B)":39.93,
        "Open LLM Score (%)":"43.42*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.165,
        "Decode Throughput (tokens\/s)":23.4,
        "Allocated Memory (MB)":23570,
        "Energy (tokens\/kWh)":221238,
        "E2E Latency (s)":11.1,
        "E2E Throughput (tokens\/s)":23.1,
        "Reserved Memory (MB)":23808,
        "Used Memory (MB)":25270
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"43.35 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0499,
        "Decode Throughput (tokens\/s)":33.8,
        "Allocated Memory (MB)":27341,
        "Energy (tokens\/kWh)":333333,
        "E2E Latency (s)":7.59,
        "E2E Throughput (tokens\/s)":33.7,
        "Reserved Memory (MB)":27369,
        "Used Memory (MB)":28829
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"43.35 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0525,
        "Decode Throughput (tokens\/s)":31.9,
        "Allocated Memory (MB)":27341,
        "Energy (tokens\/kWh)":298507,
        "E2E Latency (s)":8.05,
        "E2E Throughput (tokens\/s)":31.8,
        "Reserved Memory (MB)":27369,
        "Used Memory (MB)":28829
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"43.35*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0667,
        "Decode Throughput (tokens\/s)":32.5,
        "Allocated Memory (MB)":8672,
        "Energy (tokens\/kWh)":381679,
        "E2E Latency (s)":7.92,
        "E2E Throughput (tokens\/s)":32.3,
        "Reserved Memory (MB)":8803,
        "Used Memory (MB)":10265
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"43.35*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0697,
        "Decode Throughput (tokens\/s)":31.9,
        "Allocated Memory (MB)":9586,
        "Energy (tokens\/kWh)":431034,
        "E2E Latency (s)":8.07,
        "E2E Throughput (tokens\/s)":31.7,
        "Reserved Memory (MB)":9718,
        "Used Memory (MB)":11179
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"43.35*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.105,
        "Decode Throughput (tokens\/s)":33.2,
        "Allocated Memory (MB)":8519,
        "Energy (tokens\/kWh)":403225,
        "E2E Latency (s)":7.79,
        "E2E Throughput (tokens\/s)":32.9,
        "Reserved Memory (MB)":8671,
        "Used Memory (MB)":10131
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"43.35*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.119,
        "Decode Throughput (tokens\/s)":8.39,
        "Allocated Memory (MB)":14766,
        "Energy (tokens\/kWh)":119047,
        "E2E Latency (s)":30.5,
        "E2E Throughput (tokens\/s)":8.39,
        "Reserved Memory (MB)":14801,
        "Used Memory (MB)":16269
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"43.35*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.119,
        "Decode Throughput (tokens\/s)":8.28,
        "Allocated Memory (MB)":14766,
        "Energy (tokens\/kWh)":122100,
        "E2E Latency (s)":30.9,
        "E2E Throughput (tokens\/s)":8.28,
        "Reserved Memory (MB)":14801,
        "Used Memory (MB)":16269
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"43.35*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.135,
        "Decode Throughput (tokens\/s)":29.3,
        "Allocated Memory (MB)":8519,
        "Energy (tokens\/kWh)":366300,
        "E2E Latency (s)":8.82,
        "E2E Throughput (tokens\/s)":29.0,
        "Reserved Memory (MB)":8671,
        "Used Memory (MB)":10131
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"43.35 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.454,
        "Decode Throughput (tokens\/s)":24.5,
        "Allocated Memory (MB)":54421,
        "Energy (tokens\/kWh)":212765,
        "E2E Latency (s)":10.9,
        "E2E Throughput (tokens\/s)":23.5,
        "Reserved Memory (MB)":54773,
        "Used Memory (MB)":56224
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"43.35*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.496,
        "Decode Throughput (tokens\/s)":19.0,
        "Allocated Memory (MB)":9005,
        "Energy (tokens\/kWh)":230414,
        "E2E Latency (s)":13.9,
        "E2E Throughput (tokens\/s)":18.4,
        "Reserved Memory (MB)":9386,
        "Used Memory (MB)":10846
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":13.02,
        "Open LLM Score (%)":"43.35*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.503,
        "Decode Throughput (tokens\/s)":18.2,
        "Allocated Memory (MB)":9005,
        "Energy (tokens\/kWh)":219780,
        "E2E Latency (s)":14.5,
        "E2E Throughput (tokens\/s)":17.7,
        "Reserved Memory (MB)":9386,
        "Used Memory (MB)":10846
    },
    {
        "Model":"Salesforce\/codegen-16B-nl",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":16.0,
        "Open LLM Score (%)":"42.59 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.061,
        "Decode Throughput (tokens\/s)":26.3,
        "Allocated Memory (MB)":33100,
        "Energy (tokens\/kWh)":258397,
        "E2E Latency (s)":9.77,
        "E2E Throughput (tokens\/s)":26.2,
        "Reserved Memory (MB)":33204,
        "Used Memory (MB)":34663
    },
    {
        "Model":"Salesforce\/codegen-16B-nl",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":16.0,
        "Open LLM Score (%)":"42.59*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0787,
        "Decode Throughput (tokens\/s)":12.4,
        "Allocated Memory (MB)":17713,
        "Energy (tokens\/kWh)":177304,
        "E2E Latency (s)":20.6,
        "E2E Throughput (tokens\/s)":12.4,
        "Reserved Memory (MB)":17834,
        "Used Memory (MB)":19302
    },
    {
        "Model":"Salesforce\/codegen-16B-nl",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":16.0,
        "Open LLM Score (%)":"42.59*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0806,
        "Decode Throughput (tokens\/s)":26.3,
        "Allocated Memory (MB)":10609,
        "Energy (tokens\/kWh)":314465,
        "E2E Latency (s)":9.76,
        "E2E Throughput (tokens\/s)":26.2,
        "Reserved Memory (MB)":10718,
        "Used Memory (MB)":12180
    },
    {
        "Model":"Salesforce\/codegen-16B-nl",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":16.0,
        "Open LLM Score (%)":"42.59*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0812,
        "Decode Throughput (tokens\/s)":26.3,
        "Allocated Memory (MB)":12226,
        "Energy (tokens\/kWh)":363636,
        "E2E Latency (s)":9.79,
        "E2E Throughput (tokens\/s)":26.1,
        "Reserved Memory (MB)":12350,
        "Used Memory (MB)":13811
    },
    {
        "Model":"Salesforce\/codegen-16B-nl",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":16.0,
        "Open LLM Score (%)":"42.59*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0842,
        "Decode Throughput (tokens\/s)":11.9,
        "Allocated Memory (MB)":17707,
        "Energy (tokens\/kWh)":170068,
        "E2E Latency (s)":21.6,
        "E2E Throughput (tokens\/s)":11.9,
        "Reserved Memory (MB)":17811,
        "Used Memory (MB)":19279
    },
    {
        "Model":"Salesforce\/codegen-16B-nl",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":16.0,
        "Open LLM Score (%)":"42.59*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.128,
        "Decode Throughput (tokens\/s)":25.8,
        "Allocated Memory (MB)":10305,
        "Energy (tokens\/kWh)":320512,
        "E2E Latency (s)":10.0,
        "E2E Throughput (tokens\/s)":25.6,
        "Reserved Memory (MB)":10433,
        "Used Memory (MB)":11892
    },
    {
        "Model":"Salesforce\/codegen-16B-nl",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":16.0,
        "Open LLM Score (%)":"42.59*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.154,
        "Decode Throughput (tokens\/s)":24.8,
        "Allocated Memory (MB)":10304,
        "Energy (tokens\/kWh)":313479,
        "E2E Latency (s)":10.5,
        "E2E Throughput (tokens\/s)":24.4,
        "Reserved Memory (MB)":10433,
        "Used Memory (MB)":11892
    },
    {
        "Model":"Salesforce\/codegen-16B-nl",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":16.0,
        "Open LLM Score (%)":"42.59 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.572,
        "Decode Throughput (tokens\/s)":20.6,
        "Allocated Memory (MB)":66008,
        "Energy (tokens\/kWh)":178890,
        "E2E Latency (s)":13.0,
        "E2E Throughput (tokens\/s)":19.7,
        "Reserved Memory (MB)":66418,
        "Used Memory (MB)":67870
    },
    {
        "Model":"Salesforce\/codegen-16B-nl",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":16.0,
        "Open LLM Score (%)":"42.59*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.621,
        "Decode Throughput (tokens\/s)":19.2,
        "Allocated Memory (MB)":11264,
        "Energy (tokens\/kWh)":223214,
        "E2E Latency (s)":13.9,
        "E2E Throughput (tokens\/s)":18.4,
        "Reserved Memory (MB)":12106,
        "Used Memory (MB)":13566
    },
    {
        "Model":"Salesforce\/codegen-16B-nl",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":16.0,
        "Open LLM Score (%)":"42.59*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.63,
        "Decode Throughput (tokens\/s)":20.1,
        "Allocated Memory (MB)":11264,
        "Energy (tokens\/kWh)":219298,
        "E2E Latency (s)":13.3,
        "E2E Throughput (tokens\/s)":19.2,
        "Reserved Memory (MB)":12106,
        "Used Memory (MB)":13566
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"42.31 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0301,
        "Decode Throughput (tokens\/s)":42.9,
        "Allocated Memory (MB)":14056,
        "Energy (tokens\/kWh)":492610,
        "E2E Latency (s)":5.97,
        "E2E Throughput (tokens\/s)":42.9,
        "Reserved Memory (MB)":14092,
        "Used Memory (MB)":15552
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"42.31 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0318,
        "Decode Throughput (tokens\/s)":40.9,
        "Allocated Memory (MB)":14056,
        "Energy (tokens\/kWh)":454545,
        "E2E Latency (s)":6.27,
        "E2E Throughput (tokens\/s)":40.8,
        "Reserved Memory (MB)":14092,
        "Used Memory (MB)":15552
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"42.31 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0334,
        "Decode Throughput (tokens\/s)":42.6,
        "Allocated Memory (MB)":14056,
        "Energy (tokens\/kWh)":448430,
        "E2E Latency (s)":6.01,
        "E2E Throughput (tokens\/s)":42.6,
        "Reserved Memory (MB)":14092,
        "Used Memory (MB)":15552
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"42.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0397,
        "Decode Throughput (tokens\/s)":40.0,
        "Allocated Memory (MB)":4616,
        "Energy (tokens\/kWh)":523560,
        "E2E Latency (s)":6.42,
        "E2E Throughput (tokens\/s)":39.9,
        "Reserved Memory (MB)":4647,
        "Used Memory (MB)":6108
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"42.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0411,
        "Decode Throughput (tokens\/s)":39.0,
        "Allocated Memory (MB)":5342,
        "Energy (tokens\/kWh)":558659,
        "E2E Latency (s)":6.58,
        "E2E Throughput (tokens\/s)":38.9,
        "Reserved Memory (MB)":5375,
        "Used Memory (MB)":6836
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"42.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0614,
        "Decode Throughput (tokens\/s)":41.5,
        "Allocated Memory (MB)":4519,
        "Energy (tokens\/kWh)":543478,
        "E2E Latency (s)":6.2,
        "E2E Throughput (tokens\/s)":41.3,
        "Reserved Memory (MB)":4548,
        "Used Memory (MB)":6008
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"42.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0724,
        "Decode Throughput (tokens\/s)":37.0,
        "Allocated Memory (MB)":4519,
        "Energy (tokens\/kWh)":500000,
        "E2E Latency (s)":6.97,
        "E2E Throughput (tokens\/s)":36.7,
        "Reserved Memory (MB)":4548,
        "Used Memory (MB)":6008
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"42.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0954,
        "Decode Throughput (tokens\/s)":10.4,
        "Allocated Memory (MB)":7686,
        "Energy (tokens\/kWh)":155038,
        "E2E Latency (s)":24.7,
        "E2E Throughput (tokens\/s)":10.4,
        "Reserved Memory (MB)":7728,
        "Used Memory (MB)":9195
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"42.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0986,
        "Decode Throughput (tokens\/s)":10.2,
        "Allocated Memory (MB)":7686,
        "Energy (tokens\/kWh)":151515,
        "E2E Latency (s)":25.1,
        "E2E Throughput (tokens\/s)":10.2,
        "Reserved Memory (MB)":7728,
        "Used Memory (MB)":9195
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"42.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.166,
        "Decode Throughput (tokens\/s)":28.7,
        "Allocated Memory (MB)":4527,
        "Energy (tokens\/kWh)":389105,
        "E2E Latency (s)":9.06,
        "E2E Throughput (tokens\/s)":28.3,
        "Reserved Memory (MB)":4573,
        "Used Memory (MB)":6033
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"42.31 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.238,
        "Decode Throughput (tokens\/s)":41.7,
        "Allocated Memory (MB)":28100,
        "Energy (tokens\/kWh)":361010,
        "E2E Latency (s)":6.36,
        "E2E Throughput (tokens\/s)":40.3,
        "Reserved Memory (MB)":28458,
        "Used Memory (MB)":29909
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"42.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.268,
        "Decode Throughput (tokens\/s)":23.6,
        "Allocated Memory (MB)":4796,
        "Energy (tokens\/kWh)":299401,
        "E2E Latency (s)":11.1,
        "E2E Throughput (tokens\/s)":23.1,
        "Reserved Memory (MB)":4949,
        "Used Memory (MB)":6408
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"42.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.271,
        "Decode Throughput (tokens\/s)":22.8,
        "Allocated Memory (MB)":4795,
        "Energy (tokens\/kWh)":289017,
        "E2E Latency (s)":11.5,
        "E2E Throughput (tokens\/s)":22.3,
        "Reserved Memory (MB)":4995,
        "Used Memory (MB)":6454
    },
    {
        "Model":"RWKV\/rwkv-raven-14b",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":14.0,
        "Open LLM Score (%)":"42.09 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0548,
        "Decode Throughput (tokens\/s)":23.2,
        "Allocated Memory (MB)":28350,
        "Energy (tokens\/kWh)":264550,
        "E2E Latency (s)":11.1,
        "E2E Throughput (tokens\/s)":23.1,
        "Reserved Memory (MB)":28393,
        "Used Memory (MB)":29852
    },
    {
        "Model":"Writer\/palmyra-large",
        "Arch":"GPT-2",
        "Params (B)":0.0,
        "Open LLM Score (%)":"42.09*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0578,
        "Decode Throughput (tokens\/s)":27.2,
        "Allocated Memory (MB)":41812,
        "Energy (tokens\/kWh)":304878,
        "E2E Latency (s)":9.42,
        "E2E Throughput (tokens\/s)":27.2,
        "Reserved Memory (MB)":41903,
        "Used Memory (MB)":43362
    },
    {
        "Model":"Writer\/palmyra-large",
        "Arch":"GPT-2",
        "Params (B)":0.0,
        "Open LLM Score (%)":"42.09*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0582,
        "Decode Throughput (tokens\/s)":27.2,
        "Allocated Memory (MB)":41812,
        "Energy (tokens\/kWh)":308641,
        "E2E Latency (s)":9.42,
        "E2E Throughput (tokens\/s)":27.2,
        "Reserved Memory (MB)":41903,
        "Used Memory (MB)":43362
    },
    {
        "Model":"Writer\/palmyra-large",
        "Arch":"GPT-2",
        "Params (B)":0.0,
        "Open LLM Score (%)":"42.09 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0674,
        "Decode Throughput (tokens\/s)":27.2,
        "Allocated Memory (MB)":41812,
        "Energy (tokens\/kWh)":251889,
        "E2E Latency (s)":9.43,
        "E2E Throughput (tokens\/s)":27.1,
        "Reserved Memory (MB)":41903,
        "Used Memory (MB)":43362
    },
    {
        "Model":"Writer\/palmyra-large",
        "Arch":"GPT-2",
        "Params (B)":0.0,
        "Open LLM Score (%)":"42.09 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.072,
        "Decode Throughput (tokens\/s)":28.7,
        "Allocated Memory (MB)":41812,
        "Energy (tokens\/kWh)":263157,
        "E2E Latency (s)":8.96,
        "E2E Throughput (tokens\/s)":28.6,
        "Reserved Memory (MB)":41894,
        "Used Memory (MB)":43352
    },
    {
        "Model":"Writer\/palmyra-large",
        "Arch":"GPT-2",
        "Params (B)":0.0,
        "Open LLM Score (%)":"42.09 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0758,
        "Decode Throughput (tokens\/s)":27.1,
        "Allocated Memory (MB)":41812,
        "Energy (tokens\/kWh)":245700,
        "E2E Latency (s)":9.49,
        "E2E Throughput (tokens\/s)":27.0,
        "Reserved Memory (MB)":41903,
        "Used Memory (MB)":43362
    },
    {
        "Model":"Writer\/palmyra-large",
        "Arch":"GPT-2",
        "Params (B)":0.0,
        "Open LLM Score (%)":"42.09*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0951,
        "Decode Throughput (tokens\/s)":35.2,
        "Allocated Memory (MB)":12620,
        "Energy (tokens\/kWh)":366300,
        "E2E Latency (s)":7.34,
        "E2E Throughput (tokens\/s)":34.9,
        "Reserved Memory (MB)":12748,
        "Used Memory (MB)":14210
    },
    {
        "Model":"RWKV\/rwkv-raven-14b",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":14.0,
        "Open LLM Score (%)":"42.09*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.139,
        "Decode Throughput (tokens\/s)":7.41,
        "Allocated Memory (MB)":14963,
        "Energy (tokens\/kWh)":105708,
        "E2E Latency (s)":34.5,
        "E2E Throughput (tokens\/s)":7.42,
        "Reserved Memory (MB)":15013,
        "Used Memory (MB)":16481
    },
    {
        "Model":"RWKV\/rwkv-raven-14b",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":14.0,
        "Open LLM Score (%)":"42.09 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.49,
        "Decode Throughput (tokens\/s)":23.0,
        "Allocated Memory (MB)":56690,
        "Energy (tokens\/kWh)":198807,
        "E2E Latency (s)":11.6,
        "E2E Throughput (tokens\/s)":22.1,
        "Reserved Memory (MB)":56757,
        "Used Memory (MB)":58208
    },
    {
        "Model":"RWKV\/rwkv-raven-14b",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":14.0,
        "Open LLM Score (%)":"42.09*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.538,
        "Decode Throughput (tokens\/s)":14.1,
        "Allocated Memory (MB)":9149,
        "Energy (tokens\/kWh)":183486,
        "E2E Latency (s)":18.6,
        "E2E Throughput (tokens\/s)":13.8,
        "Reserved Memory (MB)":9829,
        "Used Memory (MB)":11288
    },
    {
        "Model":"Writer\/palmyra-large",
        "Arch":"GPT-2",
        "Params (B)":0.0,
        "Open LLM Score (%)":"42.09 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.652,
        "Decode Throughput (tokens\/s)":14.2,
        "Allocated Memory (MB)":83432,
        "Energy (tokens\/kWh)":126742,
        "E2E Latency (s)":18.6,
        "E2E Throughput (tokens\/s)":13.8,
        "Reserved Memory (MB)":83821,
        "Used Memory (MB)":85272
    },
    {
        "Model":"EleutherAI\/gpt-neox-20b",
        "Arch":"GPT-NeoX",
        "Params (B)":20.74,
        "Open LLM Score (%)":"41.69 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0776,
        "Decode Throughput (tokens\/s)":25.0,
        "Allocated Memory (MB)":42420,
        "Energy (tokens\/kWh)":228310,
        "E2E Latency (s)":10.3,
        "E2E Throughput (tokens\/s)":24.9,
        "Reserved Memory (MB)":42511,
        "Used Memory (MB)":43970
    },
    {
        "Model":"EleutherAI\/gpt-neox-20b",
        "Arch":"GPT-NeoX",
        "Params (B)":20.74,
        "Open LLM Score (%)":"41.69 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0778,
        "Decode Throughput (tokens\/s)":28.9,
        "Allocated Memory (MB)":42420,
        "Energy (tokens\/kWh)":256410,
        "E2E Latency (s)":8.9,
        "E2E Throughput (tokens\/s)":28.8,
        "Reserved Memory (MB)":42502,
        "Used Memory (MB)":43962
    },
    {
        "Model":"EleutherAI\/gpt-neox-20b",
        "Arch":"GPT-NeoX",
        "Params (B)":20.74,
        "Open LLM Score (%)":"41.69*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0928,
        "Decode Throughput (tokens\/s)":10.8,
        "Allocated Memory (MB)":22498,
        "Energy (tokens\/kWh)":151057,
        "E2E Latency (s)":23.8,
        "E2E Throughput (tokens\/s)":10.8,
        "Reserved Memory (MB)":22588,
        "Used Memory (MB)":24056
    },
    {
        "Model":"EleutherAI\/gpt-neox-20b",
        "Arch":"GPT-NeoX",
        "Params (B)":20.74,
        "Open LLM Score (%)":"41.69*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0972,
        "Decode Throughput (tokens\/s)":10.5,
        "Allocated Memory (MB)":22497,
        "Energy (tokens\/kWh)":145348,
        "E2E Latency (s)":24.5,
        "E2E Throughput (tokens\/s)":10.4,
        "Reserved Memory (MB)":22590,
        "Used Memory (MB)":24058
    },
    {
        "Model":"EleutherAI\/gpt-neox-20b",
        "Arch":"GPT-NeoX",
        "Params (B)":20.74,
        "Open LLM Score (%)":"41.69*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.102,
        "Decode Throughput (tokens\/s)":27.6,
        "Allocated Memory (MB)":13222,
        "Energy (tokens\/kWh)":305810,
        "E2E Latency (s)":9.34,
        "E2E Throughput (tokens\/s)":27.4,
        "Reserved Memory (MB)":13342,
        "Used Memory (MB)":14803
    },
    {
        "Model":"EleutherAI\/gpt-neox-20b",
        "Arch":"GPT-NeoX",
        "Params (B)":20.74,
        "Open LLM Score (%)":"41.69*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.104,
        "Decode Throughput (tokens\/s)":27.7,
        "Allocated Memory (MB)":14841,
        "Energy (tokens\/kWh)":354609,
        "E2E Latency (s)":9.32,
        "E2E Throughput (tokens\/s)":27.5,
        "Reserved Memory (MB)":14963,
        "Used Memory (MB)":16424
    },
    {
        "Model":"EleutherAI\/gpt-neox-20b",
        "Arch":"GPT-NeoX",
        "Params (B)":20.74,
        "Open LLM Score (%)":"41.69*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.171,
        "Decode Throughput (tokens\/s)":25.9,
        "Allocated Memory (MB)":12919,
        "Energy (tokens\/kWh)":307692,
        "E2E Latency (s)":10.0,
        "E2E Throughput (tokens\/s)":25.6,
        "Reserved Memory (MB)":13056,
        "Used Memory (MB)":14516
    },
    {
        "Model":"EleutherAI\/gpt-neox-20b",
        "Arch":"GPT-NeoX",
        "Params (B)":20.74,
        "Open LLM Score (%)":"41.69*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.206,
        "Decode Throughput (tokens\/s)":23.8,
        "Allocated Memory (MB)":12920,
        "Energy (tokens\/kWh)":286532,
        "E2E Latency (s)":10.9,
        "E2E Throughput (tokens\/s)":23.5,
        "Reserved Memory (MB)":13056,
        "Used Memory (MB)":14516
    },
    {
        "Model":"EleutherAI\/gpt-neox-20b",
        "Arch":"GPT-NeoX",
        "Params (B)":20.74,
        "Open LLM Score (%)":"41.69*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.826,
        "Decode Throughput (tokens\/s)":15.5,
        "Allocated Memory (MB)":14172,
        "Energy (tokens\/kWh)":170648,
        "E2E Latency (s)":17.2,
        "E2E Throughput (tokens\/s)":14.9,
        "Reserved Memory (MB)":14709,
        "Used Memory (MB)":16168
    },
    {
        "Model":"EleutherAI\/gpt-neox-20b",
        "Arch":"GPT-NeoX",
        "Params (B)":20.74,
        "Open LLM Score (%)":"41.69*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.826,
        "Decode Throughput (tokens\/s)":15.4,
        "Allocated Memory (MB)":14172,
        "Energy (tokens\/kWh)":176366,
        "E2E Latency (s)":17.4,
        "E2E Throughput (tokens\/s)":14.7,
        "Reserved Memory (MB)":14709,
        "Used Memory (MB)":16168
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"GPT-NeoX",
        "Params (B)":7.0,
        "Open LLM Score (%)":"41.49 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0281,
        "Decode Throughput (tokens\/s)":48.8,
        "Allocated Memory (MB)":14429,
        "Energy (tokens\/kWh)":510204,
        "E2E Latency (s)":5.26,
        "E2E Throughput (tokens\/s)":48.7,
        "Reserved Memory (MB)":14470,
        "Used Memory (MB)":15929
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"GPT-NeoX",
        "Params (B)":7.0,
        "Open LLM Score (%)":"41.49 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0305,
        "Decode Throughput (tokens\/s)":46.4,
        "Allocated Memory (MB)":14429,
        "Energy (tokens\/kWh)":462962,
        "E2E Latency (s)":5.52,
        "E2E Throughput (tokens\/s)":46.4,
        "Reserved Memory (MB)":14470,
        "Used Memory (MB)":15929
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"GPT-NeoX",
        "Params (B)":7.0,
        "Open LLM Score (%)":"41.49 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0311,
        "Decode Throughput (tokens\/s)":40.8,
        "Allocated Memory (MB)":14429,
        "Energy (tokens\/kWh)":469483,
        "E2E Latency (s)":6.28,
        "E2E Throughput (tokens\/s)":40.8,
        "Reserved Memory (MB)":14470,
        "Used Memory (MB)":15929
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"GPT-NeoX",
        "Params (B)":7.0,
        "Open LLM Score (%)":"41.49 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0329,
        "Decode Throughput (tokens\/s)":40.0,
        "Allocated Memory (MB)":14429,
        "Energy (tokens\/kWh)":425531,
        "E2E Latency (s)":6.4,
        "E2E Throughput (tokens\/s)":40.0,
        "Reserved Memory (MB)":14470,
        "Used Memory (MB)":15929
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"GPT-NeoX",
        "Params (B)":7.0,
        "Open LLM Score (%)":"41.49*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0395,
        "Decode Throughput (tokens\/s)":42.5,
        "Allocated Memory (MB)":5027,
        "Energy (tokens\/kWh)":552486,
        "E2E Latency (s)":6.04,
        "E2E Throughput (tokens\/s)":42.4,
        "Reserved Memory (MB)":5052,
        "Used Memory (MB)":6513
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"GPT-NeoX",
        "Params (B)":7.0,
        "Open LLM Score (%)":"41.49*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0409,
        "Decode Throughput (tokens\/s)":40.7,
        "Allocated Memory (MB)":6105,
        "Energy (tokens\/kWh)":602409,
        "E2E Latency (s)":6.3,
        "E2E Throughput (tokens\/s)":40.6,
        "Reserved Memory (MB)":6132,
        "Used Memory (MB)":7593
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"GPT-NeoX",
        "Params (B)":7.0,
        "Open LLM Score (%)":"41.49*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0623,
        "Decode Throughput (tokens\/s)":15.6,
        "Allocated Memory (MB)":7990,
        "Energy (tokens\/kWh)":230414,
        "E2E Latency (s)":16.4,
        "E2E Throughput (tokens\/s)":15.6,
        "Reserved Memory (MB)":8038,
        "Used Memory (MB)":9506
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"GPT-NeoX",
        "Params (B)":7.0,
        "Open LLM Score (%)":"41.49*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0639,
        "Decode Throughput (tokens\/s)":39.2,
        "Allocated Memory (MB)":4891,
        "Energy (tokens\/kWh)":505050,
        "E2E Latency (s)":6.57,
        "E2E Throughput (tokens\/s)":39.0,
        "Reserved Memory (MB)":4926,
        "Used Memory (MB)":6385
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"GPT-NeoX",
        "Params (B)":7.0,
        "Open LLM Score (%)":"41.49*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0676,
        "Decode Throughput (tokens\/s)":15.1,
        "Allocated Memory (MB)":7990,
        "Energy (tokens\/kWh)":214132,
        "E2E Latency (s)":17.0,
        "E2E Throughput (tokens\/s)":15.1,
        "Reserved Memory (MB)":8029,
        "Used Memory (MB)":9497
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"GPT-NeoX",
        "Params (B)":7.0,
        "Open LLM Score (%)":"41.49*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0725,
        "Decode Throughput (tokens\/s)":36.8,
        "Allocated Memory (MB)":4891,
        "Energy (tokens\/kWh)":500000,
        "E2E Latency (s)":7.0,
        "E2E Throughput (tokens\/s)":36.6,
        "Reserved Memory (MB)":4926,
        "Used Memory (MB)":6385
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"GPT-NeoX",
        "Params (B)":7.0,
        "Open LLM Score (%)":"41.49*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.163,
        "Decode Throughput (tokens\/s)":33.6,
        "Allocated Memory (MB)":4980,
        "Energy (tokens\/kWh)":440528,
        "E2E Latency (s)":7.74,
        "E2E Throughput (tokens\/s)":33.1,
        "Reserved Memory (MB)":5205,
        "Used Memory (MB)":6664
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"GPT-NeoX",
        "Params (B)":7.0,
        "Open LLM Score (%)":"41.49 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.247,
        "Decode Throughput (tokens\/s)":38.3,
        "Allocated Memory (MB)":28712,
        "Energy (tokens\/kWh)":340136,
        "E2E Latency (s)":6.91,
        "E2E Throughput (tokens\/s)":37.0,
        "Reserved Memory (MB)":28873,
        "Used Memory (MB)":30324
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"GPT-NeoX",
        "Params (B)":7.0,
        "Open LLM Score (%)":"41.49*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.277,
        "Decode Throughput (tokens\/s)":27.9,
        "Allocated Memory (MB)":5370,
        "Energy (tokens\/kWh)":342465,
        "E2E Latency (s)":9.43,
        "E2E Throughput (tokens\/s)":27.1,
        "Reserved Memory (MB)":5609,
        "Used Memory (MB)":7069
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"GPT-NeoX",
        "Params (B)":7.0,
        "Open LLM Score (%)":"41.49*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.284,
        "Decode Throughput (tokens\/s)":26.0,
        "Allocated Memory (MB)":5370,
        "Energy (tokens\/kWh)":317460,
        "E2E Latency (s)":10.1,
        "E2E Throughput (tokens\/s)":25.3,
        "Reserved Memory (MB)":5609,
        "Used Memory (MB)":7069
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.02,
        "Open LLM Score (%)":"41.44 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0181,
        "Decode Throughput (tokens\/s)":53.9,
        "Allocated Memory (MB)":6401,
        "Energy (tokens\/kWh)":709219,
        "E2E Latency (s)":4.75,
        "E2E Throughput (tokens\/s)":53.9,
        "Reserved Memory (MB)":6452,
        "Used Memory (MB)":7912
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.02,
        "Open LLM Score (%)":"41.44 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0185,
        "Decode Throughput (tokens\/s)":53.2,
        "Allocated Memory (MB)":6401,
        "Energy (tokens\/kWh)":684931,
        "E2E Latency (s)":4.81,
        "E2E Throughput (tokens\/s)":53.2,
        "Reserved Memory (MB)":6452,
        "Used Memory (MB)":7912
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.02,
        "Open LLM Score (%)":"41.44 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0187,
        "Decode Throughput (tokens\/s)":51.6,
        "Allocated Memory (MB)":6401,
        "Energy (tokens\/kWh)":675675,
        "E2E Latency (s)":4.96,
        "E2E Throughput (tokens\/s)":51.6,
        "Reserved Memory (MB)":6452,
        "Used Memory (MB)":7912
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.02,
        "Open LLM Score (%)":"41.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0206,
        "Decode Throughput (tokens\/s)":52.3,
        "Allocated Memory (MB)":2432,
        "Energy (tokens\/kWh)":735294,
        "E2E Latency (s)":4.9,
        "E2E Throughput (tokens\/s)":52.2,
        "Reserved Memory (MB)":2529,
        "Used Memory (MB)":3990
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.02,
        "Open LLM Score (%)":"41.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.021,
        "Decode Throughput (tokens\/s)":52.3,
        "Allocated Memory (MB)":2971,
        "Energy (tokens\/kWh)":781250,
        "E2E Latency (s)":4.9,
        "E2E Throughput (tokens\/s)":52.2,
        "Reserved Memory (MB)":3093,
        "Used Memory (MB)":4555
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.02,
        "Open LLM Score (%)":"41.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0309,
        "Decode Throughput (tokens\/s)":55.9,
        "Allocated Memory (MB)":2377,
        "Energy (tokens\/kWh)":799999,
        "E2E Latency (s)":4.59,
        "E2E Throughput (tokens\/s)":55.8,
        "Reserved Memory (MB)":2487,
        "Used Memory (MB)":3946
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.02,
        "Open LLM Score (%)":"41.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.035,
        "Decode Throughput (tokens\/s)":49.4,
        "Allocated Memory (MB)":2377,
        "Energy (tokens\/kWh)":694444,
        "E2E Latency (s)":5.19,
        "E2E Throughput (tokens\/s)":49.3,
        "Reserved Memory (MB)":2487,
        "Used Memory (MB)":3946
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.02,
        "Open LLM Score (%)":"41.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0722,
        "Decode Throughput (tokens\/s)":13.5,
        "Allocated Memory (MB)":3687,
        "Energy (tokens\/kWh)":212314,
        "E2E Latency (s)":19.0,
        "E2E Throughput (tokens\/s)":13.5,
        "Reserved Memory (MB)":3856,
        "Used Memory (MB)":5324
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.02,
        "Open LLM Score (%)":"41.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0726,
        "Decode Throughput (tokens\/s)":13.7,
        "Allocated Memory (MB)":3687,
        "Energy (tokens\/kWh)":203665,
        "E2E Latency (s)":18.7,
        "E2E Throughput (tokens\/s)":13.7,
        "Reserved Memory (MB)":3856,
        "Used Memory (MB)":5324
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.02,
        "Open LLM Score (%)":"41.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0755,
        "Decode Throughput (tokens\/s)":38.9,
        "Allocated Memory (MB)":2384,
        "Energy (tokens\/kWh)":555555,
        "E2E Latency (s)":6.64,
        "E2E Throughput (tokens\/s)":38.6,
        "Reserved Memory (MB)":2489,
        "Used Memory (MB)":3948
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.02,
        "Open LLM Score (%)":"41.44 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.111,
        "Decode Throughput (tokens\/s)":61.3,
        "Allocated Memory (MB)":12793,
        "Energy (tokens\/kWh)":641025,
        "E2E Latency (s)":4.27,
        "E2E Throughput (tokens\/s)":60.0,
        "Reserved Memory (MB)":12893,
        "Used Memory (MB)":14344
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.02,
        "Open LLM Score (%)":"41.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.122,
        "Decode Throughput (tokens\/s)":30.5,
        "Allocated Memory (MB)":2513,
        "Energy (tokens\/kWh)":416666,
        "E2E Latency (s)":8.49,
        "E2E Throughput (tokens\/s)":30.2,
        "Reserved Memory (MB)":2571,
        "Used Memory (MB)":4030
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.02,
        "Open LLM Score (%)":"41.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.124,
        "Decode Throughput (tokens\/s)":30.3,
        "Allocated Memory (MB)":2513,
        "Energy (tokens\/kWh)":420168,
        "E2E Latency (s)":8.53,
        "E2E Throughput (tokens\/s)":30.0,
        "Reserved Memory (MB)":2571,
        "Used Memory (MB)":4030
    },
    {
        "Model":"NucleusAI\/nucleus-22B-token-500B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":21.83,
        "Open LLM Score (%)":"41.33 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0769,
        "Decode Throughput (tokens\/s)":28.1,
        "Allocated Memory (MB)":44887,
        "Energy (tokens\/kWh)":253807,
        "E2E Latency (s)":9.16,
        "E2E Throughput (tokens\/s)":27.9,
        "Reserved Memory (MB)":45185,
        "Used Memory (MB)":46644
    },
    {
        "Model":"NucleusAI\/nucleus-22B-token-500B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":21.83,
        "Open LLM Score (%)":"41.33 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0865,
        "Decode Throughput (tokens\/s)":28.0,
        "Allocated Memory (MB)":44887,
        "Energy (tokens\/kWh)":250000,
        "E2E Latency (s)":9.21,
        "E2E Throughput (tokens\/s)":27.8,
        "Reserved Memory (MB)":45185,
        "Used Memory (MB)":46644
    },
    {
        "Model":"NucleusAI\/nucleus-22B-token-500B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":21.83,
        "Open LLM Score (%)":"41.33*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.102,
        "Decode Throughput (tokens\/s)":31.6,
        "Allocated Memory (MB)":13546,
        "Energy (tokens\/kWh)":325732,
        "E2E Latency (s)":8.16,
        "E2E Throughput (tokens\/s)":31.4,
        "Reserved Memory (MB)":13734,
        "Used Memory (MB)":15195
    },
    {
        "Model":"NucleusAI\/nucleus-22B-token-500B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":21.83,
        "Open LLM Score (%)":"41.33*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.103,
        "Decode Throughput (tokens\/s)":32.0,
        "Allocated Memory (MB)":14729,
        "Energy (tokens\/kWh)":392156,
        "E2E Latency (s)":8.08,
        "E2E Throughput (tokens\/s)":31.7,
        "Reserved Memory (MB)":14919,
        "Used Memory (MB)":16380
    },
    {
        "Model":"NucleusAI\/nucleus-22B-token-500B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":21.83,
        "Open LLM Score (%)":"41.33*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.119,
        "Decode Throughput (tokens\/s)":8.31,
        "Allocated Memory (MB)":23464,
        "Energy (tokens\/kWh)":117924,
        "E2E Latency (s)":30.8,
        "E2E Throughput (tokens\/s)":8.31,
        "Reserved Memory (MB)":23792,
        "Used Memory (MB)":25260
    },
    {
        "Model":"NucleusAI\/nucleus-22B-token-500B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":21.83,
        "Open LLM Score (%)":"41.33*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.121,
        "Decode Throughput (tokens\/s)":8.31,
        "Allocated Memory (MB)":23464,
        "Energy (tokens\/kWh)":116009,
        "E2E Latency (s)":30.8,
        "E2E Throughput (tokens\/s)":8.31,
        "Reserved Memory (MB)":23792,
        "Used Memory (MB)":25260
    },
    {
        "Model":"NucleusAI\/nucleus-22B-token-500B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":21.83,
        "Open LLM Score (%)":"41.33*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.161,
        "Decode Throughput (tokens\/s)":32.7,
        "Allocated Memory (MB)":13306,
        "Energy (tokens\/kWh)":340136,
        "E2E Latency (s)":7.96,
        "E2E Throughput (tokens\/s)":32.2,
        "Reserved Memory (MB)":13551,
        "Used Memory (MB)":15011
    },
    {
        "Model":"NucleusAI\/nucleus-22B-token-500B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":21.83,
        "Open LLM Score (%)":"41.33*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.201,
        "Decode Throughput (tokens\/s)":29.5,
        "Allocated Memory (MB)":13283,
        "Energy (tokens\/kWh)":326797,
        "E2E Latency (s)":8.83,
        "E2E Throughput (tokens\/s)":29.0,
        "Reserved Memory (MB)":13514,
        "Used Memory (MB)":14973
    },
    {
        "Model":"NucleusAI\/nucleus-22B-token-500B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":21.83,
        "Open LLM Score (%)":"41.33*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.818,
        "Decode Throughput (tokens\/s)":17.7,
        "Allocated Memory (MB)":14203,
        "Energy (tokens\/kWh)":190839,
        "E2E Latency (s)":15.2,
        "E2E Throughput (tokens\/s)":16.8,
        "Reserved Memory (MB)":14847,
        "Used Memory (MB)":16307
    },
    {
        "Model":"NucleusAI\/nucleus-22B-token-500B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":21.83,
        "Open LLM Score (%)":"41.33*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.824,
        "Decode Throughput (tokens\/s)":17.8,
        "Allocated Memory (MB)":14203,
        "Energy (tokens\/kWh)":185528,
        "E2E Latency (s)":15.1,
        "E2E Throughput (tokens\/s)":17.0,
        "Reserved Memory (MB)":14847,
        "Used Memory (MB)":16307
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"GPT-NeoX",
        "Params (B)":6.65,
        "Open LLM Score (%)":"41.25 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0297,
        "Decode Throughput (tokens\/s)":48.3,
        "Allocated Memory (MB)":14429,
        "Energy (tokens\/kWh)":502512,
        "E2E Latency (s)":5.31,
        "E2E Throughput (tokens\/s)":48.2,
        "Reserved Memory (MB)":14470,
        "Used Memory (MB)":15929
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"GPT-NeoX",
        "Params (B)":6.65,
        "Open LLM Score (%)":"41.25 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0309,
        "Decode Throughput (tokens\/s)":41.1,
        "Allocated Memory (MB)":14429,
        "Energy (tokens\/kWh)":471698,
        "E2E Latency (s)":6.23,
        "E2E Throughput (tokens\/s)":41.1,
        "Reserved Memory (MB)":14470,
        "Used Memory (MB)":15929
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"GPT-NeoX",
        "Params (B)":6.65,
        "Open LLM Score (%)":"41.25 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0329,
        "Decode Throughput (tokens\/s)":40.5,
        "Allocated Memory (MB)":14429,
        "Energy (tokens\/kWh)":429184,
        "E2E Latency (s)":6.32,
        "E2E Throughput (tokens\/s)":40.5,
        "Reserved Memory (MB)":14470,
        "Used Memory (MB)":15929
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"GPT-NeoX",
        "Params (B)":6.65,
        "Open LLM Score (%)":"41.25 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0338,
        "Decode Throughput (tokens\/s)":45.0,
        "Allocated Memory (MB)":14429,
        "Energy (tokens\/kWh)":471698,
        "E2E Latency (s)":5.7,
        "E2E Throughput (tokens\/s)":44.9,
        "Reserved Memory (MB)":14470,
        "Used Memory (MB)":15929
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"GPT-NeoX",
        "Params (B)":6.65,
        "Open LLM Score (%)":"41.25*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0406,
        "Decode Throughput (tokens\/s)":42.1,
        "Allocated Memory (MB)":5027,
        "Energy (tokens\/kWh)":555555,
        "E2E Latency (s)":6.1,
        "E2E Throughput (tokens\/s)":42.0,
        "Reserved Memory (MB)":5052,
        "Used Memory (MB)":6513
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"GPT-NeoX",
        "Params (B)":6.65,
        "Open LLM Score (%)":"41.25*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0408,
        "Decode Throughput (tokens\/s)":41.9,
        "Allocated Memory (MB)":6105,
        "Energy (tokens\/kWh)":602409,
        "E2E Latency (s)":6.12,
        "E2E Throughput (tokens\/s)":41.8,
        "Reserved Memory (MB)":6132,
        "Used Memory (MB)":7593
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"GPT-NeoX",
        "Params (B)":6.65,
        "Open LLM Score (%)":"41.25*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0618,
        "Decode Throughput (tokens\/s)":15.8,
        "Allocated Memory (MB)":7990,
        "Energy (tokens\/kWh)":228832,
        "E2E Latency (s)":16.2,
        "E2E Throughput (tokens\/s)":15.8,
        "Reserved Memory (MB)":8038,
        "Used Memory (MB)":9506
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"GPT-NeoX",
        "Params (B)":6.65,
        "Open LLM Score (%)":"41.25*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0634,
        "Decode Throughput (tokens\/s)":40.3,
        "Allocated Memory (MB)":4891,
        "Energy (tokens\/kWh)":526315,
        "E2E Latency (s)":6.39,
        "E2E Throughput (tokens\/s)":40.1,
        "Reserved Memory (MB)":4926,
        "Used Memory (MB)":6385
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"GPT-NeoX",
        "Params (B)":6.65,
        "Open LLM Score (%)":"41.25*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0675,
        "Decode Throughput (tokens\/s)":14.8,
        "Allocated Memory (MB)":7990,
        "Energy (tokens\/kWh)":211416,
        "E2E Latency (s)":17.3,
        "E2E Throughput (tokens\/s)":14.8,
        "Reserved Memory (MB)":8029,
        "Used Memory (MB)":9497
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"GPT-NeoX",
        "Params (B)":6.65,
        "Open LLM Score (%)":"41.25*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0718,
        "Decode Throughput (tokens\/s)":37.4,
        "Allocated Memory (MB)":4891,
        "Energy (tokens\/kWh)":510204,
        "E2E Latency (s)":6.88,
        "E2E Throughput (tokens\/s)":37.2,
        "Reserved Memory (MB)":4926,
        "Used Memory (MB)":6385
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"GPT-NeoX",
        "Params (B)":6.65,
        "Open LLM Score (%)":"41.25*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.163,
        "Decode Throughput (tokens\/s)":33.2,
        "Allocated Memory (MB)":4980,
        "Energy (tokens\/kWh)":444444,
        "E2E Latency (s)":7.83,
        "E2E Throughput (tokens\/s)":32.7,
        "Reserved Memory (MB)":5205,
        "Used Memory (MB)":6664
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"GPT-NeoX",
        "Params (B)":6.65,
        "Open LLM Score (%)":"41.25 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.247,
        "Decode Throughput (tokens\/s)":38.4,
        "Allocated Memory (MB)":28712,
        "Energy (tokens\/kWh)":341296,
        "E2E Latency (s)":6.89,
        "E2E Throughput (tokens\/s)":37.2,
        "Reserved Memory (MB)":28873,
        "Used Memory (MB)":30324
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"GPT-NeoX",
        "Params (B)":6.65,
        "Open LLM Score (%)":"41.25*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.277,
        "Decode Throughput (tokens\/s)":25.7,
        "Allocated Memory (MB)":5370,
        "Energy (tokens\/kWh)":324675,
        "E2E Latency (s)":10.2,
        "E2E Throughput (tokens\/s)":25.1,
        "Reserved Memory (MB)":5609,
        "Used Memory (MB)":7069
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"GPT-NeoX",
        "Params (B)":6.65,
        "Open LLM Score (%)":"41.25*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.28,
        "Decode Throughput (tokens\/s)":27.8,
        "Allocated Memory (MB)":5370,
        "Energy (tokens\/kWh)":346020,
        "E2E Latency (s)":9.45,
        "E2E Throughput (tokens\/s)":27.1,
        "Reserved Memory (MB)":5609,
        "Used Memory (MB)":7069
    },
    {
        "Model":"LLM360\/Amber",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.0,
        "Open LLM Score (%)":"40.97 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0314,
        "Decode Throughput (tokens\/s)":44.1,
        "Allocated Memory (MB)":14056,
        "Energy (tokens\/kWh)":500000,
        "E2E Latency (s)":5.81,
        "E2E Throughput (tokens\/s)":44.1,
        "Reserved Memory (MB)":14092,
        "Used Memory (MB)":15552
    },
    {
        "Model":"LLM360\/Amber",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.0,
        "Open LLM Score (%)":"40.97 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0315,
        "Decode Throughput (tokens\/s)":41.7,
        "Allocated Memory (MB)":14056,
        "Energy (tokens\/kWh)":478468,
        "E2E Latency (s)":6.14,
        "E2E Throughput (tokens\/s)":41.7,
        "Reserved Memory (MB)":14092,
        "Used Memory (MB)":15552
    },
    {
        "Model":"LLM360\/Amber",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.0,
        "Open LLM Score (%)":"40.97 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0316,
        "Decode Throughput (tokens\/s)":41.0,
        "Allocated Memory (MB)":14056,
        "Energy (tokens\/kWh)":471698,
        "E2E Latency (s)":6.25,
        "E2E Throughput (tokens\/s)":41.0,
        "Reserved Memory (MB)":14092,
        "Used Memory (MB)":15552
    },
    {
        "Model":"LLM360\/Amber",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.0,
        "Open LLM Score (%)":"40.97*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0407,
        "Decode Throughput (tokens\/s)":39.8,
        "Allocated Memory (MB)":4616,
        "Energy (tokens\/kWh)":537634,
        "E2E Latency (s)":6.44,
        "E2E Throughput (tokens\/s)":39.8,
        "Reserved Memory (MB)":4647,
        "Used Memory (MB)":6108
    },
    {
        "Model":"LLM360\/Amber",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.0,
        "Open LLM Score (%)":"40.97*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0408,
        "Decode Throughput (tokens\/s)":39.9,
        "Allocated Memory (MB)":5342,
        "Energy (tokens\/kWh)":571428,
        "E2E Latency (s)":6.43,
        "E2E Throughput (tokens\/s)":39.8,
        "Reserved Memory (MB)":5375,
        "Used Memory (MB)":6836
    },
    {
        "Model":"LLM360\/Amber",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.0,
        "Open LLM Score (%)":"40.97*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0614,
        "Decode Throughput (tokens\/s)":40.7,
        "Allocated Memory (MB)":4519,
        "Energy (tokens\/kWh)":543478,
        "E2E Latency (s)":6.33,
        "E2E Throughput (tokens\/s)":40.4,
        "Reserved Memory (MB)":4548,
        "Used Memory (MB)":6008
    },
    {
        "Model":"LLM360\/Amber",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.0,
        "Open LLM Score (%)":"40.97*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.071,
        "Decode Throughput (tokens\/s)":36.6,
        "Allocated Memory (MB)":4519,
        "Energy (tokens\/kWh)":500000,
        "E2E Latency (s)":7.03,
        "E2E Throughput (tokens\/s)":36.4,
        "Reserved Memory (MB)":4548,
        "Used Memory (MB)":6008
    },
    {
        "Model":"LLM360\/Amber",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.0,
        "Open LLM Score (%)":"40.97*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0958,
        "Decode Throughput (tokens\/s)":10.4,
        "Allocated Memory (MB)":7686,
        "Energy (tokens\/kWh)":154798,
        "E2E Latency (s)":24.6,
        "E2E Throughput (tokens\/s)":10.4,
        "Reserved Memory (MB)":7728,
        "Used Memory (MB)":9195
    },
    {
        "Model":"LLM360\/Amber",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.0,
        "Open LLM Score (%)":"40.97*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0973,
        "Decode Throughput (tokens\/s)":10.3,
        "Allocated Memory (MB)":7686,
        "Energy (tokens\/kWh)":156739,
        "E2E Latency (s)":24.9,
        "E2E Throughput (tokens\/s)":10.3,
        "Reserved Memory (MB)":7728,
        "Used Memory (MB)":9195
    },
    {
        "Model":"LLM360\/Amber",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.0,
        "Open LLM Score (%)":"40.97*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.163,
        "Decode Throughput (tokens\/s)":29.0,
        "Allocated Memory (MB)":4527,
        "Energy (tokens\/kWh)":404858,
        "E2E Latency (s)":8.95,
        "E2E Throughput (tokens\/s)":28.6,
        "Reserved Memory (MB)":4573,
        "Used Memory (MB)":6033
    },
    {
        "Model":"LLM360\/Amber",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.0,
        "Open LLM Score (%)":"40.97 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.24,
        "Decode Throughput (tokens\/s)":41.7,
        "Allocated Memory (MB)":28100,
        "Energy (tokens\/kWh)":361010,
        "E2E Latency (s)":6.35,
        "E2E Throughput (tokens\/s)":40.3,
        "Reserved Memory (MB)":28458,
        "Used Memory (MB)":29909
    },
    {
        "Model":"LLM360\/Amber",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.0,
        "Open LLM Score (%)":"40.97*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.263,
        "Decode Throughput (tokens\/s)":23.0,
        "Allocated Memory (MB)":4796,
        "Energy (tokens\/kWh)":302114,
        "E2E Latency (s)":11.4,
        "E2E Throughput (tokens\/s)":22.5,
        "Reserved Memory (MB)":4949,
        "Used Memory (MB)":6408
    },
    {
        "Model":"LLM360\/Amber",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.0,
        "Open LLM Score (%)":"40.97*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.27,
        "Decode Throughput (tokens\/s)":23.2,
        "Allocated Memory (MB)":4796,
        "Energy (tokens\/kWh)":298507,
        "E2E Latency (s)":11.3,
        "E2E Throughput (tokens\/s)":22.7,
        "Reserved Memory (MB)":4949,
        "Used Memory (MB)":6408
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-20b",
        "Arch":"GPT-2",
        "Params (B)":20.92,
        "Open LLM Score (%)":"40.71*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0572,
        "Decode Throughput (tokens\/s)":27.1,
        "Allocated Memory (MB)":41981,
        "Energy (tokens\/kWh)":300300,
        "E2E Latency (s)":9.46,
        "E2E Throughput (tokens\/s)":27.1,
        "Reserved Memory (MB)":42077,
        "Used Memory (MB)":43536
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-20b",
        "Arch":"GPT-2",
        "Params (B)":20.92,
        "Open LLM Score (%)":"40.71*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0573,
        "Decode Throughput (tokens\/s)":27.0,
        "Allocated Memory (MB)":41981,
        "Energy (tokens\/kWh)":302114,
        "E2E Latency (s)":9.49,
        "E2E Throughput (tokens\/s)":27.0,
        "Reserved Memory (MB)":42077,
        "Used Memory (MB)":43536
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-20b",
        "Arch":"GPT-2",
        "Params (B)":20.92,
        "Open LLM Score (%)":"40.71 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0663,
        "Decode Throughput (tokens\/s)":27.3,
        "Allocated Memory (MB)":41981,
        "Energy (tokens\/kWh)":251889,
        "E2E Latency (s)":9.42,
        "E2E Throughput (tokens\/s)":27.2,
        "Reserved Memory (MB)":42077,
        "Used Memory (MB)":43536
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-20b",
        "Arch":"GPT-2",
        "Params (B)":20.92,
        "Open LLM Score (%)":"40.71*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.092,
        "Decode Throughput (tokens\/s)":35.0,
        "Allocated Memory (MB)":12789,
        "Energy (tokens\/kWh)":366300,
        "E2E Latency (s)":7.37,
        "E2E Throughput (tokens\/s)":34.7,
        "Reserved Memory (MB)":12901,
        "Used Memory (MB)":14363
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-20b",
        "Arch":"GPT-2",
        "Params (B)":20.92,
        "Open LLM Score (%)":"40.71 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.673,
        "Decode Throughput (tokens\/s)":14.1,
        "Allocated Memory (MB)":83770,
        "Energy (tokens\/kWh)":125786,
        "E2E Latency (s)":18.8,
        "E2E Throughput (tokens\/s)":13.6,
        "Reserved Memory (MB)":84148,
        "Used Memory (MB)":85599
    },
    {
        "Model":"openlm-research\/open_llama_3b_v2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"40.28 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0221,
        "Decode Throughput (tokens\/s)":43.8,
        "Allocated Memory (MB)":7283,
        "Energy (tokens\/kWh)":558659,
        "E2E Latency (s)":5.84,
        "E2E Throughput (tokens\/s)":43.8,
        "Reserved Memory (MB)":7440,
        "Used Memory (MB)":8900
    },
    {
        "Model":"openlm-research\/open_llama_3b_v2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"40.28 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0225,
        "Decode Throughput (tokens\/s)":47.7,
        "Allocated Memory (MB)":7280,
        "Energy (tokens\/kWh)":625000,
        "E2E Latency (s)":5.37,
        "E2E Throughput (tokens\/s)":47.7,
        "Reserved Memory (MB)":7440,
        "Used Memory (MB)":8900
    },
    {
        "Model":"openlm-research\/open_llama_3b_v2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"40.28 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.023,
        "Decode Throughput (tokens\/s)":46.4,
        "Allocated Memory (MB)":7280,
        "Energy (tokens\/kWh)":578034,
        "E2E Latency (s)":5.51,
        "E2E Throughput (tokens\/s)":46.5,
        "Reserved Memory (MB)":7440,
        "Used Memory (MB)":8900
    },
    {
        "Model":"openlm-research\/open_llama_3b_v2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"40.28*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0813,
        "Decode Throughput (tokens\/s)":12.6,
        "Allocated Memory (MB)":4035,
        "Energy (tokens\/kWh)":185528,
        "E2E Latency (s)":20.3,
        "E2E Throughput (tokens\/s)":12.6,
        "Reserved Memory (MB)":4232,
        "Used Memory (MB)":5699
    },
    {
        "Model":"openlm-research\/open_llama_3b_v2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"40.28*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0821,
        "Decode Throughput (tokens\/s)":12.3,
        "Allocated Memory (MB)":4039,
        "Energy (tokens\/kWh)":190476,
        "E2E Latency (s)":20.8,
        "E2E Throughput (tokens\/s)":12.3,
        "Reserved Memory (MB)":4232,
        "Used Memory (MB)":5699
    },
    {
        "Model":"openlm-research\/open_llama_3b_v2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"40.28 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.13,
        "Decode Throughput (tokens\/s)":57.4,
        "Allocated Memory (MB)":14582,
        "Energy (tokens\/kWh)":571428,
        "E2E Latency (s)":4.57,
        "E2E Throughput (tokens\/s)":56.0,
        "Reserved Memory (MB)":14677,
        "Used Memory (MB)":16129
    },
    {
        "Model":"openlm-research\/open_llama_3b_v2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"40.28*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.147,
        "Decode Throughput (tokens\/s)":26.3,
        "Allocated Memory (MB)":2669,
        "Energy (tokens\/kWh)":364963,
        "E2E Latency (s)":9.85,
        "E2E Throughput (tokens\/s)":26.0,
        "Reserved Memory (MB)":2728,
        "Used Memory (MB)":4187
    },
    {
        "Model":"openlm-research\/open_llama_3b_v2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"40.28*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.149,
        "Decode Throughput (tokens\/s)":27.0,
        "Allocated Memory (MB)":2666,
        "Energy (tokens\/kWh)":370370,
        "E2E Latency (s)":9.61,
        "E2E Throughput (tokens\/s)":26.6,
        "Reserved Memory (MB)":2728,
        "Used Memory (MB)":4187
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"GPT-J",
        "Params (B)":6.0,
        "Open LLM Score (%)":"40.10 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0318,
        "Decode Throughput (tokens\/s)":33.5,
        "Allocated Memory (MB)":12726,
        "Energy (tokens\/kWh)":395256,
        "E2E Latency (s)":7.65,
        "E2E Throughput (tokens\/s)":33.5,
        "Reserved Memory (MB)":12769,
        "Used Memory (MB)":14229
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"GPT-J",
        "Params (B)":6.0,
        "Open LLM Score (%)":"40.10 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0318,
        "Decode Throughput (tokens\/s)":32.3,
        "Allocated Memory (MB)":12721,
        "Energy (tokens\/kWh)":409836,
        "E2E Latency (s)":7.92,
        "E2E Throughput (tokens\/s)":32.3,
        "Reserved Memory (MB)":12769,
        "Used Memory (MB)":14229
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"GPT-J",
        "Params (B)":6.0,
        "Open LLM Score (%)":"40.10 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0332,
        "Decode Throughput (tokens\/s)":31.0,
        "Allocated Memory (MB)":12721,
        "Energy (tokens\/kWh)":377358,
        "E2E Latency (s)":8.25,
        "E2E Throughput (tokens\/s)":31.0,
        "Reserved Memory (MB)":12769,
        "Used Memory (MB)":14229
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"GPT-J",
        "Params (B)":6.0,
        "Open LLM Score (%)":"40.10*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0406,
        "Decode Throughput (tokens\/s)":31.2,
        "Allocated Memory (MB)":5593,
        "Energy (tokens\/kWh)":469483,
        "E2E Latency (s)":8.21,
        "E2E Throughput (tokens\/s)":31.2,
        "Reserved Memory (MB)":5647,
        "Used Memory (MB)":7109
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"GPT-J",
        "Params (B)":6.0,
        "Open LLM Score (%)":"40.10*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0412,
        "Decode Throughput (tokens\/s)":30.8,
        "Allocated Memory (MB)":4515,
        "Energy (tokens\/kWh)":434782,
        "E2E Latency (s)":8.31,
        "E2E Throughput (tokens\/s)":30.8,
        "Reserved Memory (MB)":4567,
        "Used Memory (MB)":6029
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"GPT-J",
        "Params (B)":6.0,
        "Open LLM Score (%)":"40.10*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0571,
        "Decode Throughput (tokens\/s)":31.2,
        "Allocated Memory (MB)":4376,
        "Energy (tokens\/kWh)":448430,
        "E2E Latency (s)":8.22,
        "E2E Throughput (tokens\/s)":31.1,
        "Reserved Memory (MB)":4418,
        "Used Memory (MB)":5878
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"GPT-J",
        "Params (B)":6.0,
        "Open LLM Score (%)":"40.10*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0647,
        "Decode Throughput (tokens\/s)":29.0,
        "Allocated Memory (MB)":4376,
        "Energy (tokens\/kWh)":418410,
        "E2E Latency (s)":8.84,
        "E2E Throughput (tokens\/s)":29.0,
        "Reserved Memory (MB)":4418,
        "Used Memory (MB)":5878
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"GPT-J",
        "Params (B)":6.0,
        "Open LLM Score (%)":"40.10*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0833,
        "Decode Throughput (tokens\/s)":11.7,
        "Allocated Memory (MB)":7092,
        "Energy (tokens\/kWh)":176366,
        "E2E Latency (s)":21.9,
        "E2E Throughput (tokens\/s)":11.7,
        "Reserved Memory (MB)":7140,
        "Used Memory (MB)":8608
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"GPT-J",
        "Params (B)":6.0,
        "Open LLM Score (%)":"40.10*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0881,
        "Decode Throughput (tokens\/s)":11.5,
        "Allocated Memory (MB)":7088,
        "Energy (tokens\/kWh)":168634,
        "E2E Latency (s)":22.3,
        "E2E Throughput (tokens\/s)":11.5,
        "Reserved Memory (MB)":7132,
        "Used Memory (MB)":8600
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"GPT-J",
        "Params (B)":6.0,
        "Open LLM Score (%)":"40.10*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.148,
        "Decode Throughput (tokens\/s)":25.2,
        "Allocated Memory (MB)":4381,
        "Energy (tokens\/kWh)":357142,
        "E2E Latency (s)":10.2,
        "E2E Throughput (tokens\/s)":25.1,
        "Reserved Memory (MB)":4487,
        "Used Memory (MB)":5947
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"GPT-J",
        "Params (B)":6.0,
        "Open LLM Score (%)":"40.10 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.213,
        "Decode Throughput (tokens\/s)":33.4,
        "Allocated Memory (MB)":25284,
        "Energy (tokens\/kWh)":333333,
        "E2E Latency (s)":7.84,
        "E2E Throughput (tokens\/s)":32.7,
        "Reserved Memory (MB)":25486,
        "Used Memory (MB)":26937
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"GPT-J",
        "Params (B)":6.0,
        "Open LLM Score (%)":"40.10*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.242,
        "Decode Throughput (tokens\/s)":20.7,
        "Allocated Memory (MB)":4693,
        "Energy (tokens\/kWh)":283286,
        "E2E Latency (s)":12.5,
        "E2E Throughput (tokens\/s)":20.5,
        "Reserved Memory (MB)":4951,
        "Used Memory (MB)":6410
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"GPT-J",
        "Params (B)":6.0,
        "Open LLM Score (%)":"40.10*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.243,
        "Decode Throughput (tokens\/s)":21.6,
        "Allocated Memory (MB)":4693,
        "Energy (tokens\/kWh)":285714,
        "E2E Latency (s)":12.0,
        "E2E Throughput (tokens\/s)":21.3,
        "Reserved Memory (MB)":4951,
        "Used Memory (MB)":6410
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":6.0,
        "Open LLM Score (%)":"40.00 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0348,
        "Decode Throughput (tokens\/s)":29.2,
        "Allocated Memory (MB)":14859,
        "Energy (tokens\/kWh)":349650,
        "E2E Latency (s)":8.75,
        "E2E Throughput (tokens\/s)":29.3,
        "Reserved Memory (MB)":14923,
        "Used Memory (MB)":16382
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":6.0,
        "Open LLM Score (%)":"40.00 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0377,
        "Decode Throughput (tokens\/s)":27.0,
        "Allocated Memory (MB)":14855,
        "Energy (tokens\/kWh)":342465,
        "E2E Latency (s)":9.48,
        "E2E Throughput (tokens\/s)":27.0,
        "Reserved Memory (MB)":14902,
        "Used Memory (MB)":16361
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":6.0,
        "Open LLM Score (%)":"40.00 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0385,
        "Decode Throughput (tokens\/s)":26.9,
        "Allocated Memory (MB)":14855,
        "Energy (tokens\/kWh)":321543,
        "E2E Latency (s)":9.51,
        "E2E Throughput (tokens\/s)":26.9,
        "Reserved Memory (MB)":14902,
        "Used Memory (MB)":16361
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":6.0,
        "Open LLM Score (%)":"40.00*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0457,
        "Decode Throughput (tokens\/s)":27.2,
        "Allocated Memory (MB)":5158,
        "Energy (tokens\/kWh)":377358,
        "E2E Latency (s)":9.44,
        "E2E Throughput (tokens\/s)":27.1,
        "Reserved Memory (MB)":5200,
        "Used Memory (MB)":6662
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":6.0,
        "Open LLM Score (%)":"40.00*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0474,
        "Decode Throughput (tokens\/s)":27.1,
        "Allocated Memory (MB)":6235,
        "Energy (tokens\/kWh)":406504,
        "E2E Latency (s)":9.45,
        "E2E Throughput (tokens\/s)":27.1,
        "Reserved Memory (MB)":6280,
        "Used Memory (MB)":7742
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":6.0,
        "Open LLM Score (%)":"40.00*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0685,
        "Decode Throughput (tokens\/s)":27.2,
        "Allocated Memory (MB)":5020,
        "Energy (tokens\/kWh)":389105,
        "E2E Latency (s)":9.44,
        "E2E Throughput (tokens\/s)":27.1,
        "Reserved Memory (MB)":5075,
        "Used Memory (MB)":6534
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":6.0,
        "Open LLM Score (%)":"40.00*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0771,
        "Decode Throughput (tokens\/s)":26.0,
        "Allocated Memory (MB)":5020,
        "Energy (tokens\/kWh)":366300,
        "E2E Latency (s)":9.9,
        "E2E Throughput (tokens\/s)":25.9,
        "Reserved Memory (MB)":5075,
        "Used Memory (MB)":6534
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":6.0,
        "Open LLM Score (%)":"40.00*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0786,
        "Decode Throughput (tokens\/s)":12.9,
        "Allocated Memory (MB)":8220,
        "Energy (tokens\/kWh)":192307,
        "E2E Latency (s)":19.9,
        "E2E Throughput (tokens\/s)":12.9,
        "Reserved Memory (MB)":8269,
        "Used Memory (MB)":9737
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":6.0,
        "Open LLM Score (%)":"40.00*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0816,
        "Decode Throughput (tokens\/s)":12.3,
        "Allocated Memory (MB)":8216,
        "Energy (tokens\/kWh)":184162,
        "E2E Latency (s)":20.8,
        "E2E Throughput (tokens\/s)":12.3,
        "Reserved Memory (MB)":8248,
        "Used Memory (MB)":9716
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":6.0,
        "Open LLM Score (%)":"40.00*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.176,
        "Decode Throughput (tokens\/s)":23.4,
        "Allocated Memory (MB)":5023,
        "Energy (tokens\/kWh)":321543,
        "E2E Latency (s)":11.1,
        "E2E Throughput (tokens\/s)":23.1,
        "Reserved Memory (MB)":5272,
        "Used Memory (MB)":6731
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":6.0,
        "Open LLM Score (%)":"40.00 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.256,
        "Decode Throughput (tokens\/s)":28.6,
        "Allocated Memory (MB)":29527,
        "Energy (tokens\/kWh)":284900,
        "E2E Latency (s)":9.19,
        "E2E Throughput (tokens\/s)":27.9,
        "Reserved Memory (MB)":29750,
        "Used Memory (MB)":31201
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":6.0,
        "Open LLM Score (%)":"40.00*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.284,
        "Decode Throughput (tokens\/s)":19.6,
        "Allocated Memory (MB)":5351,
        "Energy (tokens\/kWh)":256410,
        "E2E Latency (s)":13.3,
        "E2E Throughput (tokens\/s)":19.2,
        "Reserved Memory (MB)":5454,
        "Used Memory (MB)":6914
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":6.0,
        "Open LLM Score (%)":"40.00*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.286,
        "Decode Throughput (tokens\/s)":20.9,
        "Allocated Memory (MB)":5351,
        "Energy (tokens\/kWh)":268817,
        "E2E Latency (s)":12.5,
        "E2E Throughput (tokens\/s)":20.5,
        "Reserved Memory (MB)":5723,
        "Used Memory (MB)":7182
    },
    {
        "Model":"RWKV\/rwkv-4-14b-pile",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":14.0,
        "Open LLM Score (%)":"39.92 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.055,
        "Decode Throughput (tokens\/s)":24.3,
        "Allocated Memory (MB)":28350,
        "Energy (tokens\/kWh)":264550,
        "E2E Latency (s)":10.6,
        "E2E Throughput (tokens\/s)":24.2,
        "Reserved Memory (MB)":28393,
        "Used Memory (MB)":29852
    },
    {
        "Model":"RWKV\/rwkv-4-14b-pile",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":14.0,
        "Open LLM Score (%)":"39.92*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.136,
        "Decode Throughput (tokens\/s)":7.57,
        "Allocated Memory (MB)":14963,
        "Energy (tokens\/kWh)":108813,
        "E2E Latency (s)":33.8,
        "E2E Throughput (tokens\/s)":7.57,
        "Reserved Memory (MB)":15013,
        "Used Memory (MB)":16481
    },
    {
        "Model":"RWKV\/rwkv-4-14b-pile",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":14.0,
        "Open LLM Score (%)":"39.92 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.517,
        "Decode Throughput (tokens\/s)":22.8,
        "Allocated Memory (MB)":56690,
        "Energy (tokens\/kWh)":196078,
        "E2E Latency (s)":11.7,
        "E2E Throughput (tokens\/s)":21.9,
        "Reserved Memory (MB)":56757,
        "Used Memory (MB)":58208
    },
    {
        "Model":"RWKV\/rwkv-4-14b-pile",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":14.0,
        "Open LLM Score (%)":"39.92*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.538,
        "Decode Throughput (tokens\/s)":13.9,
        "Allocated Memory (MB)":9149,
        "Energy (tokens\/kWh)":178890,
        "E2E Latency (s)":18.8,
        "E2E Throughput (tokens\/s)":13.6,
        "Reserved Memory (MB)":9829,
        "Used Memory (MB)":11288
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.74,
        "Open LLM Score (%)":"39.81 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0301,
        "Decode Throughput (tokens\/s)":43.1,
        "Allocated Memory (MB)":14291,
        "Energy (tokens\/kWh)":492610,
        "E2E Latency (s)":5.94,
        "E2E Throughput (tokens\/s)":43.1,
        "Reserved Memory (MB)":14313,
        "Used Memory (MB)":15772
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.74,
        "Open LLM Score (%)":"39.81 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0321,
        "Decode Throughput (tokens\/s)":40.7,
        "Allocated Memory (MB)":14291,
        "Energy (tokens\/kWh)":452488,
        "E2E Latency (s)":6.3,
        "E2E Throughput (tokens\/s)":40.6,
        "Reserved Memory (MB)":14313,
        "Used Memory (MB)":15772
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.74,
        "Open LLM Score (%)":"39.81 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0329,
        "Decode Throughput (tokens\/s)":43.4,
        "Allocated Memory (MB)":14291,
        "Energy (tokens\/kWh)":458715,
        "E2E Latency (s)":5.91,
        "E2E Throughput (tokens\/s)":43.3,
        "Reserved Memory (MB)":14313,
        "Used Memory (MB)":15772
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.74,
        "Open LLM Score (%)":"39.81*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0405,
        "Decode Throughput (tokens\/s)":39.1,
        "Allocated Memory (MB)":4851,
        "Energy (tokens\/kWh)":526315,
        "E2E Latency (s)":6.56,
        "E2E Throughput (tokens\/s)":39.0,
        "Reserved Memory (MB)":4890,
        "Used Memory (MB)":6352
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.74,
        "Open LLM Score (%)":"39.81*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0409,
        "Decode Throughput (tokens\/s)":39.6,
        "Allocated Memory (MB)":5577,
        "Energy (tokens\/kWh)":574712,
        "E2E Latency (s)":6.48,
        "E2E Throughput (tokens\/s)":39.5,
        "Reserved Memory (MB)":5618,
        "Used Memory (MB)":7079
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.74,
        "Open LLM Score (%)":"39.81*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0612,
        "Decode Throughput (tokens\/s)":40.1,
        "Allocated Memory (MB)":4755,
        "Energy (tokens\/kWh)":543478,
        "E2E Latency (s)":6.42,
        "E2E Throughput (tokens\/s)":39.9,
        "Reserved Memory (MB)":4804,
        "Used Memory (MB)":6264
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.74,
        "Open LLM Score (%)":"39.81*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0712,
        "Decode Throughput (tokens\/s)":37.0,
        "Allocated Memory (MB)":4754,
        "Energy (tokens\/kWh)":492610,
        "E2E Latency (s)":6.97,
        "E2E Throughput (tokens\/s)":36.7,
        "Reserved Memory (MB)":4802,
        "Used Memory (MB)":6262
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.74,
        "Open LLM Score (%)":"39.81*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0949,
        "Decode Throughput (tokens\/s)":10.5,
        "Allocated Memory (MB)":7921,
        "Energy (tokens\/kWh)":157480,
        "E2E Latency (s)":24.3,
        "E2E Throughput (tokens\/s)":10.5,
        "Reserved Memory (MB)":7971,
        "Used Memory (MB)":9439
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.74,
        "Open LLM Score (%)":"39.81*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0988,
        "Decode Throughput (tokens\/s)":10.3,
        "Allocated Memory (MB)":7921,
        "Energy (tokens\/kWh)":152671,
        "E2E Latency (s)":24.9,
        "E2E Throughput (tokens\/s)":10.3,
        "Reserved Memory (MB)":7971,
        "Used Memory (MB)":9439
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.74,
        "Open LLM Score (%)":"39.81*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.167,
        "Decode Throughput (tokens\/s)":29.4,
        "Allocated Memory (MB)":4762,
        "Energy (tokens\/kWh)":393700,
        "E2E Latency (s)":8.83,
        "E2E Throughput (tokens\/s)":29.0,
        "Reserved Memory (MB)":4817,
        "Used Memory (MB)":6276
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.74,
        "Open LLM Score (%)":"39.81 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.238,
        "Decode Throughput (tokens\/s)":41.7,
        "Allocated Memory (MB)":28570,
        "Energy (tokens\/kWh)":361010,
        "E2E Latency (s)":6.35,
        "E2E Throughput (tokens\/s)":40.3,
        "Reserved Memory (MB)":29018,
        "Used Memory (MB)":30469
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.74,
        "Open LLM Score (%)":"39.81*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.267,
        "Decode Throughput (tokens\/s)":23.2,
        "Allocated Memory (MB)":5031,
        "Energy (tokens\/kWh)":294117,
        "E2E Latency (s)":11.3,
        "E2E Throughput (tokens\/s)":22.7,
        "Reserved Memory (MB)":5184,
        "Used Memory (MB)":6643
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":6.74,
        "Open LLM Score (%)":"39.81*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.271,
        "Decode Throughput (tokens\/s)":23.0,
        "Allocated Memory (MB)":5031,
        "Energy (tokens\/kWh)":285714,
        "E2E Latency (s)":11.4,
        "E2E Throughput (tokens\/s)":22.5,
        "Reserved Memory (MB)":5184,
        "Used Memory (MB)":6643
    },
    {
        "Model":"EleutherAI\/pythia-12b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":12.0,
        "Open LLM Score (%)":"39.70 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0451,
        "Decode Throughput (tokens\/s)":43.3,
        "Allocated Memory (MB)":24619,
        "Energy (tokens\/kWh)":384615,
        "E2E Latency (s)":5.94,
        "E2E Throughput (tokens\/s)":43.1,
        "Reserved Memory (MB)":24658,
        "Used Memory (MB)":26117
    },
    {
        "Model":"EleutherAI\/pythia-12b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":12.0,
        "Open LLM Score (%)":"39.70 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0453,
        "Decode Throughput (tokens\/s)":36.6,
        "Allocated Memory (MB)":24619,
        "Energy (tokens\/kWh)":363636,
        "E2E Latency (s)":7.01,
        "E2E Throughput (tokens\/s)":36.5,
        "Reserved Memory (MB)":24647,
        "Used Memory (MB)":26107
    },
    {
        "Model":"EleutherAI\/pythia-12b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":12.0,
        "Open LLM Score (%)":"39.70*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0605,
        "Decode Throughput (tokens\/s)":36.7,
        "Allocated Memory (MB)":8106,
        "Energy (tokens\/kWh)":442477,
        "E2E Latency (s)":7.0,
        "E2E Throughput (tokens\/s)":36.6,
        "Reserved Memory (MB)":8122,
        "Used Memory (MB)":9583
    },
    {
        "Model":"EleutherAI\/pythia-12b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":12.0,
        "Open LLM Score (%)":"39.70*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0617,
        "Decode Throughput (tokens\/s)":37.8,
        "Allocated Memory (MB)":9453,
        "Energy (tokens\/kWh)":510204,
        "E2E Latency (s)":6.8,
        "E2E Throughput (tokens\/s)":37.6,
        "Reserved Memory (MB)":9472,
        "Used Memory (MB)":10934
    },
    {
        "Model":"EleutherAI\/pythia-12b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":12.0,
        "Open LLM Score (%)":"39.70*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0718,
        "Decode Throughput (tokens\/s)":13.8,
        "Allocated Memory (MB)":13360,
        "Energy (tokens\/kWh)":195312,
        "E2E Latency (s)":18.6,
        "E2E Throughput (tokens\/s)":13.8,
        "Reserved Memory (MB)":13390,
        "Used Memory (MB)":14858
    },
    {
        "Model":"EleutherAI\/pythia-12b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":12.0,
        "Open LLM Score (%)":"39.70*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0771,
        "Decode Throughput (tokens\/s)":13.2,
        "Allocated Memory (MB)":13360,
        "Energy (tokens\/kWh)":182815,
        "E2E Latency (s)":19.4,
        "E2E Throughput (tokens\/s)":13.2,
        "Reserved Memory (MB)":13379,
        "Used Memory (MB)":14847
    },
    {
        "Model":"EleutherAI\/pythia-12b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":12.0,
        "Open LLM Score (%)":"39.70*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0964,
        "Decode Throughput (tokens\/s)":36.0,
        "Allocated Memory (MB)":7892,
        "Energy (tokens\/kWh)":432900,
        "E2E Latency (s)":7.18,
        "E2E Throughput (tokens\/s)":35.7,
        "Reserved Memory (MB)":7956,
        "Used Memory (MB)":9416
    },
    {
        "Model":"EleutherAI\/pythia-12b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":12.0,
        "Open LLM Score (%)":"39.70*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.119,
        "Decode Throughput (tokens\/s)":33.4,
        "Allocated Memory (MB)":7893,
        "Energy (tokens\/kWh)":418410,
        "E2E Latency (s)":7.76,
        "E2E Throughput (tokens\/s)":33.0,
        "Reserved Memory (MB)":7956,
        "Used Memory (MB)":9416
    },
    {
        "Model":"EleutherAI\/pythia-12b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":12.0,
        "Open LLM Score (%)":"39.70 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.404,
        "Decode Throughput (tokens\/s)":25.5,
        "Allocated Memory (MB)":49074,
        "Energy (tokens\/kWh)":222222,
        "E2E Latency (s)":10.4,
        "E2E Throughput (tokens\/s)":24.6,
        "Reserved Memory (MB)":49111,
        "Used Memory (MB)":50562
    },
    {
        "Model":"EleutherAI\/pythia-12b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":12.0,
        "Open LLM Score (%)":"39.70*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.449,
        "Decode Throughput (tokens\/s)":22.8,
        "Allocated Memory (MB)":8652,
        "Energy (tokens\/kWh)":274725,
        "E2E Latency (s)":11.6,
        "E2E Throughput (tokens\/s)":22.1,
        "Reserved Memory (MB)":9036,
        "Used Memory (MB)":10496
    },
    {
        "Model":"EleutherAI\/pythia-12b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":12.0,
        "Open LLM Score (%)":"39.70*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.456,
        "Decode Throughput (tokens\/s)":23.8,
        "Allocated Memory (MB)":8652,
        "Energy (tokens\/kWh)":270270,
        "E2E Latency (s)":11.2,
        "E2E Throughput (tokens\/s)":22.9,
        "Reserved Memory (MB)":9036,
        "Used Memory (MB)":10496
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-6.7b-v2",
        "Arch":"GPT-2",
        "Params (B)":7.11,
        "Open LLM Score (%)":"39.49*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0252,
        "Decode Throughput (tokens\/s)":54.5,
        "Allocated Memory (MB)":14110,
        "Energy (tokens\/kWh)":666666,
        "E2E Latency (s)":4.71,
        "E2E Throughput (tokens\/s)":54.4,
        "Reserved Memory (MB)":14136,
        "Used Memory (MB)":15596
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-6.7b-v2",
        "Arch":"GPT-2",
        "Params (B)":7.11,
        "Open LLM Score (%)":"39.49*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0252,
        "Decode Throughput (tokens\/s)":53.9,
        "Allocated Memory (MB)":14110,
        "Energy (tokens\/kWh)":649350,
        "E2E Latency (s)":4.76,
        "E2E Throughput (tokens\/s)":53.8,
        "Reserved Memory (MB)":14136,
        "Used Memory (MB)":15596
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-6.7b-v2",
        "Arch":"GPT-2",
        "Params (B)":7.11,
        "Open LLM Score (%)":"39.49 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0269,
        "Decode Throughput (tokens\/s)":55.6,
        "Allocated Memory (MB)":14110,
        "Energy (tokens\/kWh)":584795,
        "E2E Latency (s)":4.62,
        "E2E Throughput (tokens\/s)":55.4,
        "Reserved Memory (MB)":14136,
        "Used Memory (MB)":15596
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-6.7b-v2",
        "Arch":"GPT-2",
        "Params (B)":7.11,
        "Open LLM Score (%)":"39.49*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.036,
        "Decode Throughput (tokens\/s)":58.1,
        "Allocated Memory (MB)":4709,
        "Energy (tokens\/kWh)":689655,
        "E2E Latency (s)":4.43,
        "E2E Throughput (tokens\/s)":57.8,
        "Reserved Memory (MB)":4739,
        "Used Memory (MB)":6201
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-6.7b-v2",
        "Arch":"GPT-2",
        "Params (B)":7.11,
        "Open LLM Score (%)":"39.49 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.231,
        "Decode Throughput (tokens\/s)":35.5,
        "Allocated Memory (MB)":28075,
        "Energy (tokens\/kWh)":330033,
        "E2E Latency (s)":7.42,
        "E2E Throughput (tokens\/s)":34.5,
        "Reserved Memory (MB)":28233,
        "Used Memory (MB)":29685
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":6.9,
        "Open LLM Score (%)":"39.30 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0276,
        "Decode Throughput (tokens\/s)":48.7,
        "Allocated Memory (MB)":14404,
        "Energy (tokens\/kWh)":510204,
        "E2E Latency (s)":5.27,
        "E2E Throughput (tokens\/s)":48.6,
        "Reserved Memory (MB)":14445,
        "Used Memory (MB)":15904
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":6.9,
        "Open LLM Score (%)":"39.30 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0299,
        "Decode Throughput (tokens\/s)":47.1,
        "Allocated Memory (MB)":14404,
        "Energy (tokens\/kWh)":478468,
        "E2E Latency (s)":5.44,
        "E2E Throughput (tokens\/s)":47.1,
        "Reserved Memory (MB)":14445,
        "Used Memory (MB)":15904
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":6.9,
        "Open LLM Score (%)":"39.30 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0299,
        "Decode Throughput (tokens\/s)":40.0,
        "Allocated Memory (MB)":14403,
        "Energy (tokens\/kWh)":473933,
        "E2E Latency (s)":6.41,
        "E2E Throughput (tokens\/s)":39.9,
        "Reserved Memory (MB)":14445,
        "Used Memory (MB)":15904
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":6.9,
        "Open LLM Score (%)":"39.30 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0315,
        "Decode Throughput (tokens\/s)":40.4,
        "Allocated Memory (MB)":14403,
        "Energy (tokens\/kWh)":431034,
        "E2E Latency (s)":6.34,
        "E2E Throughput (tokens\/s)":40.4,
        "Reserved Memory (MB)":14445,
        "Used Memory (MB)":15904
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":6.9,
        "Open LLM Score (%)":"39.30*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0394,
        "Decode Throughput (tokens\/s)":42.4,
        "Allocated Memory (MB)":5002,
        "Energy (tokens\/kWh)":558659,
        "E2E Latency (s)":6.05,
        "E2E Throughput (tokens\/s)":42.3,
        "Reserved Memory (MB)":5028,
        "Used Memory (MB)":6490
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":6.9,
        "Open LLM Score (%)":"39.30*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0401,
        "Decode Throughput (tokens\/s)":42.8,
        "Allocated Memory (MB)":6080,
        "Energy (tokens\/kWh)":598802,
        "E2E Latency (s)":6.0,
        "E2E Throughput (tokens\/s)":42.7,
        "Reserved Memory (MB)":6109,
        "Used Memory (MB)":7570
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":6.9,
        "Open LLM Score (%)":"39.30*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0637,
        "Decode Throughput (tokens\/s)":15.6,
        "Allocated Memory (MB)":7965,
        "Energy (tokens\/kWh)":230414,
        "E2E Latency (s)":16.4,
        "E2E Throughput (tokens\/s)":15.6,
        "Reserved Memory (MB)":8013,
        "Used Memory (MB)":9481
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":6.9,
        "Open LLM Score (%)":"39.30*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0661,
        "Decode Throughput (tokens\/s)":15.1,
        "Allocated Memory (MB)":7965,
        "Energy (tokens\/kWh)":216450,
        "E2E Latency (s)":17.0,
        "E2E Throughput (tokens\/s)":15.1,
        "Reserved Memory (MB)":8004,
        "Used Memory (MB)":9472
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":6.9,
        "Open LLM Score (%)":"39.30*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0728,
        "Decode Throughput (tokens\/s)":37.7,
        "Allocated Memory (MB)":4866,
        "Energy (tokens\/kWh)":505050,
        "E2E Latency (s)":6.84,
        "E2E Throughput (tokens\/s)":37.4,
        "Reserved Memory (MB)":4901,
        "Used Memory (MB)":6360
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":6.9,
        "Open LLM Score (%)":"39.30*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.162,
        "Decode Throughput (tokens\/s)":33.4,
        "Allocated Memory (MB)":4952,
        "Energy (tokens\/kWh)":446428,
        "E2E Latency (s)":7.8,
        "E2E Throughput (tokens\/s)":32.8,
        "Reserved Memory (MB)":5182,
        "Used Memory (MB)":6641
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":6.9,
        "Open LLM Score (%)":"39.30 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.247,
        "Decode Throughput (tokens\/s)":38.6,
        "Allocated Memory (MB)":28662,
        "Energy (tokens\/kWh)":340136,
        "E2E Latency (s)":6.86,
        "E2E Throughput (tokens\/s)":37.3,
        "Reserved Memory (MB)":28825,
        "Used Memory (MB)":30276
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":6.9,
        "Open LLM Score (%)":"39.30*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.276,
        "Decode Throughput (tokens\/s)":27.9,
        "Allocated Memory (MB)":5343,
        "Energy (tokens\/kWh)":344827,
        "E2E Latency (s)":9.43,
        "E2E Throughput (tokens\/s)":27.1,
        "Reserved Memory (MB)":5584,
        "Used Memory (MB)":7044
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":6.9,
        "Open LLM Score (%)":"39.30*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.277,
        "Decode Throughput (tokens\/s)":26.0,
        "Allocated Memory (MB)":5343,
        "Energy (tokens\/kWh)":322580,
        "E2E Latency (s)":10.1,
        "E2E Throughput (tokens\/s)":25.3,
        "Reserved Memory (MB)":5584,
        "Used Memory (MB)":7044
    },
    {
        "Model":"bigscience\/bloom-7b1",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":7.07,
        "Open LLM Score (%)":"39.18 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0281,
        "Decode Throughput (tokens\/s)":53.1,
        "Allocated Memory (MB)":14651,
        "Energy (tokens\/kWh)":552486,
        "E2E Latency (s)":4.83,
        "E2E Throughput (tokens\/s)":53.0,
        "Reserved Memory (MB)":14690,
        "Used Memory (MB)":16150
    },
    {
        "Model":"bigscience\/bloom-7b1",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":7.07,
        "Open LLM Score (%)":"39.18*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0364,
        "Decode Throughput (tokens\/s)":54.4,
        "Allocated Memory (MB)":5846,
        "Energy (tokens\/kWh)":666666,
        "E2E Latency (s)":4.73,
        "E2E Throughput (tokens\/s)":54.1,
        "Reserved Memory (MB)":5884,
        "Used Memory (MB)":7346
    },
    {
        "Model":"bigscience\/bloom-7b1",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":7.07,
        "Open LLM Score (%)":"39.18*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0365,
        "Decode Throughput (tokens\/s)":54.3,
        "Allocated Memory (MB)":6923,
        "Energy (tokens\/kWh)":735294,
        "E2E Latency (s)":4.74,
        "E2E Throughput (tokens\/s)":54.0,
        "Reserved Memory (MB)":6964,
        "Used Memory (MB)":8426
    },
    {
        "Model":"bigscience\/bloom-7b1",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":7.07,
        "Open LLM Score (%)":"39.18*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0557,
        "Decode Throughput (tokens\/s)":17.5,
        "Allocated Memory (MB)":8616,
        "Energy (tokens\/kWh)":248138,
        "E2E Latency (s)":14.7,
        "E2E Throughput (tokens\/s)":17.4,
        "Reserved Memory (MB)":8640,
        "Used Memory (MB)":10108
    },
    {
        "Model":"bigscience\/bloom-7b1",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":7.07,
        "Open LLM Score (%)":"39.18*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0573,
        "Decode Throughput (tokens\/s)":51.6,
        "Allocated Memory (MB)":5709,
        "Energy (tokens\/kWh)":649350,
        "E2E Latency (s)":5.0,
        "E2E Throughput (tokens\/s)":51.2,
        "Reserved Memory (MB)":5748,
        "Used Memory (MB)":7207
    },
    {
        "Model":"bigscience\/bloom-7b1",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":7.07,
        "Open LLM Score (%)":"39.18*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.059,
        "Decode Throughput (tokens\/s)":17.1,
        "Allocated Memory (MB)":8615,
        "Energy (tokens\/kWh)":245098,
        "E2E Latency (s)":15.0,
        "E2E Throughput (tokens\/s)":17.1,
        "Reserved Memory (MB)":8665,
        "Used Memory (MB)":10133
    },
    {
        "Model":"bigscience\/bloom-7b1",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":7.07,
        "Open LLM Score (%)":"39.18*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0675,
        "Decode Throughput (tokens\/s)":47.8,
        "Allocated Memory (MB)":5709,
        "Energy (tokens\/kWh)":602409,
        "E2E Latency (s)":5.4,
        "E2E Throughput (tokens\/s)":47.4,
        "Reserved Memory (MB)":5748,
        "Used Memory (MB)":7207
    },
    {
        "Model":"bigscience\/bloom-7b1",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":7.07,
        "Open LLM Score (%)":"39.18 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.257,
        "Decode Throughput (tokens\/s)":46.0,
        "Allocated Memory (MB)":29292,
        "Energy (tokens\/kWh)":399999,
        "E2E Latency (s)":5.8,
        "E2E Throughput (tokens\/s)":44.1,
        "Reserved Memory (MB)":29410,
        "Used Memory (MB)":30861
    },
    {
        "Model":"bigscience\/bloom-7b1",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":7.07,
        "Open LLM Score (%)":"39.18*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.257,
        "Decode Throughput (tokens\/s)":31.2,
        "Allocated Memory (MB)":6120,
        "Energy (tokens\/kWh)":381679,
        "E2E Latency (s)":8.44,
        "E2E Throughput (tokens\/s)":30.3,
        "Reserved Memory (MB)":6350,
        "Used Memory (MB)":7809
    },
    {
        "Model":"bigscience\/bloom-7b1",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":7.07,
        "Open LLM Score (%)":"39.18*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.258,
        "Decode Throughput (tokens\/s)":31.8,
        "Allocated Memory (MB)":6120,
        "Energy (tokens\/kWh)":381679,
        "E2E Latency (s)":8.29,
        "E2E Throughput (tokens\/s)":30.9,
        "Reserved Memory (MB)":6350,
        "Used Memory (MB)":7809
    },
    {
        "Model":"EleutherAI\/pythia-12b",
        "Arch":"GPT-NeoX",
        "Params (B)":12.0,
        "Open LLM Score (%)":"38.82 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0446,
        "Decode Throughput (tokens\/s)":43.5,
        "Allocated Memory (MB)":24619,
        "Energy (tokens\/kWh)":381679,
        "E2E Latency (s)":5.9,
        "E2E Throughput (tokens\/s)":43.4,
        "Reserved Memory (MB)":24658,
        "Used Memory (MB)":26117
    },
    {
        "Model":"EleutherAI\/pythia-12b",
        "Arch":"GPT-NeoX",
        "Params (B)":12.0,
        "Open LLM Score (%)":"38.82 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0454,
        "Decode Throughput (tokens\/s)":35.6,
        "Allocated Memory (MB)":24619,
        "Energy (tokens\/kWh)":355871,
        "E2E Latency (s)":7.21,
        "E2E Throughput (tokens\/s)":35.5,
        "Reserved Memory (MB)":24647,
        "Used Memory (MB)":26107
    },
    {
        "Model":"EleutherAI\/pythia-12b",
        "Arch":"GPT-NeoX",
        "Params (B)":12.0,
        "Open LLM Score (%)":"38.82*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0604,
        "Decode Throughput (tokens\/s)":36.8,
        "Allocated Memory (MB)":8106,
        "Energy (tokens\/kWh)":438596,
        "E2E Latency (s)":6.99,
        "E2E Throughput (tokens\/s)":36.6,
        "Reserved Memory (MB)":8122,
        "Used Memory (MB)":9583
    },
    {
        "Model":"EleutherAI\/pythia-12b",
        "Arch":"GPT-NeoX",
        "Params (B)":12.0,
        "Open LLM Score (%)":"38.82*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0614,
        "Decode Throughput (tokens\/s)":37.9,
        "Allocated Memory (MB)":9453,
        "Energy (tokens\/kWh)":512820,
        "E2E Latency (s)":6.79,
        "E2E Throughput (tokens\/s)":37.7,
        "Reserved Memory (MB)":9472,
        "Used Memory (MB)":10934
    },
    {
        "Model":"EleutherAI\/pythia-12b",
        "Arch":"GPT-NeoX",
        "Params (B)":12.0,
        "Open LLM Score (%)":"38.82*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0737,
        "Decode Throughput (tokens\/s)":13.9,
        "Allocated Memory (MB)":13360,
        "Energy (tokens\/kWh)":195694,
        "E2E Latency (s)":18.5,
        "E2E Throughput (tokens\/s)":13.8,
        "Reserved Memory (MB)":13390,
        "Used Memory (MB)":14858
    },
    {
        "Model":"EleutherAI\/pythia-12b",
        "Arch":"GPT-NeoX",
        "Params (B)":12.0,
        "Open LLM Score (%)":"38.82*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0748,
        "Decode Throughput (tokens\/s)":13.3,
        "Allocated Memory (MB)":13360,
        "Energy (tokens\/kWh)":186915,
        "E2E Latency (s)":19.3,
        "E2E Throughput (tokens\/s)":13.3,
        "Reserved Memory (MB)":13379,
        "Used Memory (MB)":14847
    },
    {
        "Model":"EleutherAI\/pythia-12b",
        "Arch":"GPT-NeoX",
        "Params (B)":12.0,
        "Open LLM Score (%)":"38.82*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0955,
        "Decode Throughput (tokens\/s)":35.7,
        "Allocated Memory (MB)":7892,
        "Energy (tokens\/kWh)":442477,
        "E2E Latency (s)":7.25,
        "E2E Throughput (tokens\/s)":35.3,
        "Reserved Memory (MB)":7956,
        "Used Memory (MB)":9416
    },
    {
        "Model":"EleutherAI\/pythia-12b",
        "Arch":"GPT-NeoX",
        "Params (B)":12.0,
        "Open LLM Score (%)":"38.82*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.119,
        "Decode Throughput (tokens\/s)":33.2,
        "Allocated Memory (MB)":7893,
        "Energy (tokens\/kWh)":414937,
        "E2E Latency (s)":7.79,
        "E2E Throughput (tokens\/s)":32.9,
        "Reserved Memory (MB)":7956,
        "Used Memory (MB)":9416
    },
    {
        "Model":"EleutherAI\/pythia-12b",
        "Arch":"GPT-NeoX",
        "Params (B)":12.0,
        "Open LLM Score (%)":"38.82 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.406,
        "Decode Throughput (tokens\/s)":25.5,
        "Allocated Memory (MB)":49074,
        "Energy (tokens\/kWh)":224719,
        "E2E Latency (s)":10.4,
        "E2E Throughput (tokens\/s)":24.6,
        "Reserved Memory (MB)":49111,
        "Used Memory (MB)":50562
    },
    {
        "Model":"EleutherAI\/pythia-12b",
        "Arch":"GPT-NeoX",
        "Params (B)":12.0,
        "Open LLM Score (%)":"38.82*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.446,
        "Decode Throughput (tokens\/s)":22.8,
        "Allocated Memory (MB)":8652,
        "Energy (tokens\/kWh)":274725,
        "E2E Latency (s)":11.6,
        "E2E Throughput (tokens\/s)":22.1,
        "Reserved Memory (MB)":9036,
        "Used Memory (MB)":10496
    },
    {
        "Model":"EleutherAI\/pythia-12b",
        "Arch":"GPT-NeoX",
        "Params (B)":12.0,
        "Open LLM Score (%)":"38.82*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.457,
        "Decode Throughput (tokens\/s)":23.8,
        "Allocated Memory (MB)":8652,
        "Energy (tokens\/kWh)":264550,
        "E2E Latency (s)":11.2,
        "E2E Throughput (tokens\/s)":22.9,
        "Reserved Memory (MB)":9036,
        "Used Memory (MB)":10496
    },
    {
        "Model":"matsuo-lab\/weblab-10b",
        "Arch":"GPT-NeoX",
        "Params (B)":10.0,
        "Open LLM Score (%)":"38.59 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0416,
        "Decode Throughput (tokens\/s)":43.0,
        "Allocated Memory (MB)":22366,
        "Energy (tokens\/kWh)":387596,
        "E2E Latency (s)":5.97,
        "E2E Throughput (tokens\/s)":42.9,
        "Reserved Memory (MB)":22540,
        "Used Memory (MB)":23999
    },
    {
        "Model":"matsuo-lab\/weblab-10b",
        "Arch":"GPT-NeoX",
        "Params (B)":10.0,
        "Open LLM Score (%)":"38.59 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0428,
        "Decode Throughput (tokens\/s)":36.5,
        "Allocated Memory (MB)":22366,
        "Energy (tokens\/kWh)":378787,
        "E2E Latency (s)":7.02,
        "E2E Throughput (tokens\/s)":36.5,
        "Reserved Memory (MB)":22540,
        "Used Memory (MB)":23999
    },
    {
        "Model":"matsuo-lab\/weblab-10b",
        "Arch":"GPT-NeoX",
        "Params (B)":10.0,
        "Open LLM Score (%)":"38.59*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.057,
        "Decode Throughput (tokens\/s)":37.5,
        "Allocated Memory (MB)":8755,
        "Energy (tokens\/kWh)":497512,
        "E2E Latency (s)":6.86,
        "E2E Throughput (tokens\/s)":37.3,
        "Reserved Memory (MB)":8835,
        "Used Memory (MB)":10297
    },
    {
        "Model":"matsuo-lab\/weblab-10b",
        "Arch":"GPT-NeoX",
        "Params (B)":10.0,
        "Open LLM Score (%)":"38.59*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0571,
        "Decode Throughput (tokens\/s)":36.5,
        "Allocated Memory (MB)":7475,
        "Energy (tokens\/kWh)":460829,
        "E2E Latency (s)":7.04,
        "E2E Throughput (tokens\/s)":36.4,
        "Reserved Memory (MB)":7553,
        "Used Memory (MB)":9015
    },
    {
        "Model":"matsuo-lab\/weblab-10b",
        "Arch":"GPT-NeoX",
        "Params (B)":10.0,
        "Open LLM Score (%)":"38.59*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0712,
        "Decode Throughput (tokens\/s)":13.9,
        "Allocated Memory (MB)":12106,
        "Energy (tokens\/kWh)":198412,
        "E2E Latency (s)":18.5,
        "E2E Throughput (tokens\/s)":13.8,
        "Reserved Memory (MB)":12362,
        "Used Memory (MB)":13830
    },
    {
        "Model":"matsuo-lab\/weblab-10b",
        "Arch":"GPT-NeoX",
        "Params (B)":10.0,
        "Open LLM Score (%)":"38.59*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0747,
        "Decode Throughput (tokens\/s)":13.4,
        "Allocated Memory (MB)":12106,
        "Energy (tokens\/kWh)":190114,
        "E2E Latency (s)":19.1,
        "E2E Throughput (tokens\/s)":13.4,
        "Reserved Memory (MB)":12341,
        "Used Memory (MB)":13809
    },
    {
        "Model":"matsuo-lab\/weblab-10b",
        "Arch":"GPT-NeoX",
        "Params (B)":10.0,
        "Open LLM Score (%)":"38.59*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0872,
        "Decode Throughput (tokens\/s)":35.3,
        "Allocated Memory (MB)":7285,
        "Energy (tokens\/kWh)":440528,
        "E2E Latency (s)":7.31,
        "E2E Throughput (tokens\/s)":35.0,
        "Reserved Memory (MB)":7350,
        "Used Memory (MB)":8810
    },
    {
        "Model":"matsuo-lab\/weblab-10b",
        "Arch":"GPT-NeoX",
        "Params (B)":10.0,
        "Open LLM Score (%)":"38.59*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.108,
        "Decode Throughput (tokens\/s)":33.0,
        "Allocated Memory (MB)":7284,
        "Energy (tokens\/kWh)":425531,
        "E2E Latency (s)":7.84,
        "E2E Throughput (tokens\/s)":32.7,
        "Reserved Memory (MB)":7369,
        "Used Memory (MB)":8829
    },
    {
        "Model":"matsuo-lab\/weblab-10b",
        "Arch":"GPT-NeoX",
        "Params (B)":10.0,
        "Open LLM Score (%)":"38.59*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.26,
        "Decode Throughput (tokens\/s)":28.7,
        "Allocated Memory (MB)":7424,
        "Energy (tokens\/kWh)":364963,
        "E2E Latency (s)":9.14,
        "E2E Throughput (tokens\/s)":28.0,
        "Reserved Memory (MB)":7530,
        "Used Memory (MB)":8990
    },
    {
        "Model":"matsuo-lab\/weblab-10b",
        "Arch":"GPT-NeoX",
        "Params (B)":10.0,
        "Open LLM Score (%)":"38.59 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.39,
        "Decode Throughput (tokens\/s)":27.6,
        "Allocated Memory (MB)":44535,
        "Energy (tokens\/kWh)":240963,
        "E2E Latency (s)":9.62,
        "E2E Throughput (tokens\/s)":26.6,
        "Reserved Memory (MB)":44765,
        "Used Memory (MB)":46217
    },
    {
        "Model":"matsuo-lab\/weblab-10b",
        "Arch":"GPT-NeoX",
        "Params (B)":10.0,
        "Open LLM Score (%)":"38.59*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.425,
        "Decode Throughput (tokens\/s)":24.5,
        "Allocated Memory (MB)":7972,
        "Energy (tokens\/kWh)":275482,
        "E2E Latency (s)":10.8,
        "E2E Throughput (tokens\/s)":23.7,
        "Reserved Memory (MB)":8348,
        "Used Memory (MB)":9808
    },
    {
        "Model":"matsuo-lab\/weblab-10b",
        "Arch":"GPT-NeoX",
        "Params (B)":10.0,
        "Open LLM Score (%)":"38.59*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.425,
        "Decode Throughput (tokens\/s)":23.4,
        "Allocated Memory (MB)":7971,
        "Energy (tokens\/kWh)":281690,
        "E2E Latency (s)":11.3,
        "E2E Throughput (tokens\/s)":22.7,
        "Reserved Memory (MB)":8348,
        "Used Memory (MB)":9808
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"GPT-NeoX",
        "Params (B)":3.0,
        "Open LLM Score (%)":"38.54 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0205,
        "Decode Throughput (tokens\/s)":48.9,
        "Allocated Memory (MB)":6068,
        "Energy (tokens\/kWh)":625000,
        "E2E Latency (s)":5.24,
        "E2E Throughput (tokens\/s)":48.9,
        "Reserved Memory (MB)":6144,
        "Used Memory (MB)":7604
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"GPT-NeoX",
        "Params (B)":3.0,
        "Open LLM Score (%)":"38.54 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0232,
        "Decode Throughput (tokens\/s)":43.4,
        "Allocated Memory (MB)":6068,
        "Energy (tokens\/kWh)":555555,
        "E2E Latency (s)":5.89,
        "E2E Throughput (tokens\/s)":43.5,
        "Reserved Memory (MB)":6144,
        "Used Memory (MB)":7604
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"GPT-NeoX",
        "Params (B)":3.0,
        "Open LLM Score (%)":"38.54*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0253,
        "Decode Throughput (tokens\/s)":41.6,
        "Allocated Memory (MB)":3061,
        "Energy (tokens\/kWh)":657894,
        "E2E Latency (s)":6.16,
        "E2E Throughput (tokens\/s)":41.6,
        "Reserved Memory (MB)":3189,
        "Used Memory (MB)":4651
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"GPT-NeoX",
        "Params (B)":3.0,
        "Open LLM Score (%)":"38.54 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0253,
        "Decode Throughput (tokens\/s)":40.3,
        "Allocated Memory (MB)":6068,
        "Energy (tokens\/kWh)":540540,
        "E2E Latency (s)":6.35,
        "E2E Throughput (tokens\/s)":40.3,
        "Reserved Memory (MB)":6144,
        "Used Memory (MB)":7604
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"GPT-NeoX",
        "Params (B)":3.0,
        "Open LLM Score (%)":"38.54*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0254,
        "Decode Throughput (tokens\/s)":42.7,
        "Allocated Memory (MB)":2388,
        "Energy (tokens\/kWh)":617283,
        "E2E Latency (s)":6.0,
        "E2E Throughput (tokens\/s)":42.7,
        "Reserved Memory (MB)":2512,
        "Used Memory (MB)":3974
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"GPT-NeoX",
        "Params (B)":3.0,
        "Open LLM Score (%)":"38.54 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0277,
        "Decode Throughput (tokens\/s)":39.5,
        "Allocated Memory (MB)":6068,
        "Energy (tokens\/kWh)":523560,
        "E2E Latency (s)":6.49,
        "E2E Throughput (tokens\/s)":39.4,
        "Reserved Memory (MB)":6144,
        "Used Memory (MB)":7604
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"GPT-NeoX",
        "Params (B)":3.0,
        "Open LLM Score (%)":"38.54*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0375,
        "Decode Throughput (tokens\/s)":39.7,
        "Allocated Memory (MB)":2340,
        "Energy (tokens\/kWh)":591715,
        "E2E Latency (s)":6.46,
        "E2E Throughput (tokens\/s)":39.6,
        "Reserved Memory (MB)":2480,
        "Used Memory (MB)":3940
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"GPT-NeoX",
        "Params (B)":3.0,
        "Open LLM Score (%)":"38.54*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0401,
        "Decode Throughput (tokens\/s)":37.6,
        "Allocated Memory (MB)":2334,
        "Energy (tokens\/kWh)":558659,
        "E2E Latency (s)":6.82,
        "E2E Throughput (tokens\/s)":37.5,
        "Reserved Memory (MB)":2472,
        "Used Memory (MB)":3932
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"GPT-NeoX",
        "Params (B)":3.0,
        "Open LLM Score (%)":"38.54*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0636,
        "Decode Throughput (tokens\/s)":15.5,
        "Allocated Memory (MB)":3605,
        "Energy (tokens\/kWh)":230946,
        "E2E Latency (s)":16.5,
        "E2E Throughput (tokens\/s)":15.5,
        "Reserved Memory (MB)":3711,
        "Used Memory (MB)":5179
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"GPT-NeoX",
        "Params (B)":3.0,
        "Open LLM Score (%)":"38.54*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0669,
        "Decode Throughput (tokens\/s)":14.8,
        "Allocated Memory (MB)":3605,
        "Energy (tokens\/kWh)":219298,
        "E2E Latency (s)":17.3,
        "E2E Throughput (tokens\/s)":14.8,
        "Reserved Memory (MB)":3711,
        "Used Memory (MB)":5179
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"GPT-NeoX",
        "Params (B)":3.0,
        "Open LLM Score (%)":"38.54*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0796,
        "Decode Throughput (tokens\/s)":33.2,
        "Allocated Memory (MB)":2338,
        "Energy (tokens\/kWh)":490196,
        "E2E Latency (s)":7.77,
        "E2E Throughput (tokens\/s)":32.9,
        "Reserved Memory (MB)":2489,
        "Used Memory (MB)":3948
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"GPT-NeoX",
        "Params (B)":3.0,
        "Open LLM Score (%)":"38.54 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.106,
        "Decode Throughput (tokens\/s)":41.9,
        "Allocated Memory (MB)":12028,
        "Energy (tokens\/kWh)":502512,
        "E2E Latency (s)":6.2,
        "E2E Throughput (tokens\/s)":41.3,
        "Reserved Memory (MB)":12069,
        "Used Memory (MB)":13520
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"GPT-NeoX",
        "Params (B)":3.0,
        "Open LLM Score (%)":"38.54*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.118,
        "Decode Throughput (tokens\/s)":27.0,
        "Allocated Memory (MB)":2457,
        "Energy (tokens\/kWh)":378787,
        "E2E Latency (s)":9.56,
        "E2E Throughput (tokens\/s)":26.8,
        "Reserved Memory (MB)":2589,
        "Used Memory (MB)":4049
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"GPT-NeoX",
        "Params (B)":3.0,
        "Open LLM Score (%)":"38.54*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.123,
        "Decode Throughput (tokens\/s)":25.2,
        "Allocated Memory (MB)":2457,
        "Energy (tokens\/kWh)":362318,
        "E2E Latency (s)":10.2,
        "E2E Throughput (tokens\/s)":25.1,
        "Reserved Memory (MB)":2589,
        "Used Memory (MB)":4049
    },
    {
        "Model":"openlm-research\/open_llama_3b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"38.26 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0225,
        "Decode Throughput (tokens\/s)":42.9,
        "Allocated Memory (MB)":7283,
        "Energy (tokens\/kWh)":558659,
        "E2E Latency (s)":5.96,
        "E2E Throughput (tokens\/s)":43.0,
        "Reserved Memory (MB)":7440,
        "Used Memory (MB)":8900
    },
    {
        "Model":"openlm-research\/open_llama_3b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"38.26 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.023,
        "Decode Throughput (tokens\/s)":46.8,
        "Allocated Memory (MB)":7280,
        "Energy (tokens\/kWh)":584795,
        "E2E Latency (s)":5.47,
        "E2E Throughput (tokens\/s)":46.8,
        "Reserved Memory (MB)":7440,
        "Used Memory (MB)":8900
    },
    {
        "Model":"openlm-research\/open_llama_3b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"38.26 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0231,
        "Decode Throughput (tokens\/s)":47.0,
        "Allocated Memory (MB)":7280,
        "Energy (tokens\/kWh)":613496,
        "E2E Latency (s)":5.44,
        "E2E Throughput (tokens\/s)":47.1,
        "Reserved Memory (MB)":7440,
        "Used Memory (MB)":8900
    },
    {
        "Model":"openlm-research\/open_llama_3b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"38.26*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0825,
        "Decode Throughput (tokens\/s)":12.1,
        "Allocated Memory (MB)":4039,
        "Energy (tokens\/kWh)":188679,
        "E2E Latency (s)":21.1,
        "E2E Throughput (tokens\/s)":12.1,
        "Reserved Memory (MB)":4232,
        "Used Memory (MB)":5699
    },
    {
        "Model":"openlm-research\/open_llama_3b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"38.26*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0828,
        "Decode Throughput (tokens\/s)":12.4,
        "Allocated Memory (MB)":4035,
        "Energy (tokens\/kWh)":184162,
        "E2E Latency (s)":20.7,
        "E2E Throughput (tokens\/s)":12.4,
        "Reserved Memory (MB)":4232,
        "Used Memory (MB)":5699
    },
    {
        "Model":"openlm-research\/open_llama_3b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"38.26 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.13,
        "Decode Throughput (tokens\/s)":57.0,
        "Allocated Memory (MB)":14582,
        "Energy (tokens\/kWh)":571428,
        "E2E Latency (s)":4.6,
        "E2E Throughput (tokens\/s)":55.7,
        "Reserved Memory (MB)":14677,
        "Used Memory (MB)":16129
    },
    {
        "Model":"openlm-research\/open_llama_3b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"38.26*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.147,
        "Decode Throughput (tokens\/s)":26.7,
        "Allocated Memory (MB)":2666,
        "Energy (tokens\/kWh)":366300,
        "E2E Latency (s)":9.71,
        "E2E Throughput (tokens\/s)":26.4,
        "Reserved Memory (MB)":2728,
        "Used Memory (MB)":4187
    },
    {
        "Model":"openlm-research\/open_llama_3b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"38.26*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.147,
        "Decode Throughput (tokens\/s)":26.5,
        "Allocated Memory (MB)":2669,
        "Energy (tokens\/kWh)":355871,
        "E2E Latency (s)":9.79,
        "E2E Throughput (tokens\/s)":26.1,
        "Reserved Memory (MB)":2728,
        "Used Memory (MB)":4187
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"GPT-NeoX",
        "Params (B)":6.65,
        "Open LLM Score (%)":"38.06 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0275,
        "Decode Throughput (tokens\/s)":48.8,
        "Allocated Memory (MB)":14404,
        "Energy (tokens\/kWh)":505050,
        "E2E Latency (s)":5.26,
        "E2E Throughput (tokens\/s)":48.7,
        "Reserved Memory (MB)":14445,
        "Used Memory (MB)":15904
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"GPT-NeoX",
        "Params (B)":6.65,
        "Open LLM Score (%)":"38.06 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0296,
        "Decode Throughput (tokens\/s)":45.3,
        "Allocated Memory (MB)":14404,
        "Energy (tokens\/kWh)":452488,
        "E2E Latency (s)":5.66,
        "E2E Throughput (tokens\/s)":45.2,
        "Reserved Memory (MB)":14445,
        "Used Memory (MB)":15904
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"GPT-NeoX",
        "Params (B)":6.65,
        "Open LLM Score (%)":"38.06 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.03,
        "Decode Throughput (tokens\/s)":41.5,
        "Allocated Memory (MB)":14403,
        "Energy (tokens\/kWh)":476190,
        "E2E Latency (s)":6.17,
        "E2E Throughput (tokens\/s)":41.5,
        "Reserved Memory (MB)":14445,
        "Used Memory (MB)":15904
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"GPT-NeoX",
        "Params (B)":6.65,
        "Open LLM Score (%)":"38.06 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0315,
        "Decode Throughput (tokens\/s)":40.4,
        "Allocated Memory (MB)":14403,
        "Energy (tokens\/kWh)":431034,
        "E2E Latency (s)":6.34,
        "E2E Throughput (tokens\/s)":40.4,
        "Reserved Memory (MB)":14445,
        "Used Memory (MB)":15904
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"GPT-NeoX",
        "Params (B)":6.65,
        "Open LLM Score (%)":"38.06*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0394,
        "Decode Throughput (tokens\/s)":40.0,
        "Allocated Memory (MB)":5002,
        "Energy (tokens\/kWh)":546448,
        "E2E Latency (s)":6.41,
        "E2E Throughput (tokens\/s)":39.9,
        "Reserved Memory (MB)":5028,
        "Used Memory (MB)":6490
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"GPT-NeoX",
        "Params (B)":6.65,
        "Open LLM Score (%)":"38.06*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0401,
        "Decode Throughput (tokens\/s)":40.9,
        "Allocated Memory (MB)":6080,
        "Energy (tokens\/kWh)":595238,
        "E2E Latency (s)":6.28,
        "E2E Throughput (tokens\/s)":40.8,
        "Reserved Memory (MB)":6109,
        "Used Memory (MB)":7570
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"GPT-NeoX",
        "Params (B)":6.65,
        "Open LLM Score (%)":"38.06*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0632,
        "Decode Throughput (tokens\/s)":39.7,
        "Allocated Memory (MB)":4866,
        "Energy (tokens\/kWh)":529100,
        "E2E Latency (s)":6.49,
        "E2E Throughput (tokens\/s)":39.4,
        "Reserved Memory (MB)":4901,
        "Used Memory (MB)":6360
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"GPT-NeoX",
        "Params (B)":6.65,
        "Open LLM Score (%)":"38.06*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0638,
        "Decode Throughput (tokens\/s)":15.6,
        "Allocated Memory (MB)":7965,
        "Energy (tokens\/kWh)":227790,
        "E2E Latency (s)":16.4,
        "E2E Throughput (tokens\/s)":15.6,
        "Reserved Memory (MB)":8013,
        "Used Memory (MB)":9481
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"GPT-NeoX",
        "Params (B)":6.65,
        "Open LLM Score (%)":"38.06*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0671,
        "Decode Throughput (tokens\/s)":15.2,
        "Allocated Memory (MB)":7965,
        "Energy (tokens\/kWh)":217864,
        "E2E Latency (s)":16.9,
        "E2E Throughput (tokens\/s)":15.1,
        "Reserved Memory (MB)":8004,
        "Used Memory (MB)":9472
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"GPT-NeoX",
        "Params (B)":6.65,
        "Open LLM Score (%)":"38.06*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.071,
        "Decode Throughput (tokens\/s)":37.8,
        "Allocated Memory (MB)":4866,
        "Energy (tokens\/kWh)":502512,
        "E2E Latency (s)":6.82,
        "E2E Throughput (tokens\/s)":37.5,
        "Reserved Memory (MB)":4896,
        "Used Memory (MB)":6356
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"GPT-NeoX",
        "Params (B)":6.65,
        "Open LLM Score (%)":"38.06*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.162,
        "Decode Throughput (tokens\/s)":33.9,
        "Allocated Memory (MB)":4952,
        "Energy (tokens\/kWh)":438596,
        "E2E Latency (s)":7.69,
        "E2E Throughput (tokens\/s)":33.3,
        "Reserved Memory (MB)":5182,
        "Used Memory (MB)":6641
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"GPT-NeoX",
        "Params (B)":6.65,
        "Open LLM Score (%)":"38.06 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.246,
        "Decode Throughput (tokens\/s)":38.3,
        "Allocated Memory (MB)":28662,
        "Energy (tokens\/kWh)":341296,
        "E2E Latency (s)":6.91,
        "E2E Throughput (tokens\/s)":37.0,
        "Reserved Memory (MB)":28825,
        "Used Memory (MB)":30276
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"GPT-NeoX",
        "Params (B)":6.65,
        "Open LLM Score (%)":"38.06*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.275,
        "Decode Throughput (tokens\/s)":27.9,
        "Allocated Memory (MB)":5343,
        "Energy (tokens\/kWh)":337837,
        "E2E Latency (s)":9.43,
        "E2E Throughput (tokens\/s)":27.1,
        "Reserved Memory (MB)":5584,
        "Used Memory (MB)":7044
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"GPT-NeoX",
        "Params (B)":6.65,
        "Open LLM Score (%)":"38.06*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.276,
        "Decode Throughput (tokens\/s)":25.7,
        "Allocated Memory (MB)":5343,
        "Energy (tokens\/kWh)":324675,
        "E2E Latency (s)":10.2,
        "E2E Throughput (tokens\/s)":25.1,
        "Reserved Memory (MB)":5584,
        "Used Memory (MB)":7044
    },
    {
        "Model":"RWKV\/rwkv-4-7b-pile",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":7.0,
        "Open LLM Score (%)":"37.95 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0339,
        "Decode Throughput (tokens\/s)":29.9,
        "Allocated Memory (MB)":14829,
        "Energy (tokens\/kWh)":373134,
        "E2E Latency (s)":8.55,
        "E2E Throughput (tokens\/s)":29.9,
        "Reserved Memory (MB)":14881,
        "Used Memory (MB)":16340
    },
    {
        "Model":"RWKV\/rwkv-4-7b-pile",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":7.0,
        "Open LLM Score (%)":"37.95 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0354,
        "Decode Throughput (tokens\/s)":30.2,
        "Allocated Memory (MB)":14829,
        "Energy (tokens\/kWh)":362318,
        "E2E Latency (s)":8.49,
        "E2E Throughput (tokens\/s)":30.2,
        "Reserved Memory (MB)":14881,
        "Used Memory (MB)":16341
    },
    {
        "Model":"RWKV\/rwkv-4-7b-pile",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":7.0,
        "Open LLM Score (%)":"37.95*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.107,
        "Decode Throughput (tokens\/s)":9.41,
        "Allocated Memory (MB)":7875,
        "Energy (tokens\/kWh)":140845,
        "E2E Latency (s)":27.2,
        "E2E Throughput (tokens\/s)":9.41,
        "Reserved Memory (MB)":7891,
        "Used Memory (MB)":9359
    },
    {
        "Model":"RWKV\/rwkv-4-7b-pile",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":7.0,
        "Open LLM Score (%)":"37.95 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.241,
        "Decode Throughput (tokens\/s)":30.8,
        "Allocated Memory (MB)":29649,
        "Energy (tokens\/kWh)":300300,
        "E2E Latency (s)":8.53,
        "E2E Throughput (tokens\/s)":30.0,
        "Reserved Memory (MB)":29725,
        "Used Memory (MB)":31176
    },
    {
        "Model":"RWKV\/rwkv-4-7b-pile",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":7.0,
        "Open LLM Score (%)":"37.95*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.272,
        "Decode Throughput (tokens\/s)":17.5,
        "Allocated Memory (MB)":5081,
        "Energy (tokens\/kWh)":241545,
        "E2E Latency (s)":14.9,
        "E2E Throughput (tokens\/s)":17.2,
        "Reserved Memory (MB)":5360,
        "Used Memory (MB)":6819
    },
    {
        "Model":"Devio\/test-22B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":21.83,
        "Open LLM Score (%)":"37.71 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.077,
        "Decode Throughput (tokens\/s)":28.1,
        "Allocated Memory (MB)":44887,
        "Energy (tokens\/kWh)":254452,
        "E2E Latency (s)":9.17,
        "E2E Throughput (tokens\/s)":27.9,
        "Reserved Memory (MB)":45185,
        "Used Memory (MB)":46644
    },
    {
        "Model":"Devio\/test-22B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":21.83,
        "Open LLM Score (%)":"37.71 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0848,
        "Decode Throughput (tokens\/s)":28.0,
        "Allocated Memory (MB)":44887,
        "Energy (tokens\/kWh)":248756,
        "E2E Latency (s)":9.2,
        "E2E Throughput (tokens\/s)":27.8,
        "Reserved Memory (MB)":45185,
        "Used Memory (MB)":46644
    },
    {
        "Model":"Devio\/test-22B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":21.83,
        "Open LLM Score (%)":"37.71*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.102,
        "Decode Throughput (tokens\/s)":30.8,
        "Allocated Memory (MB)":13546,
        "Energy (tokens\/kWh)":331125,
        "E2E Latency (s)":8.39,
        "E2E Throughput (tokens\/s)":30.5,
        "Reserved Memory (MB)":13734,
        "Used Memory (MB)":15195
    },
    {
        "Model":"Devio\/test-22B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":21.83,
        "Open LLM Score (%)":"37.71*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.103,
        "Decode Throughput (tokens\/s)":32.1,
        "Allocated Memory (MB)":14729,
        "Energy (tokens\/kWh)":398406,
        "E2E Latency (s)":8.05,
        "E2E Throughput (tokens\/s)":31.8,
        "Reserved Memory (MB)":14919,
        "Used Memory (MB)":16380
    },
    {
        "Model":"Devio\/test-22B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":21.83,
        "Open LLM Score (%)":"37.71*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.119,
        "Decode Throughput (tokens\/s)":8.33,
        "Allocated Memory (MB)":23464,
        "Energy (tokens\/kWh)":119331,
        "E2E Latency (s)":30.7,
        "E2E Throughput (tokens\/s)":8.34,
        "Reserved Memory (MB)":23792,
        "Used Memory (MB)":25260
    },
    {
        "Model":"Devio\/test-22B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":21.83,
        "Open LLM Score (%)":"37.71*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.123,
        "Decode Throughput (tokens\/s)":7.97,
        "Allocated Memory (MB)":23464,
        "Energy (tokens\/kWh)":114547,
        "E2E Latency (s)":32.1,
        "E2E Throughput (tokens\/s)":7.98,
        "Reserved Memory (MB)":23792,
        "Used Memory (MB)":25260
    },
    {
        "Model":"Devio\/test-22B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":21.83,
        "Open LLM Score (%)":"37.71*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.161,
        "Decode Throughput (tokens\/s)":32.7,
        "Allocated Memory (MB)":13306,
        "Energy (tokens\/kWh)":347222,
        "E2E Latency (s)":7.97,
        "E2E Throughput (tokens\/s)":32.1,
        "Reserved Memory (MB)":13551,
        "Used Memory (MB)":15011
    },
    {
        "Model":"Devio\/test-22B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":21.83,
        "Open LLM Score (%)":"37.71*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.202,
        "Decode Throughput (tokens\/s)":29.0,
        "Allocated Memory (MB)":13283,
        "Energy (tokens\/kWh)":323624,
        "E2E Latency (s)":9.0,
        "E2E Throughput (tokens\/s)":28.4,
        "Reserved Memory (MB)":13514,
        "Used Memory (MB)":14973
    },
    {
        "Model":"Devio\/test-22B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":21.83,
        "Open LLM Score (%)":"37.71*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.818,
        "Decode Throughput (tokens\/s)":17.6,
        "Allocated Memory (MB)":14203,
        "Energy (tokens\/kWh)":189035,
        "E2E Latency (s)":15.3,
        "E2E Throughput (tokens\/s)":16.7,
        "Reserved Memory (MB)":14847,
        "Used Memory (MB)":16307
    },
    {
        "Model":"Devio\/test-22B",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":21.83,
        "Open LLM Score (%)":"37.71*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.825,
        "Decode Throughput (tokens\/s)":17.7,
        "Allocated Memory (MB)":14203,
        "Energy (tokens\/kWh)":186219,
        "E2E Latency (s)":15.2,
        "E2E Throughput (tokens\/s)":16.8,
        "Reserved Memory (MB)":14847,
        "Used Memory (MB)":16307
    },
    {
        "Model":"cerebras\/Cerebras-GPT-13B",
        "Arch":"GPT-2",
        "Params (B)":13.0,
        "Open LLM Score (%)":"37.40*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0426,
        "Decode Throughput (tokens\/s)":36.3,
        "Allocated Memory (MB)":26723,
        "Energy (tokens\/kWh)":418410,
        "E2E Latency (s)":7.06,
        "E2E Throughput (tokens\/s)":36.3,
        "Reserved Memory (MB)":26744,
        "Used Memory (MB)":28204
    },
    {
        "Model":"cerebras\/Cerebras-GPT-13B",
        "Arch":"GPT-2",
        "Params (B)":13.0,
        "Open LLM Score (%)":"37.40*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0434,
        "Decode Throughput (tokens\/s)":36.8,
        "Allocated Memory (MB)":26723,
        "Energy (tokens\/kWh)":420168,
        "E2E Latency (s)":6.96,
        "E2E Throughput (tokens\/s)":36.8,
        "Reserved Memory (MB)":26744,
        "Used Memory (MB)":28204
    },
    {
        "Model":"cerebras\/Cerebras-GPT-13B",
        "Arch":"GPT-2",
        "Params (B)":13.0,
        "Open LLM Score (%)":"37.40 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0471,
        "Decode Throughput (tokens\/s)":36.8,
        "Allocated Memory (MB)":26723,
        "Energy (tokens\/kWh)":358422,
        "E2E Latency (s)":6.97,
        "E2E Throughput (tokens\/s)":36.7,
        "Reserved Memory (MB)":26755,
        "Used Memory (MB)":28215
    },
    {
        "Model":"cerebras\/Cerebras-GPT-13B",
        "Arch":"GPT-2",
        "Params (B)":13.0,
        "Open LLM Score (%)":"37.40*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0642,
        "Decode Throughput (tokens\/s)":44.9,
        "Allocated Memory (MB)":8352,
        "Energy (tokens\/kWh)":492610,
        "E2E Latency (s)":5.74,
        "E2E Throughput (tokens\/s)":44.6,
        "Reserved Memory (MB)":8390,
        "Used Memory (MB)":9852
    },
    {
        "Model":"cerebras\/Cerebras-GPT-13B",
        "Arch":"GPT-2",
        "Params (B)":13.0,
        "Open LLM Score (%)":"37.40*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.309,
        "Decode Throughput (tokens\/s)":34.6,
        "Allocated Memory (MB)":8169,
        "Energy (tokens\/kWh)":389105,
        "E2E Latency (s)":7.67,
        "E2E Throughput (tokens\/s)":33.4,
        "Reserved Memory (MB)":8365,
        "Used Memory (MB)":9825
    },
    {
        "Model":"cerebras\/Cerebras-GPT-13B",
        "Arch":"GPT-2",
        "Params (B)":13.0,
        "Open LLM Score (%)":"37.40 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.412,
        "Decode Throughput (tokens\/s)":22.2,
        "Allocated Memory (MB)":53269,
        "Energy (tokens\/kWh)":195694,
        "E2E Latency (s)":11.9,
        "E2E Throughput (tokens\/s)":21.5,
        "Reserved Memory (MB)":53309,
        "Used Memory (MB)":54760
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"GPT-NeoX",
        "Params (B)":4.0,
        "Open LLM Score (%)":"37.31 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0295,
        "Decode Throughput (tokens\/s)":33.9,
        "Allocated Memory (MB)":8666,
        "Energy (tokens\/kWh)":444444,
        "E2E Latency (s)":7.56,
        "E2E Throughput (tokens\/s)":33.9,
        "Reserved Memory (MB)":8745,
        "Used Memory (MB)":10204
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"GPT-NeoX",
        "Params (B)":4.0,
        "Open LLM Score (%)":"37.31 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0319,
        "Decode Throughput (tokens\/s)":30.7,
        "Allocated Memory (MB)":8666,
        "Energy (tokens\/kWh)":390625,
        "E2E Latency (s)":8.34,
        "E2E Throughput (tokens\/s)":30.7,
        "Reserved Memory (MB)":8745,
        "Used Memory (MB)":10204
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"GPT-NeoX",
        "Params (B)":4.0,
        "Open LLM Score (%)":"37.31 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.036,
        "Decode Throughput (tokens\/s)":28.2,
        "Allocated Memory (MB)":8666,
        "Energy (tokens\/kWh)":381679,
        "E2E Latency (s)":9.07,
        "E2E Throughput (tokens\/s)":28.2,
        "Reserved Memory (MB)":8745,
        "Used Memory (MB)":10204
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"GPT-NeoX",
        "Params (B)":4.0,
        "Open LLM Score (%)":"37.31 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0367,
        "Decode Throughput (tokens\/s)":27.7,
        "Allocated Memory (MB)":8666,
        "Energy (tokens\/kWh)":370370,
        "E2E Latency (s)":9.25,
        "E2E Throughput (tokens\/s)":27.7,
        "Reserved Memory (MB)":8745,
        "Used Memory (MB)":10204
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"GPT-NeoX",
        "Params (B)":4.0,
        "Open LLM Score (%)":"37.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0375,
        "Decode Throughput (tokens\/s)":28.9,
        "Allocated Memory (MB)":3911,
        "Energy (tokens\/kWh)":446428,
        "E2E Latency (s)":8.85,
        "E2E Throughput (tokens\/s)":28.9,
        "Reserved Memory (MB)":4083,
        "Used Memory (MB)":5544
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"GPT-NeoX",
        "Params (B)":4.0,
        "Open LLM Score (%)":"37.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0382,
        "Decode Throughput (tokens\/s)":27.7,
        "Allocated Memory (MB)":3237,
        "Energy (tokens\/kWh)":409836,
        "E2E Latency (s)":9.25,
        "E2E Throughput (tokens\/s)":27.7,
        "Reserved Memory (MB)":3426,
        "Used Memory (MB)":4888
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"GPT-NeoX",
        "Params (B)":4.0,
        "Open LLM Score (%)":"37.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0534,
        "Decode Throughput (tokens\/s)":26.7,
        "Allocated Memory (MB)":3191,
        "Energy (tokens\/kWh)":404858,
        "E2E Latency (s)":9.6,
        "E2E Throughput (tokens\/s)":26.7,
        "Reserved Memory (MB)":3374,
        "Used Memory (MB)":4833
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"GPT-NeoX",
        "Params (B)":4.0,
        "Open LLM Score (%)":"37.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0577,
        "Decode Throughput (tokens\/s)":25.5,
        "Allocated Memory (MB)":3182,
        "Energy (tokens\/kWh)":378787,
        "E2E Latency (s)":10.1,
        "E2E Throughput (tokens\/s)":25.3,
        "Reserved Memory (MB)":3365,
        "Used Memory (MB)":4825
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"GPT-NeoX",
        "Params (B)":4.0,
        "Open LLM Score (%)":"37.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0915,
        "Decode Throughput (tokens\/s)":10.5,
        "Allocated Memory (MB)":5049,
        "Energy (tokens\/kWh)":155763,
        "E2E Latency (s)":24.5,
        "E2E Throughput (tokens\/s)":10.4,
        "Reserved Memory (MB)":5184,
        "Used Memory (MB)":6652
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"GPT-NeoX",
        "Params (B)":4.0,
        "Open LLM Score (%)":"37.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.101,
        "Decode Throughput (tokens\/s)":10.1,
        "Allocated Memory (MB)":5052,
        "Energy (tokens\/kWh)":150829,
        "E2E Latency (s)":25.3,
        "E2E Throughput (tokens\/s)":10.1,
        "Reserved Memory (MB)":5190,
        "Used Memory (MB)":6658
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"GPT-NeoX",
        "Params (B)":4.0,
        "Open LLM Score (%)":"37.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.114,
        "Decode Throughput (tokens\/s)":22.6,
        "Allocated Memory (MB)":3184,
        "Energy (tokens\/kWh)":327868,
        "E2E Latency (s)":11.4,
        "E2E Throughput (tokens\/s)":22.5,
        "Reserved Memory (MB)":3380,
        "Used Memory (MB)":4840
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"GPT-NeoX",
        "Params (B)":4.0,
        "Open LLM Score (%)":"37.31 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.157,
        "Decode Throughput (tokens\/s)":29.1,
        "Allocated Memory (MB)":17177,
        "Energy (tokens\/kWh)":346020,
        "E2E Latency (s)":8.93,
        "E2E Throughput (tokens\/s)":28.7,
        "Reserved Memory (MB)":17207,
        "Used Memory (MB)":18658
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"GPT-NeoX",
        "Params (B)":4.0,
        "Open LLM Score (%)":"37.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.174,
        "Decode Throughput (tokens\/s)":18.5,
        "Allocated Memory (MB)":3333,
        "Energy (tokens\/kWh)":257069,
        "E2E Latency (s)":14.0,
        "E2E Throughput (tokens\/s)":18.3,
        "Reserved Memory (MB)":3527,
        "Used Memory (MB)":4986
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"GPT-NeoX",
        "Params (B)":4.0,
        "Open LLM Score (%)":"37.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.175,
        "Decode Throughput (tokens\/s)":17.3,
        "Allocated Memory (MB)":3333,
        "Energy (tokens\/kWh)":242718,
        "E2E Latency (s)":14.9,
        "E2E Throughput (tokens\/s)":17.2,
        "Reserved Memory (MB)":3527,
        "Used Memory (MB)":4986
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-6.7b",
        "Arch":"GPT-2",
        "Params (B)":7.11,
        "Open LLM Score (%)":"37.23*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0251,
        "Decode Throughput (tokens\/s)":54.3,
        "Allocated Memory (MB)":14110,
        "Energy (tokens\/kWh)":653594,
        "E2E Latency (s)":4.73,
        "E2E Throughput (tokens\/s)":54.1,
        "Reserved Memory (MB)":14136,
        "Used Memory (MB)":15596
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-6.7b",
        "Arch":"GPT-2",
        "Params (B)":7.11,
        "Open LLM Score (%)":"37.23*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0253,
        "Decode Throughput (tokens\/s)":54.4,
        "Allocated Memory (MB)":14110,
        "Energy (tokens\/kWh)":662251,
        "E2E Latency (s)":4.72,
        "E2E Throughput (tokens\/s)":54.2,
        "Reserved Memory (MB)":14136,
        "Used Memory (MB)":15596
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-6.7b",
        "Arch":"GPT-2",
        "Params (B)":7.11,
        "Open LLM Score (%)":"37.23 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.027,
        "Decode Throughput (tokens\/s)":54.5,
        "Allocated Memory (MB)":14110,
        "Energy (tokens\/kWh)":571428,
        "E2E Latency (s)":4.71,
        "E2E Throughput (tokens\/s)":54.4,
        "Reserved Memory (MB)":14136,
        "Used Memory (MB)":15596
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-6.7b",
        "Arch":"GPT-2",
        "Params (B)":7.11,
        "Open LLM Score (%)":"37.23*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.036,
        "Decode Throughput (tokens\/s)":54.8,
        "Allocated Memory (MB)":4709,
        "Energy (tokens\/kWh)":684931,
        "E2E Latency (s)":4.69,
        "E2E Throughput (tokens\/s)":54.6,
        "Reserved Memory (MB)":4739,
        "Used Memory (MB)":6201
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-6.7b",
        "Arch":"GPT-2",
        "Params (B)":7.11,
        "Open LLM Score (%)":"37.23 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.238,
        "Decode Throughput (tokens\/s)":35.6,
        "Allocated Memory (MB)":28075,
        "Energy (tokens\/kWh)":324675,
        "E2E Latency (s)":7.4,
        "E2E Throughput (tokens\/s)":34.6,
        "Reserved Memory (MB)":28233,
        "Used Memory (MB)":29685
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"GPT-NeoX",
        "Params (B)":2.91,
        "Open LLM Score (%)":"37.09 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0202,
        "Decode Throughput (tokens\/s)":49.6,
        "Allocated Memory (MB)":6052,
        "Energy (tokens\/kWh)":645161,
        "E2E Latency (s)":5.16,
        "E2E Throughput (tokens\/s)":49.6,
        "Reserved Memory (MB)":6123,
        "Used Memory (MB)":7583
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"GPT-NeoX",
        "Params (B)":2.91,
        "Open LLM Score (%)":"37.09 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0236,
        "Decode Throughput (tokens\/s)":43.1,
        "Allocated Memory (MB)":6052,
        "Energy (tokens\/kWh)":578034,
        "E2E Latency (s)":5.94,
        "E2E Throughput (tokens\/s)":43.1,
        "Reserved Memory (MB)":6123,
        "Used Memory (MB)":7583
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"GPT-NeoX",
        "Params (B)":2.91,
        "Open LLM Score (%)":"37.09 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0247,
        "Decode Throughput (tokens\/s)":40.3,
        "Allocated Memory (MB)":6052,
        "Energy (tokens\/kWh)":552486,
        "E2E Latency (s)":6.34,
        "E2E Throughput (tokens\/s)":40.4,
        "Reserved Memory (MB)":6123,
        "Used Memory (MB)":7583
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"GPT-NeoX",
        "Params (B)":2.91,
        "Open LLM Score (%)":"37.09*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0254,
        "Decode Throughput (tokens\/s)":42.6,
        "Allocated Memory (MB)":3045,
        "Energy (tokens\/kWh)":649350,
        "E2E Latency (s)":6.01,
        "E2E Throughput (tokens\/s)":42.6,
        "Reserved Memory (MB)":3168,
        "Used Memory (MB)":4630
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"GPT-NeoX",
        "Params (B)":2.91,
        "Open LLM Score (%)":"37.09*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0255,
        "Decode Throughput (tokens\/s)":42.5,
        "Allocated Memory (MB)":2372,
        "Energy (tokens\/kWh)":621118,
        "E2E Latency (s)":6.03,
        "E2E Throughput (tokens\/s)":42.5,
        "Reserved Memory (MB)":2493,
        "Used Memory (MB)":3955
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"GPT-NeoX",
        "Params (B)":2.91,
        "Open LLM Score (%)":"37.09 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0256,
        "Decode Throughput (tokens\/s)":41.3,
        "Allocated Memory (MB)":6052,
        "Energy (tokens\/kWh)":531914,
        "E2E Latency (s)":6.21,
        "E2E Throughput (tokens\/s)":41.2,
        "Reserved Memory (MB)":6123,
        "Used Memory (MB)":7583
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"GPT-NeoX",
        "Params (B)":2.91,
        "Open LLM Score (%)":"37.09*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0359,
        "Decode Throughput (tokens\/s)":40.3,
        "Allocated Memory (MB)":2324,
        "Energy (tokens\/kWh)":602409,
        "E2E Latency (s)":6.36,
        "E2E Throughput (tokens\/s)":40.3,
        "Reserved Memory (MB)":2438,
        "Used Memory (MB)":3898
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"GPT-NeoX",
        "Params (B)":2.91,
        "Open LLM Score (%)":"37.09*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0404,
        "Decode Throughput (tokens\/s)":37.9,
        "Allocated Memory (MB)":2318,
        "Energy (tokens\/kWh)":558659,
        "E2E Latency (s)":6.77,
        "E2E Throughput (tokens\/s)":37.8,
        "Reserved Memory (MB)":2432,
        "Used Memory (MB)":3892
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"GPT-NeoX",
        "Params (B)":2.91,
        "Open LLM Score (%)":"37.09*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0636,
        "Decode Throughput (tokens\/s)":15.4,
        "Allocated Memory (MB)":3588,
        "Energy (tokens\/kWh)":231481,
        "E2E Latency (s)":16.7,
        "E2E Throughput (tokens\/s)":15.3,
        "Reserved Memory (MB)":3688,
        "Used Memory (MB)":5156
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"GPT-NeoX",
        "Params (B)":2.91,
        "Open LLM Score (%)":"37.09*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0667,
        "Decode Throughput (tokens\/s)":14.9,
        "Allocated Memory (MB)":3589,
        "Energy (tokens\/kWh)":222717,
        "E2E Latency (s)":17.2,
        "E2E Throughput (tokens\/s)":14.9,
        "Reserved Memory (MB)":3688,
        "Used Memory (MB)":5156
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"GPT-NeoX",
        "Params (B)":2.91,
        "Open LLM Score (%)":"37.09*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0783,
        "Decode Throughput (tokens\/s)":34.0,
        "Allocated Memory (MB)":2321,
        "Energy (tokens\/kWh)":492610,
        "E2E Latency (s)":7.57,
        "E2E Throughput (tokens\/s)":33.8,
        "Reserved Memory (MB)":2468,
        "Used Memory (MB)":3927
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"GPT-NeoX",
        "Params (B)":2.91,
        "Open LLM Score (%)":"37.09 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.106,
        "Decode Throughput (tokens\/s)":41.6,
        "Allocated Memory (MB)":11995,
        "Energy (tokens\/kWh)":507614,
        "E2E Latency (s)":6.24,
        "E2E Throughput (tokens\/s)":41.0,
        "Reserved Memory (MB)":12043,
        "Used Memory (MB)":13495
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"GPT-NeoX",
        "Params (B)":2.91,
        "Open LLM Score (%)":"37.09*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.121,
        "Decode Throughput (tokens\/s)":25.0,
        "Allocated Memory (MB)":2439,
        "Energy (tokens\/kWh)":357142,
        "E2E Latency (s)":10.3,
        "E2E Throughput (tokens\/s)":24.9,
        "Reserved Memory (MB)":2548,
        "Used Memory (MB)":4007
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"GPT-NeoX",
        "Params (B)":2.91,
        "Open LLM Score (%)":"37.09*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.122,
        "Decode Throughput (tokens\/s)":27.2,
        "Allocated Memory (MB)":2439,
        "Energy (tokens\/kWh)":370370,
        "E2E Latency (s)":9.5,
        "E2E Throughput (tokens\/s)":26.9,
        "Reserved Memory (MB)":2548,
        "Used Memory (MB)":4007
    },
    {
        "Model":"tiiuae\/falcon-rw-1b",
        "Arch":"\ud83e\udd85 Falcon",
        "Params (B)":1.0,
        "Open LLM Score (%)":"37.07 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.015,
        "Decode Throughput (tokens\/s)":66.8,
        "Allocated Memory (MB)":2834,
        "Energy (tokens\/kWh)":854700,
        "E2E Latency (s)":3.84,
        "E2E Throughput (tokens\/s)":66.7,
        "Reserved Memory (MB)":2858,
        "Used Memory (MB)":4317
    },
    {
        "Model":"tiiuae\/falcon-rw-1b",
        "Arch":"\ud83e\udd85 Falcon",
        "Params (B)":1.0,
        "Open LLM Score (%)":"37.07*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0155,
        "Decode Throughput (tokens\/s)":70.1,
        "Allocated Memory (MB)":1080,
        "Energy (tokens\/kWh)":1028806,
        "E2E Latency (s)":3.66,
        "E2E Throughput (tokens\/s)":69.9,
        "Reserved Memory (MB)":1121,
        "Used Memory (MB)":2583
    },
    {
        "Model":"tiiuae\/falcon-rw-1b",
        "Arch":"\ud83e\udd85 Falcon",
        "Params (B)":1.0,
        "Open LLM Score (%)":"37.07 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.017,
        "Decode Throughput (tokens\/s)":65.1,
        "Allocated Memory (MB)":2834,
        "Energy (tokens\/kWh)":892857,
        "E2E Latency (s)":3.94,
        "E2E Throughput (tokens\/s)":65.0,
        "Reserved Memory (MB)":2858,
        "Used Memory (MB)":4317
    },
    {
        "Model":"tiiuae\/falcon-rw-1b",
        "Arch":"\ud83e\udd85 Falcon",
        "Params (B)":1.0,
        "Open LLM Score (%)":"37.07*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0183,
        "Decode Throughput (tokens\/s)":65.7,
        "Allocated Memory (MB)":1045,
        "Energy (tokens\/kWh)":943396,
        "E2E Latency (s)":3.9,
        "E2E Throughput (tokens\/s)":65.6,
        "Reserved Memory (MB)":1075,
        "Used Memory (MB)":2535
    },
    {
        "Model":"tiiuae\/falcon-rw-1b",
        "Arch":"\ud83e\udd85 Falcon",
        "Params (B)":1.0,
        "Open LLM Score (%)":"37.07*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0193,
        "Decode Throughput (tokens\/s)":60.1,
        "Allocated Memory (MB)":1045,
        "Energy (tokens\/kWh)":877192,
        "E2E Latency (s)":4.26,
        "E2E Throughput (tokens\/s)":60.1,
        "Reserved Memory (MB)":1075,
        "Used Memory (MB)":2535
    },
    {
        "Model":"tiiuae\/falcon-rw-1b",
        "Arch":"\ud83e\udd85 Falcon",
        "Params (B)":1.0,
        "Open LLM Score (%)":"37.07*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0362,
        "Decode Throughput (tokens\/s)":53.9,
        "Allocated Memory (MB)":1047,
        "Energy (tokens\/kWh)":793650,
        "E2E Latency (s)":4.77,
        "E2E Throughput (tokens\/s)":53.7,
        "Reserved Memory (MB)":1082,
        "Used Memory (MB)":2541
    },
    {
        "Model":"tiiuae\/falcon-rw-1b",
        "Arch":"\ud83e\udd85 Falcon",
        "Params (B)":1.0,
        "Open LLM Score (%)":"37.07*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0473,
        "Decode Throughput (tokens\/s)":21.4,
        "Allocated Memory (MB)":1629,
        "Energy (tokens\/kWh)":320512,
        "E2E Latency (s)":11.9,
        "E2E Throughput (tokens\/s)":21.5,
        "Reserved Memory (MB)":1652,
        "Used Memory (MB)":3120
    },
    {
        "Model":"tiiuae\/falcon-rw-1b",
        "Arch":"\ud83e\udd85 Falcon",
        "Params (B)":1.0,
        "Open LLM Score (%)":"37.07 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0521,
        "Decode Throughput (tokens\/s)":72.2,
        "Allocated Memory (MB)":5659,
        "Energy (tokens\/kWh)":847457,
        "E2E Latency (s)":3.58,
        "E2E Throughput (tokens\/s)":71.5,
        "Reserved Memory (MB)":5700,
        "Used Memory (MB)":7151
    },
    {
        "Model":"tiiuae\/falcon-rw-1b",
        "Arch":"\ud83e\udd85 Falcon",
        "Params (B)":1.0,
        "Open LLM Score (%)":"37.07*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0578,
        "Decode Throughput (tokens\/s)":39.0,
        "Allocated Memory (MB)":1097,
        "Energy (tokens\/kWh)":558659,
        "E2E Latency (s)":6.6,
        "E2E Throughput (tokens\/s)":38.8,
        "Reserved Memory (MB)":1153,
        "Used Memory (MB)":2612
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":2.91,
        "Open LLM Score (%)":"36.72 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0204,
        "Decode Throughput (tokens\/s)":48.9,
        "Allocated Memory (MB)":6052,
        "Energy (tokens\/kWh)":649350,
        "E2E Latency (s)":5.24,
        "E2E Throughput (tokens\/s)":48.9,
        "Reserved Memory (MB)":6123,
        "Used Memory (MB)":7583
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":2.91,
        "Open LLM Score (%)":"36.72 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0236,
        "Decode Throughput (tokens\/s)":44.0,
        "Allocated Memory (MB)":6052,
        "Energy (tokens\/kWh)":549450,
        "E2E Latency (s)":5.82,
        "E2E Throughput (tokens\/s)":44.0,
        "Reserved Memory (MB)":6123,
        "Used Memory (MB)":7583
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":2.91,
        "Open LLM Score (%)":"36.72 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0245,
        "Decode Throughput (tokens\/s)":40.7,
        "Allocated Memory (MB)":6052,
        "Energy (tokens\/kWh)":555555,
        "E2E Latency (s)":6.29,
        "E2E Throughput (tokens\/s)":40.7,
        "Reserved Memory (MB)":6123,
        "Used Memory (MB)":7583
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":2.91,
        "Open LLM Score (%)":"36.72*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0251,
        "Decode Throughput (tokens\/s)":42.9,
        "Allocated Memory (MB)":3045,
        "Energy (tokens\/kWh)":657894,
        "E2E Latency (s)":5.97,
        "E2E Throughput (tokens\/s)":42.9,
        "Reserved Memory (MB)":3168,
        "Used Memory (MB)":4630
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":2.91,
        "Open LLM Score (%)":"36.72*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0256,
        "Decode Throughput (tokens\/s)":42.2,
        "Allocated Memory (MB)":2372,
        "Energy (tokens\/kWh)":617283,
        "E2E Latency (s)":6.07,
        "E2E Throughput (tokens\/s)":42.2,
        "Reserved Memory (MB)":2493,
        "Used Memory (MB)":3955
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":2.91,
        "Open LLM Score (%)":"36.72 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.026,
        "Decode Throughput (tokens\/s)":40.4,
        "Allocated Memory (MB)":6052,
        "Energy (tokens\/kWh)":537634,
        "E2E Latency (s)":6.34,
        "E2E Throughput (tokens\/s)":40.4,
        "Reserved Memory (MB)":6123,
        "Used Memory (MB)":7583
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":2.91,
        "Open LLM Score (%)":"36.72*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0359,
        "Decode Throughput (tokens\/s)":39.8,
        "Allocated Memory (MB)":2324,
        "Energy (tokens\/kWh)":591715,
        "E2E Latency (s)":6.44,
        "E2E Throughput (tokens\/s)":39.8,
        "Reserved Memory (MB)":2438,
        "Used Memory (MB)":3898
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":2.91,
        "Open LLM Score (%)":"36.72*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.04,
        "Decode Throughput (tokens\/s)":37.4,
        "Allocated Memory (MB)":2318,
        "Energy (tokens\/kWh)":561797,
        "E2E Latency (s)":6.86,
        "E2E Throughput (tokens\/s)":37.3,
        "Reserved Memory (MB)":2432,
        "Used Memory (MB)":3892
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":2.91,
        "Open LLM Score (%)":"36.72*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0636,
        "Decode Throughput (tokens\/s)":15.4,
        "Allocated Memory (MB)":3588,
        "Energy (tokens\/kWh)":228310,
        "E2E Latency (s)":16.7,
        "E2E Throughput (tokens\/s)":15.3,
        "Reserved Memory (MB)":3688,
        "Used Memory (MB)":5156
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":2.91,
        "Open LLM Score (%)":"36.72*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0674,
        "Decode Throughput (tokens\/s)":15.1,
        "Allocated Memory (MB)":3589,
        "Energy (tokens\/kWh)":219298,
        "E2E Latency (s)":17.0,
        "E2E Throughput (tokens\/s)":15.1,
        "Reserved Memory (MB)":3688,
        "Used Memory (MB)":5156
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":2.91,
        "Open LLM Score (%)":"36.72*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0776,
        "Decode Throughput (tokens\/s)":34.2,
        "Allocated Memory (MB)":2321,
        "Energy (tokens\/kWh)":497512,
        "E2E Latency (s)":7.54,
        "E2E Throughput (tokens\/s)":34.0,
        "Reserved Memory (MB)":2468,
        "Used Memory (MB)":3927
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":2.91,
        "Open LLM Score (%)":"36.72 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.105,
        "Decode Throughput (tokens\/s)":41.4,
        "Allocated Memory (MB)":11995,
        "Energy (tokens\/kWh)":497512,
        "E2E Latency (s)":6.27,
        "E2E Throughput (tokens\/s)":40.8,
        "Reserved Memory (MB)":12043,
        "Used Memory (MB)":13495
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":2.91,
        "Open LLM Score (%)":"36.72*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.118,
        "Decode Throughput (tokens\/s)":26.9,
        "Allocated Memory (MB)":2439,
        "Energy (tokens\/kWh)":377358,
        "E2E Latency (s)":9.61,
        "E2E Throughput (tokens\/s)":26.6,
        "Reserved Memory (MB)":2548,
        "Used Memory (MB)":4007
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":2.91,
        "Open LLM Score (%)":"36.72*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.123,
        "Decode Throughput (tokens\/s)":25.6,
        "Allocated Memory (MB)":2439,
        "Energy (tokens\/kWh)":355871,
        "E2E Latency (s)":10.1,
        "E2E Throughput (tokens\/s)":25.3,
        "Reserved Memory (MB)":2548,
        "Used Memory (MB)":4007
    },
    {
        "Model":"TinyLlama\/TinyLlama-1.1B-intermediate-step-1431k-3T",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"36.42 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0171,
        "Decode Throughput (tokens\/s)":57.2,
        "Allocated Memory (MB)":2279,
        "Energy (tokens\/kWh)":833333,
        "E2E Latency (s)":4.48,
        "E2E Throughput (tokens\/s)":57.1,
        "Reserved Memory (MB)":2403,
        "Used Memory (MB)":3862
    },
    {
        "Model":"TinyLlama\/TinyLlama-1.1B-intermediate-step-1431k-3T",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"36.42 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0179,
        "Decode Throughput (tokens\/s)":53.6,
        "Allocated Memory (MB)":2279,
        "Energy (tokens\/kWh)":740740,
        "E2E Latency (s)":4.78,
        "E2E Throughput (tokens\/s)":53.6,
        "Reserved Memory (MB)":2403,
        "Used Memory (MB)":3862
    },
    {
        "Model":"TinyLlama\/TinyLlama-1.1B-intermediate-step-1431k-3T",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"36.42 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0181,
        "Decode Throughput (tokens\/s)":53.9,
        "Allocated Memory (MB)":2279,
        "Energy (tokens\/kWh)":751879,
        "E2E Latency (s)":4.75,
        "E2E Throughput (tokens\/s)":53.9,
        "Reserved Memory (MB)":2403,
        "Used Memory (MB)":3862
    },
    {
        "Model":"TinyLlama\/TinyLlama-1.1B-intermediate-step-1431k-3T",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"36.42*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0195,
        "Decode Throughput (tokens\/s)":48.4,
        "Allocated Memory (MB)":851,
        "Energy (tokens\/kWh)":709219,
        "E2E Latency (s)":5.29,
        "E2E Throughput (tokens\/s)":48.4,
        "Reserved Memory (MB)":935,
        "Used Memory (MB)":2394
    },
    {
        "Model":"TinyLlama\/TinyLlama-1.1B-intermediate-step-1431k-3T",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"36.42*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0202,
        "Decode Throughput (tokens\/s)":51.1,
        "Allocated Memory (MB)":1248,
        "Energy (tokens\/kWh)":806451,
        "E2E Latency (s)":5.01,
        "E2E Throughput (tokens\/s)":51.1,
        "Reserved Memory (MB)":1304,
        "Used Memory (MB)":2766
    },
    {
        "Model":"TinyLlama\/TinyLlama-1.1B-intermediate-step-1431k-3T",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"36.42*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0202,
        "Decode Throughput (tokens\/s)":50.1,
        "Allocated Memory (MB)":852,
        "Energy (tokens\/kWh)":787401,
        "E2E Latency (s)":5.11,
        "E2E Throughput (tokens\/s)":50.1,
        "Reserved Memory (MB)":935,
        "Used Memory (MB)":2394
    },
    {
        "Model":"TinyLlama\/TinyLlama-1.1B-intermediate-step-1431k-3T",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"36.42*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0206,
        "Decode Throughput (tokens\/s)":50.8,
        "Allocated Memory (MB)":877,
        "Energy (tokens\/kWh)":775193,
        "E2E Latency (s)":5.04,
        "E2E Throughput (tokens\/s)":50.8,
        "Reserved Memory (MB)":933,
        "Used Memory (MB)":2394
    },
    {
        "Model":"TinyLlama\/TinyLlama-1.1B-intermediate-step-1431k-3T",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"36.42 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0432,
        "Decode Throughput (tokens\/s)":56.8,
        "Allocated Memory (MB)":4492,
        "Energy (tokens\/kWh)":751879,
        "E2E Latency (s)":4.53,
        "E2E Throughput (tokens\/s)":56.5,
        "Reserved Memory (MB)":4548,
        "Used Memory (MB)":5999
    },
    {
        "Model":"TinyLlama\/TinyLlama-1.1B-intermediate-step-1431k-3T",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"36.42*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0443,
        "Decode Throughput (tokens\/s)":37.0,
        "Allocated Memory (MB)":869,
        "Energy (tokens\/kWh)":591715,
        "E2E Latency (s)":6.94,
        "E2E Throughput (tokens\/s)":36.9,
        "Reserved Memory (MB)":922,
        "Used Memory (MB)":2382
    },
    {
        "Model":"TinyLlama\/TinyLlama-1.1B-intermediate-step-1431k-3T",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"36.42*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0483,
        "Decode Throughput (tokens\/s)":32.2,
        "Allocated Memory (MB)":924,
        "Energy (tokens\/kWh)":471698,
        "E2E Latency (s)":7.97,
        "E2E Throughput (tokens\/s)":32.1,
        "Reserved Memory (MB)":1008,
        "Used Memory (MB)":2468
    },
    {
        "Model":"TinyLlama\/TinyLlama-1.1B-intermediate-step-1431k-3T",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"36.42*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0492,
        "Decode Throughput (tokens\/s)":31.4,
        "Allocated Memory (MB)":924,
        "Energy (tokens\/kWh)":465116,
        "E2E Latency (s)":8.18,
        "E2E Throughput (tokens\/s)":31.3,
        "Reserved Memory (MB)":1008,
        "Used Memory (MB)":2468
    },
    {
        "Model":"TinyLlama\/TinyLlama-1.1B-intermediate-step-1431k-3T",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"36.42*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0651,
        "Decode Throughput (tokens\/s)":15.2,
        "Allocated Memory (MB)":1380,
        "Energy (tokens\/kWh)":238095,
        "E2E Latency (s)":16.9,
        "E2E Throughput (tokens\/s)":15.1,
        "Reserved Memory (MB)":1421,
        "Used Memory (MB)":2889
    },
    {
        "Model":"TinyLlama\/TinyLlama-1.1B-intermediate-step-1431k-3T",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"36.42*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0701,
        "Decode Throughput (tokens\/s)":14.3,
        "Allocated Memory (MB)":1380,
        "Energy (tokens\/kWh)":216450,
        "E2E Latency (s)":17.9,
        "E2E Throughput (tokens\/s)":14.3,
        "Reserved Memory (MB)":1421,
        "Used Memory (MB)":2889
    },
    {
        "Model":"facebook\/xglm-7.5B",
        "Arch":"XGLM",
        "Params (B)":7.5,
        "Open LLM Score (%)":"36.38 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0308,
        "Decode Throughput (tokens\/s)":52.5,
        "Allocated Memory (MB)":15548,
        "Energy (tokens\/kWh)":540540,
        "E2E Latency (s)":4.89,
        "E2E Throughput (tokens\/s)":52.4,
        "Reserved Memory (MB)":15583,
        "Used Memory (MB)":17043
    },
    {
        "Model":"facebook\/xglm-7.5B",
        "Arch":"XGLM",
        "Params (B)":7.5,
        "Open LLM Score (%)":"36.38*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0402,
        "Decode Throughput (tokens\/s)":52.1,
        "Allocated Memory (MB)":6149,
        "Energy (tokens\/kWh)":632911,
        "E2E Latency (s)":4.93,
        "E2E Throughput (tokens\/s)":51.9,
        "Reserved Memory (MB)":6199,
        "Used Memory (MB)":7660
    },
    {
        "Model":"facebook\/xglm-7.5B",
        "Arch":"XGLM",
        "Params (B)":7.5,
        "Open LLM Score (%)":"36.38*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0411,
        "Decode Throughput (tokens\/s)":53.0,
        "Allocated Memory (MB)":7228,
        "Energy (tokens\/kWh)":709219,
        "E2E Latency (s)":4.85,
        "E2E Throughput (tokens\/s)":52.8,
        "Reserved Memory (MB)":7279,
        "Used Memory (MB)":8740
    },
    {
        "Model":"facebook\/xglm-7.5B",
        "Arch":"XGLM",
        "Params (B)":7.5,
        "Open LLM Score (%)":"36.38*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0612,
        "Decode Throughput (tokens\/s)":50.0,
        "Allocated Memory (MB)":6011,
        "Energy (tokens\/kWh)":617283,
        "E2E Latency (s)":5.16,
        "E2E Throughput (tokens\/s)":49.6,
        "Reserved Memory (MB)":6056,
        "Used Memory (MB)":7516
    },
    {
        "Model":"facebook\/xglm-7.5B",
        "Arch":"XGLM",
        "Params (B)":7.5,
        "Open LLM Score (%)":"36.38*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0703,
        "Decode Throughput (tokens\/s)":43.5,
        "Allocated Memory (MB)":6011,
        "Energy (tokens\/kWh)":552486,
        "E2E Latency (s)":5.93,
        "E2E Throughput (tokens\/s)":43.2,
        "Reserved Memory (MB)":6056,
        "Used Memory (MB)":7516
    },
    {
        "Model":"facebook\/xglm-7.5B",
        "Arch":"XGLM",
        "Params (B)":7.5,
        "Open LLM Score (%)":"36.38*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0823,
        "Decode Throughput (tokens\/s)":12.4,
        "Allocated Memory (MB)":9110,
        "Energy (tokens\/kWh)":179211,
        "E2E Latency (s)":20.7,
        "E2E Throughput (tokens\/s)":12.4,
        "Reserved Memory (MB)":9145,
        "Used Memory (MB)":10613
    },
    {
        "Model":"facebook\/xglm-7.5B",
        "Arch":"XGLM",
        "Params (B)":7.5,
        "Open LLM Score (%)":"36.38*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.284,
        "Decode Throughput (tokens\/s)":25.7,
        "Allocated Memory (MB)":6318,
        "Energy (tokens\/kWh)":332225,
        "E2E Latency (s)":10.2,
        "E2E Throughput (tokens\/s)":25.1,
        "Reserved Memory (MB)":6394,
        "Used Memory (MB)":7853
    },
    {
        "Model":"facebook\/xglm-7.5B",
        "Arch":"XGLM",
        "Params (B)":7.5,
        "Open LLM Score (%)":"36.38 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.286,
        "Decode Throughput (tokens\/s)":39.3,
        "Allocated Memory (MB)":31087,
        "Energy (tokens\/kWh)":349650,
        "E2E Latency (s)":6.78,
        "E2E Throughput (tokens\/s)":37.8,
        "Reserved Memory (MB)":31274,
        "Used Memory (MB)":32726
    },
    {
        "Model":"cerebras\/Cerebras-GPT-6.7B",
        "Arch":"GPT-2",
        "Params (B)":6.7,
        "Open LLM Score (%)":"36.27*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0263,
        "Decode Throughput (tokens\/s)":53.8,
        "Allocated Memory (MB)":13997,
        "Energy (tokens\/kWh)":645161,
        "E2E Latency (s)":4.77,
        "E2E Throughput (tokens\/s)":53.7,
        "Reserved Memory (MB)":14040,
        "Used Memory (MB)":15500
    },
    {
        "Model":"cerebras\/Cerebras-GPT-6.7B",
        "Arch":"GPT-2",
        "Params (B)":6.7,
        "Open LLM Score (%)":"36.27*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0264,
        "Decode Throughput (tokens\/s)":54.6,
        "Allocated Memory (MB)":13997,
        "Energy (tokens\/kWh)":671140,
        "E2E Latency (s)":4.7,
        "E2E Throughput (tokens\/s)":54.5,
        "Reserved Memory (MB)":14040,
        "Used Memory (MB)":15500
    },
    {
        "Model":"cerebras\/Cerebras-GPT-6.7B",
        "Arch":"GPT-2",
        "Params (B)":6.7,
        "Open LLM Score (%)":"36.27 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0272,
        "Decode Throughput (tokens\/s)":63.3,
        "Allocated Memory (MB)":13997,
        "Energy (tokens\/kWh)":602409,
        "E2E Latency (s)":4.06,
        "E2E Throughput (tokens\/s)":63.1,
        "Reserved Memory (MB)":14040,
        "Used Memory (MB)":15497
    },
    {
        "Model":"cerebras\/Cerebras-GPT-6.7B",
        "Arch":"GPT-2",
        "Params (B)":6.7,
        "Open LLM Score (%)":"36.27 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.028,
        "Decode Throughput (tokens\/s)":55.2,
        "Allocated Memory (MB)":13997,
        "Energy (tokens\/kWh)":581395,
        "E2E Latency (s)":4.65,
        "E2E Throughput (tokens\/s)":55.1,
        "Reserved Memory (MB)":14040,
        "Used Memory (MB)":15499
    },
    {
        "Model":"cerebras\/Cerebras-GPT-6.7B",
        "Arch":"GPT-2",
        "Params (B)":6.7,
        "Open LLM Score (%)":"36.27 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.029,
        "Decode Throughput (tokens\/s)":55.1,
        "Allocated Memory (MB)":13997,
        "Energy (tokens\/kWh)":552486,
        "E2E Latency (s)":4.66,
        "E2E Throughput (tokens\/s)":54.9,
        "Reserved Memory (MB)":14040,
        "Used Memory (MB)":15500
    },
    {
        "Model":"cerebras\/Cerebras-GPT-6.7B",
        "Arch":"GPT-2",
        "Params (B)":6.7,
        "Open LLM Score (%)":"36.27*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.037,
        "Decode Throughput (tokens\/s)":55.6,
        "Allocated Memory (MB)":4596,
        "Energy (tokens\/kWh)":699300,
        "E2E Latency (s)":4.63,
        "E2E Throughput (tokens\/s)":55.3,
        "Reserved Memory (MB)":4622,
        "Used Memory (MB)":6083
    },
    {
        "Model":"cerebras\/Cerebras-GPT-6.7B",
        "Arch":"GPT-2",
        "Params (B)":6.7,
        "Open LLM Score (%)":"36.27*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.161,
        "Decode Throughput (tokens\/s)":42.5,
        "Allocated Memory (MB)":4483,
        "Energy (tokens\/kWh)":543478,
        "E2E Latency (s)":6.16,
        "E2E Throughput (tokens\/s)":41.6,
        "Reserved Memory (MB)":4775,
        "Used Memory (MB)":6234
    },
    {
        "Model":"cerebras\/Cerebras-GPT-6.7B",
        "Arch":"GPT-2",
        "Params (B)":6.7,
        "Open LLM Score (%)":"36.27 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.229,
        "Decode Throughput (tokens\/s)":35.5,
        "Allocated Memory (MB)":27850,
        "Energy (tokens\/kWh)":331125,
        "E2E Latency (s)":7.41,
        "E2E Throughput (tokens\/s)":34.5,
        "Reserved Memory (MB)":28015,
        "Used Memory (MB)":29467
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"GPT-Neo",
        "Params (B)":2.72,
        "Open LLM Score (%)":"36.20 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.017,
        "Decode Throughput (tokens\/s)":56.7,
        "Allocated Memory (MB)":5782,
        "Energy (tokens\/kWh)":714285,
        "E2E Latency (s)":4.52,
        "E2E Throughput (tokens\/s)":56.6,
        "Reserved Memory (MB)":6006,
        "Used Memory (MB)":7463
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"GPT-Neo",
        "Params (B)":2.72,
        "Open LLM Score (%)":"36.20 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0219,
        "Decode Throughput (tokens\/s)":46.6,
        "Allocated Memory (MB)":5782,
        "Energy (tokens\/kWh)":591715,
        "E2E Latency (s)":5.49,
        "E2E Throughput (tokens\/s)":46.6,
        "Reserved Memory (MB)":6006,
        "Used Memory (MB)":7465
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"GPT-Neo",
        "Params (B)":2.72,
        "Open LLM Score (%)":"36.20 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0222,
        "Decode Throughput (tokens\/s)":44.4,
        "Allocated Memory (MB)":5787,
        "Energy (tokens\/kWh)":588235,
        "E2E Latency (s)":5.76,
        "E2E Throughput (tokens\/s)":44.4,
        "Reserved Memory (MB)":6027,
        "Used Memory (MB)":7486
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"GPT-Neo",
        "Params (B)":2.72,
        "Open LLM Score (%)":"36.20 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0241,
        "Decode Throughput (tokens\/s)":43.9,
        "Allocated Memory (MB)":5787,
        "Energy (tokens\/kWh)":571428,
        "E2E Latency (s)":5.83,
        "E2E Throughput (tokens\/s)":43.9,
        "Reserved Memory (MB)":6027,
        "Used Memory (MB)":7486
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"GPT-Neo",
        "Params (B)":2.72,
        "Open LLM Score (%)":"36.20*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0257,
        "Decode Throughput (tokens\/s)":45.5,
        "Allocated Memory (MB)":2129,
        "Energy (tokens\/kWh)":645161,
        "E2E Latency (s)":5.63,
        "E2E Throughput (tokens\/s)":45.5,
        "Reserved Memory (MB)":2254,
        "Used Memory (MB)":3716
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"GPT-Neo",
        "Params (B)":2.72,
        "Open LLM Score (%)":"36.20*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0264,
        "Decode Throughput (tokens\/s)":46.4,
        "Allocated Memory (MB)":2803,
        "Energy (tokens\/kWh)":704225,
        "E2E Latency (s)":5.52,
        "E2E Throughput (tokens\/s)":46.4,
        "Reserved Memory (MB)":2929,
        "Used Memory (MB)":4391
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"GPT-Neo",
        "Params (B)":2.72,
        "Open LLM Score (%)":"36.20*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0366,
        "Decode Throughput (tokens\/s)":44.9,
        "Allocated Memory (MB)":2080,
        "Energy (tokens\/kWh)":653594,
        "E2E Latency (s)":5.72,
        "E2E Throughput (tokens\/s)":44.8,
        "Reserved Memory (MB)":2197,
        "Used Memory (MB)":3657
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"GPT-Neo",
        "Params (B)":2.72,
        "Open LLM Score (%)":"36.20*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0402,
        "Decode Throughput (tokens\/s)":41.2,
        "Allocated Memory (MB)":2073,
        "Energy (tokens\/kWh)":606060,
        "E2E Latency (s)":6.23,
        "E2E Throughput (tokens\/s)":41.1,
        "Reserved Memory (MB)":2191,
        "Used Memory (MB)":3651
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"GPT-Neo",
        "Params (B)":2.72,
        "Open LLM Score (%)":"36.20*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0797,
        "Decode Throughput (tokens\/s)":32.7,
        "Allocated Memory (MB)":2077,
        "Energy (tokens\/kWh)":487804,
        "E2E Latency (s)":7.87,
        "E2E Throughput (tokens\/s)":32.5,
        "Reserved Memory (MB)":2193,
        "Used Memory (MB)":3653
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"GPT-Neo",
        "Params (B)":2.72,
        "Open LLM Score (%)":"36.20*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0822,
        "Decode Throughput (tokens\/s)":12.1,
        "Allocated Memory (MB)":3336,
        "Energy (tokens\/kWh)":181818,
        "E2E Latency (s)":21.1,
        "E2E Throughput (tokens\/s)":12.1,
        "Reserved Memory (MB)":3422,
        "Used Memory (MB)":4890
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"GPT-Neo",
        "Params (B)":2.72,
        "Open LLM Score (%)":"36.20*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0864,
        "Decode Throughput (tokens\/s)":11.8,
        "Allocated Memory (MB)":3341,
        "Energy (tokens\/kWh)":174520,
        "E2E Latency (s)":21.8,
        "E2E Throughput (tokens\/s)":11.7,
        "Reserved Memory (MB)":3422,
        "Used Memory (MB)":4890
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"GPT-Neo",
        "Params (B)":2.72,
        "Open LLM Score (%)":"36.20 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.104,
        "Decode Throughput (tokens\/s)":50.3,
        "Allocated Memory (MB)":11555,
        "Energy (tokens\/kWh)":568181,
        "E2E Latency (s)":5.17,
        "E2E Throughput (tokens\/s)":49.5,
        "Reserved Memory (MB)":11593,
        "Used Memory (MB)":13044
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"GPT-Neo",
        "Params (B)":2.72,
        "Open LLM Score (%)":"36.20*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.117,
        "Decode Throughput (tokens\/s)":25.2,
        "Allocated Memory (MB)":2164,
        "Energy (tokens\/kWh)":344827,
        "E2E Latency (s)":10.2,
        "E2E Throughput (tokens\/s)":25.1,
        "Reserved Memory (MB)":2308,
        "Used Memory (MB)":3768
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"GPT-Neo",
        "Params (B)":2.72,
        "Open LLM Score (%)":"36.20*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.121,
        "Decode Throughput (tokens\/s)":24.5,
        "Allocated Memory (MB)":2169,
        "Energy (tokens\/kWh)":338983,
        "E2E Latency (s)":10.5,
        "E2E Throughput (tokens\/s)":24.4,
        "Reserved Memory (MB)":2329,
        "Used Memory (MB)":3789
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"GPT-NeoX",
        "Params (B)":4.0,
        "Open LLM Score (%)":"36.15 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.021,
        "Decode Throughput (tokens\/s)":47.6,
        "Allocated Memory (MB)":6068,
        "Energy (tokens\/kWh)":632911,
        "E2E Latency (s)":5.38,
        "E2E Throughput (tokens\/s)":47.6,
        "Reserved Memory (MB)":6144,
        "Used Memory (MB)":7604
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"GPT-NeoX",
        "Params (B)":4.0,
        "Open LLM Score (%)":"36.15 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.022,
        "Decode Throughput (tokens\/s)":44.6,
        "Allocated Memory (MB)":6068,
        "Energy (tokens\/kWh)":564971,
        "E2E Latency (s)":5.74,
        "E2E Throughput (tokens\/s)":44.6,
        "Reserved Memory (MB)":6144,
        "Used Memory (MB)":7604
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"GPT-NeoX",
        "Params (B)":4.0,
        "Open LLM Score (%)":"36.15 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0249,
        "Decode Throughput (tokens\/s)":40.2,
        "Allocated Memory (MB)":6068,
        "Energy (tokens\/kWh)":534759,
        "E2E Latency (s)":6.36,
        "E2E Throughput (tokens\/s)":40.3,
        "Reserved Memory (MB)":6144,
        "Used Memory (MB)":7604
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"GPT-NeoX",
        "Params (B)":4.0,
        "Open LLM Score (%)":"36.15*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0255,
        "Decode Throughput (tokens\/s)":41.9,
        "Allocated Memory (MB)":3061,
        "Energy (tokens\/kWh)":621118,
        "E2E Latency (s)":6.11,
        "E2E Throughput (tokens\/s)":41.9,
        "Reserved Memory (MB)":3189,
        "Used Memory (MB)":4651
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"GPT-NeoX",
        "Params (B)":4.0,
        "Open LLM Score (%)":"36.15*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0256,
        "Decode Throughput (tokens\/s)":42.4,
        "Allocated Memory (MB)":2388,
        "Energy (tokens\/kWh)":617283,
        "E2E Latency (s)":6.05,
        "E2E Throughput (tokens\/s)":42.3,
        "Reserved Memory (MB)":2512,
        "Used Memory (MB)":3974
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"GPT-NeoX",
        "Params (B)":4.0,
        "Open LLM Score (%)":"36.15 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0266,
        "Decode Throughput (tokens\/s)":40.1,
        "Allocated Memory (MB)":6068,
        "Energy (tokens\/kWh)":546448,
        "E2E Latency (s)":6.39,
        "E2E Throughput (tokens\/s)":40.1,
        "Reserved Memory (MB)":6144,
        "Used Memory (MB)":7604
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"GPT-NeoX",
        "Params (B)":4.0,
        "Open LLM Score (%)":"36.15*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.037,
        "Decode Throughput (tokens\/s)":40.5,
        "Allocated Memory (MB)":2340,
        "Energy (tokens\/kWh)":606060,
        "E2E Latency (s)":6.33,
        "E2E Throughput (tokens\/s)":40.4,
        "Reserved Memory (MB)":2480,
        "Used Memory (MB)":3940
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"GPT-NeoX",
        "Params (B)":4.0,
        "Open LLM Score (%)":"36.15*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0393,
        "Decode Throughput (tokens\/s)":37.8,
        "Allocated Memory (MB)":2334,
        "Energy (tokens\/kWh)":561797,
        "E2E Latency (s)":6.79,
        "E2E Throughput (tokens\/s)":37.7,
        "Reserved Memory (MB)":2472,
        "Used Memory (MB)":3932
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"GPT-NeoX",
        "Params (B)":4.0,
        "Open LLM Score (%)":"36.15*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0619,
        "Decode Throughput (tokens\/s)":15.5,
        "Allocated Memory (MB)":3605,
        "Energy (tokens\/kWh)":233100,
        "E2E Latency (s)":16.5,
        "E2E Throughput (tokens\/s)":15.5,
        "Reserved Memory (MB)":3711,
        "Used Memory (MB)":5179
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"GPT-NeoX",
        "Params (B)":4.0,
        "Open LLM Score (%)":"36.15*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0674,
        "Decode Throughput (tokens\/s)":14.8,
        "Allocated Memory (MB)":3605,
        "Energy (tokens\/kWh)":220264,
        "E2E Latency (s)":17.3,
        "E2E Throughput (tokens\/s)":14.8,
        "Reserved Memory (MB)":3711,
        "Used Memory (MB)":5179
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"GPT-NeoX",
        "Params (B)":4.0,
        "Open LLM Score (%)":"36.15*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0791,
        "Decode Throughput (tokens\/s)":34.4,
        "Allocated Memory (MB)":2338,
        "Energy (tokens\/kWh)":497512,
        "E2E Latency (s)":7.49,
        "E2E Throughput (tokens\/s)":34.2,
        "Reserved Memory (MB)":2489,
        "Used Memory (MB)":3948
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"GPT-NeoX",
        "Params (B)":4.0,
        "Open LLM Score (%)":"36.15 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.106,
        "Decode Throughput (tokens\/s)":41.1,
        "Allocated Memory (MB)":12028,
        "Energy (tokens\/kWh)":497512,
        "E2E Latency (s)":6.31,
        "E2E Throughput (tokens\/s)":40.6,
        "Reserved Memory (MB)":12069,
        "Used Memory (MB)":13520
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"GPT-NeoX",
        "Params (B)":4.0,
        "Open LLM Score (%)":"36.15*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.121,
        "Decode Throughput (tokens\/s)":27.0,
        "Allocated Memory (MB)":2457,
        "Energy (tokens\/kWh)":383141,
        "E2E Latency (s)":9.57,
        "E2E Throughput (tokens\/s)":26.8,
        "Reserved Memory (MB)":2589,
        "Used Memory (MB)":4049
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"GPT-NeoX",
        "Params (B)":4.0,
        "Open LLM Score (%)":"36.15*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.122,
        "Decode Throughput (tokens\/s)":25.6,
        "Allocated Memory (MB)":2457,
        "Energy (tokens\/kWh)":362318,
        "E2E Latency (s)":10.1,
        "E2E Throughput (tokens\/s)":25.3,
        "Reserved Memory (MB)":2589,
        "Used Memory (MB)":4049
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":3.0,
        "Open LLM Score (%)":"36.07 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0177,
        "Decode Throughput (tokens\/s)":55.4,
        "Allocated Memory (MB)":6365,
        "Energy (tokens\/kWh)":657894,
        "E2E Latency (s)":4.62,
        "E2E Throughput (tokens\/s)":55.4,
        "Reserved Memory (MB)":6434,
        "Used Memory (MB)":7893
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":3.0,
        "Open LLM Score (%)":"36.07 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0193,
        "Decode Throughput (tokens\/s)":53.6,
        "Allocated Memory (MB)":6365,
        "Energy (tokens\/kWh)":671140,
        "E2E Latency (s)":4.78,
        "E2E Throughput (tokens\/s)":53.6,
        "Reserved Memory (MB)":6434,
        "Used Memory (MB)":7893
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":3.0,
        "Open LLM Score (%)":"36.07*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0201,
        "Decode Throughput (tokens\/s)":55.6,
        "Allocated Memory (MB)":3591,
        "Energy (tokens\/kWh)":819672,
        "E2E Latency (s)":4.61,
        "E2E Throughput (tokens\/s)":55.5,
        "Reserved Memory (MB)":3726,
        "Used Memory (MB)":5188
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":3.0,
        "Open LLM Score (%)":"36.07 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0202,
        "Decode Throughput (tokens\/s)":53.5,
        "Allocated Memory (MB)":6365,
        "Energy (tokens\/kWh)":671140,
        "E2E Latency (s)":4.79,
        "E2E Throughput (tokens\/s)":53.4,
        "Reserved Memory (MB)":6434,
        "Used Memory (MB)":7893
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":3.0,
        "Open LLM Score (%)":"36.07*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0203,
        "Decode Throughput (tokens\/s)":55.0,
        "Allocated Memory (MB)":2918,
        "Energy (tokens\/kWh)":775193,
        "E2E Latency (s)":4.66,
        "E2E Throughput (tokens\/s)":54.9,
        "Reserved Memory (MB)":3051,
        "Used Memory (MB)":4513
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":3.0,
        "Open LLM Score (%)":"36.07*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0312,
        "Decode Throughput (tokens\/s)":53.1,
        "Allocated Memory (MB)":2869,
        "Energy (tokens\/kWh)":746268,
        "E2E Latency (s)":4.83,
        "E2E Throughput (tokens\/s)":53.0,
        "Reserved Memory (MB)":3003,
        "Used Memory (MB)":4462
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":3.0,
        "Open LLM Score (%)":"36.07*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0357,
        "Decode Throughput (tokens\/s)":49.7,
        "Allocated Memory (MB)":2863,
        "Energy (tokens\/kWh)":694444,
        "E2E Latency (s)":5.17,
        "E2E Throughput (tokens\/s)":49.5,
        "Reserved Memory (MB)":2996,
        "Used Memory (MB)":4456
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":3.0,
        "Open LLM Score (%)":"36.07*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0561,
        "Decode Throughput (tokens\/s)":17.6,
        "Allocated Memory (MB)":4056,
        "Energy (tokens\/kWh)":255102,
        "E2E Latency (s)":14.6,
        "E2E Throughput (tokens\/s)":17.5,
        "Reserved Memory (MB)":4129,
        "Used Memory (MB)":5597
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":3.0,
        "Open LLM Score (%)":"36.07*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.058,
        "Decode Throughput (tokens\/s)":17.2,
        "Allocated Memory (MB)":4059,
        "Energy (tokens\/kWh)":250626,
        "E2E Latency (s)":14.9,
        "E2E Throughput (tokens\/s)":17.2,
        "Reserved Memory (MB)":4146,
        "Used Memory (MB)":5614
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":3.0,
        "Open LLM Score (%)":"36.07*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0669,
        "Decode Throughput (tokens\/s)":43.7,
        "Allocated Memory (MB)":2867,
        "Energy (tokens\/kWh)":613496,
        "E2E Latency (s)":5.91,
        "E2E Throughput (tokens\/s)":43.3,
        "Reserved Memory (MB)":3137,
        "Used Memory (MB)":4596
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":3.0,
        "Open LLM Score (%)":"36.07*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.107,
        "Decode Throughput (tokens\/s)":32.0,
        "Allocated Memory (MB)":2966,
        "Energy (tokens\/kWh)":434782,
        "E2E Latency (s)":8.09,
        "E2E Throughput (tokens\/s)":31.6,
        "Reserved Memory (MB)":3208,
        "Used Memory (MB)":4668
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":3.0,
        "Open LLM Score (%)":"36.07*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.11,
        "Decode Throughput (tokens\/s)":30.8,
        "Allocated Memory (MB)":2966,
        "Energy (tokens\/kWh)":425531,
        "E2E Latency (s)":8.38,
        "E2E Throughput (tokens\/s)":30.5,
        "Reserved Memory (MB)":3208,
        "Used Memory (MB)":4668
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":3.0,
        "Open LLM Score (%)":"36.07 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.113,
        "Decode Throughput (tokens\/s)":54.8,
        "Allocated Memory (MB)":12734,
        "Energy (tokens\/kWh)":588235,
        "E2E Latency (s)":4.76,
        "E2E Throughput (tokens\/s)":53.8,
        "Reserved Memory (MB)":12859,
        "Used Memory (MB)":14310
    },
    {
        "Model":"Dans-DiscountModels\/ShearedLlama-1.3b-FFT-Test1",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.3,
        "Open LLM Score (%)":"35.71 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.018,
        "Decode Throughput (tokens\/s)":56.2,
        "Allocated Memory (MB)":2991,
        "Energy (tokens\/kWh)":769230,
        "E2E Latency (s)":4.56,
        "E2E Throughput (tokens\/s)":56.1,
        "Reserved Memory (MB)":3114,
        "Used Memory (MB)":4573
    },
    {
        "Model":"Dans-DiscountModels\/ShearedLlama-1.3b-FFT-Test1",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.3,
        "Open LLM Score (%)":"35.71 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0182,
        "Decode Throughput (tokens\/s)":53.6,
        "Allocated Memory (MB)":2991,
        "Energy (tokens\/kWh)":746268,
        "E2E Latency (s)":4.78,
        "E2E Throughput (tokens\/s)":53.6,
        "Reserved Memory (MB)":3114,
        "Used Memory (MB)":4573
    },
    {
        "Model":"Dans-DiscountModels\/ShearedLlama-1.3b-FFT-Test1",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.3,
        "Open LLM Score (%)":"35.71 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0185,
        "Decode Throughput (tokens\/s)":54.8,
        "Allocated Memory (MB)":2991,
        "Energy (tokens\/kWh)":763358,
        "E2E Latency (s)":4.67,
        "E2E Throughput (tokens\/s)":54.8,
        "Reserved Memory (MB)":3114,
        "Used Memory (MB)":4573
    },
    {
        "Model":"Dans-DiscountModels\/ShearedLlama-1.3b-FFT-Test1",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.3,
        "Open LLM Score (%)":"35.71*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0201,
        "Decode Throughput (tokens\/s)":55.0,
        "Allocated Memory (MB)":1157,
        "Energy (tokens\/kWh)":813008,
        "E2E Latency (s)":4.66,
        "E2E Throughput (tokens\/s)":54.9,
        "Reserved Memory (MB)":1296,
        "Used Memory (MB)":2755
    },
    {
        "Model":"Dans-DiscountModels\/ShearedLlama-1.3b-FFT-Test1",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.3,
        "Open LLM Score (%)":"35.71*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0206,
        "Decode Throughput (tokens\/s)":52.8,
        "Allocated Memory (MB)":1544,
        "Energy (tokens\/kWh)":819672,
        "E2E Latency (s)":4.85,
        "E2E Throughput (tokens\/s)":52.8,
        "Reserved Memory (MB)":1675,
        "Used Memory (MB)":3137
    },
    {
        "Model":"Dans-DiscountModels\/ShearedLlama-1.3b-FFT-Test1",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.3,
        "Open LLM Score (%)":"35.71*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0206,
        "Decode Throughput (tokens\/s)":52.4,
        "Allocated Memory (MB)":1182,
        "Energy (tokens\/kWh)":793650,
        "E2E Latency (s)":4.89,
        "E2E Throughput (tokens\/s)":52.4,
        "Reserved Memory (MB)":1314,
        "Used Memory (MB)":2776
    },
    {
        "Model":"Dans-DiscountModels\/ShearedLlama-1.3b-FFT-Test1",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.3,
        "Open LLM Score (%)":"35.71*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0211,
        "Decode Throughput (tokens\/s)":48.1,
        "Allocated Memory (MB)":1156,
        "Energy (tokens\/kWh)":709219,
        "E2E Latency (s)":5.32,
        "E2E Throughput (tokens\/s)":48.1,
        "Reserved Memory (MB)":1293,
        "Used Memory (MB)":2753
    },
    {
        "Model":"Dans-DiscountModels\/ShearedLlama-1.3b-FFT-Test1",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.3,
        "Open LLM Score (%)":"35.71*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0463,
        "Decode Throughput (tokens\/s)":38.4,
        "Allocated Memory (MB)":1159,
        "Energy (tokens\/kWh)":588235,
        "E2E Latency (s)":6.69,
        "E2E Throughput (tokens\/s)":38.3,
        "Reserved Memory (MB)":1281,
        "Used Memory (MB)":2740
    },
    {
        "Model":"Dans-DiscountModels\/ShearedLlama-1.3b-FFT-Test1",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.3,
        "Open LLM Score (%)":"35.71 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0483,
        "Decode Throughput (tokens\/s)":60.0,
        "Allocated Memory (MB)":5969,
        "Energy (tokens\/kWh)":719424,
        "E2E Latency (s)":4.3,
        "E2E Throughput (tokens\/s)":59.5,
        "Reserved Memory (MB)":5991,
        "Used Memory (MB)":7442
    },
    {
        "Model":"Dans-DiscountModels\/ShearedLlama-1.3b-FFT-Test1",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.3,
        "Open LLM Score (%)":"35.71*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0557,
        "Decode Throughput (tokens\/s)":30.2,
        "Allocated Memory (MB)":1226,
        "Energy (tokens\/kWh)":438596,
        "E2E Latency (s)":8.51,
        "E2E Throughput (tokens\/s)":30.1,
        "Reserved Memory (MB)":1340,
        "Used Memory (MB)":2799
    },
    {
        "Model":"Dans-DiscountModels\/ShearedLlama-1.3b-FFT-Test1",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.3,
        "Open LLM Score (%)":"35.71*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0558,
        "Decode Throughput (tokens\/s)":30.7,
        "Allocated Memory (MB)":1226,
        "Energy (tokens\/kWh)":456621,
        "E2E Latency (s)":8.36,
        "E2E Throughput (tokens\/s)":30.6,
        "Reserved Memory (MB)":1340,
        "Used Memory (MB)":2799
    },
    {
        "Model":"Dans-DiscountModels\/ShearedLlama-1.3b-FFT-Test1",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.3,
        "Open LLM Score (%)":"35.71*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0714,
        "Decode Throughput (tokens\/s)":13.9,
        "Allocated Memory (MB)":1741,
        "Energy (tokens\/kWh)":217864,
        "E2E Latency (s)":18.5,
        "E2E Throughput (tokens\/s)":13.8,
        "Reserved Memory (MB)":1912,
        "Used Memory (MB)":3380
    },
    {
        "Model":"Dans-DiscountModels\/ShearedLlama-1.3b-FFT-Test1",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.3,
        "Open LLM Score (%)":"35.71*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0731,
        "Decode Throughput (tokens\/s)":13.9,
        "Allocated Memory (MB)":1741,
        "Energy (tokens\/kWh)":206611,
        "E2E Latency (s)":18.5,
        "E2E Throughput (tokens\/s)":13.8,
        "Reserved Memory (MB)":1912,
        "Used Memory (MB)":3380
    },
    {
        "Model":"bigcode\/starcoderbase",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":0.0,
        "Open LLM Score (%)":"35.55 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0534,
        "Decode Throughput (tokens\/s)":42.9,
        "Allocated Memory (MB)":31327,
        "Energy (tokens\/kWh)":383141,
        "E2E Latency (s)":6.0,
        "E2E Throughput (tokens\/s)":42.7,
        "Reserved Memory (MB)":31434,
        "Used Memory (MB)":32893
    },
    {
        "Model":"bigcode\/starcoderbase",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":0.0,
        "Open LLM Score (%)":"35.55 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0595,
        "Decode Throughput (tokens\/s)":44.0,
        "Allocated Memory (MB)":31327,
        "Energy (tokens\/kWh)":396825,
        "E2E Latency (s)":5.85,
        "E2E Throughput (tokens\/s)":43.8,
        "Reserved Memory (MB)":31501,
        "Used Memory (MB)":32958
    },
    {
        "Model":"bigcode\/starcoderbase",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":0.0,
        "Open LLM Score (%)":"35.55 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0643,
        "Decode Throughput (tokens\/s)":42.4,
        "Allocated Memory (MB)":31327,
        "Energy (tokens\/kWh)":381679,
        "E2E Latency (s)":6.08,
        "E2E Throughput (tokens\/s)":42.1,
        "Reserved Memory (MB)":31434,
        "Used Memory (MB)":32893
    },
    {
        "Model":"bigcode\/starcoderbase",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":0.0,
        "Open LLM Score (%)":"35.55*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0796,
        "Decode Throughput (tokens\/s)":13.9,
        "Allocated Memory (MB)":16181,
        "Energy (tokens\/kWh)":162866,
        "E2E Latency (s)":18.5,
        "E2E Throughput (tokens\/s)":13.8,
        "Reserved Memory (MB)":16238,
        "Used Memory (MB)":17706
    },
    {
        "Model":"bigcode\/starcoderbase",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":0.0,
        "Open LLM Score (%)":"35.55 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.569,
        "Decode Throughput (tokens\/s)":24.3,
        "Allocated Memory (MB)":62495,
        "Energy (tokens\/kWh)":212765,
        "E2E Latency (s)":11.1,
        "E2E Throughput (tokens\/s)":23.1,
        "Reserved Memory (MB)":62851,
        "Used Memory (MB)":64302
    },
    {
        "Model":"bigcode\/starcoderbase",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":0.0,
        "Open LLM Score (%)":"35.55*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.677,
        "Decode Throughput (tokens\/s)":15.7,
        "Allocated Memory (MB)":9702,
        "Energy (tokens\/kWh)":154083,
        "E2E Latency (s)":16.9,
        "E2E Throughput (tokens\/s)":15.1,
        "Reserved Memory (MB)":10485,
        "Used Memory (MB)":11945
    },
    {
        "Model":"RWKV\/rwkv-4-3b-pile",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":3.0,
        "Open LLM Score (%)":"35.25 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0325,
        "Decode Throughput (tokens\/s)":29.1,
        "Allocated Memory (MB)":6007,
        "Energy (tokens\/kWh)":413223,
        "E2E Latency (s)":8.78,
        "E2E Throughput (tokens\/s)":29.2,
        "Reserved Memory (MB)":6272,
        "Used Memory (MB)":7732
    },
    {
        "Model":"RWKV\/rwkv-4-3b-pile",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":3.0,
        "Open LLM Score (%)":"35.25 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0343,
        "Decode Throughput (tokens\/s)":29.3,
        "Allocated Memory (MB)":6007,
        "Energy (tokens\/kWh)":393700,
        "E2E Latency (s)":8.73,
        "E2E Throughput (tokens\/s)":29.3,
        "Reserved Memory (MB)":6272,
        "Used Memory (MB)":7732
    },
    {
        "Model":"RWKV\/rwkv-4-3b-pile",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":3.0,
        "Open LLM Score (%)":"35.25 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.102,
        "Decode Throughput (tokens\/s)":31.8,
        "Allocated Memory (MB)":12171,
        "Energy (tokens\/kWh)":404858,
        "E2E Latency (s)":8.12,
        "E2E Throughput (tokens\/s)":31.5,
        "Reserved Memory (MB)":12226,
        "Used Memory (MB)":13677
    },
    {
        "Model":"RWKV\/rwkv-4-3b-pile",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":3.0,
        "Open LLM Score (%)":"35.25*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.109,
        "Decode Throughput (tokens\/s)":9.27,
        "Allocated Memory (MB)":3358,
        "Energy (tokens\/kWh)":138888,
        "E2E Latency (s)":27.6,
        "E2E Throughput (tokens\/s)":9.28,
        "Reserved Memory (MB)":3462,
        "Used Memory (MB)":4930
    },
    {
        "Model":"RWKV\/rwkv-4-3b-pile",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":3.0,
        "Open LLM Score (%)":"35.25*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.119,
        "Decode Throughput (tokens\/s)":17.6,
        "Allocated Memory (MB)":2195,
        "Energy (tokens\/kWh)":255754,
        "E2E Latency (s)":14.6,
        "E2E Throughput (tokens\/s)":17.5,
        "Reserved Memory (MB)":2422,
        "Used Memory (MB)":3881
    },
    {
        "Model":"Writer\/palmyra-base",
        "Arch":"GPT-2",
        "Params (B)":0.0,
        "Open LLM Score (%)":"35.18*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0201,
        "Decode Throughput (tokens\/s)":72.4,
        "Allocated Memory (MB)":10607,
        "Energy (tokens\/kWh)":862068,
        "E2E Latency (s)":3.54,
        "E2E Throughput (tokens\/s)":72.3,
        "Reserved Memory (MB)":10649,
        "Used Memory (MB)":12108
    },
    {
        "Model":"Writer\/palmyra-base",
        "Arch":"GPT-2",
        "Params (B)":0.0,
        "Open LLM Score (%)":"35.18*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0201,
        "Decode Throughput (tokens\/s)":70.8,
        "Allocated Memory (MB)":10607,
        "Energy (tokens\/kWh)":869565,
        "E2E Latency (s)":3.62,
        "E2E Throughput (tokens\/s)":70.7,
        "Reserved Memory (MB)":10649,
        "Used Memory (MB)":12108
    },
    {
        "Model":"Writer\/palmyra-base",
        "Arch":"GPT-2",
        "Params (B)":0.0,
        "Open LLM Score (%)":"35.18 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.021,
        "Decode Throughput (tokens\/s)":84.4,
        "Allocated Memory (MB)":10607,
        "Energy (tokens\/kWh)":757575,
        "E2E Latency (s)":3.04,
        "E2E Throughput (tokens\/s)":84.2,
        "Reserved Memory (MB)":10628,
        "Used Memory (MB)":12085
    },
    {
        "Model":"Writer\/palmyra-base",
        "Arch":"GPT-2",
        "Params (B)":0.0,
        "Open LLM Score (%)":"35.18 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0214,
        "Decode Throughput (tokens\/s)":72.2,
        "Allocated Memory (MB)":10607,
        "Energy (tokens\/kWh)":763358,
        "E2E Latency (s)":3.55,
        "E2E Throughput (tokens\/s)":72.1,
        "Reserved Memory (MB)":10649,
        "Used Memory (MB)":12108
    },
    {
        "Model":"Writer\/palmyra-base",
        "Arch":"GPT-2",
        "Params (B)":0.0,
        "Open LLM Score (%)":"35.18 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0229,
        "Decode Throughput (tokens\/s)":71.4,
        "Allocated Memory (MB)":10607,
        "Energy (tokens\/kWh)":704225,
        "E2E Latency (s)":3.59,
        "E2E Throughput (tokens\/s)":71.3,
        "Reserved Memory (MB)":10649,
        "Used Memory (MB)":12108
    },
    {
        "Model":"Writer\/palmyra-base",
        "Arch":"GPT-2",
        "Params (B)":0.0,
        "Open LLM Score (%)":"35.18*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0288,
        "Decode Throughput (tokens\/s)":76.8,
        "Allocated Memory (MB)":3590,
        "Energy (tokens\/kWh)":943396,
        "E2E Latency (s)":3.35,
        "E2E Throughput (tokens\/s)":76.4,
        "Reserved Memory (MB)":3619,
        "Used Memory (MB)":5081
    },
    {
        "Model":"Writer\/palmyra-base",
        "Arch":"GPT-2",
        "Params (B)":0.0,
        "Open LLM Score (%)":"35.18*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.122,
        "Decode Throughput (tokens\/s)":55.4,
        "Allocated Memory (MB)":3561,
        "Energy (tokens\/kWh)":719424,
        "E2E Latency (s)":4.72,
        "E2E Throughput (tokens\/s)":54.2,
        "Reserved Memory (MB)":3900,
        "Used Memory (MB)":5360
    },
    {
        "Model":"Writer\/palmyra-base",
        "Arch":"GPT-2",
        "Params (B)":0.0,
        "Open LLM Score (%)":"35.18 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.173,
        "Decode Throughput (tokens\/s)":47.1,
        "Allocated Memory (MB)":21105,
        "Energy (tokens\/kWh)":442477,
        "E2E Latency (s)":5.58,
        "E2E Throughput (tokens\/s)":45.9,
        "Reserved Memory (MB)":21214,
        "Used Memory (MB)":22666
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":1.4,
        "Open LLM Score (%)":"35.00 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0154,
        "Decode Throughput (tokens\/s)":62.0,
        "Allocated Memory (MB)":3147,
        "Energy (tokens\/kWh)":877192,
        "E2E Latency (s)":4.13,
        "E2E Throughput (tokens\/s)":62.0,
        "Reserved Memory (MB)":3202,
        "Used Memory (MB)":4661
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":1.4,
        "Open LLM Score (%)":"35.00 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0158,
        "Decode Throughput (tokens\/s)":61.7,
        "Allocated Memory (MB)":3147,
        "Energy (tokens\/kWh)":806451,
        "E2E Latency (s)":4.15,
        "E2E Throughput (tokens\/s)":61.7,
        "Reserved Memory (MB)":3202,
        "Used Memory (MB)":4661
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":1.4,
        "Open LLM Score (%)":"35.00 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0184,
        "Decode Throughput (tokens\/s)":53.2,
        "Allocated Memory (MB)":3147,
        "Energy (tokens\/kWh)":740740,
        "E2E Latency (s)":4.81,
        "E2E Throughput (tokens\/s)":53.2,
        "Reserved Memory (MB)":3202,
        "Used Memory (MB)":4661
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":1.4,
        "Open LLM Score (%)":"35.00 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0189,
        "Decode Throughput (tokens\/s)":53.7,
        "Allocated Memory (MB)":3147,
        "Energy (tokens\/kWh)":757575,
        "E2E Latency (s)":4.77,
        "E2E Throughput (tokens\/s)":53.7,
        "Reserved Memory (MB)":3202,
        "Used Memory (MB)":4661
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":1.4,
        "Open LLM Score (%)":"35.00*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.019,
        "Decode Throughput (tokens\/s)":55.4,
        "Allocated Memory (MB)":1931,
        "Energy (tokens\/kWh)":862068,
        "E2E Latency (s)":4.62,
        "E2E Throughput (tokens\/s)":55.4,
        "Reserved Memory (MB)":1983,
        "Used Memory (MB)":3445
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":1.4,
        "Open LLM Score (%)":"35.00*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0198,
        "Decode Throughput (tokens\/s)":54.8,
        "Allocated Memory (MB)":1393,
        "Energy (tokens\/kWh)":826446,
        "E2E Latency (s)":4.67,
        "E2E Throughput (tokens\/s)":54.8,
        "Reserved Memory (MB)":1442,
        "Used Memory (MB)":2904
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":1.4,
        "Open LLM Score (%)":"35.00*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0218,
        "Decode Throughput (tokens\/s)":52.6,
        "Allocated Memory (MB)":1358,
        "Energy (tokens\/kWh)":806451,
        "E2E Latency (s)":4.87,
        "E2E Throughput (tokens\/s)":52.6,
        "Reserved Memory (MB)":1423,
        "Used Memory (MB)":2883
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":1.4,
        "Open LLM Score (%)":"35.00*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0228,
        "Decode Throughput (tokens\/s)":48.8,
        "Allocated Memory (MB)":1358,
        "Energy (tokens\/kWh)":729927,
        "E2E Latency (s)":5.25,
        "E2E Throughput (tokens\/s)":48.8,
        "Reserved Memory (MB)":1423,
        "Used Memory (MB)":2883
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":1.4,
        "Open LLM Score (%)":"35.00*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0441,
        "Decode Throughput (tokens\/s)":43.9,
        "Allocated Memory (MB)":1360,
        "Energy (tokens\/kWh)":671140,
        "E2E Latency (s)":5.85,
        "E2E Throughput (tokens\/s)":43.8,
        "Reserved Memory (MB)":1430,
        "Used Memory (MB)":2889
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":1.4,
        "Open LLM Score (%)":"35.00*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0476,
        "Decode Throughput (tokens\/s)":20.4,
        "Allocated Memory (MB)":1942,
        "Energy (tokens\/kWh)":323624,
        "E2E Latency (s)":12.5,
        "E2E Throughput (tokens\/s)":20.5,
        "Reserved Memory (MB)":2004,
        "Used Memory (MB)":3472
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":1.4,
        "Open LLM Score (%)":"35.00*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0559,
        "Decode Throughput (tokens\/s)":19.6,
        "Allocated Memory (MB)":1941,
        "Energy (tokens\/kWh)":297619,
        "E2E Latency (s)":13.1,
        "E2E Throughput (tokens\/s)":19.5,
        "Reserved Memory (MB)":2000,
        "Used Memory (MB)":3468
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":1.4,
        "Open LLM Score (%)":"35.00*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.059,
        "Decode Throughput (tokens\/s)":36.8,
        "Allocated Memory (MB)":1428,
        "Energy (tokens\/kWh)":531914,
        "E2E Latency (s)":6.99,
        "E2E Throughput (tokens\/s)":36.6,
        "Reserved Memory (MB)":1478,
        "Used Memory (MB)":2938
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":1.4,
        "Open LLM Score (%)":"35.00 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0604,
        "Decode Throughput (tokens\/s)":54.0,
        "Allocated Memory (MB)":6186,
        "Energy (tokens\/kWh)":653594,
        "E2E Latency (s)":4.78,
        "E2E Throughput (tokens\/s)":53.6,
        "Reserved Memory (MB)":6232,
        "Used Memory (MB)":7683
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":1.4,
        "Open LLM Score (%)":"35.00*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0607,
        "Decode Throughput (tokens\/s)":32.9,
        "Allocated Memory (MB)":1428,
        "Energy (tokens\/kWh)":495049,
        "E2E Latency (s)":7.8,
        "E2E Throughput (tokens\/s)":32.8,
        "Reserved Memory (MB)":1478,
        "Used Memory (MB)":2938
    },
    {
        "Model":"bn22\/tinyllama_frankenmerge",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.54,
        "Open LLM Score (%)":"34.64 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.026,
        "Decode Throughput (tokens\/s)":37.0,
        "Allocated Memory (MB)":3168,
        "Energy (tokens\/kWh)":540540,
        "E2E Latency (s)":6.92,
        "E2E Throughput (tokens\/s)":37.0,
        "Reserved Memory (MB)":3342,
        "Used Memory (MB)":4802
    },
    {
        "Model":"bn22\/tinyllama_frankenmerge",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.54,
        "Open LLM Score (%)":"34.64 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0266,
        "Decode Throughput (tokens\/s)":37.3,
        "Allocated Memory (MB)":3168,
        "Energy (tokens\/kWh)":546448,
        "E2E Latency (s)":6.86,
        "E2E Throughput (tokens\/s)":37.3,
        "Reserved Memory (MB)":3342,
        "Used Memory (MB)":4802
    },
    {
        "Model":"bn22\/tinyllama_frankenmerge",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.54,
        "Open LLM Score (%)":"34.64*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0284,
        "Decode Throughput (tokens\/s)":33.2,
        "Allocated Memory (MB)":1091,
        "Energy (tokens\/kWh)":510204,
        "E2E Latency (s)":7.71,
        "E2E Throughput (tokens\/s)":33.2,
        "Reserved Memory (MB)":1195,
        "Used Memory (MB)":2654
    },
    {
        "Model":"bn22\/tinyllama_frankenmerge",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.54,
        "Open LLM Score (%)":"34.64*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0286,
        "Decode Throughput (tokens\/s)":36.2,
        "Allocated Memory (MB)":1092,
        "Energy (tokens\/kWh)":574712,
        "E2E Latency (s)":7.07,
        "E2E Throughput (tokens\/s)":36.2,
        "Reserved Memory (MB)":1195,
        "Used Memory (MB)":2654
    },
    {
        "Model":"bn22\/tinyllama_frankenmerge",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.54,
        "Open LLM Score (%)":"34.64*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0296,
        "Decode Throughput (tokens\/s)":34.4,
        "Allocated Memory (MB)":1490,
        "Energy (tokens\/kWh)":552486,
        "E2E Latency (s)":7.44,
        "E2E Throughput (tokens\/s)":34.4,
        "Reserved Memory (MB)":1568,
        "Used Memory (MB)":3030
    },
    {
        "Model":"bn22\/tinyllama_frankenmerge",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.54,
        "Open LLM Score (%)":"34.64 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0595,
        "Decode Throughput (tokens\/s)":42.4,
        "Allocated Memory (MB)":6279,
        "Energy (tokens\/kWh)":581395,
        "E2E Latency (s)":6.07,
        "E2E Throughput (tokens\/s)":42.2,
        "Reserved Memory (MB)":6341,
        "Used Memory (MB)":7793
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"GPT-NeoX",
        "Params (B)":1.31,
        "Open LLM Score (%)":"34.46 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0154,
        "Decode Throughput (tokens\/s)":63.8,
        "Allocated Memory (MB)":3147,
        "Energy (tokens\/kWh)":884955,
        "E2E Latency (s)":4.02,
        "E2E Throughput (tokens\/s)":63.7,
        "Reserved Memory (MB)":3202,
        "Used Memory (MB)":4661
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"GPT-NeoX",
        "Params (B)":1.31,
        "Open LLM Score (%)":"34.46 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.016,
        "Decode Throughput (tokens\/s)":61.6,
        "Allocated Memory (MB)":3147,
        "Energy (tokens\/kWh)":806451,
        "E2E Latency (s)":4.16,
        "E2E Throughput (tokens\/s)":61.5,
        "Reserved Memory (MB)":3202,
        "Used Memory (MB)":4661
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"GPT-NeoX",
        "Params (B)":1.31,
        "Open LLM Score (%)":"34.46*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0191,
        "Decode Throughput (tokens\/s)":54.8,
        "Allocated Memory (MB)":1931,
        "Energy (tokens\/kWh)":862068,
        "E2E Latency (s)":4.67,
        "E2E Throughput (tokens\/s)":54.8,
        "Reserved Memory (MB)":1983,
        "Used Memory (MB)":3445
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"GPT-NeoX",
        "Params (B)":1.31,
        "Open LLM Score (%)":"34.46 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0194,
        "Decode Throughput (tokens\/s)":53.5,
        "Allocated Memory (MB)":3147,
        "Energy (tokens\/kWh)":751879,
        "E2E Latency (s)":4.79,
        "E2E Throughput (tokens\/s)":53.4,
        "Reserved Memory (MB)":3202,
        "Used Memory (MB)":4661
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"GPT-NeoX",
        "Params (B)":1.31,
        "Open LLM Score (%)":"34.46*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0197,
        "Decode Throughput (tokens\/s)":55.6,
        "Allocated Memory (MB)":1393,
        "Energy (tokens\/kWh)":840336,
        "E2E Latency (s)":4.61,
        "E2E Throughput (tokens\/s)":55.5,
        "Reserved Memory (MB)":1442,
        "Used Memory (MB)":2904
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"GPT-NeoX",
        "Params (B)":1.31,
        "Open LLM Score (%)":"34.46 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0198,
        "Decode Throughput (tokens\/s)":54.1,
        "Allocated Memory (MB)":3147,
        "Energy (tokens\/kWh)":751879,
        "E2E Latency (s)":4.73,
        "E2E Throughput (tokens\/s)":54.1,
        "Reserved Memory (MB)":3202,
        "Used Memory (MB)":4661
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"GPT-NeoX",
        "Params (B)":1.31,
        "Open LLM Score (%)":"34.46*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0222,
        "Decode Throughput (tokens\/s)":53.9,
        "Allocated Memory (MB)":1358,
        "Energy (tokens\/kWh)":806451,
        "E2E Latency (s)":4.75,
        "E2E Throughput (tokens\/s)":53.9,
        "Reserved Memory (MB)":1423,
        "Used Memory (MB)":2883
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"GPT-NeoX",
        "Params (B)":1.31,
        "Open LLM Score (%)":"34.46*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0235,
        "Decode Throughput (tokens\/s)":49.5,
        "Allocated Memory (MB)":1358,
        "Energy (tokens\/kWh)":751879,
        "E2E Latency (s)":5.17,
        "E2E Throughput (tokens\/s)":49.5,
        "Reserved Memory (MB)":1423,
        "Used Memory (MB)":2883
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"GPT-NeoX",
        "Params (B)":1.31,
        "Open LLM Score (%)":"34.46*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0448,
        "Decode Throughput (tokens\/s)":44.8,
        "Allocated Memory (MB)":1360,
        "Energy (tokens\/kWh)":689655,
        "E2E Latency (s)":5.73,
        "E2E Throughput (tokens\/s)":44.7,
        "Reserved Memory (MB)":1430,
        "Used Memory (MB)":2889
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"GPT-NeoX",
        "Params (B)":1.31,
        "Open LLM Score (%)":"34.46*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0472,
        "Decode Throughput (tokens\/s)":20.7,
        "Allocated Memory (MB)":1942,
        "Energy (tokens\/kWh)":319488,
        "E2E Latency (s)":12.3,
        "E2E Throughput (tokens\/s)":20.8,
        "Reserved Memory (MB)":2004,
        "Used Memory (MB)":3472
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"GPT-NeoX",
        "Params (B)":1.31,
        "Open LLM Score (%)":"34.46*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0514,
        "Decode Throughput (tokens\/s)":19.9,
        "Allocated Memory (MB)":1941,
        "Energy (tokens\/kWh)":298507,
        "E2E Latency (s)":12.9,
        "E2E Throughput (tokens\/s)":19.8,
        "Reserved Memory (MB)":2000,
        "Used Memory (MB)":3468
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"GPT-NeoX",
        "Params (B)":1.31,
        "Open LLM Score (%)":"34.46 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0543,
        "Decode Throughput (tokens\/s)":52.5,
        "Allocated Memory (MB)":6186,
        "Energy (tokens\/kWh)":689655,
        "E2E Latency (s)":4.91,
        "E2E Throughput (tokens\/s)":52.1,
        "Reserved Memory (MB)":6232,
        "Used Memory (MB)":7683
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"GPT-NeoX",
        "Params (B)":1.31,
        "Open LLM Score (%)":"34.46*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0632,
        "Decode Throughput (tokens\/s)":36.4,
        "Allocated Memory (MB)":1428,
        "Energy (tokens\/kWh)":529100,
        "E2E Latency (s)":7.06,
        "E2E Throughput (tokens\/s)":36.3,
        "Reserved Memory (MB)":1478,
        "Used Memory (MB)":2938
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"GPT-NeoX",
        "Params (B)":1.31,
        "Open LLM Score (%)":"34.46*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0635,
        "Decode Throughput (tokens\/s)":33.5,
        "Allocated Memory (MB)":1428,
        "Energy (tokens\/kWh)":497512,
        "E2E Latency (s)":7.67,
        "E2E Throughput (tokens\/s)":33.4,
        "Reserved Memory (MB)":1478,
        "Used Memory (MB)":2938
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"GPT-NeoX",
        "Params (B)":0.0,
        "Open LLM Score (%)":"34.42 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0295,
        "Decode Throughput (tokens\/s)":46.9,
        "Allocated Memory (MB)":16060,
        "Energy (tokens\/kWh)":473933,
        "E2E Latency (s)":5.47,
        "E2E Throughput (tokens\/s)":46.8,
        "Reserved Memory (MB)":16089,
        "Used Memory (MB)":17548
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"GPT-NeoX",
        "Params (B)":0.0,
        "Open LLM Score (%)":"34.42 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0309,
        "Decode Throughput (tokens\/s)":45.3,
        "Allocated Memory (MB)":16060,
        "Energy (tokens\/kWh)":478468,
        "E2E Latency (s)":5.66,
        "E2E Throughput (tokens\/s)":45.2,
        "Reserved Memory (MB)":16089,
        "Used Memory (MB)":17548
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"GPT-NeoX",
        "Params (B)":0.0,
        "Open LLM Score (%)":"34.42 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0317,
        "Decode Throughput (tokens\/s)":40.9,
        "Allocated Memory (MB)":16060,
        "Energy (tokens\/kWh)":462962,
        "E2E Latency (s)":6.27,
        "E2E Throughput (tokens\/s)":40.8,
        "Reserved Memory (MB)":16089,
        "Used Memory (MB)":17548
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"GPT-NeoX",
        "Params (B)":0.0,
        "Open LLM Score (%)":"34.42 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0333,
        "Decode Throughput (tokens\/s)":39.6,
        "Allocated Memory (MB)":16060,
        "Energy (tokens\/kWh)":438596,
        "E2E Latency (s)":6.47,
        "E2E Throughput (tokens\/s)":39.6,
        "Reserved Memory (MB)":16089,
        "Used Memory (MB)":17548
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"GPT-NeoX",
        "Params (B)":0.0,
        "Open LLM Score (%)":"34.42*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0406,
        "Decode Throughput (tokens\/s)":41.1,
        "Allocated Memory (MB)":6659,
        "Energy (tokens\/kWh)":534759,
        "E2E Latency (s)":6.25,
        "E2E Throughput (tokens\/s)":41.0,
        "Reserved Memory (MB)":6692,
        "Used Memory (MB)":8153
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"GPT-NeoX",
        "Params (B)":0.0,
        "Open LLM Score (%)":"34.42*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0418,
        "Decode Throughput (tokens\/s)":40.7,
        "Allocated Memory (MB)":7737,
        "Energy (tokens\/kWh)":568181,
        "E2E Latency (s)":6.31,
        "E2E Throughput (tokens\/s)":40.6,
        "Reserved Memory (MB)":7772,
        "Used Memory (MB)":9233
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"GPT-NeoX",
        "Params (B)":0.0,
        "Open LLM Score (%)":"34.42*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0619,
        "Decode Throughput (tokens\/s)":16.0,
        "Allocated Memory (MB)":9622,
        "Energy (tokens\/kWh)":232018,
        "E2E Latency (s)":16.0,
        "E2E Throughput (tokens\/s)":16.0,
        "Reserved Memory (MB)":9678,
        "Used Memory (MB)":11146
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"GPT-NeoX",
        "Params (B)":0.0,
        "Open LLM Score (%)":"34.42*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0636,
        "Decode Throughput (tokens\/s)":39.2,
        "Allocated Memory (MB)":6523,
        "Energy (tokens\/kWh)":515463,
        "E2E Latency (s)":6.56,
        "E2E Throughput (tokens\/s)":39.0,
        "Reserved Memory (MB)":6572,
        "Used Memory (MB)":8032
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"GPT-NeoX",
        "Params (B)":0.0,
        "Open LLM Score (%)":"34.42*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0674,
        "Decode Throughput (tokens\/s)":14.9,
        "Allocated Memory (MB)":9622,
        "Energy (tokens\/kWh)":220264,
        "E2E Latency (s)":17.2,
        "E2E Throughput (tokens\/s)":14.9,
        "Reserved Memory (MB)":9669,
        "Used Memory (MB)":11137
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"GPT-NeoX",
        "Params (B)":0.0,
        "Open LLM Score (%)":"34.42*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0758,
        "Decode Throughput (tokens\/s)":37.0,
        "Allocated Memory (MB)":6523,
        "Energy (tokens\/kWh)":492610,
        "E2E Latency (s)":6.98,
        "E2E Throughput (tokens\/s)":36.7,
        "Reserved Memory (MB)":6572,
        "Used Memory (MB)":8032
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"GPT-NeoX",
        "Params (B)":0.0,
        "Open LLM Score (%)":"34.42 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.26,
        "Decode Throughput (tokens\/s)":37.0,
        "Allocated Memory (MB)":31976,
        "Energy (tokens\/kWh)":327868,
        "E2E Latency (s)":7.16,
        "E2E Throughput (tokens\/s)":35.8,
        "Reserved Memory (MB)":32113,
        "Used Memory (MB)":33564
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"GPT-NeoX",
        "Params (B)":0.0,
        "Open LLM Score (%)":"34.42*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.282,
        "Decode Throughput (tokens\/s)":25.7,
        "Allocated Memory (MB)":7001,
        "Energy (tokens\/kWh)":322580,
        "E2E Latency (s)":10.2,
        "E2E Throughput (tokens\/s)":25.1,
        "Reserved Memory (MB)":7241,
        "Used Memory (MB)":8701
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"GPT-NeoX",
        "Params (B)":0.0,
        "Open LLM Score (%)":"34.42*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.288,
        "Decode Throughput (tokens\/s)":27.5,
        "Allocated Memory (MB)":7001,
        "Energy (tokens\/kWh)":334448,
        "E2E Latency (s)":9.55,
        "E2E Throughput (tokens\/s)":26.8,
        "Reserved Memory (MB)":7241,
        "Used Memory (MB)":8701
    },
    {
        "Model":"gpt2-xl",
        "Arch":"GPT-2",
        "Params (B)":1.61,
        "Open LLM Score (%)":"34.38 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0271,
        "Decode Throughput (tokens\/s)":35.6,
        "Allocated Memory (MB)":3561,
        "Energy (tokens\/kWh)":497512,
        "E2E Latency (s)":7.2,
        "E2E Throughput (tokens\/s)":35.6,
        "Reserved Memory (MB)":3823,
        "Used Memory (MB)":5282
    },
    {
        "Model":"gpt2-xl",
        "Arch":"GPT-2",
        "Params (B)":1.61,
        "Open LLM Score (%)":"34.38 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0316,
        "Decode Throughput (tokens\/s)":31.8,
        "Allocated Memory (MB)":3561,
        "Energy (tokens\/kWh)":448430,
        "E2E Latency (s)":8.06,
        "E2E Throughput (tokens\/s)":31.8,
        "Reserved Memory (MB)":3825,
        "Used Memory (MB)":5284
    },
    {
        "Model":"gpt2-xl",
        "Arch":"GPT-2",
        "Params (B)":1.61,
        "Open LLM Score (%)":"34.38*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0319,
        "Decode Throughput (tokens\/s)":31.2,
        "Allocated Memory (MB)":3561,
        "Energy (tokens\/kWh)":476190,
        "E2E Latency (s)":8.19,
        "E2E Throughput (tokens\/s)":31.3,
        "Reserved Memory (MB)":3827,
        "Used Memory (MB)":5286
    },
    {
        "Model":"gpt2-xl",
        "Arch":"GPT-2",
        "Params (B)":1.61,
        "Open LLM Score (%)":"34.38*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.032,
        "Decode Throughput (tokens\/s)":31.2,
        "Allocated Memory (MB)":3561,
        "Energy (tokens\/kWh)":485436,
        "E2E Latency (s)":8.19,
        "E2E Throughput (tokens\/s)":31.3,
        "Reserved Memory (MB)":3827,
        "Used Memory (MB)":5286
    },
    {
        "Model":"gpt2-xl",
        "Arch":"GPT-2",
        "Params (B)":1.61,
        "Open LLM Score (%)":"34.38 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0342,
        "Decode Throughput (tokens\/s)":30.9,
        "Allocated Memory (MB)":3561,
        "Energy (tokens\/kWh)":460829,
        "E2E Latency (s)":8.27,
        "E2E Throughput (tokens\/s)":31.0,
        "Reserved Memory (MB)":3825,
        "Used Memory (MB)":5284
    },
    {
        "Model":"gpt2-xl",
        "Arch":"GPT-2",
        "Params (B)":1.61,
        "Open LLM Score (%)":"34.38 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0647,
        "Decode Throughput (tokens\/s)":33.3,
        "Allocated Memory (MB)":7061,
        "Energy (tokens\/kWh)":425531,
        "E2E Latency (s)":7.72,
        "E2E Throughput (tokens\/s)":33.2,
        "Reserved Memory (MB)":7121,
        "Used Memory (MB)":8573
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.03,
        "Open LLM Score (%)":"34.37 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0172,
        "Decode Throughput (tokens\/s)":57.8,
        "Allocated Memory (MB)":2279,
        "Energy (tokens\/kWh)":840336,
        "E2E Latency (s)":4.43,
        "E2E Throughput (tokens\/s)":57.8,
        "Reserved Memory (MB)":2403,
        "Used Memory (MB)":3862
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.03,
        "Open LLM Score (%)":"34.37 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0186,
        "Decode Throughput (tokens\/s)":51.8,
        "Allocated Memory (MB)":2279,
        "Energy (tokens\/kWh)":735294,
        "E2E Latency (s)":4.94,
        "E2E Throughput (tokens\/s)":51.8,
        "Reserved Memory (MB)":2403,
        "Used Memory (MB)":3862
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.03,
        "Open LLM Score (%)":"34.37 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0187,
        "Decode Throughput (tokens\/s)":53.2,
        "Allocated Memory (MB)":2279,
        "Energy (tokens\/kWh)":787401,
        "E2E Latency (s)":4.81,
        "E2E Throughput (tokens\/s)":53.2,
        "Reserved Memory (MB)":2403,
        "Used Memory (MB)":3862
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.03,
        "Open LLM Score (%)":"34.37*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0199,
        "Decode Throughput (tokens\/s)":52.6,
        "Allocated Memory (MB)":852,
        "Energy (tokens\/kWh)":775193,
        "E2E Latency (s)":4.87,
        "E2E Throughput (tokens\/s)":52.6,
        "Reserved Memory (MB)":935,
        "Used Memory (MB)":2394
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.03,
        "Open LLM Score (%)":"34.37*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.02,
        "Decode Throughput (tokens\/s)":51.4,
        "Allocated Memory (MB)":1248,
        "Energy (tokens\/kWh)":813008,
        "E2E Latency (s)":4.98,
        "E2E Throughput (tokens\/s)":51.4,
        "Reserved Memory (MB)":1304,
        "Used Memory (MB)":2766
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.03,
        "Open LLM Score (%)":"34.37*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0206,
        "Decode Throughput (tokens\/s)":45.9,
        "Allocated Memory (MB)":851,
        "Energy (tokens\/kWh)":709219,
        "E2E Latency (s)":5.58,
        "E2E Throughput (tokens\/s)":45.9,
        "Reserved Memory (MB)":935,
        "Used Memory (MB)":2394
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.03,
        "Open LLM Score (%)":"34.37*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0209,
        "Decode Throughput (tokens\/s)":50.4,
        "Allocated Memory (MB)":877,
        "Energy (tokens\/kWh)":763358,
        "E2E Latency (s)":5.08,
        "E2E Throughput (tokens\/s)":50.4,
        "Reserved Memory (MB)":933,
        "Used Memory (MB)":2394
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b",
        "Arch":"GPT-NeoX",
        "Params (B)":7.0,
        "Open LLM Score (%)":"34.37 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0267,
        "Decode Throughput (tokens\/s)":68.0,
        "Allocated Memory (MB)":16428,
        "Energy (tokens\/kWh)":632911,
        "E2E Latency (s)":3.78,
        "E2E Throughput (tokens\/s)":67.7,
        "Reserved Memory (MB)":16481,
        "Used Memory (MB)":17941
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b",
        "Arch":"GPT-NeoX",
        "Params (B)":7.0,
        "Open LLM Score (%)":"34.37 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0275,
        "Decode Throughput (tokens\/s)":78.7,
        "Allocated Memory (MB)":16428,
        "Energy (tokens\/kWh)":709219,
        "E2E Latency (s)":3.27,
        "E2E Throughput (tokens\/s)":78.3,
        "Reserved Memory (MB)":16481,
        "Used Memory (MB)":17941
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b",
        "Arch":"GPT-NeoX",
        "Params (B)":7.0,
        "Open LLM Score (%)":"34.37 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0277,
        "Decode Throughput (tokens\/s)":71.2,
        "Allocated Memory (MB)":16428,
        "Energy (tokens\/kWh)":645161,
        "E2E Latency (s)":3.61,
        "E2E Throughput (tokens\/s)":70.9,
        "Reserved Memory (MB)":16485,
        "Used Memory (MB)":17945
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b",
        "Arch":"GPT-NeoX",
        "Params (B)":7.0,
        "Open LLM Score (%)":"34.37 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0288,
        "Decode Throughput (tokens\/s)":66.4,
        "Allocated Memory (MB)":16428,
        "Energy (tokens\/kWh)":602409,
        "E2E Latency (s)":3.87,
        "E2E Throughput (tokens\/s)":66.1,
        "Reserved Memory (MB)":16481,
        "Used Memory (MB)":17941
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b",
        "Arch":"GPT-NeoX",
        "Params (B)":7.0,
        "Open LLM Score (%)":"34.37*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0322,
        "Decode Throughput (tokens\/s)":31.2,
        "Allocated Memory (MB)":9183,
        "Energy (tokens\/kWh)":431034,
        "E2E Latency (s)":8.21,
        "E2E Throughput (tokens\/s)":31.2,
        "Reserved Memory (MB)":9231,
        "Used Memory (MB)":10699
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b",
        "Arch":"GPT-NeoX",
        "Params (B)":7.0,
        "Open LLM Score (%)":"34.37*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0339,
        "Decode Throughput (tokens\/s)":29.0,
        "Allocated Memory (MB)":9183,
        "Energy (tokens\/kWh)":404858,
        "E2E Latency (s)":8.83,
        "E2E Throughput (tokens\/s)":29.0,
        "Reserved Memory (MB)":9225,
        "Used Memory (MB)":10693
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b",
        "Arch":"GPT-NeoX",
        "Params (B)":7.0,
        "Open LLM Score (%)":"34.37*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0355,
        "Decode Throughput (tokens\/s)":79.9,
        "Allocated Memory (MB)":6002,
        "Energy (tokens\/kWh)":877192,
        "E2E Latency (s)":3.23,
        "E2E Throughput (tokens\/s)":79.3,
        "Reserved Memory (MB)":6064,
        "Used Memory (MB)":7526
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b",
        "Arch":"GPT-NeoX",
        "Params (B)":7.0,
        "Open LLM Score (%)":"34.37*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0357,
        "Decode Throughput (tokens\/s)":79.9,
        "Allocated Memory (MB)":7615,
        "Energy (tokens\/kWh)":1016260,
        "E2E Latency (s)":3.23,
        "E2E Throughput (tokens\/s)":79.3,
        "Reserved Memory (MB)":7679,
        "Used Memory (MB)":9141
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.03,
        "Open LLM Score (%)":"34.37 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0442,
        "Decode Throughput (tokens\/s)":58.1,
        "Allocated Memory (MB)":4492,
        "Energy (tokens\/kWh)":769230,
        "E2E Latency (s)":4.43,
        "E2E Throughput (tokens\/s)":57.8,
        "Reserved Memory (MB)":4548,
        "Used Memory (MB)":5999
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.03,
        "Open LLM Score (%)":"34.37*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0445,
        "Decode Throughput (tokens\/s)":38.8,
        "Allocated Memory (MB)":869,
        "Energy (tokens\/kWh)":602409,
        "E2E Latency (s)":6.61,
        "E2E Throughput (tokens\/s)":38.7,
        "Reserved Memory (MB)":922,
        "Used Memory (MB)":2382
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.03,
        "Open LLM Score (%)":"34.37*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0483,
        "Decode Throughput (tokens\/s)":32.4,
        "Allocated Memory (MB)":924,
        "Energy (tokens\/kWh)":476190,
        "E2E Latency (s)":7.92,
        "E2E Throughput (tokens\/s)":32.3,
        "Reserved Memory (MB)":1008,
        "Used Memory (MB)":2468
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.03,
        "Open LLM Score (%)":"34.37*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0485,
        "Decode Throughput (tokens\/s)":31.1,
        "Allocated Memory (MB)":924,
        "Energy (tokens\/kWh)":471698,
        "E2E Latency (s)":8.24,
        "E2E Throughput (tokens\/s)":31.1,
        "Reserved Memory (MB)":1008,
        "Used Memory (MB)":2468
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b",
        "Arch":"GPT-NeoX",
        "Params (B)":7.0,
        "Open LLM Score (%)":"34.37*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0591,
        "Decode Throughput (tokens\/s)":75.2,
        "Allocated Memory (MB)":5699,
        "Energy (tokens\/kWh)":847457,
        "E2E Latency (s)":3.45,
        "E2E Throughput (tokens\/s)":74.2,
        "Reserved Memory (MB)":5790,
        "Used Memory (MB)":7249
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.03,
        "Open LLM Score (%)":"34.37*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0662,
        "Decode Throughput (tokens\/s)":14.9,
        "Allocated Memory (MB)":1380,
        "Energy (tokens\/kWh)":230946,
        "E2E Latency (s)":17.2,
        "E2E Throughput (tokens\/s)":14.9,
        "Reserved Memory (MB)":1421,
        "Used Memory (MB)":2889
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.03,
        "Open LLM Score (%)":"34.37*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0675,
        "Decode Throughput (tokens\/s)":14.5,
        "Allocated Memory (MB)":1380,
        "Energy (tokens\/kWh)":219780,
        "E2E Latency (s)":17.7,
        "E2E Throughput (tokens\/s)":14.5,
        "Reserved Memory (MB)":1421,
        "Used Memory (MB)":2889
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b",
        "Arch":"GPT-NeoX",
        "Params (B)":7.0,
        "Open LLM Score (%)":"34.37*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0741,
        "Decode Throughput (tokens\/s)":73.3,
        "Allocated Memory (MB)":5699,
        "Energy (tokens\/kWh)":840336,
        "E2E Latency (s)":3.55,
        "E2E Throughput (tokens\/s)":72.1,
        "Reserved Memory (MB)":5790,
        "Used Memory (MB)":7249
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b",
        "Arch":"GPT-NeoX",
        "Params (B)":7.0,
        "Open LLM Score (%)":"34.37 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.269,
        "Decode Throughput (tokens\/s)":43.1,
        "Allocated Memory (MB)":32575,
        "Energy (tokens\/kWh)":380228,
        "E2E Latency (s)":6.19,
        "E2E Throughput (tokens\/s)":41.4,
        "Reserved Memory (MB)":32711,
        "Used Memory (MB)":34162
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b",
        "Arch":"GPT-NeoX",
        "Params (B)":7.0,
        "Open LLM Score (%)":"34.37*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.291,
        "Decode Throughput (tokens\/s)":41.8,
        "Allocated Memory (MB)":6764,
        "Energy (tokens\/kWh)":485436,
        "E2E Latency (s)":6.39,
        "E2E Throughput (tokens\/s)":40.1,
        "Reserved Memory (MB)":7163,
        "Used Memory (MB)":8623
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b",
        "Arch":"GPT-NeoX",
        "Params (B)":7.0,
        "Open LLM Score (%)":"34.37*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.299,
        "Decode Throughput (tokens\/s)":43.1,
        "Allocated Memory (MB)":6764,
        "Energy (tokens\/kWh)":480769,
        "E2E Latency (s)":6.21,
        "E2E Throughput (tokens\/s)":41.2,
        "Reserved Memory (MB)":7163,
        "Used Memory (MB)":8623
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-1.3b",
        "Arch":"GPT-2",
        "Params (B)":1.44,
        "Open LLM Score (%)":"34.31 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0113,
        "Decode Throughput (tokens\/s)":78.2,
        "Allocated Memory (MB)":2999,
        "Energy (tokens\/kWh)":1060445,
        "E2E Latency (s)":3.27,
        "E2E Throughput (tokens\/s)":78.3,
        "Reserved Memory (MB)":3045,
        "Used Memory (MB)":4502
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-1.3b",
        "Arch":"GPT-2",
        "Params (B)":1.44,
        "Open LLM Score (%)":"34.31 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0139,
        "Decode Throughput (tokens\/s)":70.4,
        "Allocated Memory (MB)":2999,
        "Energy (tokens\/kWh)":934579,
        "E2E Latency (s)":3.63,
        "E2E Throughput (tokens\/s)":70.5,
        "Reserved Memory (MB)":3045,
        "Used Memory (MB)":4504
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-1.3b",
        "Arch":"GPT-2",
        "Params (B)":1.44,
        "Open LLM Score (%)":"34.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.014,
        "Decode Throughput (tokens\/s)":72.6,
        "Allocated Memory (MB)":2999,
        "Energy (tokens\/kWh)":1043841,
        "E2E Latency (s)":3.52,
        "E2E Throughput (tokens\/s)":72.7,
        "Reserved Memory (MB)":3045,
        "Used Memory (MB)":4504
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-1.3b",
        "Arch":"GPT-2",
        "Params (B)":1.44,
        "Open LLM Score (%)":"34.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0143,
        "Decode Throughput (tokens\/s)":71.2,
        "Allocated Memory (MB)":2999,
        "Energy (tokens\/kWh)":1033057,
        "E2E Latency (s)":3.59,
        "E2E Throughput (tokens\/s)":71.3,
        "Reserved Memory (MB)":3045,
        "Used Memory (MB)":4504
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-1.3b",
        "Arch":"GPT-2",
        "Params (B)":1.44,
        "Open LLM Score (%)":"34.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0144,
        "Decode Throughput (tokens\/s)":75.4,
        "Allocated Memory (MB)":1245,
        "Energy (tokens\/kWh)":1063829,
        "E2E Latency (s)":3.39,
        "E2E Throughput (tokens\/s)":75.5,
        "Reserved Memory (MB)":1287,
        "Used Memory (MB)":2749
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-1.3b",
        "Arch":"GPT-2",
        "Params (B)":1.44,
        "Open LLM Score (%)":"34.31 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0147,
        "Decode Throughput (tokens\/s)":70.4,
        "Allocated Memory (MB)":2999,
        "Energy (tokens\/kWh)":961538,
        "E2E Latency (s)":3.63,
        "E2E Throughput (tokens\/s)":70.5,
        "Reserved Memory (MB)":3045,
        "Used Memory (MB)":4504
    },
    {
        "Model":"facebook\/xglm-4.5B",
        "Arch":"XGLM",
        "Params (B)":5.08,
        "Open LLM Score (%)":"34.31 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0292,
        "Decode Throughput (tokens\/s)":36.6,
        "Allocated Memory (MB)":9526,
        "Energy (tokens\/kWh)":460829,
        "E2E Latency (s)":6.99,
        "E2E Throughput (tokens\/s)":36.6,
        "Reserved Memory (MB)":9791,
        "Used Memory (MB)":11251
    },
    {
        "Model":"facebook\/xglm-4.5B",
        "Arch":"XGLM",
        "Params (B)":5.08,
        "Open LLM Score (%)":"34.31 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.033,
        "Decode Throughput (tokens\/s)":35.3,
        "Allocated Memory (MB)":9526,
        "Energy (tokens\/kWh)":427350,
        "E2E Latency (s)":7.26,
        "E2E Throughput (tokens\/s)":35.3,
        "Reserved Memory (MB)":9791,
        "Used Memory (MB)":11251
    },
    {
        "Model":"facebook\/xglm-4.5B",
        "Arch":"XGLM",
        "Params (B)":5.08,
        "Open LLM Score (%)":"34.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0361,
        "Decode Throughput (tokens\/s)":36.6,
        "Allocated Memory (MB)":3636,
        "Energy (tokens\/kWh)":510204,
        "E2E Latency (s)":7.0,
        "E2E Throughput (tokens\/s)":36.6,
        "Reserved Memory (MB)":3768,
        "Used Memory (MB)":5230
    },
    {
        "Model":"facebook\/xglm-4.5B",
        "Arch":"XGLM",
        "Params (B)":5.08,
        "Open LLM Score (%)":"34.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0382,
        "Decode Throughput (tokens\/s)":36.7,
        "Allocated Memory (MB)":4715,
        "Energy (tokens\/kWh)":537634,
        "E2E Latency (s)":6.98,
        "E2E Throughput (tokens\/s)":36.7,
        "Reserved Memory (MB)":4850,
        "Used Memory (MB)":6312
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-1.3b",
        "Arch":"GPT-2",
        "Params (B)":1.44,
        "Open LLM Score (%)":"34.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0413,
        "Decode Throughput (tokens\/s)":57.8,
        "Allocated Memory (MB)":1212,
        "Energy (tokens\/kWh)":854700,
        "E2E Latency (s)":4.45,
        "E2E Throughput (tokens\/s)":57.5,
        "Reserved Memory (MB)":1262,
        "Used Memory (MB)":2722
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-1.3b",
        "Arch":"GPT-2",
        "Params (B)":1.44,
        "Open LLM Score (%)":"34.31 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0535,
        "Decode Throughput (tokens\/s)":72.6,
        "Allocated Memory (MB)":5888,
        "Energy (tokens\/kWh)":854700,
        "E2E Latency (s)":3.56,
        "E2E Throughput (tokens\/s)":71.9,
        "Reserved Memory (MB)":5928,
        "Used Memory (MB)":7379
    },
    {
        "Model":"facebook\/xglm-4.5B",
        "Arch":"XGLM",
        "Params (B)":5.08,
        "Open LLM Score (%)":"34.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0567,
        "Decode Throughput (tokens\/s)":34.4,
        "Allocated Memory (MB)":3564,
        "Energy (tokens\/kWh)":492610,
        "E2E Latency (s)":7.48,
        "E2E Throughput (tokens\/s)":34.2,
        "Reserved Memory (MB)":3722,
        "Used Memory (MB)":5182
    },
    {
        "Model":"facebook\/xglm-4.5B",
        "Arch":"XGLM",
        "Params (B)":5.08,
        "Open LLM Score (%)":"34.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0594,
        "Decode Throughput (tokens\/s)":30.0,
        "Allocated Memory (MB)":3564,
        "Energy (tokens\/kWh)":432900,
        "E2E Latency (s)":8.55,
        "E2E Throughput (tokens\/s)":29.9,
        "Reserved Memory (MB)":3722,
        "Used Memory (MB)":5182
    },
    {
        "Model":"facebook\/xglm-4.5B",
        "Arch":"XGLM",
        "Params (B)":5.08,
        "Open LLM Score (%)":"34.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.121,
        "Decode Throughput (tokens\/s)":25.6,
        "Allocated Memory (MB)":3570,
        "Energy (tokens\/kWh)":357142,
        "E2E Latency (s)":10.1,
        "E2E Throughput (tokens\/s)":25.3,
        "Reserved Memory (MB)":3714,
        "Used Memory (MB)":5173
    },
    {
        "Model":"facebook\/xglm-4.5B",
        "Arch":"XGLM",
        "Params (B)":5.08,
        "Open LLM Score (%)":"34.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.134,
        "Decode Throughput (tokens\/s)":8.15,
        "Allocated Memory (MB)":5503,
        "Energy (tokens\/kWh)":121359,
        "E2E Latency (s)":31.4,
        "E2E Throughput (tokens\/s)":8.15,
        "Reserved Memory (MB)":5651,
        "Used Memory (MB)":7119
    },
    {
        "Model":"facebook\/xglm-4.5B",
        "Arch":"XGLM",
        "Params (B)":5.08,
        "Open LLM Score (%)":"34.31 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.167,
        "Decode Throughput (tokens\/s)":37.4,
        "Allocated Memory (MB)":19042,
        "Energy (tokens\/kWh)":396825,
        "E2E Latency (s)":6.99,
        "E2E Throughput (tokens\/s)":36.6,
        "Reserved Memory (MB)":19081,
        "Used Memory (MB)":20533
    },
    {
        "Model":"facebook\/xglm-4.5B",
        "Arch":"XGLM",
        "Params (B)":5.08,
        "Open LLM Score (%)":"34.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.19,
        "Decode Throughput (tokens\/s)":17.2,
        "Allocated Memory (MB)":3737,
        "Energy (tokens\/kWh)":240384,
        "E2E Latency (s)":15.0,
        "E2E Throughput (tokens\/s)":17.1,
        "Reserved Memory (MB)":3896,
        "Used Memory (MB)":5356
    },
    {
        "Model":"bigcode\/starcoderbase-7b",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":7.0,
        "Open LLM Score (%)":"33.75 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0295,
        "Decode Throughput (tokens\/s)":55.9,
        "Allocated Memory (MB)":14855,
        "Energy (tokens\/kWh)":505050,
        "E2E Latency (s)":4.59,
        "E2E Throughput (tokens\/s)":55.8,
        "Reserved Memory (MB)":14942,
        "Used Memory (MB)":16399
    },
    {
        "Model":"bigcode\/starcoderbase-7b",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":7.0,
        "Open LLM Score (%)":"33.75 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0315,
        "Decode Throughput (tokens\/s)":52.4,
        "Allocated Memory (MB)":14855,
        "Energy (tokens\/kWh)":497512,
        "E2E Latency (s)":4.9,
        "E2E Throughput (tokens\/s)":52.2,
        "Reserved Memory (MB)":14940,
        "Used Memory (MB)":16399
    },
    {
        "Model":"bigcode\/starcoderbase-7b",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":7.0,
        "Open LLM Score (%)":"33.75 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0331,
        "Decode Throughput (tokens\/s)":50.8,
        "Allocated Memory (MB)":14855,
        "Energy (tokens\/kWh)":460829,
        "E2E Latency (s)":5.05,
        "E2E Throughput (tokens\/s)":50.7,
        "Reserved Memory (MB)":14940,
        "Used Memory (MB)":16399
    },
    {
        "Model":"bigcode\/starcoderbase-7b",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":7.0,
        "Open LLM Score (%)":"33.75*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.108,
        "Decode Throughput (tokens\/s)":9.41,
        "Allocated Memory (MB)":7830,
        "Energy (tokens\/kWh)":109529,
        "E2E Latency (s)":27.2,
        "E2E Throughput (tokens\/s)":9.41,
        "Reserved Memory (MB)":7897,
        "Used Memory (MB)":9888
    },
    {
        "Model":"bigcode\/starcoderbase-7b",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":7.0,
        "Open LLM Score (%)":"33.75*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.136,
        "Decode Throughput (tokens\/s)":11.9,
        "Allocated Memory (MB)":7829,
        "Energy (tokens\/kWh)":156250,
        "E2E Latency (s)":21.6,
        "E2E Throughput (tokens\/s)":11.9,
        "Reserved Memory (MB)":7897,
        "Used Memory (MB)":29024
    },
    {
        "Model":"bigcode\/starcoderbase-7b",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":7.0,
        "Open LLM Score (%)":"33.75 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.302,
        "Decode Throughput (tokens\/s)":45.5,
        "Allocated Memory (MB)":29634,
        "Energy (tokens\/kWh)":387596,
        "E2E Latency (s)":5.9,
        "E2E Throughput (tokens\/s)":43.4,
        "Reserved Memory (MB)":29890,
        "Used Memory (MB)":31341
    },
    {
        "Model":"bigcode\/starcoderbase-7b",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":7.0,
        "Open LLM Score (%)":"33.75*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.335,
        "Decode Throughput (tokens\/s)":19.0,
        "Allocated Memory (MB)":4741,
        "Energy (tokens\/kWh)":206185,
        "E2E Latency (s)":13.7,
        "E2E Throughput (tokens\/s)":18.7,
        "Reserved Memory (MB)":4909,
        "Used Memory (MB)":6368
    },
    {
        "Model":"bigcode\/starcoderbase-7b",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":7.0,
        "Open LLM Score (%)":"33.75*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.846,
        "Decode Throughput (tokens\/s)":14.0,
        "Allocated Memory (MB)":4741,
        "Energy (tokens\/kWh)":125156,
        "E2E Latency (s)":19.0,
        "E2E Throughput (tokens\/s)":13.5,
        "Reserved Memory (MB)":4909,
        "Used Memory (MB)":13358
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"33.72 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0169,
        "Decode Throughput (tokens\/s)":57.7,
        "Allocated Memory (MB)":2279,
        "Energy (tokens\/kWh)":847457,
        "E2E Latency (s)":4.44,
        "E2E Throughput (tokens\/s)":57.7,
        "Reserved Memory (MB)":2403,
        "Used Memory (MB)":3862
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"33.72 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0178,
        "Decode Throughput (tokens\/s)":53.8,
        "Allocated Memory (MB)":2279,
        "Energy (tokens\/kWh)":781250,
        "E2E Latency (s)":4.76,
        "E2E Throughput (tokens\/s)":53.8,
        "Reserved Memory (MB)":2403,
        "Used Memory (MB)":3862
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"33.72 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0182,
        "Decode Throughput (tokens\/s)":52.0,
        "Allocated Memory (MB)":2279,
        "Energy (tokens\/kWh)":757575,
        "E2E Latency (s)":4.92,
        "E2E Throughput (tokens\/s)":52.0,
        "Reserved Memory (MB)":2403,
        "Used Memory (MB)":3862
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"33.72*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0204,
        "Decode Throughput (tokens\/s)":50.6,
        "Allocated Memory (MB)":1248,
        "Energy (tokens\/kWh)":799999,
        "E2E Latency (s)":5.06,
        "E2E Throughput (tokens\/s)":50.6,
        "Reserved Memory (MB)":1304,
        "Used Memory (MB)":2766
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"33.72*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0205,
        "Decode Throughput (tokens\/s)":47.5,
        "Allocated Memory (MB)":851,
        "Energy (tokens\/kWh)":694444,
        "E2E Latency (s)":5.39,
        "E2E Throughput (tokens\/s)":47.5,
        "Reserved Memory (MB)":935,
        "Used Memory (MB)":2394
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"33.72*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0208,
        "Decode Throughput (tokens\/s)":51.4,
        "Allocated Memory (MB)":852,
        "Energy (tokens\/kWh)":769230,
        "E2E Latency (s)":4.98,
        "E2E Throughput (tokens\/s)":51.4,
        "Reserved Memory (MB)":935,
        "Used Memory (MB)":2394
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"33.72*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.021,
        "Decode Throughput (tokens\/s)":48.1,
        "Allocated Memory (MB)":877,
        "Energy (tokens\/kWh)":781250,
        "E2E Latency (s)":5.32,
        "E2E Throughput (tokens\/s)":48.1,
        "Reserved Memory (MB)":933,
        "Used Memory (MB)":2394
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"33.72 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0432,
        "Decode Throughput (tokens\/s)":57.6,
        "Allocated Memory (MB)":4492,
        "Energy (tokens\/kWh)":769230,
        "E2E Latency (s)":4.47,
        "E2E Throughput (tokens\/s)":57.3,
        "Reserved Memory (MB)":4548,
        "Used Memory (MB)":5999
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"33.72*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0448,
        "Decode Throughput (tokens\/s)":38.3,
        "Allocated Memory (MB)":869,
        "Energy (tokens\/kWh)":584795,
        "E2E Latency (s)":6.69,
        "E2E Throughput (tokens\/s)":38.3,
        "Reserved Memory (MB)":922,
        "Used Memory (MB)":2382
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"33.72*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0486,
        "Decode Throughput (tokens\/s)":31.6,
        "Allocated Memory (MB)":924,
        "Energy (tokens\/kWh)":476190,
        "E2E Latency (s)":8.11,
        "E2E Throughput (tokens\/s)":31.6,
        "Reserved Memory (MB)":1008,
        "Used Memory (MB)":2468
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"33.72*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0487,
        "Decode Throughput (tokens\/s)":32.6,
        "Allocated Memory (MB)":924,
        "Energy (tokens\/kWh)":476190,
        "E2E Latency (s)":7.88,
        "E2E Throughput (tokens\/s)":32.5,
        "Reserved Memory (MB)":1008,
        "Used Memory (MB)":2468
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"33.72*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.066,
        "Decode Throughput (tokens\/s)":14.8,
        "Allocated Memory (MB)":1380,
        "Energy (tokens\/kWh)":236406,
        "E2E Latency (s)":17.3,
        "E2E Throughput (tokens\/s)":14.8,
        "Reserved Memory (MB)":1421,
        "Used Memory (MB)":2889
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"33.72*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0688,
        "Decode Throughput (tokens\/s)":14.5,
        "Allocated Memory (MB)":1380,
        "Energy (tokens\/kWh)":218340,
        "E2E Latency (s)":17.7,
        "E2E Throughput (tokens\/s)":14.5,
        "Reserved Memory (MB)":1421,
        "Used Memory (MB)":2889
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"GPT-Neo",
        "Params (B)":1.37,
        "Open LLM Score (%)":"33.58 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0129,
        "Decode Throughput (tokens\/s)":75.4,
        "Allocated Memory (MB)":2943,
        "Energy (tokens\/kWh)":1013171,
        "E2E Latency (s)":3.39,
        "E2E Throughput (tokens\/s)":75.5,
        "Reserved Memory (MB)":3017,
        "Used Memory (MB)":4475
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"GPT-Neo",
        "Params (B)":1.37,
        "Open LLM Score (%)":"33.58 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0158,
        "Decode Throughput (tokens\/s)":63.9,
        "Allocated Memory (MB)":2943,
        "Energy (tokens\/kWh)":862068,
        "E2E Latency (s)":4.01,
        "E2E Throughput (tokens\/s)":63.8,
        "Reserved Memory (MB)":3017,
        "Used Memory (MB)":4477
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"GPT-Neo",
        "Params (B)":1.37,
        "Open LLM Score (%)":"33.58 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0172,
        "Decode Throughput (tokens\/s)":59.7,
        "Allocated Memory (MB)":2946,
        "Energy (tokens\/kWh)":819672,
        "E2E Latency (s)":4.29,
        "E2E Throughput (tokens\/s)":59.7,
        "Reserved Memory (MB)":3038,
        "Used Memory (MB)":4498
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"GPT-Neo",
        "Params (B)":1.37,
        "Open LLM Score (%)":"33.58*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0182,
        "Decode Throughput (tokens\/s)":60.9,
        "Allocated Memory (MB)":1732,
        "Energy (tokens\/kWh)":925925,
        "E2E Latency (s)":4.21,
        "E2E Throughput (tokens\/s)":60.8,
        "Reserved Memory (MB)":1818,
        "Used Memory (MB)":3279
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"GPT-Neo",
        "Params (B)":1.37,
        "Open LLM Score (%)":"33.58*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0187,
        "Decode Throughput (tokens\/s)":60.9,
        "Allocated Memory (MB)":1193,
        "Energy (tokens\/kWh)":884955,
        "E2E Latency (s)":4.21,
        "E2E Throughput (tokens\/s)":60.8,
        "Reserved Memory (MB)":1277,
        "Used Memory (MB)":2738
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"GPT-Neo",
        "Params (B)":1.37,
        "Open LLM Score (%)":"33.58 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.019,
        "Decode Throughput (tokens\/s)":59.7,
        "Allocated Memory (MB)":2946,
        "Energy (tokens\/kWh)":793650,
        "E2E Latency (s)":4.29,
        "E2E Throughput (tokens\/s)":59.7,
        "Reserved Memory (MB)":3038,
        "Used Memory (MB)":4498
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"GPT-Neo",
        "Params (B)":1.37,
        "Open LLM Score (%)":"33.58*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0227,
        "Decode Throughput (tokens\/s)":60.6,
        "Allocated Memory (MB)":1157,
        "Energy (tokens\/kWh)":909090,
        "E2E Latency (s)":4.23,
        "E2E Throughput (tokens\/s)":60.5,
        "Reserved Memory (MB)":1247,
        "Used Memory (MB)":2707
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"GPT-Neo",
        "Params (B)":1.37,
        "Open LLM Score (%)":"33.58*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0239,
        "Decode Throughput (tokens\/s)":52.8,
        "Allocated Memory (MB)":1157,
        "Energy (tokens\/kWh)":775193,
        "E2E Latency (s)":4.85,
        "E2E Throughput (tokens\/s)":52.8,
        "Reserved Memory (MB)":1247,
        "Used Memory (MB)":2707
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"GPT-Neo",
        "Params (B)":1.37,
        "Open LLM Score (%)":"33.58*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0467,
        "Decode Throughput (tokens\/s)":44.0,
        "Allocated Memory (MB)":1160,
        "Energy (tokens\/kWh)":662251,
        "E2E Latency (s)":5.84,
        "E2E Throughput (tokens\/s)":43.8,
        "Reserved Memory (MB)":1249,
        "Used Memory (MB)":2709
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"GPT-Neo",
        "Params (B)":1.37,
        "Open LLM Score (%)":"33.58 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0567,
        "Decode Throughput (tokens\/s)":62.3,
        "Allocated Memory (MB)":5775,
        "Energy (tokens\/kWh)":781250,
        "E2E Latency (s)":4.15,
        "E2E Throughput (tokens\/s)":61.7,
        "Reserved Memory (MB)":5817,
        "Used Memory (MB)":7268
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"GPT-Neo",
        "Params (B)":1.37,
        "Open LLM Score (%)":"33.58*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0606,
        "Decode Throughput (tokens\/s)":32.7,
        "Allocated Memory (MB)":1206,
        "Energy (tokens\/kWh)":485436,
        "E2E Latency (s)":7.85,
        "E2E Throughput (tokens\/s)":32.6,
        "Reserved Memory (MB)":1300,
        "Used Memory (MB)":2759
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"GPT-Neo",
        "Params (B)":1.37,
        "Open LLM Score (%)":"33.58*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0637,
        "Decode Throughput (tokens\/s)":16.1,
        "Allocated Memory (MB)":1736,
        "Energy (tokens\/kWh)":241545,
        "E2E Latency (s)":15.9,
        "E2E Throughput (tokens\/s)":16.1,
        "Reserved Memory (MB)":1814,
        "Used Memory (MB)":3281
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"GPT-Neo",
        "Params (B)":1.37,
        "Open LLM Score (%)":"33.58*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.065,
        "Decode Throughput (tokens\/s)":32.4,
        "Allocated Memory (MB)":1210,
        "Energy (tokens\/kWh)":465116,
        "E2E Latency (s)":7.95,
        "E2E Throughput (tokens\/s)":32.2,
        "Reserved Memory (MB)":1300,
        "Used Memory (MB)":2759
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"GPT-Neo",
        "Params (B)":1.37,
        "Open LLM Score (%)":"33.58*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0676,
        "Decode Throughput (tokens\/s)":15.6,
        "Allocated Memory (MB)":1740,
        "Energy (tokens\/kWh)":234192,
        "E2E Latency (s)":16.4,
        "E2E Throughput (tokens\/s)":15.6,
        "Reserved Memory (MB)":1839,
        "Used Memory (MB)":3307
    },
    {
        "Model":"EleutherAI\/polyglot-ko-12.8b",
        "Arch":"GPT-NeoX",
        "Params (B)":13.06,
        "Open LLM Score (%)":"33.33 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0507,
        "Decode Throughput (tokens\/s)":32.6,
        "Allocated Memory (MB)":26825,
        "Energy (tokens\/kWh)":324675,
        "E2E Latency (s)":7.88,
        "E2E Throughput (tokens\/s)":32.5,
        "Reserved Memory (MB)":26866,
        "Used Memory (MB)":28326
    },
    {
        "Model":"EleutherAI\/polyglot-ko-12.8b",
        "Arch":"GPT-NeoX",
        "Params (B)":13.06,
        "Open LLM Score (%)":"33.33 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0515,
        "Decode Throughput (tokens\/s)":38.9,
        "Allocated Memory (MB)":26825,
        "Energy (tokens\/kWh)":347222,
        "E2E Latency (s)":6.6,
        "E2E Throughput (tokens\/s)":38.8,
        "Reserved Memory (MB)":26856,
        "Used Memory (MB)":28315
    },
    {
        "Model":"EleutherAI\/polyglot-ko-12.8b",
        "Arch":"GPT-NeoX",
        "Params (B)":13.06,
        "Open LLM Score (%)":"33.33*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0684,
        "Decode Throughput (tokens\/s)":33.6,
        "Allocated Memory (MB)":8454,
        "Energy (tokens\/kWh)":398406,
        "E2E Latency (s)":7.67,
        "E2E Throughput (tokens\/s)":33.4,
        "Reserved Memory (MB)":8480,
        "Used Memory (MB)":9942
    },
    {
        "Model":"EleutherAI\/polyglot-ko-12.8b",
        "Arch":"GPT-NeoX",
        "Params (B)":13.06,
        "Open LLM Score (%)":"33.33*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0686,
        "Decode Throughput (tokens\/s)":34.0,
        "Allocated Memory (MB)":9802,
        "Energy (tokens\/kWh)":462962,
        "E2E Latency (s)":7.57,
        "E2E Throughput (tokens\/s)":33.8,
        "Reserved Memory (MB)":9835,
        "Used Memory (MB)":11297
    },
    {
        "Model":"EleutherAI\/polyglot-ko-12.8b",
        "Arch":"GPT-NeoX",
        "Params (B)":13.06,
        "Open LLM Score (%)":"33.33*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0766,
        "Decode Throughput (tokens\/s)":12.6,
        "Allocated Memory (MB)":14315,
        "Energy (tokens\/kWh)":179856,
        "E2E Latency (s)":20.4,
        "E2E Throughput (tokens\/s)":12.5,
        "Reserved Memory (MB)":14352,
        "Used Memory (MB)":15820
    },
    {
        "Model":"EleutherAI\/polyglot-ko-12.8b",
        "Arch":"GPT-NeoX",
        "Params (B)":13.06,
        "Open LLM Score (%)":"33.33*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0871,
        "Decode Throughput (tokens\/s)":11.9,
        "Allocated Memory (MB)":14313,
        "Energy (tokens\/kWh)":164473,
        "E2E Latency (s)":21.6,
        "E2E Throughput (tokens\/s)":11.9,
        "Reserved Memory (MB)":14344,
        "Used Memory (MB)":15812
    },
    {
        "Model":"EleutherAI\/polyglot-ko-12.8b",
        "Arch":"GPT-NeoX",
        "Params (B)":13.06,
        "Open LLM Score (%)":"33.33*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.109,
        "Decode Throughput (tokens\/s)":31.7,
        "Allocated Memory (MB)":8240,
        "Energy (tokens\/kWh)":389105,
        "E2E Latency (s)":8.16,
        "E2E Throughput (tokens\/s)":31.4,
        "Reserved Memory (MB)":8290,
        "Used Memory (MB)":9749
    },
    {
        "Model":"EleutherAI\/polyglot-ko-12.8b",
        "Arch":"GPT-NeoX",
        "Params (B)":13.06,
        "Open LLM Score (%)":"33.33*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.133,
        "Decode Throughput (tokens\/s)":29.7,
        "Allocated Memory (MB)":8240,
        "Energy (tokens\/kWh)":367647,
        "E2E Latency (s)":8.72,
        "E2E Throughput (tokens\/s)":29.4,
        "Reserved Memory (MB)":8311,
        "Used Memory (MB)":9770
    },
    {
        "Model":"EleutherAI\/polyglot-ko-12.8b",
        "Arch":"GPT-NeoX",
        "Params (B)":13.06,
        "Open LLM Score (%)":"33.33 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.445,
        "Decode Throughput (tokens\/s)":23.0,
        "Allocated Memory (MB)":53472,
        "Energy (tokens\/kWh)":204498,
        "E2E Latency (s)":11.5,
        "E2E Throughput (tokens\/s)":22.3,
        "Reserved Memory (MB)":53517,
        "Used Memory (MB)":54968
    },
    {
        "Model":"EleutherAI\/polyglot-ko-12.8b",
        "Arch":"GPT-NeoX",
        "Params (B)":13.06,
        "Open LLM Score (%)":"33.33*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.496,
        "Decode Throughput (tokens\/s)":20.7,
        "Allocated Memory (MB)":9009,
        "Energy (tokens\/kWh)":251256,
        "E2E Latency (s)":12.8,
        "E2E Throughput (tokens\/s)":20.0,
        "Reserved Memory (MB)":9502,
        "Used Memory (MB)":10961
    },
    {
        "Model":"EleutherAI\/polyglot-ko-12.8b",
        "Arch":"GPT-NeoX",
        "Params (B)":13.06,
        "Open LLM Score (%)":"33.33*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.505,
        "Decode Throughput (tokens\/s)":21.4,
        "Allocated Memory (MB)":9009,
        "Energy (tokens\/kWh)":239808,
        "E2E Latency (s)":12.4,
        "E2E Throughput (tokens\/s)":20.6,
        "Reserved Memory (MB)":9502,
        "Used Memory (MB)":10961
    },
    {
        "Model":"cerebras\/Cerebras-GPT-2.7B",
        "Arch":"GPT-2",
        "Params (B)":2.7,
        "Open LLM Score (%)":"33.25 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0163,
        "Decode Throughput (tokens\/s)":62.3,
        "Allocated Memory (MB)":5799,
        "Energy (tokens\/kWh)":729927,
        "E2E Latency (s)":4.11,
        "E2E Throughput (tokens\/s)":62.3,
        "Reserved Memory (MB)":5869,
        "Used Memory (MB)":7329
    },
    {
        "Model":"cerebras\/Cerebras-GPT-2.7B",
        "Arch":"GPT-2",
        "Params (B)":2.7,
        "Open LLM Score (%)":"33.25*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0189,
        "Decode Throughput (tokens\/s)":55.7,
        "Allocated Memory (MB)":5799,
        "Energy (tokens\/kWh)":775193,
        "E2E Latency (s)":4.6,
        "E2E Throughput (tokens\/s)":55.7,
        "Reserved Memory (MB)":5867,
        "Used Memory (MB)":7327
    },
    {
        "Model":"cerebras\/Cerebras-GPT-2.7B",
        "Arch":"GPT-2",
        "Params (B)":2.7,
        "Open LLM Score (%)":"33.25*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.019,
        "Decode Throughput (tokens\/s)":55.0,
        "Allocated Memory (MB)":5799,
        "Energy (tokens\/kWh)":787401,
        "E2E Latency (s)":4.66,
        "E2E Throughput (tokens\/s)":54.9,
        "Reserved Memory (MB)":5867,
        "Used Memory (MB)":7327
    },
    {
        "Model":"cerebras\/Cerebras-GPT-2.7B",
        "Arch":"GPT-2",
        "Params (B)":2.7,
        "Open LLM Score (%)":"33.25 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.019,
        "Decode Throughput (tokens\/s)":54.4,
        "Allocated Memory (MB)":5799,
        "Energy (tokens\/kWh)":684931,
        "E2E Latency (s)":4.71,
        "E2E Throughput (tokens\/s)":54.4,
        "Reserved Memory (MB)":5869,
        "Used Memory (MB)":7329
    },
    {
        "Model":"cerebras\/Cerebras-GPT-2.7B",
        "Arch":"GPT-2",
        "Params (B)":2.7,
        "Open LLM Score (%)":"33.25 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0196,
        "Decode Throughput (tokens\/s)":53.9,
        "Allocated Memory (MB)":5799,
        "Energy (tokens\/kWh)":709219,
        "E2E Latency (s)":4.75,
        "E2E Throughput (tokens\/s)":53.9,
        "Reserved Memory (MB)":5869,
        "Used Memory (MB)":7329
    },
    {
        "Model":"cerebras\/Cerebras-GPT-2.7B",
        "Arch":"GPT-2",
        "Params (B)":2.7,
        "Open LLM Score (%)":"33.25*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0224,
        "Decode Throughput (tokens\/s)":57.4,
        "Allocated Memory (MB)":2119,
        "Energy (tokens\/kWh)":813008,
        "E2E Latency (s)":4.46,
        "E2E Throughput (tokens\/s)":57.4,
        "Reserved Memory (MB)":2239,
        "Used Memory (MB)":3701
    },
    {
        "Model":"RWKV\/rwkv-4-1b5-pile",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":1.0,
        "Open LLM Score (%)":"33.25 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.025,
        "Decode Throughput (tokens\/s)":39.1,
        "Allocated Memory (MB)":3066,
        "Energy (tokens\/kWh)":549450,
        "E2E Latency (s)":6.55,
        "E2E Throughput (tokens\/s)":39.1,
        "Reserved Memory (MB)":3344,
        "Used Memory (MB)":4804
    },
    {
        "Model":"RWKV\/rwkv-4-1b5-pile",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":1.0,
        "Open LLM Score (%)":"33.25 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0253,
        "Decode Throughput (tokens\/s)":39.0,
        "Allocated Memory (MB)":3066,
        "Energy (tokens\/kWh)":558659,
        "E2E Latency (s)":6.57,
        "E2E Throughput (tokens\/s)":39.0,
        "Reserved Memory (MB)":3347,
        "Used Memory (MB)":4806
    },
    {
        "Model":"RWKV\/rwkv-4-1b5-pile",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":1.0,
        "Open LLM Score (%)":"33.25 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0562,
        "Decode Throughput (tokens\/s)":40.6,
        "Allocated Memory (MB)":6124,
        "Energy (tokens\/kWh)":529100,
        "E2E Latency (s)":6.34,
        "E2E Throughput (tokens\/s)":40.4,
        "Reserved Memory (MB)":6180,
        "Used Memory (MB)":7631
    },
    {
        "Model":"RWKV\/rwkv-4-1b5-pile",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":1.0,
        "Open LLM Score (%)":"33.25*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.064,
        "Decode Throughput (tokens\/s)":23.2,
        "Allocated Memory (MB)":1255,
        "Energy (tokens\/kWh)":346020,
        "E2E Latency (s)":11.1,
        "E2E Throughput (tokens\/s)":23.1,
        "Reserved Memory (MB)":1304,
        "Used Memory (MB)":2763
    },
    {
        "Model":"cerebras\/Cerebras-GPT-2.7B",
        "Arch":"GPT-2",
        "Params (B)":2.7,
        "Open LLM Score (%)":"33.25*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.076,
        "Decode Throughput (tokens\/s)":43.1,
        "Allocated Memory (MB)":2067,
        "Energy (tokens\/kWh)":609756,
        "E2E Latency (s)":6.0,
        "E2E Throughput (tokens\/s)":42.7,
        "Reserved Memory (MB)":2216,
        "Used Memory (MB)":3676
    },
    {
        "Model":"RWKV\/rwkv-4-1b5-pile",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":1.0,
        "Open LLM Score (%)":"33.25*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0832,
        "Decode Throughput (tokens\/s)":12.1,
        "Allocated Memory (MB)":1759,
        "Energy (tokens\/kWh)":183150,
        "E2E Latency (s)":21.1,
        "E2E Throughput (tokens\/s)":12.1,
        "Reserved Memory (MB)":1809,
        "Used Memory (MB)":3277
    },
    {
        "Model":"cerebras\/Cerebras-GPT-2.7B",
        "Arch":"GPT-2",
        "Params (B)":2.7,
        "Open LLM Score (%)":"33.25 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0938,
        "Decode Throughput (tokens\/s)":56.8,
        "Allocated Memory (MB)":11488,
        "Energy (tokens\/kWh)":617283,
        "E2E Latency (s)":4.58,
        "E2E Throughput (tokens\/s)":55.9,
        "Reserved Memory (MB)":11525,
        "Used Memory (MB)":12977
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-13B",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":13.0,
        "Open LLM Score (%)":"32.95 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0495,
        "Decode Throughput (tokens\/s)":40.7,
        "Allocated Memory (MB)":27362,
        "Energy (tokens\/kWh)":373134,
        "E2E Latency (s)":6.31,
        "E2E Throughput (tokens\/s)":40.6,
        "Reserved Memory (MB)":27401,
        "Used Memory (MB)":28860
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-13B",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":13.0,
        "Open LLM Score (%)":"32.95*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0663,
        "Decode Throughput (tokens\/s)":41.7,
        "Allocated Memory (MB)":10325,
        "Energy (tokens\/kWh)":531914,
        "E2E Latency (s)":6.18,
        "E2E Throughput (tokens\/s)":41.4,
        "Reserved Memory (MB)":10366,
        "Used Memory (MB)":11827
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-13B",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":13.0,
        "Open LLM Score (%)":"32.95*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.067,
        "Decode Throughput (tokens\/s)":41.5,
        "Allocated Memory (MB)":8977,
        "Energy (tokens\/kWh)":458715,
        "E2E Latency (s)":6.22,
        "E2E Throughput (tokens\/s)":41.2,
        "Reserved Memory (MB)":9017,
        "Used Memory (MB)":10479
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-13B",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":13.0,
        "Open LLM Score (%)":"32.95*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0739,
        "Decode Throughput (tokens\/s)":13.0,
        "Allocated Memory (MB)":14853,
        "Energy (tokens\/kWh)":182149,
        "E2E Latency (s)":19.7,
        "E2E Throughput (tokens\/s)":13.0,
        "Reserved Memory (MB)":14879,
        "Used Memory (MB)":16347
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-13B",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":13.0,
        "Open LLM Score (%)":"32.95*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0785,
        "Decode Throughput (tokens\/s)":12.8,
        "Allocated Memory (MB)":14857,
        "Energy (tokens\/kWh)":175131,
        "E2E Latency (s)":20.0,
        "E2E Throughput (tokens\/s)":12.8,
        "Reserved Memory (MB)":14893,
        "Used Memory (MB)":16361
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-13B",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":13.0,
        "Open LLM Score (%)":"32.95*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.106,
        "Decode Throughput (tokens\/s)":40.0,
        "Allocated Memory (MB)":8762,
        "Energy (tokens\/kWh)":456621,
        "E2E Latency (s)":6.49,
        "E2E Throughput (tokens\/s)":39.4,
        "Reserved Memory (MB)":8808,
        "Used Memory (MB)":10267
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-13B",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":13.0,
        "Open LLM Score (%)":"32.95*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.133,
        "Decode Throughput (tokens\/s)":37.3,
        "Allocated Memory (MB)":8762,
        "Energy (tokens\/kWh)":429184,
        "E2E Latency (s)":6.97,
        "E2E Throughput (tokens\/s)":36.7,
        "Reserved Memory (MB)":8808,
        "Used Memory (MB)":10267
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-13B",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":13.0,
        "Open LLM Score (%)":"32.95 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.461,
        "Decode Throughput (tokens\/s)":25.9,
        "Allocated Memory (MB)":54714,
        "Energy (tokens\/kWh)":229357,
        "E2E Latency (s)":10.3,
        "E2E Throughput (tokens\/s)":24.9,
        "Reserved Memory (MB)":54748,
        "Used Memory (MB)":56199
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-13B",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":13.0,
        "Open LLM Score (%)":"32.95*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.491,
        "Decode Throughput (tokens\/s)":24.1,
        "Allocated Memory (MB)":9440,
        "Energy (tokens\/kWh)":271739,
        "E2E Latency (s)":11.1,
        "E2E Throughput (tokens\/s)":23.1,
        "Reserved Memory (MB)":9619,
        "Used Memory (MB)":11079
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-13B",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":13.0,
        "Open LLM Score (%)":"32.95*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.51,
        "Decode Throughput (tokens\/s)":24.3,
        "Allocated Memory (MB)":9440,
        "Energy (tokens\/kWh)":259740,
        "E2E Latency (s)":11.0,
        "E2E Throughput (tokens\/s)":23.3,
        "Reserved Memory (MB)":9619,
        "Used Memory (MB)":11079
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":1.08,
        "Open LLM Score (%)":"32.78 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0107,
        "Decode Throughput (tokens\/s)":93.1,
        "Allocated Memory (MB)":2243,
        "Energy (tokens\/kWh)":1336898,
        "E2E Latency (s)":2.75,
        "E2E Throughput (tokens\/s)":93.1,
        "Reserved Memory (MB)":2292,
        "Used Memory (MB)":3751
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":1.08,
        "Open LLM Score (%)":"32.78 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0122,
        "Decode Throughput (tokens\/s)":88.5,
        "Allocated Memory (MB)":2243,
        "Energy (tokens\/kWh)":1169590,
        "E2E Latency (s)":2.89,
        "E2E Throughput (tokens\/s)":88.6,
        "Reserved Memory (MB)":2290,
        "Used Memory (MB)":3749
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":1.08,
        "Open LLM Score (%)":"32.78 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0125,
        "Decode Throughput (tokens\/s)":78.2,
        "Allocated Memory (MB)":2243,
        "Energy (tokens\/kWh)":1096491,
        "E2E Latency (s)":3.27,
        "E2E Throughput (tokens\/s)":78.3,
        "Reserved Memory (MB)":2292,
        "Used Memory (MB)":3751
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":1.08,
        "Open LLM Score (%)":"32.78*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0131,
        "Decode Throughput (tokens\/s)":79.7,
        "Allocated Memory (MB)":1623,
        "Energy (tokens\/kWh)":1261034,
        "E2E Latency (s)":3.21,
        "E2E Throughput (tokens\/s)":79.8,
        "Reserved Memory (MB)":1675,
        "Used Memory (MB)":3137
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":1.08,
        "Open LLM Score (%)":"32.78 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0131,
        "Decode Throughput (tokens\/s)":75.4,
        "Allocated Memory (MB)":2243,
        "Energy (tokens\/kWh)":1066098,
        "E2E Latency (s)":3.39,
        "E2E Throughput (tokens\/s)":75.5,
        "Reserved Memory (MB)":2292,
        "Used Memory (MB)":3751
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":1.08,
        "Open LLM Score (%)":"32.78*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0132,
        "Decode Throughput (tokens\/s)":81.2,
        "Allocated Memory (MB)":1085,
        "Energy (tokens\/kWh)":1218026,
        "E2E Latency (s)":3.15,
        "E2E Throughput (tokens\/s)":81.3,
        "Reserved Memory (MB)":1134,
        "Used Memory (MB)":2596
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":1.08,
        "Open LLM Score (%)":"32.78*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0154,
        "Decode Throughput (tokens\/s)":76.1,
        "Allocated Memory (MB)":1050,
        "Energy (tokens\/kWh)":1091703,
        "E2E Latency (s)":3.37,
        "E2E Throughput (tokens\/s)":76.0,
        "Reserved Memory (MB)":1094,
        "Used Memory (MB)":2554
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":1.08,
        "Open LLM Score (%)":"32.78*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0154,
        "Decode Throughput (tokens\/s)":72.4,
        "Allocated Memory (MB)":1050,
        "Energy (tokens\/kWh)":1068376,
        "E2E Latency (s)":3.54,
        "E2E Throughput (tokens\/s)":72.3,
        "Reserved Memory (MB)":1094,
        "Used Memory (MB)":2554
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":1.08,
        "Open LLM Score (%)":"32.78*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0291,
        "Decode Throughput (tokens\/s)":64.2,
        "Allocated Memory (MB)":1076,
        "Energy (tokens\/kWh)":980392,
        "E2E Latency (s)":4.0,
        "E2E Throughput (tokens\/s)":64.0,
        "Reserved Memory (MB)":1117,
        "Used Memory (MB)":2577
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":1.08,
        "Open LLM Score (%)":"32.78*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0323,
        "Decode Throughput (tokens\/s)":30.3,
        "Allocated Memory (MB)":1448,
        "Energy (tokens\/kWh)":467289,
        "E2E Latency (s)":8.45,
        "E2E Throughput (tokens\/s)":30.3,
        "Reserved Memory (MB)":1495,
        "Used Memory (MB)":2963
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":1.08,
        "Open LLM Score (%)":"32.78*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0335,
        "Decode Throughput (tokens\/s)":29.1,
        "Allocated Memory (MB)":1450,
        "Energy (tokens\/kWh)":436681,
        "E2E Latency (s)":8.8,
        "E2E Throughput (tokens\/s)":29.1,
        "Reserved Memory (MB)":1499,
        "Used Memory (MB)":2967
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":1.08,
        "Open LLM Score (%)":"32.78 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.038,
        "Decode Throughput (tokens\/s)":79.2,
        "Allocated Memory (MB)":4411,
        "Energy (tokens\/kWh)":990099,
        "E2E Latency (s)":3.26,
        "E2E Throughput (tokens\/s)":78.5,
        "Reserved Memory (MB)":4445,
        "Used Memory (MB)":5897
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":1.08,
        "Open LLM Score (%)":"32.78*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0397,
        "Decode Throughput (tokens\/s)":54.3,
        "Allocated Memory (MB)":1135,
        "Energy (tokens\/kWh)":793650,
        "E2E Latency (s)":4.74,
        "E2E Throughput (tokens\/s)":54.0,
        "Reserved Memory (MB)":1216,
        "Used Memory (MB)":2675
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":1.08,
        "Open LLM Score (%)":"32.78*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0408,
        "Decode Throughput (tokens\/s)":50.1,
        "Allocated Memory (MB)":1135,
        "Energy (tokens\/kWh)":729927,
        "E2E Latency (s)":5.13,
        "E2E Throughput (tokens\/s)":49.9,
        "Reserved Memory (MB)":1216,
        "Used Memory (MB)":2675
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"32.44 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0282,
        "Decode Throughput (tokens\/s)":38.6,
        "Allocated Memory (MB)":12365,
        "Energy (tokens\/kWh)":456621,
        "E2E Latency (s)":6.64,
        "E2E Throughput (tokens\/s)":38.6,
        "Reserved Memory (MB)":12603,
        "Used Memory (MB)":14063
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"32.44 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0288,
        "Decode Throughput (tokens\/s)":40.2,
        "Allocated Memory (MB)":12357,
        "Energy (tokens\/kWh)":465116,
        "E2E Latency (s)":6.38,
        "E2E Throughput (tokens\/s)":40.1,
        "Reserved Memory (MB)":12603,
        "Used Memory (MB)":14063
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"32.44 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0316,
        "Decode Throughput (tokens\/s)":38.7,
        "Allocated Memory (MB)":12365,
        "Energy (tokens\/kWh)":432900,
        "E2E Latency (s)":6.62,
        "E2E Throughput (tokens\/s)":38.7,
        "Reserved Memory (MB)":12603,
        "Used Memory (MB)":14063
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"32.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0374,
        "Decode Throughput (tokens\/s)":37.2,
        "Allocated Memory (MB)":4117,
        "Energy (tokens\/kWh)":492610,
        "E2E Latency (s)":6.9,
        "E2E Throughput (tokens\/s)":37.1,
        "Reserved Memory (MB)":4221,
        "Used Memory (MB)":5683
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"32.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0386,
        "Decode Throughput (tokens\/s)":36.7,
        "Allocated Memory (MB)":4843,
        "Energy (tokens\/kWh)":540540,
        "E2E Latency (s)":6.99,
        "E2E Throughput (tokens\/s)":36.6,
        "Reserved Memory (MB)":4949,
        "Used Memory (MB)":6410
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"32.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0554,
        "Decode Throughput (tokens\/s)":37.2,
        "Allocated Memory (MB)":4021,
        "Energy (tokens\/kWh)":512820,
        "E2E Latency (s)":6.92,
        "E2E Throughput (tokens\/s)":37.0,
        "Reserved Memory (MB)":4158,
        "Used Memory (MB)":5618
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"32.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0641,
        "Decode Throughput (tokens\/s)":34.0,
        "Allocated Memory (MB)":4020,
        "Energy (tokens\/kWh)":462962,
        "E2E Latency (s)":7.56,
        "E2E Throughput (tokens\/s)":33.9,
        "Reserved Memory (MB)":4158,
        "Used Memory (MB)":5618
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"32.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0958,
        "Decode Throughput (tokens\/s)":10.5,
        "Allocated Memory (MB)":6791,
        "Energy (tokens\/kWh)":157480,
        "E2E Latency (s)":24.5,
        "E2E Throughput (tokens\/s)":10.4,
        "Reserved Memory (MB)":6937,
        "Used Memory (MB)":8405
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"32.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.102,
        "Decode Throughput (tokens\/s)":9.85,
        "Allocated Memory (MB)":6800,
        "Energy (tokens\/kWh)":144927,
        "E2E Latency (s)":26.0,
        "E2E Throughput (tokens\/s)":9.85,
        "Reserved Memory (MB)":6928,
        "Used Memory (MB)":8396
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"32.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.15,
        "Decode Throughput (tokens\/s)":26.8,
        "Allocated Memory (MB)":4158,
        "Energy (tokens\/kWh)":364963,
        "E2E Latency (s)":9.68,
        "E2E Throughput (tokens\/s)":26.4,
        "Reserved Memory (MB)":4303,
        "Used Memory (MB)":5762
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"32.44 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.216,
        "Decode Throughput (tokens\/s)":41.7,
        "Allocated Memory (MB)":24722,
        "Energy (tokens\/kWh)":373134,
        "E2E Latency (s)":6.33,
        "E2E Throughput (tokens\/s)":40.4,
        "Reserved Memory (MB)":24807,
        "Used Memory (MB)":26258
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"32.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.24,
        "Decode Throughput (tokens\/s)":21.4,
        "Allocated Memory (MB)":4451,
        "Energy (tokens\/kWh)":288184,
        "E2E Latency (s)":12.1,
        "E2E Throughput (tokens\/s)":21.2,
        "Reserved Memory (MB)":4722,
        "Used Memory (MB)":6182
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"32.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.246,
        "Decode Throughput (tokens\/s)":22.4,
        "Allocated Memory (MB)":4451,
        "Energy (tokens\/kWh)":293255,
        "E2E Latency (s)":11.6,
        "E2E Throughput (tokens\/s)":22.1,
        "Reserved Memory (MB)":4722,
        "Used Memory (MB)":6182
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":6.0,
        "Open LLM Score (%)":"32.43 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.034,
        "Decode Throughput (tokens\/s)":28.9,
        "Allocated Memory (MB)":14859,
        "Energy (tokens\/kWh)":346020,
        "E2E Latency (s)":8.84,
        "E2E Throughput (tokens\/s)":29.0,
        "Reserved Memory (MB)":14923,
        "Used Memory (MB)":16382
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":6.0,
        "Open LLM Score (%)":"32.43 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0383,
        "Decode Throughput (tokens\/s)":26.4,
        "Allocated Memory (MB)":14855,
        "Energy (tokens\/kWh)":338983,
        "E2E Latency (s)":9.71,
        "E2E Throughput (tokens\/s)":26.4,
        "Reserved Memory (MB)":14902,
        "Used Memory (MB)":16361
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":6.0,
        "Open LLM Score (%)":"32.43 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.04,
        "Decode Throughput (tokens\/s)":26.7,
        "Allocated Memory (MB)":14855,
        "Energy (tokens\/kWh)":326797,
        "E2E Latency (s)":9.6,
        "E2E Throughput (tokens\/s)":26.7,
        "Reserved Memory (MB)":14902,
        "Used Memory (MB)":16361
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":6.0,
        "Open LLM Score (%)":"32.43*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0455,
        "Decode Throughput (tokens\/s)":26.4,
        "Allocated Memory (MB)":5158,
        "Energy (tokens\/kWh)":374531,
        "E2E Latency (s)":9.7,
        "E2E Throughput (tokens\/s)":26.4,
        "Reserved Memory (MB)":5200,
        "Used Memory (MB)":6662
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":6.0,
        "Open LLM Score (%)":"32.43*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0474,
        "Decode Throughput (tokens\/s)":27.1,
        "Allocated Memory (MB)":6235,
        "Energy (tokens\/kWh)":408163,
        "E2E Latency (s)":9.45,
        "E2E Throughput (tokens\/s)":27.1,
        "Reserved Memory (MB)":6280,
        "Used Memory (MB)":7742
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":6.0,
        "Open LLM Score (%)":"32.43*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0682,
        "Decode Throughput (tokens\/s)":26.8,
        "Allocated Memory (MB)":5020,
        "Energy (tokens\/kWh)":386100,
        "E2E Latency (s)":9.58,
        "E2E Throughput (tokens\/s)":26.7,
        "Reserved Memory (MB)":5075,
        "Used Memory (MB)":6534
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":6.0,
        "Open LLM Score (%)":"32.43*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0758,
        "Decode Throughput (tokens\/s)":12.9,
        "Allocated Memory (MB)":8220,
        "Energy (tokens\/kWh)":194931,
        "E2E Latency (s)":19.8,
        "E2E Throughput (tokens\/s)":12.9,
        "Reserved Memory (MB)":8269,
        "Used Memory (MB)":9737
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":6.0,
        "Open LLM Score (%)":"32.43*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0771,
        "Decode Throughput (tokens\/s)":25.5,
        "Allocated Memory (MB)":5020,
        "Energy (tokens\/kWh)":369003,
        "E2E Latency (s)":10.1,
        "E2E Throughput (tokens\/s)":25.3,
        "Reserved Memory (MB)":5075,
        "Used Memory (MB)":6534
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":6.0,
        "Open LLM Score (%)":"32.43*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0808,
        "Decode Throughput (tokens\/s)":12.5,
        "Allocated Memory (MB)":8216,
        "Energy (tokens\/kWh)":184842,
        "E2E Latency (s)":20.5,
        "E2E Throughput (tokens\/s)":12.5,
        "Reserved Memory (MB)":8248,
        "Used Memory (MB)":9716
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":6.0,
        "Open LLM Score (%)":"32.43*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.173,
        "Decode Throughput (tokens\/s)":23.4,
        "Allocated Memory (MB)":5023,
        "Energy (tokens\/kWh)":323624,
        "E2E Latency (s)":11.1,
        "E2E Throughput (tokens\/s)":23.1,
        "Reserved Memory (MB)":5272,
        "Used Memory (MB)":6731
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":6.0,
        "Open LLM Score (%)":"32.43 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.256,
        "Decode Throughput (tokens\/s)":29.0,
        "Allocated Memory (MB)":29527,
        "Energy (tokens\/kWh)":283286,
        "E2E Latency (s)":9.06,
        "E2E Throughput (tokens\/s)":28.3,
        "Reserved Memory (MB)":29750,
        "Used Memory (MB)":31201
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":6.0,
        "Open LLM Score (%)":"32.43*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.285,
        "Decode Throughput (tokens\/s)":21.1,
        "Allocated Memory (MB)":5351,
        "Energy (tokens\/kWh)":271002,
        "E2E Latency (s)":12.4,
        "E2E Throughput (tokens\/s)":20.6,
        "Reserved Memory (MB)":5723,
        "Used Memory (MB)":7182
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"\u267e\ufe0f CodeGen",
        "Params (B)":6.0,
        "Open LLM Score (%)":"32.43*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.29,
        "Decode Throughput (tokens\/s)":19.6,
        "Allocated Memory (MB)":5351,
        "Energy (tokens\/kWh)":255102,
        "E2E Latency (s)":13.3,
        "E2E Throughput (tokens\/s)":19.2,
        "Reserved Memory (MB)":5454,
        "Used Memory (MB)":6914
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"GPT-NeoX",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.23 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0233,
        "Decode Throughput (tokens\/s)":43.3,
        "Allocated Memory (MB)":8277,
        "Energy (tokens\/kWh)":546448,
        "E2E Latency (s)":5.91,
        "E2E Throughput (tokens\/s)":43.3,
        "Reserved Memory (MB)":8411,
        "Used Memory (MB)":9871
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"GPT-NeoX",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.23 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0261,
        "Decode Throughput (tokens\/s)":41.7,
        "Allocated Memory (MB)":8277,
        "Energy (tokens\/kWh)":507614,
        "E2E Latency (s)":6.14,
        "E2E Throughput (tokens\/s)":41.7,
        "Reserved Memory (MB)":8411,
        "Used Memory (MB)":9871
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"GPT-NeoX",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.23 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0274,
        "Decode Throughput (tokens\/s)":37.3,
        "Allocated Memory (MB)":8277,
        "Energy (tokens\/kWh)":497512,
        "E2E Latency (s)":6.86,
        "E2E Throughput (tokens\/s)":37.3,
        "Reserved Memory (MB)":8411,
        "Used Memory (MB)":9871
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"GPT-NeoX",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.23 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.03,
        "Decode Throughput (tokens\/s)":36.2,
        "Allocated Memory (MB)":8277,
        "Energy (tokens\/kWh)":462962,
        "E2E Latency (s)":7.07,
        "E2E Throughput (tokens\/s)":36.2,
        "Reserved Memory (MB)":8411,
        "Used Memory (MB)":9871
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"GPT-NeoX",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.23*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0301,
        "Decode Throughput (tokens\/s)":37.8,
        "Allocated Memory (MB)":4056,
        "Energy (tokens\/kWh)":571428,
        "E2E Latency (s)":6.78,
        "E2E Throughput (tokens\/s)":37.8,
        "Reserved Memory (MB)":4093,
        "Used Memory (MB)":5555
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"GPT-NeoX",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.23*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0306,
        "Decode Throughput (tokens\/s)":37.0,
        "Allocated Memory (MB)":3315,
        "Energy (tokens\/kWh)":529100,
        "E2E Latency (s)":6.92,
        "E2E Throughput (tokens\/s)":37.0,
        "Reserved Memory (MB)":3351,
        "Used Memory (MB)":4812
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"GPT-NeoX",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.23*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0447,
        "Decode Throughput (tokens\/s)":35.7,
        "Allocated Memory (MB)":3242,
        "Energy (tokens\/kWh)":515463,
        "E2E Latency (s)":7.19,
        "E2E Throughput (tokens\/s)":35.6,
        "Reserved Memory (MB)":3275,
        "Used Memory (MB)":4735
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"GPT-NeoX",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.23*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0482,
        "Decode Throughput (tokens\/s)":33.6,
        "Allocated Memory (MB)":3238,
        "Energy (tokens\/kWh)":497512,
        "E2E Latency (s)":7.64,
        "E2E Throughput (tokens\/s)":33.5,
        "Reserved Memory (MB)":3271,
        "Used Memory (MB)":4731
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"GPT-NeoX",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.23*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0704,
        "Decode Throughput (tokens\/s)":13.9,
        "Allocated Memory (MB)":4819,
        "Energy (tokens\/kWh)":205761,
        "E2E Latency (s)":18.5,
        "E2E Throughput (tokens\/s)":13.8,
        "Reserved Memory (MB)":5098,
        "Used Memory (MB)":6566
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"GPT-NeoX",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.23*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0743,
        "Decode Throughput (tokens\/s)":13.4,
        "Allocated Memory (MB)":4816,
        "Energy (tokens\/kWh)":199600,
        "E2E Latency (s)":19.1,
        "E2E Throughput (tokens\/s)":13.4,
        "Reserved Memory (MB)":5077,
        "Used Memory (MB)":6545
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"GPT-NeoX",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.23*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.101,
        "Decode Throughput (tokens\/s)":30.5,
        "Allocated Memory (MB)":3235,
        "Energy (tokens\/kWh)":440528,
        "E2E Latency (s)":8.46,
        "E2E Throughput (tokens\/s)":30.3,
        "Reserved Memory (MB)":3340,
        "Used Memory (MB)":4800
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"GPT-NeoX",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.23 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.15,
        "Decode Throughput (tokens\/s)":37.4,
        "Allocated Memory (MB)":16325,
        "Energy (tokens\/kWh)":418410,
        "E2E Latency (s)":6.96,
        "E2E Throughput (tokens\/s)":36.8,
        "Reserved Memory (MB)":16601,
        "Used Memory (MB)":18052
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"GPT-NeoX",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.23*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.165,
        "Decode Throughput (tokens\/s)":24.5,
        "Allocated Memory (MB)":3362,
        "Energy (tokens\/kWh)":340136,
        "E2E Latency (s)":10.6,
        "E2E Throughput (tokens\/s)":24.2,
        "Reserved Memory (MB)":3535,
        "Used Memory (MB)":4993
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"GPT-NeoX",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.23*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.171,
        "Decode Throughput (tokens\/s)":22.6,
        "Allocated Memory (MB)":3359,
        "Energy (tokens\/kWh)":314465,
        "E2E Latency (s)":11.5,
        "E2E Throughput (tokens\/s)":22.3,
        "Reserved Memory (MB)":3535,
        "Used Memory (MB)":4995
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"GPT-NeoX",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.14 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.023,
        "Decode Throughput (tokens\/s)":43.0,
        "Allocated Memory (MB)":8277,
        "Energy (tokens\/kWh)":549450,
        "E2E Latency (s)":5.95,
        "E2E Throughput (tokens\/s)":43.0,
        "Reserved Memory (MB)":8411,
        "Used Memory (MB)":9871
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"GPT-NeoX",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.14 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0249,
        "Decode Throughput (tokens\/s)":40.6,
        "Allocated Memory (MB)":8277,
        "Energy (tokens\/kWh)":497512,
        "E2E Latency (s)":6.3,
        "E2E Throughput (tokens\/s)":40.6,
        "Reserved Memory (MB)":8411,
        "Used Memory (MB)":9871
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"GPT-NeoX",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.14 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0278,
        "Decode Throughput (tokens\/s)":36.2,
        "Allocated Memory (MB)":8277,
        "Energy (tokens\/kWh)":487804,
        "E2E Latency (s)":7.08,
        "E2E Throughput (tokens\/s)":36.2,
        "Reserved Memory (MB)":8411,
        "Used Memory (MB)":9871
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"GPT-NeoX",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.14 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0284,
        "Decode Throughput (tokens\/s)":35.8,
        "Allocated Memory (MB)":8277,
        "Energy (tokens\/kWh)":450450,
        "E2E Latency (s)":7.16,
        "E2E Throughput (tokens\/s)":35.8,
        "Reserved Memory (MB)":8411,
        "Used Memory (MB)":9871
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"GPT-NeoX",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.14*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0297,
        "Decode Throughput (tokens\/s)":37.2,
        "Allocated Memory (MB)":3315,
        "Energy (tokens\/kWh)":526315,
        "E2E Latency (s)":6.88,
        "E2E Throughput (tokens\/s)":37.2,
        "Reserved Memory (MB)":3351,
        "Used Memory (MB)":4812
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"GPT-NeoX",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.14*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0303,
        "Decode Throughput (tokens\/s)":37.1,
        "Allocated Memory (MB)":4056,
        "Energy (tokens\/kWh)":564971,
        "E2E Latency (s)":6.9,
        "E2E Throughput (tokens\/s)":37.1,
        "Reserved Memory (MB)":4093,
        "Used Memory (MB)":5555
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"GPT-NeoX",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.14*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.045,
        "Decode Throughput (tokens\/s)":35.6,
        "Allocated Memory (MB)":3242,
        "Energy (tokens\/kWh)":526315,
        "E2E Latency (s)":7.21,
        "E2E Throughput (tokens\/s)":35.5,
        "Reserved Memory (MB)":3275,
        "Used Memory (MB)":4735
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"GPT-NeoX",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.14*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0481,
        "Decode Throughput (tokens\/s)":32.7,
        "Allocated Memory (MB)":3238,
        "Energy (tokens\/kWh)":469483,
        "E2E Latency (s)":7.85,
        "E2E Throughput (tokens\/s)":32.6,
        "Reserved Memory (MB)":3271,
        "Used Memory (MB)":4731
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"GPT-NeoX",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.14*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0731,
        "Decode Throughput (tokens\/s)":13.9,
        "Allocated Memory (MB)":4819,
        "Energy (tokens\/kWh)":205338,
        "E2E Latency (s)":18.4,
        "E2E Throughput (tokens\/s)":13.9,
        "Reserved Memory (MB)":5098,
        "Used Memory (MB)":6566
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"GPT-NeoX",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.14*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0761,
        "Decode Throughput (tokens\/s)":13.1,
        "Allocated Memory (MB)":4816,
        "Energy (tokens\/kWh)":194174,
        "E2E Latency (s)":19.5,
        "E2E Throughput (tokens\/s)":13.1,
        "Reserved Memory (MB)":5077,
        "Used Memory (MB)":6545
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"GPT-NeoX",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.14*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.103,
        "Decode Throughput (tokens\/s)":30.1,
        "Allocated Memory (MB)":3235,
        "Energy (tokens\/kWh)":432900,
        "E2E Latency (s)":8.56,
        "E2E Throughput (tokens\/s)":29.9,
        "Reserved Memory (MB)":3340,
        "Used Memory (MB)":4800
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"GPT-NeoX",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.14 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.15,
        "Decode Throughput (tokens\/s)":36.5,
        "Allocated Memory (MB)":16325,
        "Energy (tokens\/kWh)":413223,
        "E2E Latency (s)":7.14,
        "E2E Throughput (tokens\/s)":35.9,
        "Reserved Memory (MB)":16601,
        "Used Memory (MB)":18052
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"GPT-NeoX",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.14*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.17,
        "Decode Throughput (tokens\/s)":22.6,
        "Allocated Memory (MB)":3359,
        "Energy (tokens\/kWh)":308641,
        "E2E Latency (s)":11.5,
        "E2E Throughput (tokens\/s)":22.3,
        "Reserved Memory (MB)":3535,
        "Used Memory (MB)":4995
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"GPT-NeoX",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.14*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.171,
        "Decode Throughput (tokens\/s)":25.0,
        "Allocated Memory (MB)":3362,
        "Energy (tokens\/kWh)":335570,
        "E2E Latency (s)":10.4,
        "E2E Throughput (tokens\/s)":24.6,
        "Reserved Memory (MB)":3535,
        "Used Memory (MB)":4993
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"31.86 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0168,
        "Decode Throughput (tokens\/s)":58.0,
        "Allocated Memory (MB)":2279,
        "Energy (tokens\/kWh)":826446,
        "E2E Latency (s)":4.42,
        "E2E Throughput (tokens\/s)":57.9,
        "Reserved Memory (MB)":2403,
        "Used Memory (MB)":3862
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"31.86 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0178,
        "Decode Throughput (tokens\/s)":54.8,
        "Allocated Memory (MB)":2279,
        "Energy (tokens\/kWh)":757575,
        "E2E Latency (s)":4.67,
        "E2E Throughput (tokens\/s)":54.8,
        "Reserved Memory (MB)":2403,
        "Used Memory (MB)":3862
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"31.86 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.018,
        "Decode Throughput (tokens\/s)":52.1,
        "Allocated Memory (MB)":2279,
        "Energy (tokens\/kWh)":769230,
        "E2E Latency (s)":4.91,
        "E2E Throughput (tokens\/s)":52.1,
        "Reserved Memory (MB)":2403,
        "Used Memory (MB)":3862
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"31.86*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0196,
        "Decode Throughput (tokens\/s)":47.8,
        "Allocated Memory (MB)":851,
        "Energy (tokens\/kWh)":714285,
        "E2E Latency (s)":5.36,
        "E2E Throughput (tokens\/s)":47.8,
        "Reserved Memory (MB)":935,
        "Used Memory (MB)":2394
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"31.86*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.02,
        "Decode Throughput (tokens\/s)":50.1,
        "Allocated Memory (MB)":1248,
        "Energy (tokens\/kWh)":813008,
        "E2E Latency (s)":5.11,
        "E2E Throughput (tokens\/s)":50.1,
        "Reserved Memory (MB)":1304,
        "Used Memory (MB)":2766
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"31.86*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0201,
        "Decode Throughput (tokens\/s)":52.4,
        "Allocated Memory (MB)":852,
        "Energy (tokens\/kWh)":787401,
        "E2E Latency (s)":4.89,
        "E2E Throughput (tokens\/s)":52.4,
        "Reserved Memory (MB)":935,
        "Used Memory (MB)":2394
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"31.86*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0218,
        "Decode Throughput (tokens\/s)":48.9,
        "Allocated Memory (MB)":877,
        "Energy (tokens\/kWh)":775193,
        "E2E Latency (s)":5.24,
        "E2E Throughput (tokens\/s)":48.9,
        "Reserved Memory (MB)":933,
        "Used Memory (MB)":2394
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"31.86 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0434,
        "Decode Throughput (tokens\/s)":57.3,
        "Allocated Memory (MB)":4492,
        "Energy (tokens\/kWh)":763358,
        "E2E Latency (s)":4.49,
        "E2E Throughput (tokens\/s)":57.0,
        "Reserved Memory (MB)":4548,
        "Used Memory (MB)":5999
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"31.86*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0451,
        "Decode Throughput (tokens\/s)":37.9,
        "Allocated Memory (MB)":869,
        "Energy (tokens\/kWh)":588235,
        "E2E Latency (s)":6.77,
        "E2E Throughput (tokens\/s)":37.8,
        "Reserved Memory (MB)":922,
        "Used Memory (MB)":2382
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"31.86*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0487,
        "Decode Throughput (tokens\/s)":32.4,
        "Allocated Memory (MB)":924,
        "Energy (tokens\/kWh)":485436,
        "E2E Latency (s)":7.91,
        "E2E Throughput (tokens\/s)":32.4,
        "Reserved Memory (MB)":1008,
        "Used Memory (MB)":2468
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"31.86*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0496,
        "Decode Throughput (tokens\/s)":31.2,
        "Allocated Memory (MB)":924,
        "Energy (tokens\/kWh)":460829,
        "E2E Latency (s)":8.23,
        "E2E Throughput (tokens\/s)":31.1,
        "Reserved Memory (MB)":1008,
        "Used Memory (MB)":2468
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"31.86*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0651,
        "Decode Throughput (tokens\/s)":15.1,
        "Allocated Memory (MB)":1380,
        "Energy (tokens\/kWh)":238095,
        "E2E Latency (s)":17.0,
        "E2E Throughput (tokens\/s)":15.1,
        "Reserved Memory (MB)":1421,
        "Used Memory (MB)":2889
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.1,
        "Open LLM Score (%)":"31.86*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0693,
        "Decode Throughput (tokens\/s)":14.5,
        "Allocated Memory (MB)":1380,
        "Energy (tokens\/kWh)":219780,
        "E2E Latency (s)":17.7,
        "E2E Throughput (tokens\/s)":14.5,
        "Reserved Memory (MB)":1421,
        "Used Memory (MB)":2889
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.55 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0157,
        "Decode Throughput (tokens\/s)":63.9,
        "Allocated Memory (MB)":1028,
        "Energy (tokens\/kWh)":990099,
        "E2E Latency (s)":4.01,
        "E2E Throughput (tokens\/s)":63.8,
        "Reserved Memory (MB)":1121,
        "Used Memory (MB)":2581
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.55 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0164,
        "Decode Throughput (tokens\/s)":59.2,
        "Allocated Memory (MB)":1028,
        "Energy (tokens\/kWh)":877192,
        "E2E Latency (s)":4.33,
        "E2E Throughput (tokens\/s)":59.1,
        "Reserved Memory (MB)":1121,
        "Used Memory (MB)":2581
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.55 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0181,
        "Decode Throughput (tokens\/s)":55.3,
        "Allocated Memory (MB)":1028,
        "Energy (tokens\/kWh)":877192,
        "E2E Latency (s)":4.63,
        "E2E Throughput (tokens\/s)":55.3,
        "Reserved Memory (MB)":1121,
        "Used Memory (MB)":2581
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.55*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0186,
        "Decode Throughput (tokens\/s)":56.0,
        "Allocated Memory (MB)":869,
        "Energy (tokens\/kWh)":900900,
        "E2E Latency (s)":4.57,
        "E2E Throughput (tokens\/s)":56.0,
        "Reserved Memory (MB)":958,
        "Used Memory (MB)":2420
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.55 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0193,
        "Decode Throughput (tokens\/s)":53.6,
        "Allocated Memory (MB)":1028,
        "Energy (tokens\/kWh)":793650,
        "E2E Latency (s)":4.78,
        "E2E Throughput (tokens\/s)":53.6,
        "Reserved Memory (MB)":1121,
        "Used Memory (MB)":2581
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.55*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0195,
        "Decode Throughput (tokens\/s)":54.5,
        "Allocated Memory (MB)":601,
        "Energy (tokens\/kWh)":854700,
        "E2E Latency (s)":4.7,
        "E2E Throughput (tokens\/s)":54.5,
        "Reserved Memory (MB)":679,
        "Used Memory (MB)":2141
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.55*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0202,
        "Decode Throughput (tokens\/s)":52.8,
        "Allocated Memory (MB)":590,
        "Energy (tokens\/kWh)":799999,
        "E2E Latency (s)":4.85,
        "E2E Throughput (tokens\/s)":52.8,
        "Reserved Memory (MB)":685,
        "Used Memory (MB)":2145
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.55*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0203,
        "Decode Throughput (tokens\/s)":49.0,
        "Allocated Memory (MB)":590,
        "Energy (tokens\/kWh)":775193,
        "E2E Latency (s)":5.22,
        "E2E Throughput (tokens\/s)":49.0,
        "Reserved Memory (MB)":685,
        "Used Memory (MB)":2145
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.55 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0231,
        "Decode Throughput (tokens\/s)":53.1,
        "Allocated Memory (MB)":1948,
        "Energy (tokens\/kWh)":813008,
        "E2E Latency (s)":4.82,
        "E2E Throughput (tokens\/s)":53.1,
        "Reserved Memory (MB)":2006,
        "Used Memory (MB)":3458
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.55*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0324,
        "Decode Throughput (tokens\/s)":35.9,
        "Allocated Memory (MB)":603,
        "Energy (tokens\/kWh)":555555,
        "E2E Latency (s)":7.13,
        "E2E Throughput (tokens\/s)":35.9,
        "Reserved Memory (MB)":713,
        "Used Memory (MB)":2172
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.55*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0351,
        "Decode Throughput (tokens\/s)":44.7,
        "Allocated Memory (MB)":592,
        "Energy (tokens\/kWh)":709219,
        "E2E Latency (s)":5.75,
        "E2E Throughput (tokens\/s)":44.5,
        "Reserved Memory (MB)":700,
        "Used Memory (MB)":2160
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.55*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0356,
        "Decode Throughput (tokens\/s)":34.3,
        "Allocated Memory (MB)":603,
        "Energy (tokens\/kWh)":534759,
        "E2E Latency (s)":7.47,
        "E2E Throughput (tokens\/s)":34.3,
        "Reserved Memory (MB)":713,
        "Used Memory (MB)":2172
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.55*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0471,
        "Decode Throughput (tokens\/s)":20.2,
        "Allocated Memory (MB)":742,
        "Energy (tokens\/kWh)":318471,
        "E2E Latency (s)":12.6,
        "E2E Throughput (tokens\/s)":20.3,
        "Reserved Memory (MB)":832,
        "Used Memory (MB)":2300
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.55*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0506,
        "Decode Throughput (tokens\/s)":20.1,
        "Allocated Memory (MB)":743,
        "Energy (tokens\/kWh)":306748,
        "E2E Latency (s)":12.8,
        "E2E Throughput (tokens\/s)":20.0,
        "Reserved Memory (MB)":834,
        "Used Memory (MB)":2302
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"GPT-NeoX",
        "Params (B)":3.0,
        "Open LLM Score (%)":"31.50 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0143,
        "Decode Throughput (tokens\/s)":93.8,
        "Allocated Memory (MB)":7829,
        "Energy (tokens\/kWh)":961538,
        "E2E Latency (s)":2.73,
        "E2E Throughput (tokens\/s)":93.8,
        "Reserved Memory (MB)":7853,
        "Used Memory (MB)":9313
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"GPT-NeoX",
        "Params (B)":3.0,
        "Open LLM Score (%)":"31.50 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0154,
        "Decode Throughput (tokens\/s)":90.1,
        "Allocated Memory (MB)":7829,
        "Energy (tokens\/kWh)":917431,
        "E2E Latency (s)":2.85,
        "E2E Throughput (tokens\/s)":89.8,
        "Reserved Memory (MB)":7853,
        "Used Memory (MB)":9313
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"GPT-NeoX",
        "Params (B)":3.0,
        "Open LLM Score (%)":"31.50 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0154,
        "Decode Throughput (tokens\/s)":79.2,
        "Allocated Memory (MB)":7829,
        "Energy (tokens\/kWh)":900900,
        "E2E Latency (s)":3.24,
        "E2E Throughput (tokens\/s)":79.0,
        "Reserved Memory (MB)":7853,
        "Used Memory (MB)":9313
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"GPT-NeoX",
        "Params (B)":3.0,
        "Open LLM Score (%)":"31.50 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0172,
        "Decode Throughput (tokens\/s)":79.2,
        "Allocated Memory (MB)":7829,
        "Energy (tokens\/kWh)":854700,
        "E2E Latency (s)":3.24,
        "E2E Throughput (tokens\/s)":79.0,
        "Reserved Memory (MB)":7853,
        "Used Memory (MB)":9313
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"GPT-NeoX",
        "Params (B)":3.0,
        "Open LLM Score (%)":"31.50*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0201,
        "Decode Throughput (tokens\/s)":81.5,
        "Allocated Memory (MB)":3195,
        "Energy (tokens\/kWh)":1072961,
        "E2E Latency (s)":3.15,
        "E2E Throughput (tokens\/s)":81.3,
        "Reserved Memory (MB)":3212,
        "Used Memory (MB)":4674
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"GPT-NeoX",
        "Params (B)":3.0,
        "Open LLM Score (%)":"31.50*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0205,
        "Decode Throughput (tokens\/s)":79.7,
        "Allocated Memory (MB)":4271,
        "Energy (tokens\/kWh)":1176470,
        "E2E Latency (s)":3.22,
        "E2E Throughput (tokens\/s)":79.5,
        "Reserved Memory (MB)":4290,
        "Used Memory (MB)":5752
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"GPT-NeoX",
        "Params (B)":3.0,
        "Open LLM Score (%)":"31.50*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0314,
        "Decode Throughput (tokens\/s)":78.0,
        "Allocated Memory (MB)":3060,
        "Energy (tokens\/kWh)":1048218,
        "E2E Latency (s)":3.3,
        "E2E Throughput (tokens\/s)":77.6,
        "Reserved Memory (MB)":3091,
        "Used Memory (MB)":4550
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"GPT-NeoX",
        "Params (B)":3.0,
        "Open LLM Score (%)":"31.50*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0319,
        "Decode Throughput (tokens\/s)":31.1,
        "Allocated Memory (MB)":4609,
        "Energy (tokens\/kWh)":442477,
        "E2E Latency (s)":8.24,
        "E2E Throughput (tokens\/s)":31.1,
        "Reserved Memory (MB)":4640,
        "Used Memory (MB)":6108
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"GPT-NeoX",
        "Params (B)":3.0,
        "Open LLM Score (%)":"31.50*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0351,
        "Decode Throughput (tokens\/s)":29.2,
        "Allocated Memory (MB)":4609,
        "Energy (tokens\/kWh)":403225,
        "E2E Latency (s)":8.76,
        "E2E Throughput (tokens\/s)":29.2,
        "Reserved Memory (MB)":4636,
        "Used Memory (MB)":6104
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"GPT-NeoX",
        "Params (B)":3.0,
        "Open LLM Score (%)":"31.50*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0365,
        "Decode Throughput (tokens\/s)":73.5,
        "Allocated Memory (MB)":3060,
        "Energy (tokens\/kWh)":1012145,
        "E2E Latency (s)":3.51,
        "E2E Throughput (tokens\/s)":72.9,
        "Reserved Memory (MB)":3091,
        "Used Memory (MB)":4550
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"GPT-NeoX",
        "Params (B)":3.0,
        "Open LLM Score (%)":"31.50*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0825,
        "Decode Throughput (tokens\/s)":65.6,
        "Allocated Memory (MB)":3280,
        "Energy (tokens\/kWh)":869565,
        "E2E Latency (s)":3.97,
        "E2E Throughput (tokens\/s)":64.5,
        "Reserved Memory (MB)":3391,
        "Used Memory (MB)":4850
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"GPT-NeoX",
        "Params (B)":3.0,
        "Open LLM Score (%)":"31.50 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.127,
        "Decode Throughput (tokens\/s)":74.1,
        "Allocated Memory (MB)":15380,
        "Energy (tokens\/kWh)":657894,
        "E2E Latency (s)":3.57,
        "E2E Throughput (tokens\/s)":71.7,
        "Reserved Memory (MB)":15466,
        "Used Memory (MB)":16917
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"GPT-NeoX",
        "Params (B)":3.0,
        "Open LLM Score (%)":"31.50*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.138,
        "Decode Throughput (tokens\/s)":54.6,
        "Allocated Memory (MB)":3516,
        "Energy (tokens\/kWh)":662251,
        "E2E Latency (s)":4.81,
        "E2E Throughput (tokens\/s)":53.2,
        "Reserved Memory (MB)":3879,
        "Used Memory (MB)":5339
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"GPT-NeoX",
        "Params (B)":3.0,
        "Open LLM Score (%)":"31.50*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.138,
        "Decode Throughput (tokens\/s)":50.3,
        "Allocated Memory (MB)":3516,
        "Energy (tokens\/kWh)":621118,
        "E2E Latency (s)":5.21,
        "E2E Throughput (tokens\/s)":49.1,
        "Reserved Memory (MB)":3879,
        "Used Memory (MB)":5339
    },
    {
        "Model":"bigcode\/starcoderbase-3b",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":3.0,
        "Open LLM Score (%)":"31.38 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0365,
        "Decode Throughput (tokens\/s)":40.5,
        "Allocated Memory (MB)":6282,
        "Energy (tokens\/kWh)":352112,
        "E2E Latency (s)":6.33,
        "E2E Throughput (tokens\/s)":40.4,
        "Reserved Memory (MB)":6425,
        "Used Memory (MB)":13333
    },
    {
        "Model":"bigcode\/starcoderbase-3b",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":3.0,
        "Open LLM Score (%)":"31.38 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0427,
        "Decode Throughput (tokens\/s)":54.6,
        "Allocated Memory (MB)":6282,
        "Energy (tokens\/kWh)":558659,
        "E2E Latency (s)":4.71,
        "E2E Throughput (tokens\/s)":54.4,
        "Reserved Memory (MB)":6425,
        "Used Memory (MB)":29163
    },
    {
        "Model":"bigcode\/starcoderbase-3b",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":3.0,
        "Open LLM Score (%)":"31.38 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0471,
        "Decode Throughput (tokens\/s)":41.7,
        "Allocated Memory (MB)":6282,
        "Energy (tokens\/kWh)":366300,
        "E2E Latency (s)":6.17,
        "E2E Throughput (tokens\/s)":41.5,
        "Reserved Memory (MB)":6425,
        "Used Memory (MB)":52928
    },
    {
        "Model":"bigcode\/starcoderbase-3b",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":3.0,
        "Open LLM Score (%)":"31.38*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0708,
        "Decode Throughput (tokens\/s)":14.2,
        "Allocated Memory (MB)":3387,
        "Energy (tokens\/kWh)":184162,
        "E2E Latency (s)":18.0,
        "E2E Throughput (tokens\/s)":14.2,
        "Reserved Memory (MB)":3667,
        "Used Memory (MB)":8172
    },
    {
        "Model":"bigcode\/starcoderbase-3b",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":3.0,
        "Open LLM Score (%)":"31.38*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.147,
        "Decode Throughput (tokens\/s)":23.8,
        "Allocated Memory (MB)":2192,
        "Energy (tokens\/kWh)":248138,
        "E2E Latency (s)":10.8,
        "E2E Throughput (tokens\/s)":23.7,
        "Reserved Memory (MB)":2371,
        "Used Memory (MB)":3831
    },
    {
        "Model":"bigcode\/starcoderbase-3b",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":3.0,
        "Open LLM Score (%)":"31.38*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.149,
        "Decode Throughput (tokens\/s)":23.4,
        "Allocated Memory (MB)":2193,
        "Energy (tokens\/kWh)":288184,
        "E2E Latency (s)":11.0,
        "E2E Throughput (tokens\/s)":23.3,
        "Reserved Memory (MB)":2371,
        "Used Memory (MB)":3831
    },
    {
        "Model":"cerebras\/Cerebras-GPT-1.3B",
        "Arch":"GPT-2",
        "Params (B)":1.3,
        "Open LLM Score (%)":"31.30 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0115,
        "Decode Throughput (tokens\/s)":86.4,
        "Allocated Memory (MB)":2943,
        "Energy (tokens\/kWh)":1129943,
        "E2E Latency (s)":2.96,
        "E2E Throughput (tokens\/s)":86.5,
        "Reserved Memory (MB)":2984,
        "Used Memory (MB)":4441
    },
    {
        "Model":"cerebras\/Cerebras-GPT-1.3B",
        "Arch":"GPT-2",
        "Params (B)":1.3,
        "Open LLM Score (%)":"31.30*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0142,
        "Decode Throughput (tokens\/s)":72.0,
        "Allocated Memory (MB)":2943,
        "Energy (tokens\/kWh)":1039501,
        "E2E Latency (s)":3.55,
        "E2E Throughput (tokens\/s)":72.1,
        "Reserved Memory (MB)":2984,
        "Used Memory (MB)":4443
    },
    {
        "Model":"cerebras\/Cerebras-GPT-1.3B",
        "Arch":"GPT-2",
        "Params (B)":1.3,
        "Open LLM Score (%)":"31.30*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0146,
        "Decode Throughput (tokens\/s)":77.0,
        "Allocated Memory (MB)":1188,
        "Energy (tokens\/kWh)":1098901,
        "E2E Latency (s)":3.32,
        "E2E Throughput (tokens\/s)":77.1,
        "Reserved Memory (MB)":1226,
        "Used Memory (MB)":2688
    },
    {
        "Model":"cerebras\/Cerebras-GPT-1.3B",
        "Arch":"GPT-2",
        "Params (B)":1.3,
        "Open LLM Score (%)":"31.30 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0147,
        "Decode Throughput (tokens\/s)":68.2,
        "Allocated Memory (MB)":2943,
        "Energy (tokens\/kWh)":900900,
        "E2E Latency (s)":3.75,
        "E2E Throughput (tokens\/s)":68.3,
        "Reserved Memory (MB)":2984,
        "Used Memory (MB)":4443
    },
    {
        "Model":"cerebras\/Cerebras-GPT-1.3B",
        "Arch":"GPT-2",
        "Params (B)":1.3,
        "Open LLM Score (%)":"31.30 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0151,
        "Decode Throughput (tokens\/s)":70.4,
        "Allocated Memory (MB)":2943,
        "Energy (tokens\/kWh)":1000000,
        "E2E Latency (s)":3.64,
        "E2E Throughput (tokens\/s)":70.3,
        "Reserved Memory (MB)":2984,
        "Used Memory (MB)":4443
    },
    {
        "Model":"cerebras\/Cerebras-GPT-1.3B",
        "Arch":"GPT-2",
        "Params (B)":1.3,
        "Open LLM Score (%)":"31.30*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0153,
        "Decode Throughput (tokens\/s)":67.6,
        "Allocated Memory (MB)":2943,
        "Energy (tokens\/kWh)":990099,
        "E2E Latency (s)":3.79,
        "E2E Throughput (tokens\/s)":67.5,
        "Reserved Memory (MB)":2984,
        "Used Memory (MB)":4443
    },
    {
        "Model":"cerebras\/Cerebras-GPT-1.3B",
        "Arch":"GPT-2",
        "Params (B)":1.3,
        "Open LLM Score (%)":"31.30*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0425,
        "Decode Throughput (tokens\/s)":57.4,
        "Allocated Memory (MB)":1156,
        "Energy (tokens\/kWh)":869565,
        "E2E Latency (s)":4.48,
        "E2E Throughput (tokens\/s)":57.1,
        "Reserved Memory (MB)":1186,
        "Used Memory (MB)":2646
    },
    {
        "Model":"cerebras\/Cerebras-GPT-1.3B",
        "Arch":"GPT-2",
        "Params (B)":1.3,
        "Open LLM Score (%)":"31.30 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0524,
        "Decode Throughput (tokens\/s)":73.1,
        "Allocated Memory (MB)":5776,
        "Energy (tokens\/kWh)":833333,
        "E2E Latency (s)":3.54,
        "E2E Throughput (tokens\/s)":72.3,
        "Reserved Memory (MB)":5802,
        "Used Memory (MB)":7253
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.29 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0153,
        "Decode Throughput (tokens\/s)":65.6,
        "Allocated Memory (MB)":1028,
        "Energy (tokens\/kWh)":1023541,
        "E2E Latency (s)":3.91,
        "E2E Throughput (tokens\/s)":65.5,
        "Reserved Memory (MB)":1121,
        "Used Memory (MB)":2581
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.29 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0158,
        "Decode Throughput (tokens\/s)":59.7,
        "Allocated Memory (MB)":1028,
        "Energy (tokens\/kWh)":877192,
        "E2E Latency (s)":4.29,
        "E2E Throughput (tokens\/s)":59.7,
        "Reserved Memory (MB)":1121,
        "Used Memory (MB)":2581
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.29*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0186,
        "Decode Throughput (tokens\/s)":55.9,
        "Allocated Memory (MB)":869,
        "Energy (tokens\/kWh)":892857,
        "E2E Latency (s)":4.58,
        "E2E Throughput (tokens\/s)":55.9,
        "Reserved Memory (MB)":958,
        "Used Memory (MB)":2420
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.29 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0191,
        "Decode Throughput (tokens\/s)":55.1,
        "Allocated Memory (MB)":1028,
        "Energy (tokens\/kWh)":826446,
        "E2E Latency (s)":4.65,
        "E2E Throughput (tokens\/s)":55.1,
        "Reserved Memory (MB)":1121,
        "Used Memory (MB)":2581
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.29*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0195,
        "Decode Throughput (tokens\/s)":55.6,
        "Allocated Memory (MB)":601,
        "Energy (tokens\/kWh)":847457,
        "E2E Latency (s)":4.61,
        "E2E Throughput (tokens\/s)":55.5,
        "Reserved Memory (MB)":681,
        "Used Memory (MB)":2143
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.29*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0201,
        "Decode Throughput (tokens\/s)":53.1,
        "Allocated Memory (MB)":590,
        "Energy (tokens\/kWh)":793650,
        "E2E Latency (s)":4.82,
        "E2E Throughput (tokens\/s)":53.1,
        "Reserved Memory (MB)":685,
        "Used Memory (MB)":2145
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.29*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0203,
        "Decode Throughput (tokens\/s)":49.1,
        "Allocated Memory (MB)":590,
        "Energy (tokens\/kWh)":714285,
        "E2E Latency (s)":5.21,
        "E2E Throughput (tokens\/s)":49.1,
        "Reserved Memory (MB)":685,
        "Used Memory (MB)":2145
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.29 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0237,
        "Decode Throughput (tokens\/s)":54.3,
        "Allocated Memory (MB)":1948,
        "Energy (tokens\/kWh)":806451,
        "E2E Latency (s)":4.72,
        "E2E Throughput (tokens\/s)":54.2,
        "Reserved Memory (MB)":2006,
        "Used Memory (MB)":3458
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.29*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0332,
        "Decode Throughput (tokens\/s)":36.4,
        "Allocated Memory (MB)":603,
        "Energy (tokens\/kWh)":552486,
        "E2E Latency (s)":7.04,
        "E2E Throughput (tokens\/s)":36.4,
        "Reserved Memory (MB)":710,
        "Used Memory (MB)":2170
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.29*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0346,
        "Decode Throughput (tokens\/s)":44.4,
        "Allocated Memory (MB)":592,
        "Energy (tokens\/kWh)":694444,
        "E2E Latency (s)":5.77,
        "E2E Throughput (tokens\/s)":44.4,
        "Reserved Memory (MB)":700,
        "Used Memory (MB)":2160
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.29*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0362,
        "Decode Throughput (tokens\/s)":33.7,
        "Allocated Memory (MB)":603,
        "Energy (tokens\/kWh)":523560,
        "E2E Latency (s)":7.61,
        "E2E Throughput (tokens\/s)":33.6,
        "Reserved Memory (MB)":713,
        "Used Memory (MB)":2172
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.29*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0484,
        "Decode Throughput (tokens\/s)":20.2,
        "Allocated Memory (MB)":742,
        "Energy (tokens\/kWh)":315457,
        "E2E Latency (s)":12.6,
        "E2E Throughput (tokens\/s)":20.3,
        "Reserved Memory (MB)":832,
        "Used Memory (MB)":2300
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.29*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0545,
        "Decode Throughput (tokens\/s)":19.2,
        "Allocated Memory (MB)":743,
        "Energy (tokens\/kWh)":298507,
        "E2E Latency (s)":13.4,
        "E2E Throughput (tokens\/s)":19.1,
        "Reserved Memory (MB)":832,
        "Used Memory (MB)":2300
    },
    {
        "Model":"RWKV\/rwkv-4-430m-pile",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":0.43,
        "Open LLM Score (%)":"30.45 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0237,
        "Decode Throughput (tokens\/s)":41.1,
        "Allocated Memory (MB)":896,
        "Energy (tokens\/kWh)":657894,
        "E2E Latency (s)":6.23,
        "E2E Throughput (tokens\/s)":41.1,
        "Reserved Memory (MB)":918,
        "Used Memory (MB)":2378
    },
    {
        "Model":"RWKV\/rwkv-4-430m-pile",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":0.43,
        "Open LLM Score (%)":"30.45 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.024,
        "Decode Throughput (tokens\/s)":39.3,
        "Allocated Memory (MB)":895,
        "Energy (tokens\/kWh)":578034,
        "E2E Latency (s)":6.51,
        "E2E Throughput (tokens\/s)":39.3,
        "Reserved Memory (MB)":914,
        "Used Memory (MB)":2373
    },
    {
        "Model":"RWKV\/rwkv-4-430m-pile",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":0.43,
        "Open LLM Score (%)":"30.45 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0248,
        "Decode Throughput (tokens\/s)":41.3,
        "Allocated Memory (MB)":1784,
        "Energy (tokens\/kWh)":645161,
        "E2E Latency (s)":6.19,
        "E2E Throughput (tokens\/s)":41.4,
        "Reserved Memory (MB)":1809,
        "Used Memory (MB)":3261
    },
    {
        "Model":"RWKV\/rwkv-4-430m-pile",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":0.43,
        "Open LLM Score (%)":"30.45*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0529,
        "Decode Throughput (tokens\/s)":23.4,
        "Allocated Memory (MB)":428,
        "Energy (tokens\/kWh)":366300,
        "E2E Latency (s)":11.0,
        "E2E Throughput (tokens\/s)":23.3,
        "Reserved Memory (MB)":488,
        "Used Memory (MB)":1948
    },
    {
        "Model":"RWKV\/rwkv-4-430m-pile",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":0.43,
        "Open LLM Score (%)":"30.45*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0813,
        "Decode Throughput (tokens\/s)":12.4,
        "Allocated Memory (MB)":569,
        "Energy (tokens\/kWh)":193050,
        "E2E Latency (s)":20.6,
        "E2E Throughput (tokens\/s)":12.4,
        "Reserved Memory (MB)":606,
        "Used Memory (MB)":2074
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-356m",
        "Arch":"GPT-2",
        "Params (B)":0.47,
        "Open LLM Score (%)":"30.41 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0113,
        "Decode Throughput (tokens\/s)":78.5,
        "Allocated Memory (MB)":951,
        "Energy (tokens\/kWh)":1190476,
        "E2E Latency (s)":3.26,
        "E2E Throughput (tokens\/s)":78.5,
        "Reserved Memory (MB)":1048,
        "Used Memory (MB)":2506
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-356m",
        "Arch":"GPT-2",
        "Params (B)":0.47,
        "Open LLM Score (%)":"30.41 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0133,
        "Decode Throughput (tokens\/s)":71.0,
        "Allocated Memory (MB)":951,
        "Energy (tokens\/kWh)":1119820,
        "E2E Latency (s)":3.6,
        "E2E Throughput (tokens\/s)":71.1,
        "Reserved Memory (MB)":1048,
        "Used Memory (MB)":2506
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-356m",
        "Arch":"GPT-2",
        "Params (B)":0.47,
        "Open LLM Score (%)":"30.41*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0136,
        "Decode Throughput (tokens\/s)":70.8,
        "Allocated Memory (MB)":951,
        "Energy (tokens\/kWh)":1084598,
        "E2E Latency (s)":3.61,
        "E2E Throughput (tokens\/s)":70.9,
        "Reserved Memory (MB)":1048,
        "Used Memory (MB)":2506
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-356m",
        "Arch":"GPT-2",
        "Params (B)":0.47,
        "Open LLM Score (%)":"30.41*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.014,
        "Decode Throughput (tokens\/s)":69.7,
        "Allocated Memory (MB)":951,
        "Energy (tokens\/kWh)":1067235,
        "E2E Latency (s)":3.67,
        "E2E Throughput (tokens\/s)":69.8,
        "Reserved Memory (MB)":1048,
        "Used Memory (MB)":2506
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-356m",
        "Arch":"GPT-2",
        "Params (B)":0.47,
        "Open LLM Score (%)":"30.41*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0142,
        "Decode Throughput (tokens\/s)":75.4,
        "Allocated Memory (MB)":525,
        "Energy (tokens\/kWh)":1166861,
        "E2E Latency (s)":3.39,
        "E2E Throughput (tokens\/s)":75.5,
        "Reserved Memory (MB)":627,
        "Used Memory (MB)":2088
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-356m",
        "Arch":"GPT-2",
        "Params (B)":0.47,
        "Open LLM Score (%)":"30.41 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0149,
        "Decode Throughput (tokens\/s)":69.5,
        "Allocated Memory (MB)":951,
        "Energy (tokens\/kWh)":1036269,
        "E2E Latency (s)":3.68,
        "E2E Throughput (tokens\/s)":69.6,
        "Reserved Memory (MB)":1048,
        "Used Memory (MB)":2506
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-356m",
        "Arch":"GPT-2",
        "Params (B)":0.47,
        "Open LLM Score (%)":"30.41 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0209,
        "Decode Throughput (tokens\/s)":71.8,
        "Allocated Memory (MB)":1792,
        "Energy (tokens\/kWh)":1052631,
        "E2E Latency (s)":3.57,
        "E2E Throughput (tokens\/s)":71.7,
        "Reserved Memory (MB)":1828,
        "Used Memory (MB)":3279
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-356m",
        "Arch":"GPT-2",
        "Params (B)":0.47,
        "Open LLM Score (%)":"30.41*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0295,
        "Decode Throughput (tokens\/s)":56.7,
        "Allocated Memory (MB)":517,
        "Energy (tokens\/kWh)":892857,
        "E2E Latency (s)":4.53,
        "E2E Throughput (tokens\/s)":56.5,
        "Reserved Memory (MB)":635,
        "Used Memory (MB)":2094
    },
    {
        "Model":"robowaifudev\/megatron-gpt2-345m",
        "Arch":"GPT-2",
        "Params (B)":0.38,
        "Open LLM Score (%)":"30.40 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0138,
        "Decode Throughput (tokens\/s)":68.5,
        "Allocated Memory (MB)":844,
        "Energy (tokens\/kWh)":1026694,
        "E2E Latency (s)":3.73,
        "E2E Throughput (tokens\/s)":68.6,
        "Reserved Memory (MB)":935,
        "Used Memory (MB)":2394
    },
    {
        "Model":"robowaifudev\/megatron-gpt2-345m",
        "Arch":"GPT-2",
        "Params (B)":0.38,
        "Open LLM Score (%)":"30.40 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0155,
        "Decode Throughput (tokens\/s)":62.8,
        "Allocated Memory (MB)":844,
        "Energy (tokens\/kWh)":1000000,
        "E2E Latency (s)":4.08,
        "E2E Throughput (tokens\/s)":62.7,
        "Reserved Memory (MB)":935,
        "Used Memory (MB)":2394
    },
    {
        "Model":"robowaifudev\/megatron-gpt2-345m",
        "Arch":"GPT-2",
        "Params (B)":0.38,
        "Open LLM Score (%)":"30.40 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0158,
        "Decode Throughput (tokens\/s)":61.2,
        "Allocated Memory (MB)":844,
        "Energy (tokens\/kWh)":917431,
        "E2E Latency (s)":4.19,
        "E2E Throughput (tokens\/s)":61.1,
        "Reserved Memory (MB)":935,
        "Used Memory (MB)":2394
    },
    {
        "Model":"robowaifudev\/megatron-gpt2-345m",
        "Arch":"GPT-2",
        "Params (B)":0.38,
        "Open LLM Score (%)":"30.40*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0161,
        "Decode Throughput (tokens\/s)":61.9,
        "Allocated Memory (MB)":844,
        "Energy (tokens\/kWh)":952380,
        "E2E Latency (s)":4.14,
        "E2E Throughput (tokens\/s)":61.8,
        "Reserved Memory (MB)":935,
        "Used Memory (MB)":2394
    },
    {
        "Model":"robowaifudev\/megatron-gpt2-345m",
        "Arch":"GPT-2",
        "Params (B)":0.38,
        "Open LLM Score (%)":"30.40*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0162,
        "Decode Throughput (tokens\/s)":61.4,
        "Allocated Memory (MB)":844,
        "Energy (tokens\/kWh)":909090,
        "E2E Latency (s)":4.17,
        "E2E Throughput (tokens\/s)":61.4,
        "Reserved Memory (MB)":935,
        "Used Memory (MB)":2394
    },
    {
        "Model":"robowaifudev\/megatron-gpt2-345m",
        "Arch":"GPT-2",
        "Params (B)":0.38,
        "Open LLM Score (%)":"30.40*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0168,
        "Decode Throughput (tokens\/s)":64.9,
        "Allocated Memory (MB)":407,
        "Energy (tokens\/kWh)":1040582,
        "E2E Latency (s)":3.95,
        "E2E Throughput (tokens\/s)":64.8,
        "Reserved Memory (MB)":492,
        "Used Memory (MB)":1954
    },
    {
        "Model":"robowaifudev\/megatron-gpt2-345m",
        "Arch":"GPT-2",
        "Params (B)":0.38,
        "Open LLM Score (%)":"30.40 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0206,
        "Decode Throughput (tokens\/s)":62.8,
        "Allocated Memory (MB)":1656,
        "Energy (tokens\/kWh)":925925,
        "E2E Latency (s)":4.08,
        "E2E Throughput (tokens\/s)":62.7,
        "Reserved Memory (MB)":1696,
        "Used Memory (MB)":3147
    },
    {
        "Model":"robowaifudev\/megatron-gpt2-345m",
        "Arch":"GPT-2",
        "Params (B)":0.38,
        "Open LLM Score (%)":"30.40*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0309,
        "Decode Throughput (tokens\/s)":51.6,
        "Allocated Memory (MB)":399,
        "Energy (tokens\/kWh)":813008,
        "E2E Latency (s)":4.97,
        "E2E Throughput (tokens\/s)":51.5,
        "Reserved Memory (MB)":499,
        "Used Memory (MB)":1958
    },
    {
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.46,
        "Open LLM Score (%)":"30.17 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0182,
        "Decode Throughput (tokens\/s)":52.8,
        "Allocated Memory (MB)":1020,
        "Energy (tokens\/kWh)":854700,
        "E2E Latency (s)":4.85,
        "E2E Throughput (tokens\/s)":52.8,
        "Reserved Memory (MB)":1101,
        "Used Memory (MB)":2560
    },
    {
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.46,
        "Open LLM Score (%)":"30.17 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0188,
        "Decode Throughput (tokens\/s)":51.0,
        "Allocated Memory (MB)":1020,
        "Energy (tokens\/kWh)":819672,
        "E2E Latency (s)":5.02,
        "E2E Throughput (tokens\/s)":51.0,
        "Reserved Memory (MB)":1103,
        "Used Memory (MB)":2562
    },
    {
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.46,
        "Open LLM Score (%)":"30.17 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0196,
        "Decode Throughput (tokens\/s)":49.2,
        "Allocated Memory (MB)":1020,
        "Energy (tokens\/kWh)":740740,
        "E2E Latency (s)":5.2,
        "E2E Throughput (tokens\/s)":49.2,
        "Reserved Memory (MB)":1103,
        "Used Memory (MB)":2562
    },
    {
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.46,
        "Open LLM Score (%)":"30.17*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0213,
        "Decode Throughput (tokens\/s)":44.0,
        "Allocated Memory (MB)":489,
        "Energy (tokens\/kWh)":671140,
        "E2E Latency (s)":5.81,
        "E2E Throughput (tokens\/s)":44.1,
        "Reserved Memory (MB)":532,
        "Used Memory (MB)":1992
    },
    {
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.46,
        "Open LLM Score (%)":"30.17*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0216,
        "Decode Throughput (tokens\/s)":47.4,
        "Allocated Memory (MB)":768,
        "Energy (tokens\/kWh)":751879,
        "E2E Latency (s)":5.4,
        "E2E Throughput (tokens\/s)":47.4,
        "Reserved Memory (MB)":796,
        "Used Memory (MB)":2258
    },
    {
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.46,
        "Open LLM Score (%)":"30.17*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0217,
        "Decode Throughput (tokens\/s)":48.9,
        "Allocated Memory (MB)":489,
        "Energy (tokens\/kWh)":751879,
        "E2E Latency (s)":5.24,
        "E2E Throughput (tokens\/s)":48.9,
        "Reserved Memory (MB)":532,
        "Used Memory (MB)":1992
    },
    {
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.46,
        "Open LLM Score (%)":"30.17*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0225,
        "Decode Throughput (tokens\/s)":46.2,
        "Allocated Memory (MB)":499,
        "Energy (tokens\/kWh)":704225,
        "E2E Latency (s)":5.54,
        "E2E Throughput (tokens\/s)":46.2,
        "Reserved Memory (MB)":538,
        "Used Memory (MB)":2000
    },
    {
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.46,
        "Open LLM Score (%)":"30.17 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.023,
        "Decode Throughput (tokens\/s)":55.0,
        "Allocated Memory (MB)":1936,
        "Energy (tokens\/kWh)":787401,
        "E2E Latency (s)":4.66,
        "E2E Throughput (tokens\/s)":54.9,
        "Reserved Memory (MB)":1986,
        "Used Memory (MB)":3437
    },
    {
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.46,
        "Open LLM Score (%)":"30.17*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0447,
        "Decode Throughput (tokens\/s)":29.4,
        "Allocated Memory (MB)":504,
        "Energy (tokens\/kWh)":454545,
        "E2E Latency (s)":8.71,
        "E2E Throughput (tokens\/s)":29.4,
        "Reserved Memory (MB)":568,
        "Used Memory (MB)":2027
    },
    {
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.46,
        "Open LLM Score (%)":"30.17*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0464,
        "Decode Throughput (tokens\/s)":28.3,
        "Allocated Memory (MB)":504,
        "Energy (tokens\/kWh)":444444,
        "E2E Latency (s)":9.05,
        "E2E Throughput (tokens\/s)":28.3,
        "Reserved Memory (MB)":570,
        "Used Memory (MB)":2029
    },
    {
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.46,
        "Open LLM Score (%)":"30.17*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0483,
        "Decode Throughput (tokens\/s)":35.4,
        "Allocated Memory (MB)":490,
        "Energy (tokens\/kWh)":564971,
        "E2E Latency (s)":7.25,
        "E2E Throughput (tokens\/s)":35.3,
        "Reserved Memory (MB)":551,
        "Used Memory (MB)":2011
    },
    {
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.46,
        "Open LLM Score (%)":"30.17*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0724,
        "Decode Throughput (tokens\/s)":13.8,
        "Allocated Memory (MB)":662,
        "Energy (tokens\/kWh)":220264,
        "E2E Latency (s)":18.6,
        "E2E Throughput (tokens\/s)":13.8,
        "Reserved Memory (MB)":704,
        "Used Memory (MB)":2172
    },
    {
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.46,
        "Open LLM Score (%)":"30.17*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0743,
        "Decode Throughput (tokens\/s)":13.1,
        "Allocated Memory (MB)":662,
        "Energy (tokens\/kWh)":207468,
        "E2E Latency (s)":19.5,
        "E2E Throughput (tokens\/s)":13.1,
        "Reserved Memory (MB)":706,
        "Used Memory (MB)":2174
    },
    {
        "Model":"uukuguy\/Orca-2-7b-f16",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"30.15 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0307,
        "Decode Throughput (tokens\/s)":43.1,
        "Allocated Memory (MB)":14089,
        "Energy (tokens\/kWh)":487804,
        "E2E Latency (s)":5.94,
        "E2E Throughput (tokens\/s)":43.1,
        "Reserved Memory (MB)":14128,
        "Used Memory (MB)":15588
    },
    {
        "Model":"uukuguy\/Orca-2-7b-f16",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"30.15 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0328,
        "Decode Throughput (tokens\/s)":40.8,
        "Allocated Memory (MB)":14089,
        "Energy (tokens\/kWh)":450450,
        "E2E Latency (s)":6.28,
        "E2E Throughput (tokens\/s)":40.8,
        "Reserved Memory (MB)":14128,
        "Used Memory (MB)":15588
    },
    {
        "Model":"uukuguy\/Orca-2-7b-f16",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"30.15*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0413,
        "Decode Throughput (tokens\/s)":40.2,
        "Allocated Memory (MB)":4649,
        "Energy (tokens\/kWh)":523560,
        "E2E Latency (s)":6.39,
        "E2E Throughput (tokens\/s)":40.1,
        "Reserved Memory (MB)":4685,
        "Used Memory (MB)":6146
    },
    {
        "Model":"uukuguy\/Orca-2-7b-f16",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"30.15*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0417,
        "Decode Throughput (tokens\/s)":40.2,
        "Allocated Memory (MB)":5375,
        "Energy (tokens\/kWh)":568181,
        "E2E Latency (s)":6.38,
        "E2E Throughput (tokens\/s)":40.1,
        "Reserved Memory (MB)":5412,
        "Used Memory (MB)":6874
    },
    {
        "Model":"uukuguy\/Orca-2-7b-f16",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"30.15*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0635,
        "Decode Throughput (tokens\/s)":40.1,
        "Allocated Memory (MB)":4553,
        "Energy (tokens\/kWh)":543478,
        "E2E Latency (s)":6.42,
        "E2E Throughput (tokens\/s)":39.9,
        "Reserved Memory (MB)":4590,
        "Used Memory (MB)":6050
    },
    {
        "Model":"uukuguy\/Orca-2-7b-f16",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"30.15*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0725,
        "Decode Throughput (tokens\/s)":36.7,
        "Allocated Memory (MB)":4552,
        "Energy (tokens\/kWh)":495049,
        "E2E Latency (s)":7.01,
        "E2E Throughput (tokens\/s)":36.5,
        "Reserved Memory (MB)":4590,
        "Used Memory (MB)":6050
    },
    {
        "Model":"uukuguy\/Orca-2-7b-f16",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"30.15*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0935,
        "Decode Throughput (tokens\/s)":10.6,
        "Allocated Memory (MB)":7719,
        "Energy (tokens\/kWh)":157232,
        "E2E Latency (s)":24.1,
        "E2E Throughput (tokens\/s)":10.6,
        "Reserved Memory (MB)":7761,
        "Used Memory (MB)":9229
    },
    {
        "Model":"uukuguy\/Orca-2-7b-f16",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"30.15*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.1,
        "Decode Throughput (tokens\/s)":10.2,
        "Allocated Memory (MB)":7719,
        "Energy (tokens\/kWh)":153139,
        "E2E Latency (s)":25.1,
        "E2E Throughput (tokens\/s)":10.2,
        "Reserved Memory (MB)":7761,
        "Used Memory (MB)":9229
    },
    {
        "Model":"uukuguy\/Orca-2-7b-f16",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"30.15*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.166,
        "Decode Throughput (tokens\/s)":28.3,
        "Allocated Memory (MB)":4561,
        "Energy (tokens\/kWh)":387596,
        "E2E Latency (s)":9.19,
        "E2E Throughput (tokens\/s)":27.9,
        "Reserved Memory (MB)":4611,
        "Used Memory (MB)":6071
    },
    {
        "Model":"uukuguy\/Orca-2-7b-f16",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"30.15 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.238,
        "Decode Throughput (tokens\/s)":41.7,
        "Allocated Memory (MB)":28167,
        "Energy (tokens\/kWh)":366300,
        "E2E Latency (s)":6.35,
        "E2E Throughput (tokens\/s)":40.3,
        "Reserved Memory (MB)":28531,
        "Used Memory (MB)":29982
    },
    {
        "Model":"uukuguy\/Orca-2-7b-f16",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"30.15*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.269,
        "Decode Throughput (tokens\/s)":23.2,
        "Allocated Memory (MB)":4829,
        "Energy (tokens\/kWh)":291545,
        "E2E Latency (s)":11.3,
        "E2E Throughput (tokens\/s)":22.7,
        "Reserved Memory (MB)":4987,
        "Used Memory (MB)":6446
    },
    {
        "Model":"uukuguy\/Orca-2-7b-f16",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":7.0,
        "Open LLM Score (%)":"30.15*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.273,
        "Decode Throughput (tokens\/s)":22.6,
        "Allocated Memory (MB)":4829,
        "Energy (tokens\/kWh)":287356,
        "E2E Latency (s)":11.6,
        "E2E Throughput (tokens\/s)":22.1,
        "Reserved Memory (MB)":5033,
        "Used Memory (MB)":6492
    },
    {
        "Model":"bigcode\/starcoderbase-1b",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":1.14,
        "Open LLM Score (%)":"30.06 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0097,
        "Decode Throughput (tokens\/s)":94.8,
        "Allocated Memory (MB)":2417,
        "Energy (tokens\/kWh)":1135073,
        "E2E Latency (s)":2.7,
        "E2E Throughput (tokens\/s)":94.8,
        "Reserved Memory (MB)":2478,
        "Used Memory (MB)":3936
    },
    {
        "Model":"bigcode\/starcoderbase-1b",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":1.14,
        "Open LLM Score (%)":"30.06 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0109,
        "Decode Throughput (tokens\/s)":87.6,
        "Allocated Memory (MB)":2417,
        "Energy (tokens\/kWh)":1092896,
        "E2E Latency (s)":2.92,
        "E2E Throughput (tokens\/s)":87.7,
        "Reserved Memory (MB)":2478,
        "Used Memory (MB)":3938
    },
    {
        "Model":"bigcode\/starcoderbase-1b",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":1.14,
        "Open LLM Score (%)":"30.06 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0117,
        "Decode Throughput (tokens\/s)":84.4,
        "Allocated Memory (MB)":2417,
        "Energy (tokens\/kWh)":1101321,
        "E2E Latency (s)":3.03,
        "E2E Throughput (tokens\/s)":84.5,
        "Reserved Memory (MB)":2478,
        "Used Memory (MB)":3938
    },
    {
        "Model":"bigcode\/starcoderbase-1b",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":1.14,
        "Open LLM Score (%)":"30.06*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0472,
        "Decode Throughput (tokens\/s)":22.0,
        "Allocated Memory (MB)":1402,
        "Energy (tokens\/kWh)":312500,
        "E2E Latency (s)":11.6,
        "E2E Throughput (tokens\/s)":22.1,
        "Reserved Memory (MB)":1449,
        "Used Memory (MB)":2917
    },
    {
        "Model":"bigcode\/starcoderbase-1b",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":1.14,
        "Open LLM Score (%)":"30.06*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0477,
        "Decode Throughput (tokens\/s)":19.5,
        "Allocated Memory (MB)":1407,
        "Energy (tokens\/kWh)":263852,
        "E2E Latency (s)":13.1,
        "E2E Throughput (tokens\/s)":19.5,
        "Reserved Memory (MB)":1444,
        "Used Memory (MB)":2910
    },
    {
        "Model":"bigcode\/starcoderbase-1b",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":1.14,
        "Open LLM Score (%)":"30.06 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0519,
        "Decode Throughput (tokens\/s)":90.7,
        "Allocated Memory (MB)":4739,
        "Energy (tokens\/kWh)":990099,
        "E2E Latency (s)":2.86,
        "E2E Throughput (tokens\/s)":89.5,
        "Reserved Memory (MB)":4823,
        "Used Memory (MB)":6274
    },
    {
        "Model":"bigcode\/starcoderbase-1b",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":1.14,
        "Open LLM Score (%)":"30.06*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0533,
        "Decode Throughput (tokens\/s)":32.7,
        "Allocated Memory (MB)":1010,
        "Energy (tokens\/kWh)":434782,
        "E2E Latency (s)":7.86,
        "E2E Throughput (tokens\/s)":32.6,
        "Reserved Memory (MB)":1088,
        "Used Memory (MB)":2547
    },
    {
        "Model":"bigcode\/starcoderbase-1b",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":1.14,
        "Open LLM Score (%)":"30.06*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0543,
        "Decode Throughput (tokens\/s)":37.6,
        "Allocated Memory (MB)":1010,
        "Energy (tokens\/kWh)":483091,
        "E2E Latency (s)":6.83,
        "E2E Throughput (tokens\/s)":37.5,
        "Reserved Memory (MB)":1088,
        "Used Memory (MB)":2548
    },
    {
        "Model":"facebook\/xglm-564M",
        "Arch":"XGLM",
        "Params (B)":0.56,
        "Open LLM Score (%)":"29.55 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0155,
        "Decode Throughput (tokens\/s)":75.7,
        "Allocated Memory (MB)":1325,
        "Energy (tokens\/kWh)":1094091,
        "E2E Latency (s)":3.39,
        "E2E Throughput (tokens\/s)":75.5,
        "Reserved Memory (MB)":1396,
        "Used Memory (MB)":2856
    },
    {
        "Model":"facebook\/xglm-564M",
        "Arch":"XGLM",
        "Params (B)":0.56,
        "Open LLM Score (%)":"29.55 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0158,
        "Decode Throughput (tokens\/s)":74.6,
        "Allocated Memory (MB)":1325,
        "Energy (tokens\/kWh)":1091703,
        "E2E Latency (s)":3.44,
        "E2E Throughput (tokens\/s)":74.4,
        "Reserved Memory (MB)":1396,
        "Used Memory (MB)":2856
    },
    {
        "Model":"facebook\/xglm-564M",
        "Arch":"XGLM",
        "Params (B)":0.56,
        "Open LLM Score (%)":"29.55*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0162,
        "Decode Throughput (tokens\/s)":74.1,
        "Allocated Memory (MB)":1156,
        "Energy (tokens\/kWh)":1146788,
        "E2E Latency (s)":3.46,
        "E2E Throughput (tokens\/s)":74.0,
        "Reserved Memory (MB)":1228,
        "Used Memory (MB)":2690
    },
    {
        "Model":"facebook\/xglm-564M",
        "Arch":"XGLM",
        "Params (B)":0.56,
        "Open LLM Score (%)":"29.55*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0164,
        "Decode Throughput (tokens\/s)":71.4,
        "Allocated Memory (MB)":886,
        "Energy (tokens\/kWh)":1043841,
        "E2E Latency (s)":3.59,
        "E2E Throughput (tokens\/s)":71.3,
        "Reserved Memory (MB)":968,
        "Used Memory (MB)":2430
    },
    {
        "Model":"facebook\/xglm-564M",
        "Arch":"XGLM",
        "Params (B)":0.56,
        "Open LLM Score (%)":"29.55*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0177,
        "Decode Throughput (tokens\/s)":68.7,
        "Allocated Memory (MB)":877,
        "Energy (tokens\/kWh)":970873,
        "E2E Latency (s)":3.73,
        "E2E Throughput (tokens\/s)":68.6,
        "Reserved Memory (MB)":964,
        "Used Memory (MB)":2424
    },
    {
        "Model":"facebook\/xglm-564M",
        "Arch":"XGLM",
        "Params (B)":0.56,
        "Open LLM Score (%)":"29.55*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0179,
        "Decode Throughput (tokens\/s)":58.4,
        "Allocated Memory (MB)":877,
        "Energy (tokens\/kWh)":862068,
        "E2E Latency (s)":4.39,
        "E2E Throughput (tokens\/s)":58.3,
        "Reserved Memory (MB)":962,
        "Used Memory (MB)":2422
    },
    {
        "Model":"facebook\/xglm-564M",
        "Arch":"XGLM",
        "Params (B)":0.56,
        "Open LLM Score (%)":"29.55 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0282,
        "Decode Throughput (tokens\/s)":73.7,
        "Allocated Memory (MB)":2644,
        "Energy (tokens\/kWh)":990099,
        "E2E Latency (s)":3.49,
        "E2E Throughput (tokens\/s)":73.4,
        "Reserved Memory (MB)":2667,
        "Used Memory (MB)":4118
    },
    {
        "Model":"facebook\/xglm-564M",
        "Arch":"XGLM",
        "Params (B)":0.56,
        "Open LLM Score (%)":"29.55*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0392,
        "Decode Throughput (tokens\/s)":49.7,
        "Allocated Memory (MB)":878,
        "Energy (tokens\/kWh)":763358,
        "E2E Latency (s)":5.17,
        "E2E Throughput (tokens\/s)":49.5,
        "Reserved Memory (MB)":966,
        "Used Memory (MB)":2426
    },
    {
        "Model":"facebook\/xglm-564M",
        "Arch":"XGLM",
        "Params (B)":0.56,
        "Open LLM Score (%)":"29.55*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0401,
        "Decode Throughput (tokens\/s)":33.6,
        "Allocated Memory (MB)":890,
        "Energy (tokens\/kWh)":520833,
        "E2E Latency (s)":7.64,
        "E2E Throughput (tokens\/s)":33.5,
        "Reserved Memory (MB)":998,
        "Used Memory (MB)":2457
    },
    {
        "Model":"facebook\/xglm-564M",
        "Arch":"XGLM",
        "Params (B)":0.56,
        "Open LLM Score (%)":"29.55*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0626,
        "Decode Throughput (tokens\/s)":16.6,
        "Allocated Memory (MB)":1023,
        "Energy (tokens\/kWh)":248138,
        "E2E Latency (s)":15.5,
        "E2E Throughput (tokens\/s)":16.5,
        "Reserved Memory (MB)":1105,
        "Used Memory (MB)":2573
    },
    {
        "Model":"winglian\/Llama-2-3b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"29.53 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0154,
        "Decode Throughput (tokens\/s)":78.7,
        "Allocated Memory (MB)":7311,
        "Energy (tokens\/kWh)":952380,
        "E2E Latency (s)":3.26,
        "E2E Throughput (tokens\/s)":78.5,
        "Reserved Memory (MB)":7342,
        "Used Memory (MB)":8801
    },
    {
        "Model":"winglian\/Llama-2-3b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"29.53 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0163,
        "Decode Throughput (tokens\/s)":82.5,
        "Allocated Memory (MB)":7311,
        "Energy (tokens\/kWh)":884955,
        "E2E Latency (s)":3.11,
        "E2E Throughput (tokens\/s)":82.3,
        "Reserved Memory (MB)":7342,
        "Used Memory (MB)":8801
    },
    {
        "Model":"winglian\/Llama-2-3b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"29.53 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0165,
        "Decode Throughput (tokens\/s)":79.4,
        "Allocated Memory (MB)":7311,
        "Energy (tokens\/kWh)":877192,
        "E2E Latency (s)":3.23,
        "E2E Throughput (tokens\/s)":79.3,
        "Reserved Memory (MB)":7342,
        "Used Memory (MB)":8801
    },
    {
        "Model":"winglian\/Llama-2-3b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"29.53*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0203,
        "Decode Throughput (tokens\/s)":76.3,
        "Allocated Memory (MB)":2637,
        "Energy (tokens\/kWh)":1000000,
        "E2E Latency (s)":3.36,
        "E2E Throughput (tokens\/s)":76.2,
        "Reserved Memory (MB)":2675,
        "Used Memory (MB)":4137
    },
    {
        "Model":"winglian\/Llama-2-3b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"29.53*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0208,
        "Decode Throughput (tokens\/s)":76.6,
        "Allocated Memory (MB)":3360,
        "Energy (tokens\/kWh)":1100110,
        "E2E Latency (s)":3.35,
        "E2E Throughput (tokens\/s)":76.4,
        "Reserved Memory (MB)":3401,
        "Used Memory (MB)":4863
    },
    {
        "Model":"winglian\/Llama-2-3b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"29.53*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0308,
        "Decode Throughput (tokens\/s)":82.0,
        "Allocated Memory (MB)":2543,
        "Energy (tokens\/kWh)":1083423,
        "E2E Latency (s)":3.14,
        "E2E Throughput (tokens\/s)":81.5,
        "Reserved Memory (MB)":2581,
        "Used Memory (MB)":4041
    },
    {
        "Model":"winglian\/Llama-2-3b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"29.53*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0362,
        "Decode Throughput (tokens\/s)":70.2,
        "Allocated Memory (MB)":2543,
        "Energy (tokens\/kWh)":961538,
        "E2E Latency (s)":3.67,
        "E2E Throughput (tokens\/s)":69.8,
        "Reserved Memory (MB)":2560,
        "Used Memory (MB)":4020
    },
    {
        "Model":"winglian\/Llama-2-3b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"29.53*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0486,
        "Decode Throughput (tokens\/s)":20.4,
        "Allocated Memory (MB)":4126,
        "Energy (tokens\/kWh)":303951,
        "E2E Latency (s)":12.5,
        "E2E Throughput (tokens\/s)":20.5,
        "Reserved Memory (MB)":4158,
        "Used Memory (MB)":5626
    },
    {
        "Model":"winglian\/Llama-2-3b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"29.53*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0491,
        "Decode Throughput (tokens\/s)":20.7,
        "Allocated Memory (MB)":4126,
        "Energy (tokens\/kWh)":300300,
        "E2E Latency (s)":12.3,
        "E2E Throughput (tokens\/s)":20.8,
        "Reserved Memory (MB)":4158,
        "Used Memory (MB)":5626
    },
    {
        "Model":"winglian\/Llama-2-3b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"29.53*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0845,
        "Decode Throughput (tokens\/s)":58.1,
        "Allocated Memory (MB)":2584,
        "Energy (tokens\/kWh)":781250,
        "E2E Latency (s)":4.47,
        "E2E Throughput (tokens\/s)":57.3,
        "Reserved Memory (MB)":2686,
        "Used Memory (MB)":4146
    },
    {
        "Model":"winglian\/Llama-2-3b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"29.53 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.121,
        "Decode Throughput (tokens\/s)":80.4,
        "Allocated Memory (MB)":14612,
        "Energy (tokens\/kWh)":704225,
        "E2E Latency (s)":3.29,
        "E2E Throughput (tokens\/s)":77.8,
        "Reserved Memory (MB)":14807,
        "Used Memory (MB)":16259
    },
    {
        "Model":"winglian\/Llama-2-3b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"29.53*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.134,
        "Decode Throughput (tokens\/s)":45.6,
        "Allocated Memory (MB)":2776,
        "Energy (tokens\/kWh)":571428,
        "E2E Latency (s)":5.72,
        "E2E Throughput (tokens\/s)":44.8,
        "Reserved Memory (MB)":3053,
        "Used Memory (MB)":4513
    },
    {
        "Model":"winglian\/Llama-2-3b-hf",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":3.0,
        "Open LLM Score (%)":"29.53*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.134,
        "Decode Throughput (tokens\/s)":45.2,
        "Allocated Memory (MB)":2776,
        "Energy (tokens\/kWh)":568181,
        "E2E Latency (s)":5.77,
        "E2E Throughput (tokens\/s)":44.4,
        "Reserved Memory (MB)":3053,
        "Used Memory (MB)":4513
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"GPT-Neo",
        "Params (B)":0.15,
        "Open LLM Score (%)":"29.47 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00641,
        "Decode Throughput (tokens\/s)":147.0,
        "Allocated Memory (MB)":363,
        "Energy (tokens\/kWh)":2325581,
        "E2E Latency (s)":1.74,
        "E2E Throughput (tokens\/s)":147.0,
        "Reserved Memory (MB)":411,
        "Used Memory (MB)":1868
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"GPT-Neo",
        "Params (B)":0.15,
        "Open LLM Score (%)":"29.47 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00791,
        "Decode Throughput (tokens\/s)":122.0,
        "Allocated Memory (MB)":363,
        "Energy (tokens\/kWh)":1869158,
        "E2E Latency (s)":2.1,
        "E2E Throughput (tokens\/s)":122.0,
        "Reserved Memory (MB)":411,
        "Used Memory (MB)":1870
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"GPT-Neo",
        "Params (B)":0.15,
        "Open LLM Score (%)":"29.47 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00838,
        "Decode Throughput (tokens\/s)":121.0,
        "Allocated Memory (MB)":363,
        "Energy (tokens\/kWh)":1953124,
        "E2E Latency (s)":2.12,
        "E2E Throughput (tokens\/s)":121.0,
        "Reserved Memory (MB)":411,
        "Used Memory (MB)":1870
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"GPT-Neo",
        "Params (B)":0.15,
        "Open LLM Score (%)":"29.47 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00875,
        "Decode Throughput (tokens\/s)":115.0,
        "Allocated Memory (MB)":363,
        "Energy (tokens\/kWh)":1748251,
        "E2E Latency (s)":2.22,
        "E2E Throughput (tokens\/s)":115.0,
        "Reserved Memory (MB)":411,
        "Used Memory (MB)":1870
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"GPT-Neo",
        "Params (B)":0.15,
        "Open LLM Score (%)":"29.47*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00928,
        "Decode Throughput (tokens\/s)":115.0,
        "Allocated Memory (MB)":436,
        "Energy (tokens\/kWh)":1858736,
        "E2E Latency (s)":2.22,
        "E2E Throughput (tokens\/s)":115.0,
        "Reserved Memory (MB)":486,
        "Used Memory (MB)":1948
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"GPT-Neo",
        "Params (B)":0.15,
        "Open LLM Score (%)":"29.47*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00953,
        "Decode Throughput (tokens\/s)":114.0,
        "Allocated Memory (MB)":235,
        "Energy (tokens\/kWh)":1834862,
        "E2E Latency (s)":2.25,
        "E2E Throughput (tokens\/s)":114.0,
        "Reserved Memory (MB)":278,
        "Used Memory (MB)":1740
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"GPT-Neo",
        "Params (B)":0.15,
        "Open LLM Score (%)":"29.47*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.00962,
        "Decode Throughput (tokens\/s)":103.0,
        "Allocated Memory (MB)":230,
        "Energy (tokens\/kWh)":1599999,
        "E2E Latency (s)":2.49,
        "E2E Throughput (tokens\/s)":103.0,
        "Reserved Memory (MB)":291,
        "Used Memory (MB)":1751
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"GPT-Neo",
        "Params (B)":0.15,
        "Open LLM Score (%)":"29.47*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.00975,
        "Decode Throughput (tokens\/s)":116.0,
        "Allocated Memory (MB)":230,
        "Energy (tokens\/kWh)":1757469,
        "E2E Latency (s)":2.2,
        "E2E Throughput (tokens\/s)":116.0,
        "Reserved Memory (MB)":291,
        "Used Memory (MB)":1751
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"GPT-Neo",
        "Params (B)":0.15,
        "Open LLM Score (%)":"29.47 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00981,
        "Decode Throughput (tokens\/s)":123.0,
        "Allocated Memory (MB)":658,
        "Energy (tokens\/kWh)":1838235,
        "E2E Latency (s)":2.08,
        "E2E Throughput (tokens\/s)":123.0,
        "Reserved Memory (MB)":746,
        "Used Memory (MB)":2197
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"GPT-Neo",
        "Params (B)":0.15,
        "Open LLM Score (%)":"29.47*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0196,
        "Decode Throughput (tokens\/s)":64.2,
        "Allocated Memory (MB)":233,
        "Energy (tokens\/kWh)":980392,
        "E2E Latency (s)":3.99,
        "E2E Throughput (tokens\/s)":64.2,
        "Reserved Memory (MB)":304,
        "Used Memory (MB)":1763
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"GPT-Neo",
        "Params (B)":0.15,
        "Open LLM Score (%)":"29.47*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0208,
        "Decode Throughput (tokens\/s)":85.9,
        "Allocated Memory (MB)":230,
        "Energy (tokens\/kWh)":1369863,
        "E2E Latency (s)":2.99,
        "E2E Throughput (tokens\/s)":85.6,
        "Reserved Memory (MB)":299,
        "Used Memory (MB)":1759
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"GPT-Neo",
        "Params (B)":0.15,
        "Open LLM Score (%)":"29.47*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.021,
        "Decode Throughput (tokens\/s)":59.9,
        "Allocated Memory (MB)":233,
        "Energy (tokens\/kWh)":961538,
        "E2E Latency (s)":4.28,
        "E2E Throughput (tokens\/s)":59.8,
        "Reserved Memory (MB)":301,
        "Used Memory (MB)":1761
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"GPT-Neo",
        "Params (B)":0.15,
        "Open LLM Score (%)":"29.47*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0324,
        "Decode Throughput (tokens\/s)":31.2,
        "Allocated Memory (MB)":271,
        "Energy (tokens\/kWh)":487804,
        "E2E Latency (s)":8.2,
        "E2E Throughput (tokens\/s)":31.2,
        "Reserved Memory (MB)":339,
        "Used Memory (MB)":1807
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"GPT-Neo",
        "Params (B)":0.15,
        "Open LLM Score (%)":"29.47*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0325,
        "Decode Throughput (tokens\/s)":31.3,
        "Allocated Memory (MB)":270,
        "Energy (tokens\/kWh)":487804,
        "E2E Latency (s)":8.18,
        "E2E Throughput (tokens\/s)":31.3,
        "Reserved Memory (MB)":339,
        "Used Memory (MB)":1807
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-220M-GQA",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.22,
        "Open LLM Score (%)":"29.44 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00784,
        "Decode Throughput (tokens\/s)":118.0,
        "Allocated Memory (MB)":500,
        "Energy (tokens\/kWh)":1872659,
        "E2E Latency (s)":2.18,
        "E2E Throughput (tokens\/s)":117.0,
        "Reserved Memory (MB)":549,
        "Used Memory (MB)":2009
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-220M-GQA",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.22,
        "Open LLM Score (%)":"29.44 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00789,
        "Decode Throughput (tokens\/s)":120.0,
        "Allocated Memory (MB)":500,
        "Energy (tokens\/kWh)":1897533,
        "E2E Latency (s)":2.14,
        "E2E Throughput (tokens\/s)":120.0,
        "Reserved Memory (MB)":547,
        "Used Memory (MB)":2006
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-220M-GQA",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.22,
        "Open LLM Score (%)":"29.44 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00855,
        "Decode Throughput (tokens\/s)":109.0,
        "Allocated Memory (MB)":500,
        "Energy (tokens\/kWh)":1736111,
        "E2E Latency (s)":2.35,
        "E2E Throughput (tokens\/s)":109.0,
        "Reserved Memory (MB)":549,
        "Used Memory (MB)":2009
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-220M-GQA",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.22,
        "Open LLM Score (%)":"29.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.00919,
        "Decode Throughput (tokens\/s)":109.0,
        "Allocated Memory (MB)":275,
        "Energy (tokens\/kWh)":1697792,
        "E2E Latency (s)":2.34,
        "E2E Throughput (tokens\/s)":109.0,
        "Reserved Memory (MB)":301,
        "Used Memory (MB)":1761
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-220M-GQA",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.22,
        "Open LLM Score (%)":"29.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00921,
        "Decode Throughput (tokens\/s)":109.0,
        "Allocated Memory (MB)":553,
        "Energy (tokens\/kWh)":1715265,
        "E2E Latency (s)":2.35,
        "E2E Throughput (tokens\/s)":109.0,
        "Reserved Memory (MB)":583,
        "Used Memory (MB)":2044
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-220M-GQA",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.22,
        "Open LLM Score (%)":"29.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00938,
        "Decode Throughput (tokens\/s)":105.0,
        "Allocated Memory (MB)":283,
        "Energy (tokens\/kWh)":1658374,
        "E2E Latency (s)":2.43,
        "E2E Throughput (tokens\/s)":105.0,
        "Reserved Memory (MB)":308,
        "Used Memory (MB)":1769
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-220M-GQA",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.22,
        "Open LLM Score (%)":"29.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0096,
        "Decode Throughput (tokens\/s)":98.5,
        "Allocated Memory (MB)":275,
        "Energy (tokens\/kWh)":1550387,
        "E2E Latency (s)":2.6,
        "E2E Throughput (tokens\/s)":98.5,
        "Reserved Memory (MB)":301,
        "Used Memory (MB)":1761
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-220M-GQA",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.22,
        "Open LLM Score (%)":"29.44 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0108,
        "Decode Throughput (tokens\/s)":126.0,
        "Allocated Memory (MB)":932,
        "Energy (tokens\/kWh)":1779359,
        "E2E Latency (s)":2.04,
        "E2E Throughput (tokens\/s)":125.0,
        "Reserved Memory (MB)":968,
        "Used Memory (MB)":2420
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-220M-GQA",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.22,
        "Open LLM Score (%)":"29.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0185,
        "Decode Throughput (tokens\/s)":70.1,
        "Allocated Memory (MB)":281,
        "Energy (tokens\/kWh)":1066098,
        "E2E Latency (s)":3.66,
        "E2E Throughput (tokens\/s)":69.9,
        "Reserved Memory (MB)":322,
        "Used Memory (MB)":1782
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-220M-GQA",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.22,
        "Open LLM Score (%)":"29.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0188,
        "Decode Throughput (tokens\/s)":67.8,
        "Allocated Memory (MB)":281,
        "Energy (tokens\/kWh)":1049317,
        "E2E Latency (s)":3.78,
        "E2E Throughput (tokens\/s)":67.7,
        "Reserved Memory (MB)":325,
        "Used Memory (MB)":1784
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-220M-GQA",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.22,
        "Open LLM Score (%)":"29.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.02,
        "Decode Throughput (tokens\/s)":82.0,
        "Allocated Memory (MB)":275,
        "Energy (tokens\/kWh)":1321003,
        "E2E Latency (s)":3.13,
        "E2E Throughput (tokens\/s)":81.8,
        "Reserved Memory (MB)":320,
        "Used Memory (MB)":1780
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-220M-GQA",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.22,
        "Open LLM Score (%)":"29.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0306,
        "Decode Throughput (tokens\/s)":32.2,
        "Allocated Memory (MB)":348,
        "Energy (tokens\/kWh)":510204,
        "E2E Latency (s)":7.94,
        "E2E Throughput (tokens\/s)":32.2,
        "Reserved Memory (MB)":375,
        "Used Memory (MB)":1843
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-220M-GQA",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.22,
        "Open LLM Score (%)":"29.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0312,
        "Decode Throughput (tokens\/s)":31.4,
        "Allocated Memory (MB)":348,
        "Energy (tokens\/kWh)":485436,
        "E2E Latency (s)":8.14,
        "E2E Throughput (tokens\/s)":31.4,
        "Reserved Memory (MB)":375,
        "Used Memory (MB)":1843
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":0.16,
        "Open LLM Score (%)":"29.41 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0078,
        "Decode Throughput (tokens\/s)":116.0,
        "Allocated Memory (MB)":446,
        "Energy (tokens\/kWh)":1862197,
        "E2E Latency (s)":2.21,
        "E2E Throughput (tokens\/s)":116.0,
        "Reserved Memory (MB)":469,
        "Used Memory (MB)":1927
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":0.16,
        "Open LLM Score (%)":"29.41 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0089,
        "Decode Throughput (tokens\/s)":112.0,
        "Allocated Memory (MB)":446,
        "Energy (tokens\/kWh)":1824817,
        "E2E Latency (s)":2.29,
        "E2E Throughput (tokens\/s)":112.0,
        "Reserved Memory (MB)":469,
        "Used Memory (MB)":1929
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":0.16,
        "Open LLM Score (%)":"29.41*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00962,
        "Decode Throughput (tokens\/s)":111.0,
        "Allocated Memory (MB)":470,
        "Energy (tokens\/kWh)":1798561,
        "E2E Latency (s)":2.31,
        "E2E Throughput (tokens\/s)":111.0,
        "Reserved Memory (MB)":482,
        "Used Memory (MB)":1944
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":0.16,
        "Open LLM Score (%)":"29.41*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00997,
        "Decode Throughput (tokens\/s)":109.0,
        "Allocated Memory (MB)":269,
        "Energy (tokens\/kWh)":1745200,
        "E2E Latency (s)":2.34,
        "E2E Throughput (tokens\/s)":109.0,
        "Reserved Memory (MB)":295,
        "Used Memory (MB)":1757
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":0.16,
        "Open LLM Score (%)":"29.41 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0104,
        "Decode Throughput (tokens\/s)":111.0,
        "Allocated Memory (MB)":446,
        "Energy (tokens\/kWh)":1718213,
        "E2E Latency (s)":2.31,
        "E2E Throughput (tokens\/s)":111.0,
        "Reserved Memory (MB)":469,
        "Used Memory (MB)":1929
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":0.16,
        "Open LLM Score (%)":"29.41*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0105,
        "Decode Throughput (tokens\/s)":103.0,
        "Allocated Memory (MB)":264,
        "Energy (tokens\/kWh)":1623376,
        "E2E Latency (s)":2.49,
        "E2E Throughput (tokens\/s)":103.0,
        "Reserved Memory (MB)":287,
        "Used Memory (MB)":1746
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":0.16,
        "Open LLM Score (%)":"29.41*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0108,
        "Decode Throughput (tokens\/s)":92.1,
        "Allocated Memory (MB)":263,
        "Energy (tokens\/kWh)":1445086,
        "E2E Latency (s)":2.78,
        "E2E Throughput (tokens\/s)":92.1,
        "Reserved Memory (MB)":287,
        "Used Memory (MB)":1746
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":0.16,
        "Open LLM Score (%)":"29.41 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0115,
        "Decode Throughput (tokens\/s)":109.0,
        "Allocated Memory (MB)":804,
        "Energy (tokens\/kWh)":1727115,
        "E2E Latency (s)":2.36,
        "E2E Throughput (tokens\/s)":108.0,
        "Reserved Memory (MB)":870,
        "Used Memory (MB)":2321
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":0.16,
        "Open LLM Score (%)":"29.41*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0226,
        "Decode Throughput (tokens\/s)":79.2,
        "Allocated Memory (MB)":264,
        "Energy (tokens\/kWh)":1293661,
        "E2E Latency (s)":3.24,
        "E2E Throughput (tokens\/s)":79.0,
        "Reserved Memory (MB)":295,
        "Used Memory (MB)":1755
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":0.16,
        "Open LLM Score (%)":"29.41*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0229,
        "Decode Throughput (tokens\/s)":55.2,
        "Allocated Memory (MB)":269,
        "Energy (tokens\/kWh)":877192,
        "E2E Latency (s)":4.64,
        "E2E Throughput (tokens\/s)":55.2,
        "Reserved Memory (MB)":304,
        "Used Memory (MB)":1763
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":0.16,
        "Open LLM Score (%)":"29.41*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0232,
        "Decode Throughput (tokens\/s)":55.4,
        "Allocated Memory (MB)":269,
        "Energy (tokens\/kWh)":892857,
        "E2E Latency (s)":4.62,
        "E2E Throughput (tokens\/s)":55.4,
        "Reserved Memory (MB)":301,
        "Used Memory (MB)":1759
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":0.16,
        "Open LLM Score (%)":"29.41*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0335,
        "Decode Throughput (tokens\/s)":29.3,
        "Allocated Memory (MB)":320,
        "Energy (tokens\/kWh)":460829,
        "E2E Latency (s)":8.74,
        "E2E Throughput (tokens\/s)":29.3,
        "Reserved Memory (MB)":354,
        "Used Memory (MB)":1820
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":0.16,
        "Open LLM Score (%)":"29.41*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0373,
        "Decode Throughput (tokens\/s)":27.7,
        "Allocated Memory (MB)":320,
        "Energy (tokens\/kWh)":434782,
        "E2E Latency (s)":9.25,
        "E2E Throughput (tokens\/s)":27.7,
        "Reserved Memory (MB)":352,
        "Used Memory (MB)":1820
    },
    {
        "Model":"cerebras\/Cerebras-GPT-256M",
        "Arch":"GPT-2",
        "Params (B)":0.26,
        "Open LLM Score (%)":"29.38 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00683,
        "Decode Throughput (tokens\/s)":130.0,
        "Allocated Memory (MB)":665,
        "Energy (tokens\/kWh)":1855287,
        "E2E Latency (s)":1.97,
        "E2E Throughput (tokens\/s)":130.0,
        "Reserved Memory (MB)":748,
        "Used Memory (MB)":2208
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.38 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00793,
        "Decode Throughput (tokens\/s)":128.0,
        "Allocated Memory (MB)":458,
        "Energy (tokens\/kWh)":2028397,
        "E2E Latency (s)":2.01,
        "E2E Throughput (tokens\/s)":127.0,
        "Reserved Memory (MB)":509,
        "Used Memory (MB)":1969
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.38 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00807,
        "Decode Throughput (tokens\/s)":118.0,
        "Allocated Memory (MB)":458,
        "Energy (tokens\/kWh)":1763668,
        "E2E Latency (s)":2.17,
        "E2E Throughput (tokens\/s)":118.0,
        "Reserved Memory (MB)":509,
        "Used Memory (MB)":1969
    },
    {
        "Model":"cerebras\/Cerebras-GPT-256M",
        "Arch":"GPT-2",
        "Params (B)":0.26,
        "Open LLM Score (%)":"29.38 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00825,
        "Decode Throughput (tokens\/s)":120.0,
        "Allocated Memory (MB)":665,
        "Energy (tokens\/kWh)":1872659,
        "E2E Latency (s)":2.14,
        "E2E Throughput (tokens\/s)":120.0,
        "Reserved Memory (MB)":748,
        "Used Memory (MB)":2208
    },
    {
        "Model":"cerebras\/Cerebras-GPT-256M",
        "Arch":"GPT-2",
        "Params (B)":0.26,
        "Open LLM Score (%)":"29.38*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.00836,
        "Decode Throughput (tokens\/s)":115.0,
        "Allocated Memory (MB)":664,
        "Energy (tokens\/kWh)":1724137,
        "E2E Latency (s)":2.22,
        "E2E Throughput (tokens\/s)":115.0,
        "Reserved Memory (MB)":748,
        "Used Memory (MB)":2208
    },
    {
        "Model":"cerebras\/Cerebras-GPT-256M",
        "Arch":"GPT-2",
        "Params (B)":0.26,
        "Open LLM Score (%)":"29.38 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0085,
        "Decode Throughput (tokens\/s)":114.0,
        "Allocated Memory (MB)":665,
        "Energy (tokens\/kWh)":1721170,
        "E2E Latency (s)":2.25,
        "E2E Throughput (tokens\/s)":114.0,
        "Reserved Memory (MB)":748,
        "Used Memory (MB)":2208
    },
    {
        "Model":"cerebras\/Cerebras-GPT-256M",
        "Arch":"GPT-2",
        "Params (B)":0.26,
        "Open LLM Score (%)":"29.38*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0085,
        "Decode Throughput (tokens\/s)":114.0,
        "Allocated Memory (MB)":664,
        "Energy (tokens\/kWh)":1727115,
        "E2E Latency (s)":2.24,
        "E2E Throughput (tokens\/s)":114.0,
        "Reserved Memory (MB)":748,
        "Used Memory (MB)":2208
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.38 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00925,
        "Decode Throughput (tokens\/s)":109.0,
        "Allocated Memory (MB)":458,
        "Energy (tokens\/kWh)":1773049,
        "E2E Latency (s)":2.35,
        "E2E Throughput (tokens\/s)":109.0,
        "Reserved Memory (MB)":509,
        "Used Memory (MB)":1969
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.38 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00928,
        "Decode Throughput (tokens\/s)":106.0,
        "Allocated Memory (MB)":458,
        "Energy (tokens\/kWh)":1661129,
        "E2E Latency (s)":2.41,
        "E2E Throughput (tokens\/s)":106.0,
        "Reserved Memory (MB)":509,
        "Used Memory (MB)":1969
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.38*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00966,
        "Decode Throughput (tokens\/s)":107.0,
        "Allocated Memory (MB)":521,
        "Energy (tokens\/kWh)":1721170,
        "E2E Latency (s)":2.39,
        "E2E Throughput (tokens\/s)":107.0,
        "Reserved Memory (MB)":566,
        "Used Memory (MB)":2027
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.38*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00978,
        "Decode Throughput (tokens\/s)":107.0,
        "Allocated Memory (MB)":320,
        "Energy (tokens\/kWh)":1721170,
        "E2E Latency (s)":2.4,
        "E2E Throughput (tokens\/s)":107.0,
        "Reserved Memory (MB)":377,
        "Used Memory (MB)":1839
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.38*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0103,
        "Decode Throughput (tokens\/s)":95.5,
        "Allocated Memory (MB)":315,
        "Energy (tokens\/kWh)":1477104,
        "E2E Latency (s)":2.68,
        "E2E Throughput (tokens\/s)":95.5,
        "Reserved Memory (MB)":392,
        "Used Memory (MB)":1851
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.38 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0106,
        "Decode Throughput (tokens\/s)":108.0,
        "Allocated Memory (MB)":828,
        "Energy (tokens\/kWh)":1642036,
        "E2E Latency (s)":2.37,
        "E2E Throughput (tokens\/s)":108.0,
        "Reserved Memory (MB)":903,
        "Used Memory (MB)":2355
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.38*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0106,
        "Decode Throughput (tokens\/s)":102.0,
        "Allocated Memory (MB)":315,
        "Energy (tokens\/kWh)":1538461,
        "E2E Latency (s)":2.5,
        "E2E Throughput (tokens\/s)":102.0,
        "Reserved Memory (MB)":392,
        "Used Memory (MB)":1851
    },
    {
        "Model":"cerebras\/Cerebras-GPT-256M",
        "Arch":"GPT-2",
        "Params (B)":0.26,
        "Open LLM Score (%)":"29.38 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0127,
        "Decode Throughput (tokens\/s)":123.0,
        "Allocated Memory (MB)":1257,
        "Energy (tokens\/kWh)":1757469,
        "E2E Latency (s)":2.08,
        "E2E Throughput (tokens\/s)":123.0,
        "Reserved Memory (MB)":1321,
        "Used Memory (MB)":2772
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.38*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0165,
        "Decode Throughput (tokens\/s)":68.9,
        "Allocated Memory (MB)":320,
        "Energy (tokens\/kWh)":1077586,
        "E2E Latency (s)":3.72,
        "E2E Throughput (tokens\/s)":68.8,
        "Reserved Memory (MB)":381,
        "Used Memory (MB)":1841
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.38*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0172,
        "Decode Throughput (tokens\/s)":87.9,
        "Allocated Memory (MB)":317,
        "Energy (tokens\/kWh)":1386962,
        "E2E Latency (s)":2.92,
        "E2E Throughput (tokens\/s)":87.7,
        "Reserved Memory (MB)":379,
        "Used Memory (MB)":1839
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.38*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0186,
        "Decode Throughput (tokens\/s)":65.1,
        "Allocated Memory (MB)":320,
        "Energy (tokens\/kWh)":1027749,
        "E2E Latency (s)":3.94,
        "E2E Throughput (tokens\/s)":65.0,
        "Reserved Memory (MB)":381,
        "Used Memory (MB)":1841
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.38*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0244,
        "Decode Throughput (tokens\/s)":39.4,
        "Allocated Memory (MB)":363,
        "Energy (tokens\/kWh)":621118,
        "E2E Latency (s)":6.49,
        "E2E Throughput (tokens\/s)":39.4,
        "Reserved Memory (MB)":415,
        "Used Memory (MB)":1883
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.38*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0253,
        "Decode Throughput (tokens\/s)":39.4,
        "Allocated Memory (MB)":363,
        "Energy (tokens\/kWh)":602409,
        "E2E Latency (s)":6.51,
        "E2E Throughput (tokens\/s)":39.3,
        "Reserved Memory (MB)":415,
        "Used Memory (MB)":1883
    },
    {
        "Model":"chargoddard\/SmolLlamix-8x101M-take2",
        "Arch":"\u24c2\ufe0f Mixtral",
        "Params (B)":0.4,
        "Open LLM Score (%)":"29.35 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.025,
        "Decode Throughput (tokens\/s)":78.5,
        "Allocated Memory (MB)":894,
        "Energy (tokens\/kWh)":1215066,
        "E2E Latency (s)":3.28,
        "E2E Throughput (tokens\/s)":78.0,
        "Reserved Memory (MB)":945,
        "Used Memory (MB)":2405
    },
    {
        "Model":"chargoddard\/SmolLlamix-8x101M-take2",
        "Arch":"\u24c2\ufe0f Mixtral",
        "Params (B)":0.4,
        "Open LLM Score (%)":"29.35 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0251,
        "Decode Throughput (tokens\/s)":83.1,
        "Allocated Memory (MB)":1697,
        "Energy (tokens\/kWh)":1344086,
        "E2E Latency (s)":3.1,
        "E2E Throughput (tokens\/s)":82.6,
        "Reserved Memory (MB)":1895,
        "Used Memory (MB)":3347
    },
    {
        "Model":"chargoddard\/SmolLlamix-8x101M-take2",
        "Arch":"\u24c2\ufe0f Mixtral",
        "Params (B)":0.4,
        "Open LLM Score (%)":"29.35 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0251,
        "Decode Throughput (tokens\/s)":77.5,
        "Allocated Memory (MB)":894,
        "Energy (tokens\/kWh)":1230012,
        "E2E Latency (s)":3.32,
        "E2E Throughput (tokens\/s)":77.1,
        "Reserved Memory (MB)":945,
        "Used Memory (MB)":2405
    },
    {
        "Model":"bit-dny\/MindLLM",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.28 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0135,
        "Decode Throughput (tokens\/s)":75.4,
        "Allocated Memory (MB)":3045,
        "Energy (tokens\/kWh)":1024590,
        "E2E Latency (s)":3.39,
        "E2E Throughput (tokens\/s)":75.5,
        "Reserved Memory (MB)":3131,
        "Used Memory (MB)":4588
    },
    {
        "Model":"bit-dny\/MindLLM",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.28 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0157,
        "Decode Throughput (tokens\/s)":65.7,
        "Allocated Memory (MB)":3045,
        "Energy (tokens\/kWh)":854700,
        "E2E Latency (s)":3.9,
        "E2E Throughput (tokens\/s)":65.6,
        "Reserved Memory (MB)":3131,
        "Used Memory (MB)":4590
    },
    {
        "Model":"bit-dny\/MindLLM",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.28 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0172,
        "Decode Throughput (tokens\/s)":61.4,
        "Allocated Memory (MB)":3048,
        "Energy (tokens\/kWh)":877192,
        "E2E Latency (s)":4.17,
        "E2E Throughput (tokens\/s)":61.4,
        "Reserved Memory (MB)":3131,
        "Used Memory (MB)":4590
    },
    {
        "Model":"bit-dny\/MindLLM",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.28 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0172,
        "Decode Throughput (tokens\/s)":58.9,
        "Allocated Memory (MB)":3048,
        "Energy (tokens\/kWh)":819672,
        "E2E Latency (s)":4.35,
        "E2E Throughput (tokens\/s)":58.9,
        "Reserved Memory (MB)":3131,
        "Used Memory (MB)":4590
    },
    {
        "Model":"bit-dny\/MindLLM",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.28*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0189,
        "Decode Throughput (tokens\/s)":59.9,
        "Allocated Memory (MB)":1834,
        "Energy (tokens\/kWh)":917431,
        "E2E Latency (s)":4.28,
        "E2E Throughput (tokens\/s)":59.8,
        "Reserved Memory (MB)":1931,
        "Used Memory (MB)":3393
    },
    {
        "Model":"bit-dny\/MindLLM",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.28*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0195,
        "Decode Throughput (tokens\/s)":59.3,
        "Allocated Memory (MB)":1296,
        "Energy (tokens\/kWh)":884955,
        "E2E Latency (s)":4.32,
        "E2E Throughput (tokens\/s)":59.3,
        "Reserved Memory (MB)":1390,
        "Used Memory (MB)":2852
    },
    {
        "Model":"bit-dny\/MindLLM",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.28*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0224,
        "Decode Throughput (tokens\/s)":57.6,
        "Allocated Memory (MB)":1260,
        "Energy (tokens\/kWh)":877192,
        "E2E Latency (s)":4.45,
        "E2E Throughput (tokens\/s)":57.5,
        "Reserved Memory (MB)":1346,
        "Used Memory (MB)":2805
    },
    {
        "Model":"bit-dny\/MindLLM",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.28*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0233,
        "Decode Throughput (tokens\/s)":51.9,
        "Allocated Memory (MB)":1260,
        "Energy (tokens\/kWh)":757575,
        "E2E Latency (s)":4.93,
        "E2E Throughput (tokens\/s)":51.9,
        "Reserved Memory (MB)":1346,
        "Used Memory (MB)":2805
    },
    {
        "Model":"bit-dny\/MindLLM",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.28*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0471,
        "Decode Throughput (tokens\/s)":43.4,
        "Allocated Memory (MB)":1262,
        "Energy (tokens\/kWh)":657894,
        "E2E Latency (s)":5.93,
        "E2E Throughput (tokens\/s)":43.2,
        "Reserved Memory (MB)":1350,
        "Used Memory (MB)":2810
    },
    {
        "Model":"bit-dny\/MindLLM",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.28 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0553,
        "Decode Throughput (tokens\/s)":63.8,
        "Allocated Memory (MB)":5980,
        "Energy (tokens\/kWh)":813008,
        "E2E Latency (s)":4.06,
        "E2E Throughput (tokens\/s)":63.1,
        "Reserved Memory (MB)":6025,
        "Used Memory (MB)":7476
    },
    {
        "Model":"bit-dny\/MindLLM",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.28*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.062,
        "Decode Throughput (tokens\/s)":33.1,
        "Allocated Memory (MB)":1308,
        "Energy (tokens\/kWh)":490196,
        "E2E Latency (s)":7.77,
        "E2E Throughput (tokens\/s)":32.9,
        "Reserved Memory (MB)":1400,
        "Used Memory (MB)":2860
    },
    {
        "Model":"bit-dny\/MindLLM",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.28*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0633,
        "Decode Throughput (tokens\/s)":15.8,
        "Allocated Memory (MB)":1838,
        "Energy (tokens\/kWh)":238663,
        "E2E Latency (s)":16.2,
        "E2E Throughput (tokens\/s)":15.8,
        "Reserved Memory (MB)":1927,
        "Used Memory (MB)":3395
    },
    {
        "Model":"bit-dny\/MindLLM",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.28*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0642,
        "Decode Throughput (tokens\/s)":15.6,
        "Allocated Memory (MB)":1842,
        "Energy (tokens\/kWh)":241545,
        "E2E Latency (s)":16.4,
        "E2E Throughput (tokens\/s)":15.6,
        "Reserved Memory (MB)":1931,
        "Used Memory (MB)":3399
    },
    {
        "Model":"bit-dny\/MindLLM",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.28*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.066,
        "Decode Throughput (tokens\/s)":32.2,
        "Allocated Memory (MB)":1312,
        "Energy (tokens\/kWh)":485436,
        "E2E Latency (s)":7.98,
        "E2E Throughput (tokens\/s)":32.1,
        "Reserved Memory (MB)":1400,
        "Used Memory (MB)":2860
    },
    {
        "Model":"BEE-spoke-data\/NanoLlama-GQA-L10-A32_KV8-v13-KI",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.22,
        "Open LLM Score (%)":"29.23 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00778,
        "Decode Throughput (tokens\/s)":121.0,
        "Allocated Memory (MB)":500,
        "Energy (tokens\/kWh)":1930501,
        "E2E Latency (s)":2.11,
        "E2E Throughput (tokens\/s)":121.0,
        "Reserved Memory (MB)":547,
        "Used Memory (MB)":2006
    },
    {
        "Model":"BEE-spoke-data\/NanoLlama-GQA-L10-A32_KV8-v13-KI",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.22,
        "Open LLM Score (%)":"29.23 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00789,
        "Decode Throughput (tokens\/s)":116.0,
        "Allocated Memory (MB)":500,
        "Energy (tokens\/kWh)":1869158,
        "E2E Latency (s)":2.21,
        "E2E Throughput (tokens\/s)":116.0,
        "Reserved Memory (MB)":549,
        "Used Memory (MB)":2009
    },
    {
        "Model":"BEE-spoke-data\/NanoLlama-GQA-L10-A32_KV8-v13-KI",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.22,
        "Open LLM Score (%)":"29.23 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00816,
        "Decode Throughput (tokens\/s)":114.0,
        "Allocated Memory (MB)":500,
        "Energy (tokens\/kWh)":1669449,
        "E2E Latency (s)":2.24,
        "E2E Throughput (tokens\/s)":114.0,
        "Reserved Memory (MB)":549,
        "Used Memory (MB)":2009
    },
    {
        "Model":"BEE-spoke-data\/NanoLlama-GQA-L10-A32_KV8-v13-KI",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.22,
        "Open LLM Score (%)":"29.23*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.00908,
        "Decode Throughput (tokens\/s)":102.0,
        "Allocated Memory (MB)":275,
        "Energy (tokens\/kWh)":1567398,
        "E2E Latency (s)":2.5,
        "E2E Throughput (tokens\/s)":102.0,
        "Reserved Memory (MB)":301,
        "Used Memory (MB)":1761
    },
    {
        "Model":"BEE-spoke-data\/NanoLlama-GQA-L10-A32_KV8-v13-KI",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.22,
        "Open LLM Score (%)":"29.23*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.00926,
        "Decode Throughput (tokens\/s)":112.0,
        "Allocated Memory (MB)":275,
        "Energy (tokens\/kWh)":1692047,
        "E2E Latency (s)":2.28,
        "E2E Throughput (tokens\/s)":112.0,
        "Reserved Memory (MB)":301,
        "Used Memory (MB)":1761
    },
    {
        "Model":"BEE-spoke-data\/NanoLlama-GQA-L10-A32_KV8-v13-KI",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.22,
        "Open LLM Score (%)":"29.23*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00938,
        "Decode Throughput (tokens\/s)":107.0,
        "Allocated Memory (MB)":553,
        "Energy (tokens\/kWh)":1724137,
        "E2E Latency (s)":2.39,
        "E2E Throughput (tokens\/s)":107.0,
        "Reserved Memory (MB)":583,
        "Used Memory (MB)":2044
    },
    {
        "Model":"BEE-spoke-data\/NanoLlama-GQA-L10-A32_KV8-v13-KI",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.22,
        "Open LLM Score (%)":"29.23*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00991,
        "Decode Throughput (tokens\/s)":108.0,
        "Allocated Memory (MB)":283,
        "Energy (tokens\/kWh)":1715265,
        "E2E Latency (s)":2.38,
        "E2E Throughput (tokens\/s)":108.0,
        "Reserved Memory (MB)":308,
        "Used Memory (MB)":1769
    },
    {
        "Model":"BEE-spoke-data\/NanoLlama-GQA-L10-A32_KV8-v13-KI",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.22,
        "Open LLM Score (%)":"29.23 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0103,
        "Decode Throughput (tokens\/s)":122.0,
        "Allocated Memory (MB)":932,
        "Energy (tokens\/kWh)":1805054,
        "E2E Latency (s)":2.1,
        "E2E Throughput (tokens\/s)":122.0,
        "Reserved Memory (MB)":968,
        "Used Memory (MB)":2420
    },
    {
        "Model":"BEE-spoke-data\/NanoLlama-GQA-L10-A32_KV8-v13-KI",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.22,
        "Open LLM Score (%)":"29.23*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0182,
        "Decode Throughput (tokens\/s)":69.5,
        "Allocated Memory (MB)":281,
        "Energy (tokens\/kWh)":1041666,
        "E2E Latency (s)":3.69,
        "E2E Throughput (tokens\/s)":69.4,
        "Reserved Memory (MB)":322,
        "Used Memory (MB)":1782
    },
    {
        "Model":"BEE-spoke-data\/NanoLlama-GQA-L10-A32_KV8-v13-KI",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.22,
        "Open LLM Score (%)":"29.23*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0188,
        "Decode Throughput (tokens\/s)":67.8,
        "Allocated Memory (MB)":281,
        "Energy (tokens\/kWh)":1064962,
        "E2E Latency (s)":3.78,
        "E2E Throughput (tokens\/s)":67.7,
        "Reserved Memory (MB)":325,
        "Used Memory (MB)":1784
    },
    {
        "Model":"BEE-spoke-data\/NanoLlama-GQA-L10-A32_KV8-v13-KI",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.22,
        "Open LLM Score (%)":"29.23*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0203,
        "Decode Throughput (tokens\/s)":82.8,
        "Allocated Memory (MB)":275,
        "Energy (tokens\/kWh)":1267427,
        "E2E Latency (s)":3.1,
        "E2E Throughput (tokens\/s)":82.6,
        "Reserved Memory (MB)":320,
        "Used Memory (MB)":1780
    },
    {
        "Model":"BEE-spoke-data\/NanoLlama-GQA-L10-A32_KV8-v13-KI",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.22,
        "Open LLM Score (%)":"29.23*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0305,
        "Decode Throughput (tokens\/s)":32.1,
        "Allocated Memory (MB)":348,
        "Energy (tokens\/kWh)":510204,
        "E2E Latency (s)":7.98,
        "E2E Throughput (tokens\/s)":32.1,
        "Reserved Memory (MB)":373,
        "Used Memory (MB)":1841
    },
    {
        "Model":"BEE-spoke-data\/NanoLlama-GQA-L10-A32_KV8-v13-KI",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.22,
        "Open LLM Score (%)":"29.23*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0319,
        "Decode Throughput (tokens\/s)":31.2,
        "Allocated Memory (MB)":348,
        "Energy (tokens\/kWh)":485436,
        "E2E Latency (s)":8.2,
        "E2E Throughput (tokens\/s)":31.2,
        "Reserved Memory (MB)":375,
        "Used Memory (MB)":1843
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"29.15 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00391,
        "Decode Throughput (tokens\/s)":243.0,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3984063,
        "E2E Latency (s)":1.05,
        "E2E Throughput (tokens\/s)":244.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1602
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"29.15 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00431,
        "Decode Throughput (tokens\/s)":220.0,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3521126,
        "E2E Latency (s)":1.16,
        "E2E Throughput (tokens\/s)":221.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1602
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"29.15 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00482,
        "Decode Throughput (tokens\/s)":207.0,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3496503,
        "E2E Latency (s)":1.23,
        "E2E Throughput (tokens\/s)":208.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1602
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"29.15 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00484,
        "Decode Throughput (tokens\/s)":204.0,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3236245,
        "E2E Latency (s)":1.25,
        "E2E Throughput (tokens\/s)":205.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1602
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"29.15*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00499,
        "Decode Throughput (tokens\/s)":198.0,
        "Allocated Memory (MB)":186,
        "Energy (tokens\/kWh)":3267973,
        "E2E Latency (s)":1.29,
        "E2E Throughput (tokens\/s)":198.0,
        "Reserved Memory (MB)":205,
        "Used Memory (MB)":1667
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"29.15*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00512,
        "Decode Throughput (tokens\/s)":204.0,
        "Allocated Memory (MB)":119,
        "Energy (tokens\/kWh)":3278688,
        "E2E Latency (s)":1.26,
        "E2E Throughput (tokens\/s)":203.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1597
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"29.15*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.00521,
        "Decode Throughput (tokens\/s)":182.0,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2906976,
        "E2E Latency (s)":1.41,
        "E2E Throughput (tokens\/s)":182.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1595
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"29.15 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00534,
        "Decode Throughput (tokens\/s)":206.0,
        "Allocated Memory (MB)":221,
        "Energy (tokens\/kWh)":3257328,
        "E2E Latency (s)":1.25,
        "E2E Throughput (tokens\/s)":205.0,
        "Reserved Memory (MB)":234,
        "Used Memory (MB)":1686
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"29.15*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.00535,
        "Decode Throughput (tokens\/s)":192.0,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":3086419,
        "E2E Latency (s)":1.34,
        "E2E Throughput (tokens\/s)":191.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1595
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"29.15*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00844,
        "Decode Throughput (tokens\/s)":134.0,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2079002,
        "E2E Latency (s)":1.92,
        "E2E Throughput (tokens\/s)":133.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1595
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"29.15*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00905,
        "Decode Throughput (tokens\/s)":126.0,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2049180,
        "E2E Latency (s)":2.04,
        "E2E Throughput (tokens\/s)":125.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1595
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"29.15*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.00911,
        "Decode Throughput (tokens\/s)":167.0,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2710027,
        "E2E Latency (s)":1.54,
        "E2E Throughput (tokens\/s)":166.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1595
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"29.15*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0124,
        "Decode Throughput (tokens\/s)":78.7,
        "Allocated Memory (MB)":121,
        "Energy (tokens\/kWh)":1231527,
        "E2E Latency (s)":3.25,
        "E2E Throughput (tokens\/s)":78.8,
        "Reserved Memory (MB)":138,
        "Used Memory (MB)":1606
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"29.15*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0129,
        "Decode Throughput (tokens\/s)":75.9,
        "Allocated Memory (MB)":121,
        "Energy (tokens\/kWh)":1203369,
        "E2E Latency (s)":3.37,
        "E2E Throughput (tokens\/s)":76.0,
        "Reserved Memory (MB)":138,
        "Used Memory (MB)":1606
    },
    {
        "Model":"roneneldan\/TinyStories-1M",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.14 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0047,
        "Decode Throughput (tokens\/s)":193.0,
        "Allocated Memory (MB)":77,
        "Energy (tokens\/kWh)":3257328,
        "E2E Latency (s)":1.32,
        "E2E Throughput (tokens\/s)":194.0,
        "Reserved Memory (MB)":96,
        "Used Memory (MB)":1556
    },
    {
        "Model":"roneneldan\/TinyStories-1M",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.14 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00526,
        "Decode Throughput (tokens\/s)":182.0,
        "Allocated Memory (MB)":112,
        "Energy (tokens\/kWh)":2890173,
        "E2E Latency (s)":1.41,
        "E2E Throughput (tokens\/s)":182.0,
        "Reserved Memory (MB)":140,
        "Used Memory (MB)":1591
    },
    {
        "Model":"roneneldan\/TinyStories-1M",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.14 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00542,
        "Decode Throughput (tokens\/s)":182.0,
        "Allocated Memory (MB)":77,
        "Energy (tokens\/kWh)":3030303,
        "E2E Latency (s)":1.41,
        "E2E Throughput (tokens\/s)":182.0,
        "Reserved Memory (MB)":96,
        "Used Memory (MB)":1556
    },
    {
        "Model":"roneneldan\/TinyStories-1M",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.14 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00571,
        "Decode Throughput (tokens\/s)":175.0,
        "Allocated Memory (MB)":77,
        "Energy (tokens\/kWh)":2777777,
        "E2E Latency (s)":1.47,
        "E2E Throughput (tokens\/s)":174.0,
        "Reserved Memory (MB)":96,
        "Used Memory (MB)":1556
    },
    {
        "Model":"roneneldan\/TinyStories-1M",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.14 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00643,
        "Decode Throughput (tokens\/s)":173.0,
        "Allocated Memory (MB)":77,
        "Energy (tokens\/kWh)":2793296,
        "E2E Latency (s)":1.48,
        "E2E Throughput (tokens\/s)":173.0,
        "Reserved Memory (MB)":96,
        "Used Memory (MB)":1556
    },
    {
        "Model":"roneneldan\/TinyStories-1M",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.14*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0132,
        "Decode Throughput (tokens\/s)":93.8,
        "Allocated Memory (MB)":75,
        "Energy (tokens\/kWh)":1515151,
        "E2E Latency (s)":2.73,
        "E2E Throughput (tokens\/s)":93.8,
        "Reserved Memory (MB)":94,
        "Used Memory (MB)":1553
    },
    {
        "Model":"roneneldan\/TinyStories-1M",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.14*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0138,
        "Decode Throughput (tokens\/s)":90.7,
        "Allocated Memory (MB)":75,
        "Energy (tokens\/kWh)":1464128,
        "E2E Latency (s)":2.82,
        "E2E Throughput (tokens\/s)":90.8,
        "Reserved Memory (MB)":94,
        "Used Memory (MB)":1553
    },
    {
        "Model":"roneneldan\/TinyStories-1M",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.14*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0214,
        "Decode Throughput (tokens\/s)":47.0,
        "Allocated Memory (MB)":76,
        "Energy (tokens\/kWh)":735294,
        "E2E Latency (s)":5.45,
        "E2E Throughput (tokens\/s)":47.0,
        "Reserved Memory (MB)":94,
        "Used Memory (MB)":1562
    },
    {
        "Model":"roneneldan\/TinyStories-1M",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.14*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0217,
        "Decode Throughput (tokens\/s)":45.4,
        "Allocated Memory (MB)":76,
        "Energy (tokens\/kWh)":735294,
        "E2E Latency (s)":5.64,
        "E2E Throughput (tokens\/s)":45.4,
        "Reserved Memory (MB)":94,
        "Used Memory (MB)":1562
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.11 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0135,
        "Decode Throughput (tokens\/s)":69.5,
        "Allocated Memory (MB)":1939,
        "Energy (tokens\/kWh)":970873,
        "E2E Latency (s)":3.68,
        "E2E Throughput (tokens\/s)":69.6,
        "Reserved Memory (MB)":2084,
        "Used Memory (MB)":3544
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.11 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0151,
        "Decode Throughput (tokens\/s)":67.3,
        "Allocated Memory (MB)":1939,
        "Energy (tokens\/kWh)":1000000,
        "E2E Latency (s)":3.81,
        "E2E Throughput (tokens\/s)":67.2,
        "Reserved Memory (MB)":2084,
        "Used Memory (MB)":3544
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.11 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0152,
        "Decode Throughput (tokens\/s)":68.0,
        "Allocated Memory (MB)":1939,
        "Energy (tokens\/kWh)":925925,
        "E2E Latency (s)":3.77,
        "E2E Throughput (tokens\/s)":67.9,
        "Reserved Memory (MB)":2084,
        "Used Memory (MB)":3544
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.11*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0155,
        "Decode Throughput (tokens\/s)":70.4,
        "Allocated Memory (MB)":962,
        "Energy (tokens\/kWh)":1054852,
        "E2E Latency (s)":3.64,
        "E2E Throughput (tokens\/s)":70.3,
        "Reserved Memory (MB)":1090,
        "Used Memory (MB)":2552
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.11*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0156,
        "Decode Throughput (tokens\/s)":71.4,
        "Allocated Memory (MB)":1365,
        "Energy (tokens\/kWh)":1104972,
        "E2E Latency (s)":3.59,
        "E2E Throughput (tokens\/s)":71.3,
        "Reserved Memory (MB)":1497,
        "Used Memory (MB)":2959
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.11*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0163,
        "Decode Throughput (tokens\/s)":60.7,
        "Allocated Memory (MB)":942,
        "Energy (tokens\/kWh)":917431,
        "E2E Latency (s)":4.22,
        "E2E Throughput (tokens\/s)":60.7,
        "Reserved Memory (MB)":1073,
        "Used Memory (MB)":2533
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.11*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0164,
        "Decode Throughput (tokens\/s)":66.9,
        "Allocated Memory (MB)":945,
        "Energy (tokens\/kWh)":1007049,
        "E2E Latency (s)":3.83,
        "E2E Throughput (tokens\/s)":66.8,
        "Reserved Memory (MB)":1075,
        "Used Memory (MB)":2535
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.11*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0301,
        "Decode Throughput (tokens\/s)":55.2,
        "Allocated Memory (MB)":943,
        "Energy (tokens\/kWh)":833333,
        "E2E Latency (s)":4.65,
        "E2E Throughput (tokens\/s)":55.1,
        "Reserved Memory (MB)":1084,
        "Used Memory (MB)":2543
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.11*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0354,
        "Decode Throughput (tokens\/s)":39.2,
        "Allocated Memory (MB)":972,
        "Energy (tokens\/kWh)":595238,
        "E2E Latency (s)":6.54,
        "E2E Throughput (tokens\/s)":39.1,
        "Reserved Memory (MB)":1147,
        "Used Memory (MB)":2606
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.11*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.036,
        "Decode Throughput (tokens\/s)":38.9,
        "Allocated Memory (MB)":972,
        "Energy (tokens\/kWh)":598802,
        "E2E Latency (s)":6.59,
        "E2E Throughput (tokens\/s)":38.8,
        "Reserved Memory (MB)":1147,
        "Used Memory (MB)":2606
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.11 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0373,
        "Decode Throughput (tokens\/s)":70.8,
        "Allocated Memory (MB)":3893,
        "Energy (tokens\/kWh)":909090,
        "E2E Latency (s)":3.64,
        "E2E Throughput (tokens\/s)":70.3,
        "Reserved Memory (MB)":3942,
        "Used Memory (MB)":5393
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.11*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0454,
        "Decode Throughput (tokens\/s)":21.6,
        "Allocated Memory (MB)":1262,
        "Energy (tokens\/kWh)":330033,
        "E2E Latency (s)":11.8,
        "E2E Throughput (tokens\/s)":21.7,
        "Reserved Memory (MB)":1436,
        "Used Memory (MB)":2904
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.11*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0469,
        "Decode Throughput (tokens\/s)":20.7,
        "Allocated Memory (MB)":1259,
        "Energy (tokens\/kWh)":319488,
        "E2E Latency (s)":12.3,
        "E2E Throughput (tokens\/s)":20.8,
        "Reserved Memory (MB)":1436,
        "Used Memory (MB)":2904
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.02 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0079,
        "Decode Throughput (tokens\/s)":129.0,
        "Allocated Memory (MB)":458,
        "Energy (tokens\/kWh)":2044989,
        "E2E Latency (s)":1.98,
        "E2E Throughput (tokens\/s)":129.0,
        "Reserved Memory (MB)":509,
        "Used Memory (MB)":1969
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.02 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00844,
        "Decode Throughput (tokens\/s)":115.0,
        "Allocated Memory (MB)":458,
        "Energy (tokens\/kWh)":1779359,
        "E2E Latency (s)":2.22,
        "E2E Throughput (tokens\/s)":115.0,
        "Reserved Memory (MB)":509,
        "Used Memory (MB)":1969
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.02 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00918,
        "Decode Throughput (tokens\/s)":108.0,
        "Allocated Memory (MB)":458,
        "Energy (tokens\/kWh)":1776198,
        "E2E Latency (s)":2.38,
        "E2E Throughput (tokens\/s)":108.0,
        "Reserved Memory (MB)":509,
        "Used Memory (MB)":1969
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.02*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00968,
        "Decode Throughput (tokens\/s)":106.0,
        "Allocated Memory (MB)":521,
        "Energy (tokens\/kWh)":1683501,
        "E2E Latency (s)":2.41,
        "E2E Throughput (tokens\/s)":106.0,
        "Reserved Memory (MB)":566,
        "Used Memory (MB)":2027
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.02 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00969,
        "Decode Throughput (tokens\/s)":107.0,
        "Allocated Memory (MB)":458,
        "Energy (tokens\/kWh)":1536098,
        "E2E Latency (s)":2.4,
        "E2E Throughput (tokens\/s)":107.0,
        "Reserved Memory (MB)":509,
        "Used Memory (MB)":1969
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.02*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00975,
        "Decode Throughput (tokens\/s)":106.0,
        "Allocated Memory (MB)":320,
        "Energy (tokens\/kWh)":1697792,
        "E2E Latency (s)":2.42,
        "E2E Throughput (tokens\/s)":106.0,
        "Reserved Memory (MB)":377,
        "Used Memory (MB)":1839
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.02 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0103,
        "Decode Throughput (tokens\/s)":108.0,
        "Allocated Memory (MB)":828,
        "Energy (tokens\/kWh)":1628664,
        "E2E Latency (s)":2.37,
        "E2E Throughput (tokens\/s)":108.0,
        "Reserved Memory (MB)":903,
        "Used Memory (MB)":2355
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.02*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0103,
        "Decode Throughput (tokens\/s)":103.0,
        "Allocated Memory (MB)":315,
        "Energy (tokens\/kWh)":1562500,
        "E2E Latency (s)":2.49,
        "E2E Throughput (tokens\/s)":103.0,
        "Reserved Memory (MB)":392,
        "Used Memory (MB)":1851
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.02*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0105,
        "Decode Throughput (tokens\/s)":92.4,
        "Allocated Memory (MB)":315,
        "Energy (tokens\/kWh)":1470588,
        "E2E Latency (s)":2.77,
        "E2E Throughput (tokens\/s)":92.4,
        "Reserved Memory (MB)":392,
        "Used Memory (MB)":1851
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.02*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0163,
        "Decode Throughput (tokens\/s)":68.9,
        "Allocated Memory (MB)":320,
        "Energy (tokens\/kWh)":1064962,
        "E2E Latency (s)":3.72,
        "E2E Throughput (tokens\/s)":68.8,
        "Reserved Memory (MB)":381,
        "Used Memory (MB)":1841
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.02*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0179,
        "Decode Throughput (tokens\/s)":65.9,
        "Allocated Memory (MB)":320,
        "Energy (tokens\/kWh)":1036269,
        "E2E Latency (s)":3.89,
        "E2E Throughput (tokens\/s)":65.8,
        "Reserved Memory (MB)":381,
        "Used Memory (MB)":1841
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.02*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.018,
        "Decode Throughput (tokens\/s)":82.8,
        "Allocated Memory (MB)":317,
        "Energy (tokens\/kWh)":1383125,
        "E2E Latency (s)":3.1,
        "E2E Throughput (tokens\/s)":82.6,
        "Reserved Memory (MB)":379,
        "Used Memory (MB)":1839
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.02*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.024,
        "Decode Throughput (tokens\/s)":40.1,
        "Allocated Memory (MB)":363,
        "Energy (tokens\/kWh)":625000,
        "E2E Latency (s)":6.38,
        "E2E Throughput (tokens\/s)":40.1,
        "Reserved Memory (MB)":415,
        "Used Memory (MB)":1883
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.02*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0256,
        "Decode Throughput (tokens\/s)":39.1,
        "Allocated Memory (MB)":363,
        "Energy (tokens\/kWh)":609756,
        "E2E Latency (s)":6.56,
        "E2E Throughput (tokens\/s)":39.0,
        "Reserved Memory (MB)":415,
        "Used Memory (MB)":1883
    },
    {
        "Model":"chargoddard\/SmolLlamix-8x101M",
        "Arch":"\u24c2\ufe0f Mixtral",
        "Params (B)":0.4,
        "Open LLM Score (%)":"28.98 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0248,
        "Decode Throughput (tokens\/s)":77.0,
        "Allocated Memory (MB)":895,
        "Energy (tokens\/kWh)":1222493,
        "E2E Latency (s)":3.33,
        "E2E Throughput (tokens\/s)":76.9,
        "Reserved Memory (MB)":945,
        "Used Memory (MB)":2405
    },
    {
        "Model":"chargoddard\/SmolLlamix-8x101M",
        "Arch":"\u24c2\ufe0f Mixtral",
        "Params (B)":0.4,
        "Open LLM Score (%)":"28.98 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0252,
        "Decode Throughput (tokens\/s)":82.5,
        "Allocated Memory (MB)":1697,
        "Energy (tokens\/kWh)":1349527,
        "E2E Latency (s)":3.12,
        "E2E Throughput (tokens\/s)":82.1,
        "Reserved Memory (MB)":1895,
        "Used Memory (MB)":3347
    },
    {
        "Model":"chargoddard\/SmolLlamix-8x101M",
        "Arch":"\u24c2\ufe0f Mixtral",
        "Params (B)":0.4,
        "Open LLM Score (%)":"28.98 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0255,
        "Decode Throughput (tokens\/s)":76.8,
        "Allocated Memory (MB)":895,
        "Energy (tokens\/kWh)":1184834,
        "E2E Latency (s)":3.35,
        "E2E Throughput (tokens\/s)":76.4,
        "Reserved Memory (MB)":945,
        "Used Memory (MB)":2405
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-101M-GQA",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.97 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00491,
        "Decode Throughput (tokens\/s)":192.0,
        "Allocated Memory (MB)":269,
        "Energy (tokens\/kWh)":3048780,
        "E2E Latency (s)":1.33,
        "E2E Throughput (tokens\/s)":192.0,
        "Reserved Memory (MB)":291,
        "Used Memory (MB)":1751
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-101M-GQA",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.97 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00495,
        "Decode Throughput (tokens\/s)":185.0,
        "Allocated Memory (MB)":269,
        "Energy (tokens\/kWh)":3012048,
        "E2E Latency (s)":1.38,
        "E2E Throughput (tokens\/s)":186.0,
        "Reserved Memory (MB)":293,
        "Used Memory (MB)":1753
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-101M-GQA",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.97 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00517,
        "Decode Throughput (tokens\/s)":181.0,
        "Allocated Memory (MB)":269,
        "Energy (tokens\/kWh)":2777777,
        "E2E Latency (s)":1.42,
        "E2E Throughput (tokens\/s)":180.0,
        "Reserved Memory (MB)":293,
        "Used Memory (MB)":1753
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-101M-GQA",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.97*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.00559,
        "Decode Throughput (tokens\/s)":177.0,
        "Allocated Memory (MB)":190,
        "Energy (tokens\/kWh)":2816901,
        "E2E Latency (s)":1.45,
        "E2E Throughput (tokens\/s)":177.0,
        "Reserved Memory (MB)":213,
        "Used Memory (MB)":1673
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-101M-GQA",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.97*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00567,
        "Decode Throughput (tokens\/s)":173.0,
        "Allocated Memory (MB)":396,
        "Energy (tokens\/kWh)":2793296,
        "E2E Latency (s)":1.48,
        "E2E Throughput (tokens\/s)":173.0,
        "Reserved Memory (MB)":417,
        "Used Memory (MB)":1879
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-101M-GQA",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.97*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.00567,
        "Decode Throughput (tokens\/s)":158.0,
        "Allocated Memory (MB)":189,
        "Energy (tokens\/kWh)":2386634,
        "E2E Latency (s)":1.62,
        "E2E Throughput (tokens\/s)":158.0,
        "Reserved Memory (MB)":213,
        "Used Memory (MB)":1673
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-101M-GQA",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.97 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00572,
        "Decode Throughput (tokens\/s)":199.0,
        "Allocated Memory (MB)":456,
        "Energy (tokens\/kWh)":3021148,
        "E2E Latency (s)":1.29,
        "E2E Throughput (tokens\/s)":198.0,
        "Reserved Memory (MB)":513,
        "Used Memory (MB)":1964
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-101M-GQA",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.97*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00598,
        "Decode Throughput (tokens\/s)":170.0,
        "Allocated Memory (MB)":195,
        "Energy (tokens\/kWh)":2702702,
        "E2E Latency (s)":1.51,
        "E2E Throughput (tokens\/s)":170.0,
        "Reserved Memory (MB)":209,
        "Used Memory (MB)":1671
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-101M-GQA",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.97*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0113,
        "Decode Throughput (tokens\/s)":112.0,
        "Allocated Memory (MB)":192,
        "Energy (tokens\/kWh)":1715265,
        "E2E Latency (s)":2.28,
        "E2E Throughput (tokens\/s)":112.0,
        "Reserved Memory (MB)":213,
        "Used Memory (MB)":1673
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-101M-GQA",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.97*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0114,
        "Decode Throughput (tokens\/s)":110.0,
        "Allocated Memory (MB)":192,
        "Energy (tokens\/kWh)":1703577,
        "E2E Latency (s)":2.33,
        "E2E Throughput (tokens\/s)":110.0,
        "Reserved Memory (MB)":216,
        "Used Memory (MB)":1675
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-101M-GQA",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.97*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0126,
        "Decode Throughput (tokens\/s)":130.0,
        "Allocated Memory (MB)":190,
        "Energy (tokens\/kWh)":2079002,
        "E2E Latency (s)":1.97,
        "E2E Throughput (tokens\/s)":130.0,
        "Reserved Memory (MB)":213,
        "Used Memory (MB)":1673
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-101M-GQA",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.97*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0185,
        "Decode Throughput (tokens\/s)":53.8,
        "Allocated Memory (MB)":214,
        "Energy (tokens\/kWh)":826446,
        "E2E Latency (s)":4.76,
        "E2E Throughput (tokens\/s)":53.8,
        "Reserved Memory (MB)":234,
        "Used Memory (MB)":1702
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-101M-GQA",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.97*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.019,
        "Decode Throughput (tokens\/s)":51.1,
        "Allocated Memory (MB)":214,
        "Energy (tokens\/kWh)":813008,
        "E2E Latency (s)":5.01,
        "E2E Throughput (tokens\/s)":51.1,
        "Reserved Memory (MB)":236,
        "Used Memory (MB)":1704
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"GPT-NeoX",
        "Params (B)":0.0,
        "Open LLM Score (%)":"28.88 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0155,
        "Decode Throughput (tokens\/s)":63.4,
        "Allocated Memory (MB)":1976,
        "Energy (tokens\/kWh)":952380,
        "E2E Latency (s)":4.04,
        "E2E Throughput (tokens\/s)":63.4,
        "Reserved Memory (MB)":2113,
        "Used Memory (MB)":3573
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"GPT-NeoX",
        "Params (B)":0.0,
        "Open LLM Score (%)":"28.88 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0173,
        "Decode Throughput (tokens\/s)":58.1,
        "Allocated Memory (MB)":1976,
        "Energy (tokens\/kWh)":854700,
        "E2E Latency (s)":4.41,
        "E2E Throughput (tokens\/s)":58.0,
        "Reserved Memory (MB)":2113,
        "Used Memory (MB)":3573
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"GPT-NeoX",
        "Params (B)":0.0,
        "Open LLM Score (%)":"28.88*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0191,
        "Decode Throughput (tokens\/s)":55.0,
        "Allocated Memory (MB)":1387,
        "Energy (tokens\/kWh)":869565,
        "E2E Latency (s)":4.66,
        "E2E Throughput (tokens\/s)":54.9,
        "Reserved Memory (MB)":1522,
        "Used Memory (MB)":2984
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"GPT-NeoX",
        "Params (B)":0.0,
        "Open LLM Score (%)":"28.88 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0196,
        "Decode Throughput (tokens\/s)":50.4,
        "Allocated Memory (MB)":1976,
        "Energy (tokens\/kWh)":806451,
        "E2E Latency (s)":5.08,
        "E2E Throughput (tokens\/s)":50.4,
        "Reserved Memory (MB)":2113,
        "Used Memory (MB)":3573
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"GPT-NeoX",
        "Params (B)":0.0,
        "Open LLM Score (%)":"28.88*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.02,
        "Decode Throughput (tokens\/s)":53.8,
        "Allocated Memory (MB)":968,
        "Energy (tokens\/kWh)":819672,
        "E2E Latency (s)":4.76,
        "E2E Throughput (tokens\/s)":53.8,
        "Reserved Memory (MB)":1098,
        "Used Memory (MB)":2558
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"GPT-NeoX",
        "Params (B)":0.0,
        "Open LLM Score (%)":"28.88 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.02,
        "Decode Throughput (tokens\/s)":52.4,
        "Allocated Memory (MB)":1976,
        "Energy (tokens\/kWh)":769230,
        "E2E Latency (s)":4.89,
        "E2E Throughput (tokens\/s)":52.4,
        "Reserved Memory (MB)":2113,
        "Used Memory (MB)":3573
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"GPT-NeoX",
        "Params (B)":0.0,
        "Open LLM Score (%)":"28.88*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0201,
        "Decode Throughput (tokens\/s)":49.8,
        "Allocated Memory (MB)":965,
        "Energy (tokens\/kWh)":724637,
        "E2E Latency (s)":5.14,
        "E2E Throughput (tokens\/s)":49.8,
        "Reserved Memory (MB)":1096,
        "Used Memory (MB)":2556
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"GPT-NeoX",
        "Params (B)":0.0,
        "Open LLM Score (%)":"28.88*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0204,
        "Decode Throughput (tokens\/s)":54.5,
        "Allocated Memory (MB)":983,
        "Energy (tokens\/kWh)":833333,
        "E2E Latency (s)":4.7,
        "E2E Throughput (tokens\/s)":54.5,
        "Reserved Memory (MB)":1115,
        "Used Memory (MB)":2577
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"GPT-NeoX",
        "Params (B)":0.0,
        "Open LLM Score (%)":"28.88 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0353,
        "Decode Throughput (tokens\/s)":53.9,
        "Allocated Memory (MB)":3836,
        "Energy (tokens\/kWh)":746268,
        "E2E Latency (s)":4.77,
        "E2E Throughput (tokens\/s)":53.7,
        "Reserved Memory (MB)":3915,
        "Used Memory (MB)":5366
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"GPT-NeoX",
        "Params (B)":0.0,
        "Open LLM Score (%)":"28.88*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0361,
        "Decode Throughput (tokens\/s)":44.5,
        "Allocated Memory (MB)":962,
        "Energy (tokens\/kWh)":694444,
        "E2E Latency (s)":5.77,
        "E2E Throughput (tokens\/s)":44.4,
        "Reserved Memory (MB)":1090,
        "Used Memory (MB)":2550
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"GPT-NeoX",
        "Params (B)":0.0,
        "Open LLM Score (%)":"28.88*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0425,
        "Decode Throughput (tokens\/s)":36.0,
        "Allocated Memory (MB)":998,
        "Energy (tokens\/kWh)":537634,
        "E2E Latency (s)":7.13,
        "E2E Throughput (tokens\/s)":35.9,
        "Reserved Memory (MB)":1124,
        "Used Memory (MB)":2583
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"GPT-NeoX",
        "Params (B)":0.0,
        "Open LLM Score (%)":"28.88*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0444,
        "Decode Throughput (tokens\/s)":33.3,
        "Allocated Memory (MB)":998,
        "Energy (tokens\/kWh)":510204,
        "E2E Latency (s)":7.7,
        "E2E Throughput (tokens\/s)":33.2,
        "Reserved Memory (MB)":1124,
        "Used Memory (MB)":2583
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"GPT-NeoX",
        "Params (B)":0.0,
        "Open LLM Score (%)":"28.88*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0483,
        "Decode Throughput (tokens\/s)":20.1,
        "Allocated Memory (MB)":1305,
        "Energy (tokens\/kWh)":311526,
        "E2E Latency (s)":12.7,
        "E2E Throughput (tokens\/s)":20.2,
        "Reserved Memory (MB)":1440,
        "Used Memory (MB)":2908
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"GPT-NeoX",
        "Params (B)":0.0,
        "Open LLM Score (%)":"28.88*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0507,
        "Decode Throughput (tokens\/s)":19.8,
        "Allocated Memory (MB)":1303,
        "Energy (tokens\/kWh)":310559,
        "E2E Latency (s)":13.0,
        "E2E Throughput (tokens\/s)":19.7,
        "Reserved Memory (MB)":1442,
        "Used Memory (MB)":2910
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.85 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00389,
        "Decode Throughput (tokens\/s)":245.0,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":4032258,
        "E2E Latency (s)":1.04,
        "E2E Throughput (tokens\/s)":246.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1602
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.85 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00413,
        "Decode Throughput (tokens\/s)":224.0,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3571428,
        "E2E Latency (s)":1.14,
        "E2E Throughput (tokens\/s)":225.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1602
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.85 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00474,
        "Decode Throughput (tokens\/s)":204.0,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3225806,
        "E2E Latency (s)":1.25,
        "E2E Throughput (tokens\/s)":205.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1602
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.85*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00493,
        "Decode Throughput (tokens\/s)":201.0,
        "Allocated Memory (MB)":186,
        "Energy (tokens\/kWh)":3300330,
        "E2E Latency (s)":1.27,
        "E2E Throughput (tokens\/s)":202.0,
        "Reserved Memory (MB)":205,
        "Used Memory (MB)":1667
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.85 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00494,
        "Decode Throughput (tokens\/s)":206.0,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3436426,
        "E2E Latency (s)":1.24,
        "E2E Throughput (tokens\/s)":206.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1602
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.85*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.005,
        "Decode Throughput (tokens\/s)":199.0,
        "Allocated Memory (MB)":119,
        "Energy (tokens\/kWh)":3184713,
        "E2E Latency (s)":1.28,
        "E2E Throughput (tokens\/s)":200.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1597
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.85 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0051,
        "Decode Throughput (tokens\/s)":204.0,
        "Allocated Memory (MB)":221,
        "Energy (tokens\/kWh)":3225806,
        "E2E Latency (s)":1.26,
        "E2E Throughput (tokens\/s)":203.0,
        "Reserved Memory (MB)":234,
        "Used Memory (MB)":1686
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.85*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.00513,
        "Decode Throughput (tokens\/s)":185.0,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2801120,
        "E2E Latency (s)":1.39,
        "E2E Throughput (tokens\/s)":184.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1595
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.85*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.00515,
        "Decode Throughput (tokens\/s)":196.0,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2906976,
        "E2E Latency (s)":1.31,
        "E2E Throughput (tokens\/s)":195.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1595
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.85*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.00875,
        "Decode Throughput (tokens\/s)":163.0,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2645502,
        "E2E Latency (s)":1.57,
        "E2E Throughput (tokens\/s)":163.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1595
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.85*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00893,
        "Decode Throughput (tokens\/s)":131.0,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2066115,
        "E2E Latency (s)":1.96,
        "E2E Throughput (tokens\/s)":131.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1595
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.85*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0092,
        "Decode Throughput (tokens\/s)":126.0,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2016129,
        "E2E Latency (s)":2.03,
        "E2E Throughput (tokens\/s)":126.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1595
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.85*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0123,
        "Decode Throughput (tokens\/s)":79.7,
        "Allocated Memory (MB)":121,
        "Energy (tokens\/kWh)":1251564,
        "E2E Latency (s)":3.21,
        "E2E Throughput (tokens\/s)":79.8,
        "Reserved Memory (MB)":138,
        "Used Memory (MB)":1606
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.85*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0131,
        "Decode Throughput (tokens\/s)":73.5,
        "Allocated Memory (MB)":121,
        "Energy (tokens\/kWh)":1189060,
        "E2E Latency (s)":3.48,
        "E2E Throughput (tokens\/s)":73.6,
        "Reserved Memory (MB)":138,
        "Used Memory (MB)":1606
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.81 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0041,
        "Decode Throughput (tokens\/s)":238.0,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3937007,
        "E2E Latency (s)":1.07,
        "E2E Throughput (tokens\/s)":239.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1602
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.81 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00417,
        "Decode Throughput (tokens\/s)":224.0,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3508771,
        "E2E Latency (s)":1.14,
        "E2E Throughput (tokens\/s)":225.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1602
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.81 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00468,
        "Decode Throughput (tokens\/s)":209.0,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3484320,
        "E2E Latency (s)":1.22,
        "E2E Throughput (tokens\/s)":210.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1602
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.81 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0048,
        "Decode Throughput (tokens\/s)":204.0,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3267973,
        "E2E Latency (s)":1.25,
        "E2E Throughput (tokens\/s)":205.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1602
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.81*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00483,
        "Decode Throughput (tokens\/s)":206.0,
        "Allocated Memory (MB)":186,
        "Energy (tokens\/kWh)":3289473,
        "E2E Latency (s)":1.24,
        "E2E Throughput (tokens\/s)":206.0,
        "Reserved Memory (MB)":205,
        "Used Memory (MB)":1667
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.81*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00516,
        "Decode Throughput (tokens\/s)":202.0,
        "Allocated Memory (MB)":119,
        "Energy (tokens\/kWh)":3184713,
        "E2E Latency (s)":1.27,
        "E2E Throughput (tokens\/s)":202.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1597
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.81 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00526,
        "Decode Throughput (tokens\/s)":202.0,
        "Allocated Memory (MB)":221,
        "Energy (tokens\/kWh)":3205128,
        "E2E Latency (s)":1.27,
        "E2E Throughput (tokens\/s)":202.0,
        "Reserved Memory (MB)":234,
        "Used Memory (MB)":1686
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.81*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0053,
        "Decode Throughput (tokens\/s)":195.0,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2949852,
        "E2E Latency (s)":1.32,
        "E2E Throughput (tokens\/s)":194.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1595
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.81*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.00552,
        "Decode Throughput (tokens\/s)":176.0,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2710027,
        "E2E Latency (s)":1.46,
        "E2E Throughput (tokens\/s)":175.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1595
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.81*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.00875,
        "Decode Throughput (tokens\/s)":166.0,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2702702,
        "E2E Latency (s)":1.55,
        "E2E Throughput (tokens\/s)":165.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1595
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.81*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00877,
        "Decode Throughput (tokens\/s)":131.0,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2092050,
        "E2E Latency (s)":1.95,
        "E2E Throughput (tokens\/s)":131.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1595
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.81*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00906,
        "Decode Throughput (tokens\/s)":126.0,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2032520,
        "E2E Latency (s)":2.03,
        "E2E Throughput (tokens\/s)":126.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1595
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.81*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0123,
        "Decode Throughput (tokens\/s)":78.0,
        "Allocated Memory (MB)":121,
        "Energy (tokens\/kWh)":1197604,
        "E2E Latency (s)":3.28,
        "E2E Throughput (tokens\/s)":78.0,
        "Reserved Memory (MB)":138,
        "Used Memory (MB)":1606
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.81*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0127,
        "Decode Throughput (tokens\/s)":75.9,
        "Allocated Memory (MB)":121,
        "Energy (tokens\/kWh)":1213592,
        "E2E Latency (s)":3.37,
        "E2E Throughput (tokens\/s)":76.0,
        "Reserved Memory (MB)":138,
        "Used Memory (MB)":1606
    },
    {
        "Model":"Locutusque\/TinyMistral-248M-v2",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":0.25,
        "Open LLM Score (%)":"28.78 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0113,
        "Decode Throughput (tokens\/s)":87.3,
        "Allocated Memory (MB)":608,
        "Energy (tokens\/kWh)":1356852,
        "E2E Latency (s)":2.93,
        "E2E Throughput (tokens\/s)":87.4,
        "Reserved Memory (MB)":660,
        "Used Memory (MB)":2120
    },
    {
        "Model":"Locutusque\/TinyMistral-248M-v2",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":0.25,
        "Open LLM Score (%)":"28.78 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0114,
        "Decode Throughput (tokens\/s)":88.2,
        "Allocated Memory (MB)":608,
        "Energy (tokens\/kWh)":1356852,
        "E2E Latency (s)":2.9,
        "E2E Throughput (tokens\/s)":88.3,
        "Reserved Memory (MB)":656,
        "Used Memory (MB)":2116
    },
    {
        "Model":"Locutusque\/TinyMistral-248M-v2",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":0.25,
        "Open LLM Score (%)":"28.78 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0128,
        "Decode Throughput (tokens\/s)":95.5,
        "Allocated Memory (MB)":1153,
        "Energy (tokens\/kWh)":1412429,
        "E2E Latency (s)":2.68,
        "E2E Throughput (tokens\/s)":95.5,
        "Reserved Memory (MB)":1199,
        "Used Memory (MB)":2650
    },
    {
        "Model":"Locutusque\/TinyMistral-248M-v2",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":0.25,
        "Open LLM Score (%)":"28.78*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0128,
        "Decode Throughput (tokens\/s)":85.9,
        "Allocated Memory (MB)":338,
        "Energy (tokens\/kWh)":1290322,
        "E2E Latency (s)":2.98,
        "E2E Throughput (tokens\/s)":85.9,
        "Reserved Memory (MB)":371,
        "Used Memory (MB)":1830
    },
    {
        "Model":"Locutusque\/TinyMistral-248M-v2",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":0.25,
        "Open LLM Score (%)":"28.78*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.013,
        "Decode Throughput (tokens\/s)":76.6,
        "Allocated Memory (MB)":338,
        "Energy (tokens\/kWh)":1169590,
        "E2E Latency (s)":3.34,
        "E2E Throughput (tokens\/s)":76.6,
        "Reserved Memory (MB)":371,
        "Used Memory (MB)":1830
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.06,
        "Open LLM Score (%)":"28.70 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00452,
        "Decode Throughput (tokens\/s)":196.0,
        "Allocated Memory (MB)":180,
        "Energy (tokens\/kWh)":3215434,
        "E2E Latency (s)":1.3,
        "E2E Throughput (tokens\/s)":197.0,
        "Reserved Memory (MB)":209,
        "Used Memory (MB)":1669
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.06,
        "Open LLM Score (%)":"28.70 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00474,
        "Decode Throughput (tokens\/s)":190.0,
        "Allocated Memory (MB)":180,
        "Energy (tokens\/kWh)":2881844,
        "E2E Latency (s)":1.34,
        "E2E Throughput (tokens\/s)":191.0,
        "Reserved Memory (MB)":209,
        "Used Memory (MB)":1669
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.06,
        "Open LLM Score (%)":"28.70 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00483,
        "Decode Throughput (tokens\/s)":190.0,
        "Allocated Memory (MB)":180,
        "Energy (tokens\/kWh)":3134796,
        "E2E Latency (s)":1.34,
        "E2E Throughput (tokens\/s)":191.0,
        "Reserved Memory (MB)":209,
        "Used Memory (MB)":1669
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.06,
        "Open LLM Score (%)":"28.70 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00484,
        "Decode Throughput (tokens\/s)":204.0,
        "Allocated Memory (MB)":288,
        "Energy (tokens\/kWh)":3215434,
        "E2E Latency (s)":1.25,
        "E2E Throughput (tokens\/s)":205.0,
        "Reserved Memory (MB)":327,
        "Used Memory (MB)":1778
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.06,
        "Open LLM Score (%)":"28.70*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00523,
        "Decode Throughput (tokens\/s)":186.0,
        "Allocated Memory (MB)":279,
        "Energy (tokens\/kWh)":3021148,
        "E2E Latency (s)":1.38,
        "E2E Throughput (tokens\/s)":186.0,
        "Reserved Memory (MB)":308,
        "Used Memory (MB)":1769
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.06,
        "Open LLM Score (%)":"28.70*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.00526,
        "Decode Throughput (tokens\/s)":189.0,
        "Allocated Memory (MB)":143,
        "Energy (tokens\/kWh)":2941176,
        "E2E Latency (s)":1.36,
        "E2E Throughput (tokens\/s)":188.0,
        "Reserved Memory (MB)":169,
        "Used Memory (MB)":1629
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.06,
        "Open LLM Score (%)":"28.70*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.00528,
        "Decode Throughput (tokens\/s)":175.0,
        "Allocated Memory (MB)":143,
        "Energy (tokens\/kWh)":2710027,
        "E2E Latency (s)":1.47,
        "E2E Throughput (tokens\/s)":174.0,
        "Reserved Memory (MB)":169,
        "Used Memory (MB)":1629
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.06,
        "Open LLM Score (%)":"28.70*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00533,
        "Decode Throughput (tokens\/s)":185.0,
        "Allocated Memory (MB)":145,
        "Energy (tokens\/kWh)":2865329,
        "E2E Latency (s)":1.39,
        "E2E Throughput (tokens\/s)":184.0,
        "Reserved Memory (MB)":167,
        "Used Memory (MB)":1629
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.06,
        "Open LLM Score (%)":"28.70*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.011,
        "Decode Throughput (tokens\/s)":113.0,
        "Allocated Memory (MB)":144,
        "Energy (tokens\/kWh)":1727115,
        "E2E Latency (s)":2.26,
        "E2E Throughput (tokens\/s)":113.0,
        "Reserved Memory (MB)":169,
        "Used Memory (MB)":1629
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.06,
        "Open LLM Score (%)":"28.70*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0114,
        "Decode Throughput (tokens\/s)":107.0,
        "Allocated Memory (MB)":144,
        "Energy (tokens\/kWh)":1718213,
        "E2E Latency (s)":2.39,
        "E2E Throughput (tokens\/s)":107.0,
        "Reserved Memory (MB)":169,
        "Used Memory (MB)":1629
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.06,
        "Open LLM Score (%)":"28.70*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0115,
        "Decode Throughput (tokens\/s)":139.0,
        "Allocated Memory (MB)":143,
        "Energy (tokens\/kWh)":2262443,
        "E2E Latency (s)":1.85,
        "E2E Throughput (tokens\/s)":138.0,
        "Reserved Memory (MB)":169,
        "Used Memory (MB)":1629
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.06,
        "Open LLM Score (%)":"28.70*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0186,
        "Decode Throughput (tokens\/s)":53.2,
        "Allocated Memory (MB)":155,
        "Energy (tokens\/kWh)":840336,
        "E2E Latency (s)":4.81,
        "E2E Throughput (tokens\/s)":53.2,
        "Reserved Memory (MB)":182,
        "Used Memory (MB)":1650
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.06,
        "Open LLM Score (%)":"28.70*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0191,
        "Decode Throughput (tokens\/s)":52.6,
        "Allocated Memory (MB)":155,
        "Energy (tokens\/kWh)":813008,
        "E2E Latency (s)":4.87,
        "E2E Throughput (tokens\/s)":52.6,
        "Reserved Memory (MB)":182,
        "Used Memory (MB)":1650
    },
    {
        "Model":"RWKV\/rwkv-4-169m-pile",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":0.17,
        "Open LLM Score (%)":"28.64 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0126,
        "Decode Throughput (tokens\/s)":78.5,
        "Allocated Memory (MB)":381,
        "Energy (tokens\/kWh)":1210653,
        "E2E Latency (s)":3.26,
        "E2E Throughput (tokens\/s)":78.5,
        "Reserved Memory (MB)":398,
        "Used Memory (MB)":1858
    },
    {
        "Model":"RWKV\/rwkv-4-169m-pile",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":0.17,
        "Open LLM Score (%)":"28.64 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.013,
        "Decode Throughput (tokens\/s)":78.5,
        "Allocated Memory (MB)":381,
        "Energy (tokens\/kWh)":1280409,
        "E2E Latency (s)":3.26,
        "E2E Throughput (tokens\/s)":78.5,
        "Reserved Memory (MB)":400,
        "Used Memory (MB)":1860
    },
    {
        "Model":"RWKV\/rwkv-4-169m-pile",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":0.17,
        "Open LLM Score (%)":"28.64 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0137,
        "Decode Throughput (tokens\/s)":80.2,
        "Allocated Memory (MB)":740,
        "Energy (tokens\/kWh)":1226993,
        "E2E Latency (s)":3.19,
        "E2E Throughput (tokens\/s)":80.3,
        "Reserved Memory (MB)":815,
        "Used Memory (MB)":2266
    },
    {
        "Model":"RWKV\/rwkv-4-169m-pile",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":0.17,
        "Open LLM Score (%)":"28.64*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0274,
        "Decode Throughput (tokens\/s)":45.9,
        "Allocated Memory (MB)":241,
        "Energy (tokens\/kWh)":719424,
        "E2E Latency (s)":5.59,
        "E2E Throughput (tokens\/s)":45.8,
        "Reserved Memory (MB)":276,
        "Used Memory (MB)":1736
    },
    {
        "Model":"RWKV\/rwkv-4-169m-pile",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":0.17,
        "Open LLM Score (%)":"28.64*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0411,
        "Decode Throughput (tokens\/s)":24.5,
        "Allocated Memory (MB)":283,
        "Energy (tokens\/kWh)":377358,
        "E2E Latency (s)":10.4,
        "E2E Throughput (tokens\/s)":24.6,
        "Reserved Memory (MB)":316,
        "Used Memory (MB)":1784
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.61 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00391,
        "Decode Throughput (tokens\/s)":243.0,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3937007,
        "E2E Latency (s)":1.05,
        "E2E Throughput (tokens\/s)":244.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1602
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.61 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00413,
        "Decode Throughput (tokens\/s)":218.0,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3401360,
        "E2E Latency (s)":1.17,
        "E2E Throughput (tokens\/s)":219.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1602
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.61 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00472,
        "Decode Throughput (tokens\/s)":207.0,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3436426,
        "E2E Latency (s)":1.23,
        "E2E Throughput (tokens\/s)":208.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1602
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.61*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00492,
        "Decode Throughput (tokens\/s)":199.0,
        "Allocated Memory (MB)":186,
        "Energy (tokens\/kWh)":3267973,
        "E2E Latency (s)":1.28,
        "E2E Throughput (tokens\/s)":200.0,
        "Reserved Memory (MB)":205,
        "Used Memory (MB)":1667
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.61*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00496,
        "Decode Throughput (tokens\/s)":201.0,
        "Allocated Memory (MB)":119,
        "Energy (tokens\/kWh)":3236245,
        "E2E Latency (s)":1.27,
        "E2E Throughput (tokens\/s)":202.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1597
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.61*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.00513,
        "Decode Throughput (tokens\/s)":195.0,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":3095975,
        "E2E Latency (s)":1.32,
        "E2E Throughput (tokens\/s)":194.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1595
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.61 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0053,
        "Decode Throughput (tokens\/s)":204.0,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3194888,
        "E2E Latency (s)":1.26,
        "E2E Throughput (tokens\/s)":203.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1602
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.61*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.00532,
        "Decode Throughput (tokens\/s)":183.0,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2865329,
        "E2E Latency (s)":1.4,
        "E2E Throughput (tokens\/s)":183.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1595
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.61 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00545,
        "Decode Throughput (tokens\/s)":207.0,
        "Allocated Memory (MB)":221,
        "Energy (tokens\/kWh)":3311258,
        "E2E Latency (s)":1.24,
        "E2E Throughput (tokens\/s)":206.0,
        "Reserved Memory (MB)":234,
        "Used Memory (MB)":1686
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.61*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00845,
        "Decode Throughput (tokens\/s)":133.0,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2061855,
        "E2E Latency (s)":1.93,
        "E2E Throughput (tokens\/s)":133.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1595
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.61*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.00881,
        "Decode Throughput (tokens\/s)":166.0,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2695417,
        "E2E Latency (s)":1.55,
        "E2E Throughput (tokens\/s)":165.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1595
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.61*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00917,
        "Decode Throughput (tokens\/s)":128.0,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2049180,
        "E2E Latency (s)":2.01,
        "E2E Throughput (tokens\/s)":127.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1595
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.61*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0125,
        "Decode Throughput (tokens\/s)":78.0,
        "Allocated Memory (MB)":121,
        "Energy (tokens\/kWh)":1226993,
        "E2E Latency (s)":3.28,
        "E2E Throughput (tokens\/s)":78.0,
        "Reserved Memory (MB)":138,
        "Used Memory (MB)":1606
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.61*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0127,
        "Decode Throughput (tokens\/s)":75.9,
        "Allocated Memory (MB)":121,
        "Energy (tokens\/kWh)":1183431,
        "E2E Latency (s)":3.37,
        "E2E Throughput (tokens\/s)":76.0,
        "Reserved Memory (MB)":138,
        "Used Memory (MB)":1606
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.60 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00387,
        "Decode Throughput (tokens\/s)":241.0,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":4065040,
        "E2E Latency (s)":1.06,
        "E2E Throughput (tokens\/s)":242.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1602
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.60 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00419,
        "Decode Throughput (tokens\/s)":220.0,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3472222,
        "E2E Latency (s)":1.16,
        "E2E Throughput (tokens\/s)":221.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1602
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.60 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0047,
        "Decode Throughput (tokens\/s)":207.0,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3472222,
        "E2E Latency (s)":1.23,
        "E2E Throughput (tokens\/s)":208.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1602
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.60 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00481,
        "Decode Throughput (tokens\/s)":204.0,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3278688,
        "E2E Latency (s)":1.25,
        "E2E Throughput (tokens\/s)":205.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1602
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.60*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00482,
        "Decode Throughput (tokens\/s)":204.0,
        "Allocated Memory (MB)":186,
        "Energy (tokens\/kWh)":3311258,
        "E2E Latency (s)":1.25,
        "E2E Throughput (tokens\/s)":205.0,
        "Reserved Memory (MB)":205,
        "Used Memory (MB)":1667
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.60*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00499,
        "Decode Throughput (tokens\/s)":198.0,
        "Allocated Memory (MB)":119,
        "Energy (tokens\/kWh)":3205128,
        "E2E Latency (s)":1.29,
        "E2E Throughput (tokens\/s)":198.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1597
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.60*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.00516,
        "Decode Throughput (tokens\/s)":193.0,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":3076923,
        "E2E Latency (s)":1.33,
        "E2E Throughput (tokens\/s)":192.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1595
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.60 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00545,
        "Decode Throughput (tokens\/s)":209.0,
        "Allocated Memory (MB)":221,
        "Energy (tokens\/kWh)":3278688,
        "E2E Latency (s)":1.23,
        "E2E Throughput (tokens\/s)":208.0,
        "Reserved Memory (MB)":234,
        "Used Memory (MB)":1686
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.60*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.00545,
        "Decode Throughput (tokens\/s)":182.0,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2881844,
        "E2E Latency (s)":1.41,
        "E2E Throughput (tokens\/s)":182.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1595
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.60*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00854,
        "Decode Throughput (tokens\/s)":134.0,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2150537,
        "E2E Latency (s)":1.91,
        "E2E Throughput (tokens\/s)":134.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1595
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.60*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.00893,
        "Decode Throughput (tokens\/s)":167.0,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2702702,
        "E2E Latency (s)":1.54,
        "E2E Throughput (tokens\/s)":166.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1595
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.60*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00917,
        "Decode Throughput (tokens\/s)":125.0,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2008032,
        "E2E Latency (s)":2.05,
        "E2E Throughput (tokens\/s)":125.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1595
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.60*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0121,
        "Decode Throughput (tokens\/s)":79.9,
        "Allocated Memory (MB)":121,
        "Energy (tokens\/kWh)":1261034,
        "E2E Latency (s)":3.2,
        "E2E Throughput (tokens\/s)":80.0,
        "Reserved Memory (MB)":138,
        "Used Memory (MB)":1606
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.60*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0128,
        "Decode Throughput (tokens\/s)":74.6,
        "Allocated Memory (MB)":121,
        "Energy (tokens\/kWh)":1201923,
        "E2E Latency (s)":3.43,
        "E2E Throughput (tokens\/s)":74.6,
        "Reserved Memory (MB)":138,
        "Used Memory (MB)":1606
    },
    {
        "Model":"gpt2",
        "Arch":"GPT-2",
        "Params (B)":0.14,
        "Open LLM Score (%)":"28.53 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00695,
        "Decode Throughput (tokens\/s)":131.0,
        "Allocated Memory (MB)":328,
        "Energy (tokens\/kWh)":1934235,
        "E2E Latency (s)":1.95,
        "E2E Throughput (tokens\/s)":131.0,
        "Reserved Memory (MB)":381,
        "Used Memory (MB)":1841
    },
    {
        "Model":"gpt2",
        "Arch":"GPT-2",
        "Params (B)":0.14,
        "Open LLM Score (%)":"28.53*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.00804,
        "Decode Throughput (tokens\/s)":121.0,
        "Allocated Memory (MB)":328,
        "Energy (tokens\/kWh)":1934235,
        "E2E Latency (s)":2.11,
        "E2E Throughput (tokens\/s)":121.0,
        "Reserved Memory (MB)":381,
        "Used Memory (MB)":1841
    },
    {
        "Model":"gpt2",
        "Arch":"GPT-2",
        "Params (B)":0.14,
        "Open LLM Score (%)":"28.53 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00807,
        "Decode Throughput (tokens\/s)":120.0,
        "Allocated Memory (MB)":328,
        "Energy (tokens\/kWh)":1953124,
        "E2E Latency (s)":2.13,
        "E2E Throughput (tokens\/s)":120.0,
        "Reserved Memory (MB)":381,
        "Used Memory (MB)":1841
    },
    {
        "Model":"gpt2",
        "Arch":"GPT-2",
        "Params (B)":0.14,
        "Open LLM Score (%)":"28.53 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00827,
        "Decode Throughput (tokens\/s)":118.0,
        "Allocated Memory (MB)":328,
        "Energy (tokens\/kWh)":1776198,
        "E2E Latency (s)":2.17,
        "E2E Throughput (tokens\/s)":118.0,
        "Reserved Memory (MB)":381,
        "Used Memory (MB)":1841
    },
    {
        "Model":"gpt2",
        "Arch":"GPT-2",
        "Params (B)":0.14,
        "Open LLM Score (%)":"28.53*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00859,
        "Decode Throughput (tokens\/s)":125.0,
        "Allocated Memory (MB)":200,
        "Energy (tokens\/kWh)":1992031,
        "E2E Latency (s)":2.05,
        "E2E Throughput (tokens\/s)":125.0,
        "Reserved Memory (MB)":270,
        "Used Memory (MB)":1732
    },
    {
        "Model":"gpt2",
        "Arch":"GPT-2",
        "Params (B)":0.14,
        "Open LLM Score (%)":"28.53*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.00867,
        "Decode Throughput (tokens\/s)":115.0,
        "Allocated Memory (MB)":328,
        "Energy (tokens\/kWh)":1876172,
        "E2E Latency (s)":2.23,
        "E2E Throughput (tokens\/s)":115.0,
        "Reserved Memory (MB)":381,
        "Used Memory (MB)":1841
    },
    {
        "Model":"gpt2",
        "Arch":"GPT-2",
        "Params (B)":0.14,
        "Open LLM Score (%)":"28.53 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00945,
        "Decode Throughput (tokens\/s)":120.0,
        "Allocated Memory (MB)":621,
        "Energy (tokens\/kWh)":1788908,
        "E2E Latency (s)":2.13,
        "E2E Throughput (tokens\/s)":120.0,
        "Reserved Memory (MB)":717,
        "Used Memory (MB)":2168
    },
    {
        "Model":"gpt2",
        "Arch":"GPT-2",
        "Params (B)":0.14,
        "Open LLM Score (%)":"28.53*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0161,
        "Decode Throughput (tokens\/s)":98.5,
        "Allocated Memory (MB)":197,
        "Energy (tokens\/kWh)":1584786,
        "E2E Latency (s)":2.61,
        "E2E Throughput (tokens\/s)":98.1,
        "Reserved Memory (MB)":270,
        "Used Memory (MB)":1730
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":1.12,
        "Open LLM Score (%)":"28.49 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00938,
        "Decode Throughput (tokens\/s)":97.3,
        "Allocated Memory (MB)":2329,
        "Energy (tokens\/kWh)":1344086,
        "E2E Latency (s)":2.63,
        "E2E Throughput (tokens\/s)":97.3,
        "Reserved Memory (MB)":2403,
        "Used Memory (MB)":3860
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":1.12,
        "Open LLM Score (%)":"28.49 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.011,
        "Decode Throughput (tokens\/s)":86.4,
        "Allocated Memory (MB)":2329,
        "Energy (tokens\/kWh)":1256281,
        "E2E Latency (s)":2.96,
        "E2E Throughput (tokens\/s)":86.5,
        "Reserved Memory (MB)":2403,
        "Used Memory (MB)":3862
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":1.12,
        "Open LLM Score (%)":"28.49*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0115,
        "Decode Throughput (tokens\/s)":93.4,
        "Allocated Memory (MB)":1395,
        "Energy (tokens\/kWh)":1468428,
        "E2E Latency (s)":2.74,
        "E2E Throughput (tokens\/s)":93.4,
        "Reserved Memory (MB)":1430,
        "Used Memory (MB)":2891
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":1.12,
        "Open LLM Score (%)":"28.49 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0117,
        "Decode Throughput (tokens\/s)":83.9,
        "Allocated Memory (MB)":2329,
        "Energy (tokens\/kWh)":1194743,
        "E2E Latency (s)":3.05,
        "E2E Throughput (tokens\/s)":83.9,
        "Reserved Memory (MB)":2403,
        "Used Memory (MB)":3862
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":1.12,
        "Open LLM Score (%)":"28.49*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0118,
        "Decode Throughput (tokens\/s)":91.1,
        "Allocated Memory (MB)":856,
        "Energy (tokens\/kWh)":1404494,
        "E2E Latency (s)":2.81,
        "E2E Throughput (tokens\/s)":91.1,
        "Reserved Memory (MB)":889,
        "Used Memory (MB)":2350
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":1.12,
        "Open LLM Score (%)":"28.49*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0144,
        "Decode Throughput (tokens\/s)":87.9,
        "Allocated Memory (MB)":838,
        "Energy (tokens\/kWh)":1293661,
        "E2E Latency (s)":2.91,
        "E2E Throughput (tokens\/s)":88.0,
        "Reserved Memory (MB)":859,
        "Used Memory (MB)":2319
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":1.12,
        "Open LLM Score (%)":"28.49*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0151,
        "Decode Throughput (tokens\/s)":79.2,
        "Allocated Memory (MB)":838,
        "Energy (tokens\/kWh)":1154734,
        "E2E Latency (s)":3.24,
        "E2E Throughput (tokens\/s)":79.0,
        "Reserved Memory (MB)":859,
        "Used Memory (MB)":2319
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":1.12,
        "Open LLM Score (%)":"28.49*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0306,
        "Decode Throughput (tokens\/s)":67.8,
        "Allocated Memory (MB)":890,
        "Energy (tokens\/kWh)":1007049,
        "E2E Latency (s)":3.79,
        "E2E Throughput (tokens\/s)":67.5,
        "Reserved Memory (MB)":912,
        "Used Memory (MB)":2371
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":1.12,
        "Open LLM Score (%)":"28.49*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0421,
        "Decode Throughput (tokens\/s)":23.8,
        "Allocated Memory (MB)":1312,
        "Energy (tokens\/kWh)":366300,
        "E2E Latency (s)":10.7,
        "E2E Throughput (tokens\/s)":23.9,
        "Reserved Memory (MB)":1356,
        "Used Memory (MB)":2822
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":1.12,
        "Open LLM Score (%)":"28.49*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0428,
        "Decode Throughput (tokens\/s)":23.4,
        "Allocated Memory (MB)":1311,
        "Energy (tokens\/kWh)":341296,
        "E2E Latency (s)":10.9,
        "E2E Throughput (tokens\/s)":23.5,
        "Reserved Memory (MB)":1369,
        "Used Memory (MB)":2837
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":1.12,
        "Open LLM Score (%)":"28.49*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0464,
        "Decode Throughput (tokens\/s)":48.7,
        "Allocated Memory (MB)":970,
        "Energy (tokens\/kWh)":689655,
        "E2E Latency (s)":5.29,
        "E2E Throughput (tokens\/s)":48.4,
        "Reserved Memory (MB)":991,
        "Used Memory (MB)":2449
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":1.12,
        "Open LLM Score (%)":"28.49*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0472,
        "Decode Throughput (tokens\/s)":47.0,
        "Allocated Memory (MB)":970,
        "Energy (tokens\/kWh)":689655,
        "E2E Latency (s)":5.48,
        "E2E Throughput (tokens\/s)":46.7,
        "Reserved Memory (MB)":991,
        "Used Memory (MB)":2451
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"\u2b50 StarCoder",
        "Params (B)":1.12,
        "Open LLM Score (%)":"28.49 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0476,
        "Decode Throughput (tokens\/s)":88.5,
        "Allocated Memory (MB)":4628,
        "Energy (tokens\/kWh)":1104972,
        "E2E Latency (s)":2.93,
        "E2E Throughput (tokens\/s)":87.4,
        "Reserved Memory (MB)":4708,
        "Used Memory (MB)":6159
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-126m",
        "Arch":"GPT-2",
        "Params (B)":0.19,
        "Open LLM Score (%)":"28.45 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00554,
        "Decode Throughput (tokens\/s)":155.0,
        "Allocated Memory (MB)":404,
        "Energy (tokens\/kWh)":2358490,
        "E2E Latency (s)":1.66,
        "E2E Throughput (tokens\/s)":154.0,
        "Reserved Memory (MB)":459,
        "Used Memory (MB)":1916
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-126m",
        "Arch":"GPT-2",
        "Params (B)":0.19,
        "Open LLM Score (%)":"28.45 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00673,
        "Decode Throughput (tokens\/s)":137.0,
        "Allocated Memory (MB)":404,
        "Energy (tokens\/kWh)":2109704,
        "E2E Latency (s)":1.87,
        "E2E Throughput (tokens\/s)":137.0,
        "Reserved Memory (MB)":459,
        "Used Memory (MB)":1916
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-126m",
        "Arch":"GPT-2",
        "Params (B)":0.19,
        "Open LLM Score (%)":"28.45 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00693,
        "Decode Throughput (tokens\/s)":139.0,
        "Allocated Memory (MB)":404,
        "Energy (tokens\/kWh)":2207505,
        "E2E Latency (s)":1.84,
        "E2E Throughput (tokens\/s)":139.0,
        "Reserved Memory (MB)":459,
        "Used Memory (MB)":1916
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-126m",
        "Arch":"GPT-2",
        "Params (B)":0.19,
        "Open LLM Score (%)":"28.45*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0071,
        "Decode Throughput (tokens\/s)":136.0,
        "Allocated Memory (MB)":392,
        "Energy (tokens\/kWh)":2136752,
        "E2E Latency (s)":1.88,
        "E2E Throughput (tokens\/s)":136.0,
        "Reserved Memory (MB)":461,
        "Used Memory (MB)":1918
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-126m",
        "Arch":"GPT-2",
        "Params (B)":0.19,
        "Open LLM Score (%)":"28.45*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.00715,
        "Decode Throughput (tokens\/s)":135.0,
        "Allocated Memory (MB)":392,
        "Energy (tokens\/kWh)":2024291,
        "E2E Latency (s)":1.9,
        "E2E Throughput (tokens\/s)":135.0,
        "Reserved Memory (MB)":461,
        "Used Memory (MB)":1918
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-126m",
        "Arch":"GPT-2",
        "Params (B)":0.19,
        "Open LLM Score (%)":"28.45*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00718,
        "Decode Throughput (tokens\/s)":143.0,
        "Allocated Memory (MB)":268,
        "Energy (tokens\/kWh)":2267573,
        "E2E Latency (s)":1.79,
        "E2E Throughput (tokens\/s)":143.0,
        "Reserved Memory (MB)":327,
        "Used Memory (MB)":1788
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-126m",
        "Arch":"GPT-2",
        "Params (B)":0.19,
        "Open LLM Score (%)":"28.45 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00813,
        "Decode Throughput (tokens\/s)":133.0,
        "Allocated Memory (MB)":721,
        "Energy (tokens\/kWh)":2057613,
        "E2E Latency (s)":1.93,
        "E2E Throughput (tokens\/s)":133.0,
        "Reserved Memory (MB)":803,
        "Used Memory (MB)":2254
    },
    {
        "Model":"AI-Sweden-Models\/gpt-sw3-126m",
        "Arch":"GPT-2",
        "Params (B)":0.19,
        "Open LLM Score (%)":"28.45*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0146,
        "Decode Throughput (tokens\/s)":109.0,
        "Allocated Memory (MB)":266,
        "Energy (tokens\/kWh)":1766784,
        "E2E Latency (s)":2.36,
        "E2E Throughput (tokens\/s)":108.0,
        "Reserved Memory (MB)":327,
        "Used Memory (MB)":1786
    },
    {
        "Model":"BEE-spoke-data\/Mixtral-GQA-400m-v2",
        "Arch":"\u24c2\ufe0f Mixtral",
        "Params (B)":2.01,
        "Open LLM Score (%)":"28.45 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0246,
        "Decode Throughput (tokens\/s)":79.9,
        "Allocated Memory (MB)":4083,
        "Energy (tokens\/kWh)":1161440,
        "E2E Latency (s)":3.21,
        "E2E Throughput (tokens\/s)":79.8,
        "Reserved Memory (MB)":4112,
        "Used Memory (MB)":5572
    },
    {
        "Model":"BEE-spoke-data\/Mixtral-GQA-400m-v2",
        "Arch":"\u24c2\ufe0f Mixtral",
        "Params (B)":2.01,
        "Open LLM Score (%)":"28.45 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0248,
        "Decode Throughput (tokens\/s)":78.2,
        "Allocated Memory (MB)":4083,
        "Energy (tokens\/kWh)":1160092,
        "E2E Latency (s)":3.28,
        "E2E Throughput (tokens\/s)":78.0,
        "Reserved Memory (MB)":4108,
        "Used Memory (MB)":5567
    },
    {
        "Model":"BEE-spoke-data\/Mixtral-GQA-400m-v2",
        "Arch":"\u24c2\ufe0f Mixtral",
        "Params (B)":2.01,
        "Open LLM Score (%)":"28.45 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0248,
        "Decode Throughput (tokens\/s)":75.9,
        "Allocated Memory (MB)":4083,
        "Energy (tokens\/kWh)":1118568,
        "E2E Latency (s)":3.38,
        "E2E Throughput (tokens\/s)":75.7,
        "Reserved Memory (MB)":4112,
        "Used Memory (MB)":5572
    },
    {
        "Model":"BEE-spoke-data\/Mixtral-GQA-400m-v2",
        "Arch":"\u24c2\ufe0f Mixtral",
        "Params (B)":2.01,
        "Open LLM Score (%)":"28.45*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0343,
        "Decode Throughput (tokens\/s)":29.6,
        "Allocated Memory (MB)":2211,
        "Energy (tokens\/kWh)":480769,
        "E2E Latency (s)":8.64,
        "E2E Throughput (tokens\/s)":29.6,
        "Reserved Memory (MB)":2241,
        "Used Memory (MB)":3709
    },
    {
        "Model":"BEE-spoke-data\/Mixtral-GQA-400m-v2",
        "Arch":"\u24c2\ufe0f Mixtral",
        "Params (B)":2.01,
        "Open LLM Score (%)":"28.45*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0361,
        "Decode Throughput (tokens\/s)":29.4,
        "Allocated Memory (MB)":2211,
        "Energy (tokens\/kWh)":454545,
        "E2E Latency (s)":8.7,
        "E2E Throughput (tokens\/s)":29.4,
        "Reserved Memory (MB)":2248,
        "Used Memory (MB)":3716
    },
    {
        "Model":"BEE-spoke-data\/Mixtral-GQA-400m-v2",
        "Arch":"\u24c2\ufe0f Mixtral",
        "Params (B)":2.01,
        "Open LLM Score (%)":"28.45*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0367,
        "Decode Throughput (tokens\/s)":54.5,
        "Allocated Memory (MB)":1429,
        "Energy (tokens\/kWh)":819672,
        "E2E Latency (s)":4.72,
        "E2E Throughput (tokens\/s)":54.2,
        "Reserved Memory (MB)":1568,
        "Used Memory (MB)":3028
    },
    {
        "Model":"BEE-spoke-data\/Mixtral-GQA-400m-v2",
        "Arch":"\u24c2\ufe0f Mixtral",
        "Params (B)":2.01,
        "Open LLM Score (%)":"28.45*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0372,
        "Decode Throughput (tokens\/s)":54.1,
        "Allocated Memory (MB)":1429,
        "Energy (tokens\/kWh)":806451,
        "E2E Latency (s)":4.75,
        "E2E Throughput (tokens\/s)":53.9,
        "Reserved Memory (MB)":1568,
        "Used Memory (MB)":3028
    },
    {
        "Model":"BEE-spoke-data\/Mixtral-GQA-400m-v2",
        "Arch":"\u24c2\ufe0f Mixtral",
        "Params (B)":2.01,
        "Open LLM Score (%)":"28.45 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0415,
        "Decode Throughput (tokens\/s)":84.2,
        "Allocated Memory (MB)":8095,
        "Energy (tokens\/kWh)":1218026,
        "E2E Latency (s)":3.07,
        "E2E Throughput (tokens\/s)":83.4,
        "Reserved Memory (MB)":8143,
        "Used Memory (MB)":9594
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.44 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00394,
        "Decode Throughput (tokens\/s)":238.0,
        "Allocated Memory (MB)":216,
        "Energy (tokens\/kWh)":3846153,
        "E2E Latency (s)":1.07,
        "E2E Throughput (tokens\/s)":239.0,
        "Reserved Memory (MB)":236,
        "Used Memory (MB)":1696
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.44 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00421,
        "Decode Throughput (tokens\/s)":220.0,
        "Allocated Memory (MB)":216,
        "Energy (tokens\/kWh)":3484320,
        "E2E Latency (s)":1.16,
        "E2E Throughput (tokens\/s)":221.0,
        "Reserved Memory (MB)":236,
        "Used Memory (MB)":1696
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.0,
        "Open LLM Score (%)":"28.44 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00443,
        "Decode Throughput (tokens\/s)":283.0,
        "Allocated Memory (MB)":2229,
        "Energy (tokens\/kWh)":3144654,
        "E2E Latency (s)":0.905,
        "E2E Throughput (tokens\/s)":283.0,
        "Reserved Memory (MB)":2250,
        "Used Memory (MB)":3709
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"GPT-Neo",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.44 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00444,
        "Decode Throughput (tokens\/s)":212.0,
        "Allocated Memory (MB)":182,
        "Energy (tokens\/kWh)":3412969,
        "E2E Latency (s)":1.2,
        "E2E Throughput (tokens\/s)":213.0,
        "Reserved Memory (MB)":222,
        "Used Memory (MB)":1681
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.0,
        "Open LLM Score (%)":"28.44 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00449,
        "Decode Throughput (tokens\/s)":268.0,
        "Allocated Memory (MB)":2229,
        "Energy (tokens\/kWh)":3086419,
        "E2E Latency (s)":0.956,
        "E2E Throughput (tokens\/s)":268.0,
        "Reserved Memory (MB)":2250,
        "Used Memory (MB)":3709
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.0,
        "Open LLM Score (%)":"28.44 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00458,
        "Decode Throughput (tokens\/s)":278.0,
        "Allocated Memory (MB)":2229,
        "Energy (tokens\/kWh)":3184713,
        "E2E Latency (s)":0.921,
        "E2E Throughput (tokens\/s)":278.0,
        "Reserved Memory (MB)":2250,
        "Used Memory (MB)":3709
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.44 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00476,
        "Decode Throughput (tokens\/s)":204.0,
        "Allocated Memory (MB)":216,
        "Energy (tokens\/kWh)":3355704,
        "E2E Latency (s)":1.25,
        "E2E Throughput (tokens\/s)":205.0,
        "Reserved Memory (MB)":236,
        "Used Memory (MB)":1696
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.44 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00486,
        "Decode Throughput (tokens\/s)":201.0,
        "Allocated Memory (MB)":216,
        "Energy (tokens\/kWh)":3154574,
        "E2E Latency (s)":1.27,
        "E2E Throughput (tokens\/s)":202.0,
        "Reserved Memory (MB)":236,
        "Used Memory (MB)":1696
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00492,
        "Decode Throughput (tokens\/s)":201.0,
        "Allocated Memory (MB)":321,
        "Energy (tokens\/kWh)":3205128,
        "E2E Latency (s)":1.27,
        "E2E Throughput (tokens\/s)":202.0,
        "Reserved Memory (MB)":339,
        "Used Memory (MB)":1801
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.005,
        "Decode Throughput (tokens\/s)":198.0,
        "Allocated Memory (MB)":186,
        "Energy (tokens\/kWh)":3184713,
        "E2E Latency (s)":1.29,
        "E2E Throughput (tokens\/s)":198.0,
        "Reserved Memory (MB)":201,
        "Used Memory (MB)":1662
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.00529,
        "Decode Throughput (tokens\/s)":181.0,
        "Allocated Memory (MB)":184,
        "Energy (tokens\/kWh)":2801120,
        "E2E Latency (s)":1.42,
        "E2E Throughput (tokens\/s)":180.0,
        "Reserved Memory (MB)":222,
        "Used Memory (MB)":1681
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"GPT-Neo",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.44 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00536,
        "Decode Throughput (tokens\/s)":177.0,
        "Allocated Memory (MB)":182,
        "Energy (tokens\/kWh)":2808988,
        "E2E Latency (s)":1.45,
        "E2E Throughput (tokens\/s)":177.0,
        "Reserved Memory (MB)":222,
        "Used Memory (MB)":1681
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.00545,
        "Decode Throughput (tokens\/s)":185.0,
        "Allocated Memory (MB)":184,
        "Energy (tokens\/kWh)":3058103,
        "E2E Latency (s)":1.39,
        "E2E Throughput (tokens\/s)":184.0,
        "Reserved Memory (MB)":222,
        "Used Memory (MB)":1681
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.0,
        "Open LLM Score (%)":"28.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00548,
        "Decode Throughput (tokens\/s)":265.0,
        "Allocated Memory (MB)":1128,
        "Energy (tokens\/kWh)":3558718,
        "E2E Latency (s)":0.968,
        "E2E Throughput (tokens\/s)":264.0,
        "Reserved Memory (MB)":1161,
        "Used Memory (MB)":2623
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.44 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00549,
        "Decode Throughput (tokens\/s)":207.0,
        "Allocated Memory (MB)":397,
        "Energy (tokens\/kWh)":3125000,
        "E2E Latency (s)":1.24,
        "E2E Throughput (tokens\/s)":206.0,
        "Reserved Memory (MB)":425,
        "Used Memory (MB)":1876
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.0,
        "Open LLM Score (%)":"28.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00559,
        "Decode Throughput (tokens\/s)":274.0,
        "Allocated Memory (MB)":1850,
        "Energy (tokens\/kWh)":3937007,
        "E2E Latency (s)":0.938,
        "E2E Throughput (tokens\/s)":273.0,
        "Reserved Memory (MB)":1885,
        "Used Memory (MB)":3347
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"GPT-Neo",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.44 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00584,
        "Decode Throughput (tokens\/s)":176.0,
        "Allocated Memory (MB)":182,
        "Energy (tokens\/kWh)":2898550,
        "E2E Latency (s)":1.46,
        "E2E Throughput (tokens\/s)":175.0,
        "Reserved Memory (MB)":222,
        "Used Memory (MB)":1681
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"GPT-Neo",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.44 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00608,
        "Decode Throughput (tokens\/s)":171.0,
        "Allocated Memory (MB)":182,
        "Energy (tokens\/kWh)":2688172,
        "E2E Latency (s)":1.5,
        "E2E Throughput (tokens\/s)":171.0,
        "Reserved Memory (MB)":222,
        "Used Memory (MB)":1681
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"GPT-Neo",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.44 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00613,
        "Decode Throughput (tokens\/s)":183.0,
        "Allocated Memory (MB)":320,
        "Energy (tokens\/kWh)":2688172,
        "E2E Latency (s)":1.4,
        "E2E Throughput (tokens\/s)":183.0,
        "Reserved Memory (MB)":356,
        "Used Memory (MB)":1807
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"GPT-Neo",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0064,
        "Decode Throughput (tokens\/s)":170.0,
        "Allocated Memory (MB)":146,
        "Energy (tokens\/kWh)":2659574,
        "E2E Latency (s)":1.51,
        "E2E Throughput (tokens\/s)":170.0,
        "Reserved Memory (MB)":178,
        "Used Memory (MB)":1639
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"GPT-Neo",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0065,
        "Decode Throughput (tokens\/s)":170.0,
        "Allocated Memory (MB)":281,
        "Energy (tokens\/kWh)":2710027,
        "E2E Latency (s)":1.51,
        "E2E Throughput (tokens\/s)":170.0,
        "Reserved Memory (MB)":316,
        "Used Memory (MB)":1778
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"GPT-Neo",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.00674,
        "Decode Throughput (tokens\/s)":151.0,
        "Allocated Memory (MB)":144,
        "Energy (tokens\/kWh)":2272727,
        "E2E Latency (s)":1.7,
        "E2E Throughput (tokens\/s)":151.0,
        "Reserved Memory (MB)":178,
        "Used Memory (MB)":1637
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"GPT-Neo",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.00684,
        "Decode Throughput (tokens\/s)":163.0,
        "Allocated Memory (MB)":144,
        "Energy (tokens\/kWh)":2638522,
        "E2E Latency (s)":1.57,
        "E2E Throughput (tokens\/s)":163.0,
        "Reserved Memory (MB)":178,
        "Used Memory (MB)":1637
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.0,
        "Open LLM Score (%)":"28.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.00827,
        "Decode Throughput (tokens\/s)":275.0,
        "Allocated Memory (MB)":1050,
        "Energy (tokens\/kWh)":3472222,
        "E2E Latency (s)":0.935,
        "E2E Throughput (tokens\/s)":274.0,
        "Reserved Memory (MB)":1088,
        "Used Memory (MB)":2548
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00834,
        "Decode Throughput (tokens\/s)":133.0,
        "Allocated Memory (MB)":185,
        "Energy (tokens\/kWh)":2008032,
        "E2E Latency (s)":1.93,
        "E2E Throughput (tokens\/s)":133.0,
        "Reserved Memory (MB)":222,
        "Used Memory (MB)":1681
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.00888,
        "Decode Throughput (tokens\/s)":165.0,
        "Allocated Memory (MB)":184,
        "Energy (tokens\/kWh)":2666666,
        "E2E Latency (s)":1.56,
        "E2E Throughput (tokens\/s)":164.0,
        "Reserved Memory (MB)":201,
        "Used Memory (MB)":1660
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00903,
        "Decode Throughput (tokens\/s)":128.0,
        "Allocated Memory (MB)":185,
        "Energy (tokens\/kWh)":1992031,
        "E2E Latency (s)":2.01,
        "E2E Throughput (tokens\/s)":127.0,
        "Reserved Memory (MB)":222,
        "Used Memory (MB)":1681
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.0,
        "Open LLM Score (%)":"28.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.00972,
        "Decode Throughput (tokens\/s)":252.0,
        "Allocated Memory (MB)":1050,
        "Energy (tokens\/kWh)":3311258,
        "E2E Latency (s)":1.02,
        "E2E Throughput (tokens\/s)":251.0,
        "Reserved Memory (MB)":1088,
        "Used Memory (MB)":2548
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0121,
        "Decode Throughput (tokens\/s)":78.5,
        "Allocated Memory (MB)":193,
        "Energy (tokens\/kWh)":1234567,
        "E2E Latency (s)":3.26,
        "E2E Throughput (tokens\/s)":78.5,
        "Reserved Memory (MB)":213,
        "Used Memory (MB)":1681
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.0,
        "Open LLM Score (%)":"28.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0124,
        "Decode Throughput (tokens\/s)":78.5,
        "Allocated Memory (MB)":1432,
        "Energy (tokens\/kWh)":1213592,
        "E2E Latency (s)":3.26,
        "E2E Throughput (tokens\/s)":78.5,
        "Reserved Memory (MB)":1476,
        "Used Memory (MB)":2944
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.0,
        "Open LLM Score (%)":"28.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.013,
        "Decode Throughput (tokens\/s)":78.0,
        "Allocated Memory (MB)":1432,
        "Energy (tokens\/kWh)":1144164,
        "E2E Latency (s)":3.28,
        "E2E Throughput (tokens\/s)":78.0,
        "Reserved Memory (MB)":1476,
        "Used Memory (MB)":2944
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"GPT-NeoX",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.013,
        "Decode Throughput (tokens\/s)":75.4,
        "Allocated Memory (MB)":193,
        "Energy (tokens\/kWh)":1135073,
        "E2E Latency (s)":3.39,
        "E2E Throughput (tokens\/s)":75.5,
        "Reserved Memory (MB)":213,
        "Used Memory (MB)":1681
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"GPT-Neo",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0136,
        "Decode Throughput (tokens\/s)":93.8,
        "Allocated Memory (MB)":145,
        "Energy (tokens\/kWh)":1455604,
        "E2E Latency (s)":2.73,
        "E2E Throughput (tokens\/s)":93.8,
        "Reserved Memory (MB)":178,
        "Used Memory (MB)":1637
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"GPT-Neo",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0137,
        "Decode Throughput (tokens\/s)":123.0,
        "Allocated Memory (MB)":144,
        "Energy (tokens\/kWh)":2040816,
        "E2E Latency (s)":2.08,
        "E2E Throughput (tokens\/s)":123.0,
        "Reserved Memory (MB)":178,
        "Used Memory (MB)":1637
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"GPT-Neo",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0138,
        "Decode Throughput (tokens\/s)":91.1,
        "Allocated Memory (MB)":145,
        "Energy (tokens\/kWh)":1451378,
        "E2E Latency (s)":2.81,
        "E2E Throughput (tokens\/s)":91.1,
        "Reserved Memory (MB)":178,
        "Used Memory (MB)":1637
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"GPT-Neo",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0208,
        "Decode Throughput (tokens\/s)":46.8,
        "Allocated Memory (MB)":156,
        "Energy (tokens\/kWh)":735294,
        "E2E Latency (s)":5.47,
        "E2E Throughput (tokens\/s)":46.8,
        "Reserved Memory (MB)":190,
        "Used Memory (MB)":1658
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.0,
        "Open LLM Score (%)":"28.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0215,
        "Decode Throughput (tokens\/s)":202.0,
        "Allocated Memory (MB)":1225,
        "Energy (tokens\/kWh)":2785515,
        "E2E Latency (s)":1.28,
        "E2E Throughput (tokens\/s)":200.0,
        "Reserved Memory (MB)":1277,
        "Used Memory (MB)":2736
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"GPT-Neo",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0216,
        "Decode Throughput (tokens\/s)":45.5,
        "Allocated Memory (MB)":156,
        "Energy (tokens\/kWh)":719424,
        "E2E Latency (s)":5.62,
        "E2E Throughput (tokens\/s)":45.6,
        "Reserved Memory (MB)":190,
        "Used Memory (MB)":1658
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.0,
        "Open LLM Score (%)":"28.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0338,
        "Decode Throughput (tokens\/s)":165.0,
        "Allocated Memory (MB)":1315,
        "Energy (tokens\/kWh)":2192982,
        "E2E Latency (s)":1.58,
        "E2E Throughput (tokens\/s)":162.0,
        "Reserved Memory (MB)":1476,
        "Used Memory (MB)":2935
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.0,
        "Open LLM Score (%)":"28.44*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.034,
        "Decode Throughput (tokens\/s)":158.0,
        "Allocated Memory (MB)":1315,
        "Energy (tokens\/kWh)":2057613,
        "E2E Latency (s)":1.64,
        "E2E Throughput (tokens\/s)":156.0,
        "Reserved Memory (MB)":1476,
        "Used Memory (MB)":2935
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":1.0,
        "Open LLM Score (%)":"28.44 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0347,
        "Decode Throughput (tokens\/s)":270.0,
        "Allocated Memory (MB)":4446,
        "Energy (tokens\/kWh)":2341920,
        "E2E Latency (s)":0.978,
        "E2E Throughput (tokens\/s)":262.0,
        "Reserved Memory (MB)":4510,
        "Used Memory (MB)":5962
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"GPT-Neo",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.41 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00256,
        "Decode Throughput (tokens\/s)":354.0,
        "Allocated Memory (MB)":197,
        "Energy (tokens\/kWh)":5714285,
        "E2E Latency (s)":0.723,
        "E2E Throughput (tokens\/s)":354.0,
        "Reserved Memory (MB)":230,
        "Used Memory (MB)":1690
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"GPT-Neo",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.41 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00311,
        "Decode Throughput (tokens\/s)":313.0,
        "Allocated Memory (MB)":197,
        "Energy (tokens\/kWh)":4608294,
        "E2E Latency (s)":0.818,
        "E2E Throughput (tokens\/s)":313.0,
        "Reserved Memory (MB)":230,
        "Used Memory (MB)":1690
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"GPT-Neo",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.41 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00332,
        "Decode Throughput (tokens\/s)":309.0,
        "Allocated Memory (MB)":197,
        "Energy (tokens\/kWh)":4926108,
        "E2E Latency (s)":0.829,
        "E2E Throughput (tokens\/s)":309.0,
        "Reserved Memory (MB)":230,
        "Used Memory (MB)":1690
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"GPT-Neo",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.41 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00337,
        "Decode Throughput (tokens\/s)":300.0,
        "Allocated Memory (MB)":197,
        "Energy (tokens\/kWh)":4608294,
        "E2E Latency (s)":0.853,
        "E2E Throughput (tokens\/s)":300.0,
        "Reserved Memory (MB)":230,
        "Used Memory (MB)":1690
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"GPT-Neo",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.41*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00359,
        "Decode Throughput (tokens\/s)":302.0,
        "Allocated Memory (MB)":360,
        "Energy (tokens\/kWh)":4807692,
        "E2E Latency (s)":0.847,
        "E2E Throughput (tokens\/s)":302.0,
        "Reserved Memory (MB)":400,
        "Used Memory (MB)":1862
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"GPT-Neo",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.41*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0036,
        "Decode Throughput (tokens\/s)":301.0,
        "Allocated Memory (MB)":159,
        "Energy (tokens\/kWh)":4716981,
        "E2E Latency (s)":0.851,
        "E2E Throughput (tokens\/s)":301.0,
        "Reserved Memory (MB)":192,
        "Used Memory (MB)":1654
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"GPT-Neo",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.41*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.00371,
        "Decode Throughput (tokens\/s)":272.0,
        "Allocated Memory (MB)":154,
        "Energy (tokens\/kWh)":4149377,
        "E2E Latency (s)":0.942,
        "E2E Throughput (tokens\/s)":272.0,
        "Reserved Memory (MB)":205,
        "Used Memory (MB)":1665
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"GPT-Neo",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.41*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.00375,
        "Decode Throughput (tokens\/s)":293.0,
        "Allocated Memory (MB)":154,
        "Energy (tokens\/kWh)":4587155,
        "E2E Latency (s)":0.873,
        "E2E Throughput (tokens\/s)":293.0,
        "Reserved Memory (MB)":205,
        "Used Memory (MB)":1665
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"GPT-Neo",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.41 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.004,
        "Decode Throughput (tokens\/s)":324.0,
        "Allocated Memory (MB)":366,
        "Energy (tokens\/kWh)":4716981,
        "E2E Latency (s)":0.79,
        "E2E Throughput (tokens\/s)":324.0,
        "Reserved Memory (MB)":419,
        "Used Memory (MB)":1870
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"GPT-Neo",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.41*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00698,
        "Decode Throughput (tokens\/s)":176.0,
        "Allocated Memory (MB)":154,
        "Energy (tokens\/kWh)":2747252,
        "E2E Latency (s)":1.46,
        "E2E Throughput (tokens\/s)":175.0,
        "Reserved Memory (MB)":192,
        "Used Memory (MB)":1652
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"GPT-Neo",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.41*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.00745,
        "Decode Throughput (tokens\/s)":228.0,
        "Allocated Memory (MB)":154,
        "Energy (tokens\/kWh)":3623188,
        "E2E Latency (s)":1.13,
        "E2E Throughput (tokens\/s)":227.0,
        "Reserved Memory (MB)":192,
        "Used Memory (MB)":1652
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"GPT-Neo",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.41*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00749,
        "Decode Throughput (tokens\/s)":172.0,
        "Allocated Memory (MB)":155,
        "Energy (tokens\/kWh)":2645502,
        "E2E Latency (s)":1.49,
        "E2E Throughput (tokens\/s)":172.0,
        "Reserved Memory (MB)":192,
        "Used Memory (MB)":1652
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"GPT-Neo",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.41*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0109,
        "Decode Throughput (tokens\/s)":89.5,
        "Allocated Memory (MB)":166,
        "Energy (tokens\/kWh)":1414427,
        "E2E Latency (s)":2.86,
        "E2E Throughput (tokens\/s)":89.5,
        "Reserved Memory (MB)":199,
        "Used Memory (MB)":1667
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"GPT-Neo",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.41*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0112,
        "Decode Throughput (tokens\/s)":88.9,
        "Allocated Memory (MB)":168,
        "Energy (tokens\/kWh)":1369863,
        "E2E Latency (s)":2.88,
        "E2E Throughput (tokens\/s)":88.9,
        "Reserved Memory (MB)":220,
        "Used Memory (MB)":1688
    },
    {
        "Model":"SaylorTwift\/gpt2_test",
        "Arch":"GPT-2",
        "Params (B)":0.14,
        "Open LLM Score (%)":"28.40 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00696,
        "Decode Throughput (tokens\/s)":132.0,
        "Allocated Memory (MB)":328,
        "Energy (tokens\/kWh)":1988071,
        "E2E Latency (s)":1.94,
        "E2E Throughput (tokens\/s)":132.0,
        "Reserved Memory (MB)":381,
        "Used Memory (MB)":1841
    },
    {
        "Model":"SaylorTwift\/gpt2_test",
        "Arch":"GPT-2",
        "Params (B)":0.14,
        "Open LLM Score (%)":"28.40 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00816,
        "Decode Throughput (tokens\/s)":120.0,
        "Allocated Memory (MB)":328,
        "Energy (tokens\/kWh)":1930501,
        "E2E Latency (s)":2.14,
        "E2E Throughput (tokens\/s)":120.0,
        "Reserved Memory (MB)":381,
        "Used Memory (MB)":1841
    },
    {
        "Model":"SaylorTwift\/gpt2_test",
        "Arch":"GPT-2",
        "Params (B)":0.14,
        "Open LLM Score (%)":"28.40*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.00817,
        "Decode Throughput (tokens\/s)":120.0,
        "Allocated Memory (MB)":328,
        "Energy (tokens\/kWh)":1858736,
        "E2E Latency (s)":2.13,
        "E2E Throughput (tokens\/s)":120.0,
        "Reserved Memory (MB)":381,
        "Used Memory (MB)":1841
    },
    {
        "Model":"SaylorTwift\/gpt2_test",
        "Arch":"GPT-2",
        "Params (B)":0.14,
        "Open LLM Score (%)":"28.40 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0083,
        "Decode Throughput (tokens\/s)":119.0,
        "Allocated Memory (MB)":328,
        "Energy (tokens\/kWh)":1792114,
        "E2E Latency (s)":2.15,
        "E2E Throughput (tokens\/s)":119.0,
        "Reserved Memory (MB)":381,
        "Used Memory (MB)":1841
    },
    {
        "Model":"SaylorTwift\/gpt2_test",
        "Arch":"GPT-2",
        "Params (B)":0.14,
        "Open LLM Score (%)":"28.40*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.00847,
        "Decode Throughput (tokens\/s)":120.0,
        "Allocated Memory (MB)":328,
        "Energy (tokens\/kWh)":1858736,
        "E2E Latency (s)":2.13,
        "E2E Throughput (tokens\/s)":120.0,
        "Reserved Memory (MB)":381,
        "Used Memory (MB)":1841
    },
    {
        "Model":"SaylorTwift\/gpt2_test",
        "Arch":"GPT-2",
        "Params (B)":0.14,
        "Open LLM Score (%)":"28.40*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00858,
        "Decode Throughput (tokens\/s)":122.0,
        "Allocated Memory (MB)":200,
        "Energy (tokens\/kWh)":1956947,
        "E2E Latency (s)":2.1,
        "E2E Throughput (tokens\/s)":122.0,
        "Reserved Memory (MB)":270,
        "Used Memory (MB)":1732
    },
    {
        "Model":"SaylorTwift\/gpt2_test",
        "Arch":"GPT-2",
        "Params (B)":0.14,
        "Open LLM Score (%)":"28.40 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00967,
        "Decode Throughput (tokens\/s)":118.0,
        "Allocated Memory (MB)":621,
        "Energy (tokens\/kWh)":1824817,
        "E2E Latency (s)":2.18,
        "E2E Throughput (tokens\/s)":117.0,
        "Reserved Memory (MB)":717,
        "Used Memory (MB)":2168
    },
    {
        "Model":"SaylorTwift\/gpt2_test",
        "Arch":"GPT-2",
        "Params (B)":0.14,
        "Open LLM Score (%)":"28.40*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0157,
        "Decode Throughput (tokens\/s)":100.0,
        "Allocated Memory (MB)":197,
        "Energy (tokens\/kWh)":1589825,
        "E2E Latency (s)":2.57,
        "E2E Throughput (tokens\/s)":99.6,
        "Reserved Memory (MB)":270,
        "Used Memory (MB)":1730
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"GPT-Neo",
        "Params (B)":0.01,
        "Open LLM Score (%)":"28.31 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00446,
        "Decode Throughput (tokens\/s)":220.0,
        "Allocated Memory (MB)":112,
        "Energy (tokens\/kWh)":3636363,
        "E2E Latency (s)":1.16,
        "E2E Throughput (tokens\/s)":221.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1602
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"GPT-Neo",
        "Params (B)":0.01,
        "Open LLM Score (%)":"28.31 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00531,
        "Decode Throughput (tokens\/s)":183.0,
        "Allocated Memory (MB)":112,
        "Energy (tokens\/kWh)":2881844,
        "E2E Latency (s)":1.4,
        "E2E Throughput (tokens\/s)":183.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1602
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"GPT-Neo",
        "Params (B)":0.01,
        "Open LLM Score (%)":"28.31 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00564,
        "Decode Throughput (tokens\/s)":186.0,
        "Allocated Memory (MB)":183,
        "Energy (tokens\/kWh)":2958579,
        "E2E Latency (s)":1.38,
        "E2E Throughput (tokens\/s)":186.0,
        "Reserved Memory (MB)":213,
        "Used Memory (MB)":1665
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"GPT-Neo",
        "Params (B)":0.01,
        "Open LLM Score (%)":"28.31 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00583,
        "Decode Throughput (tokens\/s)":175.0,
        "Allocated Memory (MB)":112,
        "Energy (tokens\/kWh)":2739726,
        "E2E Latency (s)":1.47,
        "E2E Throughput (tokens\/s)":174.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1602
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"GPT-Neo",
        "Params (B)":0.01,
        "Open LLM Score (%)":"28.31 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00591,
        "Decode Throughput (tokens\/s)":178.0,
        "Allocated Memory (MB)":112,
        "Energy (tokens\/kWh)":2958579,
        "E2E Latency (s)":1.44,
        "E2E Throughput (tokens\/s)":178.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1602
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"GPT-Neo",
        "Params (B)":0.01,
        "Open LLM Score (%)":"28.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00631,
        "Decode Throughput (tokens\/s)":169.0,
        "Allocated Memory (MB)":170,
        "Energy (tokens\/kWh)":2724795,
        "E2E Latency (s)":1.52,
        "E2E Throughput (tokens\/s)":168.0,
        "Reserved Memory (MB)":203,
        "Used Memory (MB)":1665
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"GPT-Neo",
        "Params (B)":0.01,
        "Open LLM Score (%)":"28.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.00635,
        "Decode Throughput (tokens\/s)":153.0,
        "Allocated Memory (MB)":102,
        "Energy (tokens\/kWh)":2427184,
        "E2E Latency (s)":1.68,
        "E2E Throughput (tokens\/s)":152.0,
        "Reserved Memory (MB)":134,
        "Used Memory (MB)":1593
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"GPT-Neo",
        "Params (B)":0.01,
        "Open LLM Score (%)":"28.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00647,
        "Decode Throughput (tokens\/s)":168.0,
        "Allocated Memory (MB)":103,
        "Energy (tokens\/kWh)":2590673,
        "E2E Latency (s)":1.53,
        "E2E Throughput (tokens\/s)":167.0,
        "Reserved Memory (MB)":134,
        "Used Memory (MB)":1595
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"GPT-Neo",
        "Params (B)":0.01,
        "Open LLM Score (%)":"28.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.00651,
        "Decode Throughput (tokens\/s)":169.0,
        "Allocated Memory (MB)":102,
        "Energy (tokens\/kWh)":2659574,
        "E2E Latency (s)":1.52,
        "E2E Throughput (tokens\/s)":168.0,
        "Reserved Memory (MB)":134,
        "Used Memory (MB)":1593
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"GPT-Neo",
        "Params (B)":0.01,
        "Open LLM Score (%)":"28.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0129,
        "Decode Throughput (tokens\/s)":93.8,
        "Allocated Memory (MB)":102,
        "Energy (tokens\/kWh)":1483679,
        "E2E Latency (s)":2.73,
        "E2E Throughput (tokens\/s)":93.8,
        "Reserved Memory (MB)":134,
        "Used Memory (MB)":1593
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"GPT-Neo",
        "Params (B)":0.01,
        "Open LLM Score (%)":"28.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0137,
        "Decode Throughput (tokens\/s)":92.1,
        "Allocated Memory (MB)":102,
        "Energy (tokens\/kWh)":1477104,
        "E2E Latency (s)":2.78,
        "E2E Throughput (tokens\/s)":92.1,
        "Reserved Memory (MB)":134,
        "Used Memory (MB)":1593
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"GPT-Neo",
        "Params (B)":0.01,
        "Open LLM Score (%)":"28.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0139,
        "Decode Throughput (tokens\/s)":126.0,
        "Allocated Memory (MB)":102,
        "Energy (tokens\/kWh)":2044989,
        "E2E Latency (s)":2.04,
        "E2E Throughput (tokens\/s)":125.0,
        "Reserved Memory (MB)":134,
        "Used Memory (MB)":1593
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"GPT-Neo",
        "Params (B)":0.01,
        "Open LLM Score (%)":"28.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0209,
        "Decode Throughput (tokens\/s)":46.4,
        "Allocated Memory (MB)":105,
        "Energy (tokens\/kWh)":729927,
        "E2E Latency (s)":5.52,
        "E2E Throughput (tokens\/s)":46.4,
        "Reserved Memory (MB)":138,
        "Used Memory (MB)":1606
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"GPT-Neo",
        "Params (B)":0.01,
        "Open LLM Score (%)":"28.31*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.022,
        "Decode Throughput (tokens\/s)":45.5,
        "Allocated Memory (MB)":105,
        "Energy (tokens\/kWh)":714285,
        "E2E Latency (s)":5.62,
        "E2E Throughput (tokens\/s)":45.6,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1604
    },
    {
        "Model":"instructkr\/ko-wand-136M",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":0.14,
        "Open LLM Score (%)":"28.29 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00761,
        "Decode Throughput (tokens\/s)":127.0,
        "Allocated Memory (MB)":347,
        "Energy (tokens\/kWh)":2070393,
        "E2E Latency (s)":2.02,
        "E2E Throughput (tokens\/s)":127.0,
        "Reserved Memory (MB)":387,
        "Used Memory (MB)":1847
    },
    {
        "Model":"instructkr\/ko-wand-136M",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":0.14,
        "Open LLM Score (%)":"28.29 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0077,
        "Decode Throughput (tokens\/s)":128.0,
        "Allocated Memory (MB)":347,
        "Energy (tokens\/kWh)":1996007,
        "E2E Latency (s)":2.0,
        "E2E Throughput (tokens\/s)":128.0,
        "Reserved Memory (MB)":383,
        "Used Memory (MB)":1843
    },
    {
        "Model":"instructkr\/ko-wand-136M",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":0.14,
        "Open LLM Score (%)":"28.29 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00784,
        "Decode Throughput (tokens\/s)":140.0,
        "Allocated Memory (MB)":613,
        "Energy (tokens\/kWh)":2237136,
        "E2E Latency (s)":1.83,
        "E2E Throughput (tokens\/s)":140.0,
        "Reserved Memory (MB)":668,
        "Used Memory (MB)":2120
    },
    {
        "Model":"instructkr\/ko-wand-136M",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":0.14,
        "Open LLM Score (%)":"28.29*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00837,
        "Decode Throughput (tokens\/s)":122.0,
        "Allocated Memory (MB)":488,
        "Energy (tokens\/kWh)":1956947,
        "E2E Latency (s)":2.1,
        "E2E Throughput (tokens\/s)":122.0,
        "Reserved Memory (MB)":517,
        "Used Memory (MB)":1979
    },
    {
        "Model":"instructkr\/ko-wand-136M",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":0.14,
        "Open LLM Score (%)":"28.29*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.00841,
        "Decode Throughput (tokens\/s)":125.0,
        "Allocated Memory (MB)":213,
        "Energy (tokens\/kWh)":1992031,
        "E2E Latency (s)":2.05,
        "E2E Throughput (tokens\/s)":125.0,
        "Reserved Memory (MB)":241,
        "Used Memory (MB)":1700
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.27 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00389,
        "Decode Throughput (tokens\/s)":248.0,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":4000000,
        "E2E Latency (s)":1.03,
        "E2E Throughput (tokens\/s)":249.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1602
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.27 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00429,
        "Decode Throughput (tokens\/s)":220.0,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3508771,
        "E2E Latency (s)":1.16,
        "E2E Throughput (tokens\/s)":221.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1602
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.27 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00472,
        "Decode Throughput (tokens\/s)":207.0,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3436426,
        "E2E Latency (s)":1.23,
        "E2E Throughput (tokens\/s)":208.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1602
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.27 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00476,
        "Decode Throughput (tokens\/s)":204.0,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3236245,
        "E2E Latency (s)":1.25,
        "E2E Throughput (tokens\/s)":205.0,
        "Reserved Memory (MB)":142,
        "Used Memory (MB)":1602
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.27*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0049,
        "Decode Throughput (tokens\/s)":202.0,
        "Allocated Memory (MB)":186,
        "Energy (tokens\/kWh)":3344481,
        "E2E Latency (s)":1.26,
        "E2E Throughput (tokens\/s)":203.0,
        "Reserved Memory (MB)":205,
        "Used Memory (MB)":1667
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.27 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00499,
        "Decode Throughput (tokens\/s)":206.0,
        "Allocated Memory (MB)":221,
        "Energy (tokens\/kWh)":3134796,
        "E2E Latency (s)":1.24,
        "E2E Throughput (tokens\/s)":206.0,
        "Reserved Memory (MB)":234,
        "Used Memory (MB)":1686
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.27*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00499,
        "Decode Throughput (tokens\/s)":199.0,
        "Allocated Memory (MB)":119,
        "Energy (tokens\/kWh)":3205128,
        "E2E Latency (s)":1.28,
        "E2E Throughput (tokens\/s)":200.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1597
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.27*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.00513,
        "Decode Throughput (tokens\/s)":183.0,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2724795,
        "E2E Latency (s)":1.4,
        "E2E Throughput (tokens\/s)":183.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1595
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.27*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.00521,
        "Decode Throughput (tokens\/s)":193.0,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":3086419,
        "E2E Latency (s)":1.33,
        "E2E Throughput (tokens\/s)":192.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1595
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.27*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00821,
        "Decode Throughput (tokens\/s)":134.0,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2105263,
        "E2E Latency (s)":1.92,
        "E2E Throughput (tokens\/s)":133.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1595
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.27*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.00895,
        "Decode Throughput (tokens\/s)":158.0,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2702702,
        "E2E Latency (s)":1.62,
        "E2E Throughput (tokens\/s)":158.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1595
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.27*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00931,
        "Decode Throughput (tokens\/s)":128.0,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2036659,
        "E2E Latency (s)":2.01,
        "E2E Throughput (tokens\/s)":127.0,
        "Reserved Memory (MB)":136,
        "Used Memory (MB)":1595
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.27*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.012,
        "Decode Throughput (tokens\/s)":78.9,
        "Allocated Memory (MB)":121,
        "Energy (tokens\/kWh)":1236093,
        "E2E Latency (s)":3.24,
        "E2E Throughput (tokens\/s)":79.0,
        "Reserved Memory (MB)":138,
        "Used Memory (MB)":1606
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"GPT-NeoX",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.27*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0129,
        "Decode Throughput (tokens\/s)":75.7,
        "Allocated Memory (MB)":121,
        "Energy (tokens\/kWh)":1169590,
        "E2E Latency (s)":3.38,
        "E2E Throughput (tokens\/s)":75.7,
        "Reserved Memory (MB)":138,
        "Used Memory (MB)":1606
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"28.19 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00452,
        "Decode Throughput (tokens\/s)":218.0,
        "Allocated Memory (MB)":87,
        "Energy (tokens\/kWh)":3546099,
        "E2E Latency (s)":1.17,
        "E2E Throughput (tokens\/s)":219.0,
        "Reserved Memory (MB)":115,
        "Used Memory (MB)":1574
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"28.19 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00536,
        "Decode Throughput (tokens\/s)":180.0,
        "Allocated Memory (MB)":87,
        "Energy (tokens\/kWh)":2906976,
        "E2E Latency (s)":1.43,
        "E2E Throughput (tokens\/s)":179.0,
        "Reserved Memory (MB)":115,
        "Used Memory (MB)":1574
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"28.19 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00546,
        "Decode Throughput (tokens\/s)":185.0,
        "Allocated Memory (MB)":132,
        "Energy (tokens\/kWh)":2923976,
        "E2E Latency (s)":1.39,
        "E2E Throughput (tokens\/s)":184.0,
        "Reserved Memory (MB)":161,
        "Used Memory (MB)":1612
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"28.19 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00582,
        "Decode Throughput (tokens\/s)":178.0,
        "Allocated Memory (MB)":87,
        "Energy (tokens\/kWh)":2976190,
        "E2E Latency (s)":1.44,
        "E2E Throughput (tokens\/s)":178.0,
        "Reserved Memory (MB)":115,
        "Used Memory (MB)":1574
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"28.19 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00591,
        "Decode Throughput (tokens\/s)":171.0,
        "Allocated Memory (MB)":87,
        "Energy (tokens\/kWh)":2832861,
        "E2E Latency (s)":1.5,
        "E2E Throughput (tokens\/s)":171.0,
        "Reserved Memory (MB)":115,
        "Used Memory (MB)":1574
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"28.19*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.00634,
        "Decode Throughput (tokens\/s)":169.0,
        "Allocated Memory (MB)":84,
        "Energy (tokens\/kWh)":2717391,
        "E2E Latency (s)":1.52,
        "E2E Throughput (tokens\/s)":168.0,
        "Reserved Memory (MB)":113,
        "Used Memory (MB)":1572
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"28.19*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.00643,
        "Decode Throughput (tokens\/s)":149.0,
        "Allocated Memory (MB)":84,
        "Energy (tokens\/kWh)":2450980,
        "E2E Latency (s)":1.72,
        "E2E Throughput (tokens\/s)":149.0,
        "Reserved Memory (MB)":113,
        "Used Memory (MB)":1572
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"28.19*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00651,
        "Decode Throughput (tokens\/s)":167.0,
        "Allocated Memory (MB)":84,
        "Energy (tokens\/kWh)":2739726,
        "E2E Latency (s)":1.54,
        "E2E Throughput (tokens\/s)":166.0,
        "Reserved Memory (MB)":113,
        "Used Memory (MB)":1574
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"28.19*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0128,
        "Decode Throughput (tokens\/s)":95.1,
        "Allocated Memory (MB)":84,
        "Energy (tokens\/kWh)":1497005,
        "E2E Latency (s)":2.69,
        "E2E Throughput (tokens\/s)":95.2,
        "Reserved Memory (MB)":113,
        "Used Memory (MB)":1572
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"28.19*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0137,
        "Decode Throughput (tokens\/s)":92.7,
        "Allocated Memory (MB)":84,
        "Energy (tokens\/kWh)":1492537,
        "E2E Latency (s)":2.76,
        "E2E Throughput (tokens\/s)":92.8,
        "Reserved Memory (MB)":113,
        "Used Memory (MB)":1572
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"28.19*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0142,
        "Decode Throughput (tokens\/s)":128.0,
        "Allocated Memory (MB)":84,
        "Energy (tokens\/kWh)":2087682,
        "E2E Latency (s)":2.0,
        "E2E Throughput (tokens\/s)":128.0,
        "Reserved Memory (MB)":113,
        "Used Memory (MB)":1572
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"28.19*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.021,
        "Decode Throughput (tokens\/s)":46.4,
        "Allocated Memory (MB)":85,
        "Energy (tokens\/kWh)":746268,
        "E2E Latency (s)":5.52,
        "E2E Throughput (tokens\/s)":46.4,
        "Reserved Memory (MB)":113,
        "Used Memory (MB)":1581
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"GPT-Neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"28.19*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0212,
        "Decode Throughput (tokens\/s)":46.4,
        "Allocated Memory (MB)":85,
        "Energy (tokens\/kWh)":746268,
        "E2E Latency (s)":5.52,
        "E2E Throughput (tokens\/s)":46.4,
        "Reserved Memory (MB)":113,
        "Used Memory (MB)":1581
    },
    {
        "Model":"beomi\/KoRWKV-6B",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":6.53,
        "Open LLM Score (%)":"28.19 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0296,
        "Decode Throughput (tokens\/s)":34.2,
        "Allocated Memory (MB)":13112,
        "Energy (tokens\/kWh)":427350,
        "E2E Latency (s)":7.49,
        "E2E Throughput (tokens\/s)":34.2,
        "Reserved Memory (MB)":13165,
        "Used Memory (MB)":14625
    },
    {
        "Model":"beomi\/KoRWKV-6B",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":6.53,
        "Open LLM Score (%)":"28.19 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0316,
        "Decode Throughput (tokens\/s)":33.9,
        "Allocated Memory (MB)":13112,
        "Energy (tokens\/kWh)":395256,
        "E2E Latency (s)":7.55,
        "E2E Throughput (tokens\/s)":33.9,
        "Reserved Memory (MB)":13165,
        "Used Memory (MB)":14625
    },
    {
        "Model":"beomi\/KoRWKV-6B",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":6.53,
        "Open LLM Score (%)":"28.19*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0943,
        "Decode Throughput (tokens\/s)":10.4,
        "Allocated Memory (MB)":7030,
        "Energy (tokens\/kWh)":155038,
        "E2E Latency (s)":24.6,
        "E2E Throughput (tokens\/s)":10.4,
        "Reserved Memory (MB)":7048,
        "Used Memory (MB)":8514
    },
    {
        "Model":"beomi\/KoRWKV-6B",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":6.53,
        "Open LLM Score (%)":"28.19 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.211,
        "Decode Throughput (tokens\/s)":35.8,
        "Allocated Memory (MB)":26214,
        "Energy (tokens\/kWh)":347222,
        "E2E Latency (s)":7.34,
        "E2E Throughput (tokens\/s)":34.9,
        "Reserved Memory (MB)":26294,
        "Used Memory (MB)":27745
    },
    {
        "Model":"beomi\/KoRWKV-6B",
        "Arch":"\ud83d\udc26\u200d\u2b1b RWKV",
        "Params (B)":6.53,
        "Open LLM Score (%)":"28.19*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.25,
        "Decode Throughput (tokens\/s)":20.6,
        "Allocated Memory (MB)":4633,
        "Energy (tokens\/kWh)":265251,
        "E2E Latency (s)":12.7,
        "E2E Throughput (tokens\/s)":20.2,
        "Reserved Memory (MB)":4888,
        "Used Memory (MB)":6348
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-81M-tied",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.08,
        "Open LLM Score (%)":"28.17 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00454,
        "Decode Throughput (tokens\/s)":193.0,
        "Allocated Memory (MB)":232,
        "Energy (tokens\/kWh)":2941176,
        "E2E Latency (s)":1.32,
        "E2E Throughput (tokens\/s)":194.0,
        "Reserved Memory (MB)":274,
        "Used Memory (MB)":1734
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-81M-tied",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.08,
        "Open LLM Score (%)":"28.17 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00459,
        "Decode Throughput (tokens\/s)":195.0,
        "Allocated Memory (MB)":232,
        "Energy (tokens\/kWh)":3144654,
        "E2E Latency (s)":1.31,
        "E2E Throughput (tokens\/s)":195.0,
        "Reserved Memory (MB)":274,
        "Used Memory (MB)":1734
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-81M-tied",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.08,
        "Open LLM Score (%)":"28.17 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00468,
        "Decode Throughput (tokens\/s)":195.0,
        "Allocated Memory (MB)":232,
        "Energy (tokens\/kWh)":3058103,
        "E2E Latency (s)":1.31,
        "E2E Throughput (tokens\/s)":195.0,
        "Reserved Memory (MB)":274,
        "Used Memory (MB)":1734
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-81M-tied",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.08,
        "Open LLM Score (%)":"28.17*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.00528,
        "Decode Throughput (tokens\/s)":172.0,
        "Allocated Memory (MB)":145,
        "Energy (tokens\/kWh)":2652519,
        "E2E Latency (s)":1.49,
        "E2E Throughput (tokens\/s)":172.0,
        "Reserved Memory (MB)":184,
        "Used Memory (MB)":1644
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-81M-tied",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.08,
        "Open LLM Score (%)":"28.17*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00531,
        "Decode Throughput (tokens\/s)":185.0,
        "Allocated Memory (MB)":351,
        "Energy (tokens\/kWh)":2949852,
        "E2E Latency (s)":1.39,
        "E2E Throughput (tokens\/s)":184.0,
        "Reserved Memory (MB)":387,
        "Used Memory (MB)":1849
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-81M-tied",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.08,
        "Open LLM Score (%)":"28.17*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.00534,
        "Decode Throughput (tokens\/s)":193.0,
        "Allocated Memory (MB)":145,
        "Energy (tokens\/kWh)":2941176,
        "E2E Latency (s)":1.33,
        "E2E Throughput (tokens\/s)":192.0,
        "Reserved Memory (MB)":186,
        "Used Memory (MB)":1646
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-81M-tied",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.08,
        "Open LLM Score (%)":"28.17 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00537,
        "Decode Throughput (tokens\/s)":214.0,
        "Allocated Memory (MB)":387,
        "Energy (tokens\/kWh)":3215434,
        "E2E Latency (s)":1.2,
        "E2E Throughput (tokens\/s)":213.0,
        "Reserved Memory (MB)":438,
        "Used Memory (MB)":1889
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-81M-tied",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.08,
        "Open LLM Score (%)":"28.17*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00537,
        "Decode Throughput (tokens\/s)":185.0,
        "Allocated Memory (MB)":150,
        "Energy (tokens\/kWh)":2840909,
        "E2E Latency (s)":1.39,
        "E2E Throughput (tokens\/s)":184.0,
        "Reserved Memory (MB)":180,
        "Used Memory (MB)":1642
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-81M-tied",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.08,
        "Open LLM Score (%)":"28.17*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0112,
        "Decode Throughput (tokens\/s)":112.0,
        "Allocated Memory (MB)":147,
        "Energy (tokens\/kWh)":1742160,
        "E2E Latency (s)":2.29,
        "E2E Throughput (tokens\/s)":112.0,
        "Reserved Memory (MB)":184,
        "Used Memory (MB)":1644
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-81M-tied",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.08,
        "Open LLM Score (%)":"28.17*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0116,
        "Decode Throughput (tokens\/s)":111.0,
        "Allocated Memory (MB)":147,
        "Energy (tokens\/kWh)":1715265,
        "E2E Latency (s)":2.3,
        "E2E Throughput (tokens\/s)":111.0,
        "Reserved Memory (MB)":184,
        "Used Memory (MB)":1644
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-81M-tied",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.08,
        "Open LLM Score (%)":"28.17*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0117,
        "Decode Throughput (tokens\/s)":139.0,
        "Allocated Memory (MB)":145,
        "Energy (tokens\/kWh)":2242152,
        "E2E Latency (s)":1.84,
        "E2E Throughput (tokens\/s)":139.0,
        "Reserved Memory (MB)":184,
        "Used Memory (MB)":1644
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-81M-tied",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.08,
        "Open LLM Score (%)":"28.17*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0181,
        "Decode Throughput (tokens\/s)":53.6,
        "Allocated Memory (MB)":171,
        "Energy (tokens\/kWh)":826446,
        "E2E Latency (s)":4.78,
        "E2E Throughput (tokens\/s)":53.6,
        "Reserved Memory (MB)":207,
        "Used Memory (MB)":1675
    },
    {
        "Model":"BEE-spoke-data\/smol_llama-81M-tied",
        "Arch":"\ud83e\udd99 LLaMA",
        "Params (B)":0.08,
        "Open LLM Score (%)":"28.17*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0183,
        "Decode Throughput (tokens\/s)":52.8,
        "Allocated Memory (MB)":171,
        "Energy (tokens\/kWh)":833333,
        "E2E Latency (s)":4.85,
        "E2E Throughput (tokens\/s)":52.8,
        "Reserved Memory (MB)":207,
        "Used Memory (MB)":1675
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"27.95 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0072,
        "Decode Throughput (tokens\/s)":134.0,
        "Allocated Memory (MB)":480,
        "Energy (tokens\/kWh)":2012072,
        "E2E Latency (s)":1.92,
        "E2E Throughput (tokens\/s)":133.0,
        "Reserved Memory (MB)":532,
        "Used Memory (MB)":1992
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"27.95 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00752,
        "Decode Throughput (tokens\/s)":134.0,
        "Allocated Memory (MB)":480,
        "Energy (tokens\/kWh)":2159827,
        "E2E Latency (s)":1.91,
        "E2E Throughput (tokens\/s)":134.0,
        "Reserved Memory (MB)":553,
        "Used Memory (MB)":2013
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"27.95 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00784,
        "Decode Throughput (tokens\/s)":128.0,
        "Allocated Memory (MB)":480,
        "Energy (tokens\/kWh)":1919385,
        "E2E Latency (s)":2.0,
        "E2E Throughput (tokens\/s)":128.0,
        "Reserved Memory (MB)":553,
        "Used Memory (MB)":2013
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"27.95*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00786,
        "Decode Throughput (tokens\/s)":132.0,
        "Allocated Memory (MB)":553,
        "Energy (tokens\/kWh)":2096436,
        "E2E Latency (s)":1.94,
        "E2E Throughput (tokens\/s)":132.0,
        "Reserved Memory (MB)":629,
        "Used Memory (MB)":2090
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"27.95*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00803,
        "Decode Throughput (tokens\/s)":129.0,
        "Allocated Memory (MB)":352,
        "Energy (tokens\/kWh)":2061855,
        "E2E Latency (s)":1.99,
        "E2E Throughput (tokens\/s)":129.0,
        "Reserved Memory (MB)":421,
        "Used Memory (MB)":1883
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"27.95*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.00843,
        "Decode Throughput (tokens\/s)":126.0,
        "Allocated Memory (MB)":347,
        "Energy (tokens\/kWh)":1945525,
        "E2E Latency (s)":2.03,
        "E2E Throughput (tokens\/s)":126.0,
        "Reserved Memory (MB)":413,
        "Used Memory (MB)":1872
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"27.95*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.00856,
        "Decode Throughput (tokens\/s)":115.0,
        "Allocated Memory (MB)":347,
        "Energy (tokens\/kWh)":1766784,
        "E2E Latency (s)":2.23,
        "E2E Throughput (tokens\/s)":115.0,
        "Reserved Memory (MB)":415,
        "Used Memory (MB)":1874
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"27.95 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.011,
        "Decode Throughput (tokens\/s)":135.0,
        "Allocated Memory (MB)":934,
        "Energy (tokens\/kWh)":2004008,
        "E2E Latency (s)":1.9,
        "E2E Throughput (tokens\/s)":135.0,
        "Reserved Memory (MB)":1035,
        "Used Memory (MB)":2487
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"27.95*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0149,
        "Decode Throughput (tokens\/s)":76.8,
        "Allocated Memory (MB)":350,
        "Energy (tokens\/kWh)":1176470,
        "E2E Latency (s)":3.33,
        "E2E Throughput (tokens\/s)":76.9,
        "Reserved Memory (MB)":425,
        "Used Memory (MB)":1885
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"27.95*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0157,
        "Decode Throughput (tokens\/s)":106.0,
        "Allocated Memory (MB)":350,
        "Energy (tokens\/kWh)":1618122,
        "E2E Latency (s)":2.42,
        "E2E Throughput (tokens\/s)":106.0,
        "Reserved Memory (MB)":421,
        "Used Memory (MB)":1881
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"27.95*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0163,
        "Decode Throughput (tokens\/s)":75.7,
        "Allocated Memory (MB)":350,
        "Energy (tokens\/kWh)":1187648,
        "E2E Latency (s)":3.39,
        "E2E Throughput (tokens\/s)":75.5,
        "Reserved Memory (MB)":425,
        "Used Memory (MB)":1885
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"27.95*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.023,
        "Decode Throughput (tokens\/s)":41.7,
        "Allocated Memory (MB)":392,
        "Energy (tokens\/kWh)":653594,
        "E2E Latency (s)":6.13,
        "E2E Throughput (tokens\/s)":41.8,
        "Reserved Memory (MB)":457,
        "Used Memory (MB)":1925
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"\ud83c\udf38 Bloom",
        "Params (B)":0.0,
        "Open LLM Score (%)":"27.95*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0238,
        "Decode Throughput (tokens\/s)":41.8,
        "Allocated Memory (MB)":393,
        "Energy (tokens\/kWh)":649350,
        "E2E Latency (s)":6.12,
        "E2E Throughput (tokens\/s)":41.8,
        "Reserved Memory (MB)":457,
        "Used Memory (MB)":1925
    },
    {
        "Model":"cerebras\/Cerebras-GPT-111M",
        "Arch":"GPT-2",
        "Params (B)":0.11,
        "Open LLM Score (%)":"27.75 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00514,
        "Decode Throughput (tokens\/s)":180.0,
        "Allocated Memory (MB)":332,
        "Energy (tokens\/kWh)":2710027,
        "E2E Latency (s)":1.43,
        "E2E Throughput (tokens\/s)":179.0,
        "Reserved Memory (MB)":381,
        "Used Memory (MB)":1841
    },
    {
        "Model":"cerebras\/Cerebras-GPT-111M",
        "Arch":"GPT-2",
        "Params (B)":0.11,
        "Open LLM Score (%)":"27.75 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00601,
        "Decode Throughput (tokens\/s)":162.0,
        "Allocated Memory (MB)":332,
        "Energy (tokens\/kWh)":2590673,
        "E2E Latency (s)":1.58,
        "E2E Throughput (tokens\/s)":162.0,
        "Reserved Memory (MB)":381,
        "Used Memory (MB)":1841
    },
    {
        "Model":"cerebras\/Cerebras-GPT-111M",
        "Arch":"GPT-2",
        "Params (B)":0.11,
        "Open LLM Score (%)":"27.75 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00613,
        "Decode Throughput (tokens\/s)":153.0,
        "Allocated Memory (MB)":332,
        "Energy (tokens\/kWh)":2314814,
        "E2E Latency (s)":1.68,
        "E2E Throughput (tokens\/s)":152.0,
        "Reserved Memory (MB)":381,
        "Used Memory (MB)":1841
    },
    {
        "Model":"cerebras\/Cerebras-GPT-111M",
        "Arch":"GPT-2",
        "Params (B)":0.11,
        "Open LLM Score (%)":"27.75*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.00615,
        "Decode Throughput (tokens\/s)":158.0,
        "Allocated Memory (MB)":323,
        "Energy (tokens\/kWh)":2500000,
        "E2E Latency (s)":1.62,
        "E2E Throughput (tokens\/s)":158.0,
        "Reserved Memory (MB)":381,
        "Used Memory (MB)":1841
    },
    {
        "Model":"cerebras\/Cerebras-GPT-111M",
        "Arch":"GPT-2",
        "Params (B)":0.11,
        "Open LLM Score (%)":"27.75*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.00625,
        "Decode Throughput (tokens\/s)":158.0,
        "Allocated Memory (MB)":323,
        "Energy (tokens\/kWh)":2577319,
        "E2E Latency (s)":1.62,
        "E2E Throughput (tokens\/s)":158.0,
        "Reserved Memory (MB)":381,
        "Used Memory (MB)":1841
    },
    {
        "Model":"cerebras\/Cerebras-GPT-111M",
        "Arch":"GPT-2",
        "Params (B)":0.11,
        "Open LLM Score (%)":"27.75*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0064,
        "Decode Throughput (tokens\/s)":167.0,
        "Allocated Memory (MB)":219,
        "Energy (tokens\/kWh)":2673796,
        "E2E Latency (s)":1.54,
        "E2E Throughput (tokens\/s)":166.0,
        "Reserved Memory (MB)":268,
        "Used Memory (MB)":1730
    },
    {
        "Model":"cerebras\/Cerebras-GPT-111M",
        "Arch":"GPT-2",
        "Params (B)":0.11,
        "Open LLM Score (%)":"27.75 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00707,
        "Decode Throughput (tokens\/s)":157.0,
        "Allocated Memory (MB)":592,
        "Energy (tokens\/kWh)":2364066,
        "E2E Latency (s)":1.63,
        "E2E Throughput (tokens\/s)":157.0,
        "Reserved Memory (MB)":675,
        "Used Memory (MB)":2126
    },
    {
        "Model":"cerebras\/Cerebras-GPT-111M",
        "Arch":"GPT-2",
        "Params (B)":0.11,
        "Open LLM Score (%)":"27.75*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0125,
        "Decode Throughput (tokens\/s)":131.0,
        "Allocated Memory (MB)":219,
        "Energy (tokens\/kWh)":2049180,
        "E2E Latency (s)":1.95,
        "E2E Throughput (tokens\/s)":131.0,
        "Reserved Memory (MB)":289,
        "Used Memory (MB)":1748
    },
    {
        "Model":"Locutusque\/TinyMistral-248m",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":0.25,
        "Open LLM Score (%)":"27.73 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.011,
        "Decode Throughput (tokens\/s)":90.4,
        "Allocated Memory (MB)":608,
        "Energy (tokens\/kWh)":1477104,
        "E2E Latency (s)":2.83,
        "E2E Throughput (tokens\/s)":90.5,
        "Reserved Memory (MB)":656,
        "Used Memory (MB)":2115
    },
    {
        "Model":"Locutusque\/TinyMistral-248m",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":0.25,
        "Open LLM Score (%)":"27.73 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0111,
        "Decode Throughput (tokens\/s)":83.9,
        "Allocated Memory (MB)":608,
        "Energy (tokens\/kWh)":1285347,
        "E2E Latency (s)":3.05,
        "E2E Throughput (tokens\/s)":83.9,
        "Reserved Memory (MB)":656,
        "Used Memory (MB)":2115
    },
    {
        "Model":"Locutusque\/TinyMistral-248m",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":0.25,
        "Open LLM Score (%)":"27.73 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0118,
        "Decode Throughput (tokens\/s)":87.9,
        "Allocated Memory (MB)":608,
        "Energy (tokens\/kWh)":1305483,
        "E2E Latency (s)":2.91,
        "E2E Throughput (tokens\/s)":88.0,
        "Reserved Memory (MB)":660,
        "Used Memory (MB)":2120
    },
    {
        "Model":"Locutusque\/TinyMistral-248m",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":0.25,
        "Open LLM Score (%)":"27.73*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0129,
        "Decode Throughput (tokens\/s)":85.9,
        "Allocated Memory (MB)":347,
        "Energy (tokens\/kWh)":1314060,
        "E2E Latency (s)":2.98,
        "E2E Throughput (tokens\/s)":85.9,
        "Reserved Memory (MB)":373,
        "Used Memory (MB)":1834
    },
    {
        "Model":"Locutusque\/TinyMistral-248m",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":0.25,
        "Open LLM Score (%)":"27.73*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0129,
        "Decode Throughput (tokens\/s)":84.4,
        "Allocated Memory (MB)":338,
        "Energy (tokens\/kWh)":1317523,
        "E2E Latency (s)":3.03,
        "E2E Throughput (tokens\/s)":84.5,
        "Reserved Memory (MB)":371,
        "Used Memory (MB)":1830
    },
    {
        "Model":"Locutusque\/TinyMistral-248m",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":0.25,
        "Open LLM Score (%)":"27.73*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0129,
        "Decode Throughput (tokens\/s)":75.7,
        "Allocated Memory (MB)":338,
        "Energy (tokens\/kWh)":1200480,
        "E2E Latency (s)":3.38,
        "E2E Throughput (tokens\/s)":75.7,
        "Reserved Memory (MB)":371,
        "Used Memory (MB)":1830
    },
    {
        "Model":"Locutusque\/TinyMistral-248m",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":0.25,
        "Open LLM Score (%)":"27.73 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.013,
        "Decode Throughput (tokens\/s)":97.0,
        "Allocated Memory (MB)":1153,
        "Energy (tokens\/kWh)":1416430,
        "E2E Latency (s)":2.64,
        "E2E Throughput (tokens\/s)":97.0,
        "Reserved Memory (MB)":1199,
        "Used Memory (MB)":2650
    },
    {
        "Model":"Locutusque\/TinyMistral-248m",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":0.25,
        "Open LLM Score (%)":"27.73*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0134,
        "Decode Throughput (tokens\/s)":81.5,
        "Allocated Memory (MB)":616,
        "Energy (tokens\/kWh)":1362397,
        "E2E Latency (s)":3.14,
        "E2E Throughput (tokens\/s)":81.5,
        "Reserved Memory (MB)":652,
        "Used Memory (MB)":2113
    },
    {
        "Model":"Locutusque\/TinyMistral-248m",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":0.25,
        "Open LLM Score (%)":"27.73*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0239,
        "Decode Throughput (tokens\/s)":51.4,
        "Allocated Memory (MB)":346,
        "Energy (tokens\/kWh)":781250,
        "E2E Latency (s)":4.98,
        "E2E Throughput (tokens\/s)":51.4,
        "Reserved Memory (MB)":396,
        "Used Memory (MB)":1855
    },
    {
        "Model":"Locutusque\/TinyMistral-248m",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":0.25,
        "Open LLM Score (%)":"27.73*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0241,
        "Decode Throughput (tokens\/s)":53.3,
        "Allocated Memory (MB)":346,
        "Energy (tokens\/kWh)":819672,
        "E2E Latency (s)":4.8,
        "E2E Throughput (tokens\/s)":53.3,
        "Reserved Memory (MB)":396,
        "Used Memory (MB)":1855
    },
    {
        "Model":"Locutusque\/TinyMistral-248m",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":0.25,
        "Open LLM Score (%)":"27.73*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0252,
        "Decode Throughput (tokens\/s)":66.4,
        "Allocated Memory (MB)":339,
        "Energy (tokens\/kWh)":1050420,
        "E2E Latency (s)":3.87,
        "E2E Throughput (tokens\/s)":66.1,
        "Reserved Memory (MB)":373,
        "Used Memory (MB)":1832
    },
    {
        "Model":"Locutusque\/TinyMistral-248m",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":0.25,
        "Open LLM Score (%)":"27.73*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0377,
        "Decode Throughput (tokens\/s)":25.6,
        "Allocated Memory (MB)":427,
        "Energy (tokens\/kWh)":408163,
        "E2E Latency (s)":10.0,
        "E2E Throughput (tokens\/s)":25.6,
        "Reserved Memory (MB)":465,
        "Used Memory (MB)":1933
    },
    {
        "Model":"Locutusque\/TinyMistral-248m",
        "Arch":"\u24c2\ufe0f Mistral",
        "Params (B)":0.25,
        "Open LLM Score (%)":"27.73*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0396,
        "Decode Throughput (tokens\/s)":25.6,
        "Allocated Memory (MB)":427,
        "Energy (tokens\/kWh)":384615,
        "E2E Latency (s)":10.0,
        "E2E Throughput (tokens\/s)":25.6,
        "Reserved Memory (MB)":465,
        "Used Memory (MB)":1933
    },
    {
        "Model":"ai-forever\/mGPT",
        "Arch":"GPT-2",
        "Params (B)":0.0,
        "Open LLM Score (%)":"27.61 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0135,
        "Decode Throughput (tokens\/s)":71.8,
        "Allocated Memory (MB)":3147,
        "Energy (tokens\/kWh)":980392,
        "E2E Latency (s)":3.56,
        "E2E Throughput (tokens\/s)":71.9,
        "Reserved Memory (MB)":3191,
        "Used Memory (MB)":4649
    },
    {
        "Model":"ai-forever\/mGPT",
        "Arch":"GPT-2",
        "Params (B)":0.0,
        "Open LLM Score (%)":"27.61 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0156,
        "Decode Throughput (tokens\/s)":64.4,
        "Allocated Memory (MB)":3147,
        "Energy (tokens\/kWh)":909090,
        "E2E Latency (s)":3.98,
        "E2E Throughput (tokens\/s)":64.3,
        "Reserved Memory (MB)":3191,
        "Used Memory (MB)":4651
    },
    {
        "Model":"ai-forever\/mGPT",
        "Arch":"GPT-2",
        "Params (B)":0.0,
        "Open LLM Score (%)":"27.61 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0159,
        "Decode Throughput (tokens\/s)":61.6,
        "Allocated Memory (MB)":3147,
        "Energy (tokens\/kWh)":884955,
        "E2E Latency (s)":4.16,
        "E2E Throughput (tokens\/s)":61.5,
        "Reserved Memory (MB)":3191,
        "Used Memory (MB)":4651
    },
    {
        "Model":"ai-forever\/mGPT",
        "Arch":"GPT-2",
        "Params (B)":0.0,
        "Open LLM Score (%)":"27.61*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0162,
        "Decode Throughput (tokens\/s)":66.9,
        "Allocated Memory (MB)":1392,
        "Energy (tokens\/kWh)":1004016,
        "E2E Latency (s)":3.83,
        "E2E Throughput (tokens\/s)":66.8,
        "Reserved Memory (MB)":1434,
        "Used Memory (MB)":2896
    },
    {
        "Model":"ai-forever\/mGPT",
        "Arch":"GPT-2",
        "Params (B)":0.0,
        "Open LLM Score (%)":"27.61*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0162,
        "Decode Throughput (tokens\/s)":63.3,
        "Allocated Memory (MB)":3147,
        "Energy (tokens\/kWh)":934579,
        "E2E Latency (s)":4.05,
        "E2E Throughput (tokens\/s)":63.2,
        "Reserved Memory (MB)":3191,
        "Used Memory (MB)":4649
    },
    {
        "Model":"ai-forever\/mGPT",
        "Arch":"GPT-2",
        "Params (B)":0.0,
        "Open LLM Score (%)":"27.61*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0165,
        "Decode Throughput (tokens\/s)":63.0,
        "Allocated Memory (MB)":3147,
        "Energy (tokens\/kWh)":892857,
        "E2E Latency (s)":4.07,
        "E2E Throughput (tokens\/s)":62.9,
        "Reserved Memory (MB)":3191,
        "Used Memory (MB)":4649
    },
    {
        "Model":"ai-forever\/mGPT",
        "Arch":"GPT-2",
        "Params (B)":0.0,
        "Open LLM Score (%)":"27.61*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit",
        "Prefill Latency (s)":0.0433,
        "Decode Throughput (tokens\/s)":51.2,
        "Allocated Memory (MB)":1360,
        "Energy (tokens\/kWh)":787401,
        "E2E Latency (s)":5.02,
        "E2E Throughput (tokens\/s)":51.0,
        "Reserved Memory (MB)":1390,
        "Used Memory (MB)":2849
    },
    {
        "Model":"team-lucid\/mptk-1b",
        "Arch":"\ud83e\uddf1 MPT",
        "Params (B)":1.31,
        "Open LLM Score (%)":"20.84 ",
        "DType":"pytorch",
        "Backend":"bfloat16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0116,
        "Decode Throughput (tokens\/s)":87.3,
        "Allocated Memory (MB)":2834,
        "Energy (tokens\/kWh)":1118568,
        "E2E Latency (s)":2.93,
        "E2E Throughput (tokens\/s)":87.4,
        "Reserved Memory (MB)":2856,
        "Used Memory (MB)":4315
    },
    {
        "Model":"team-lucid\/mptk-1b",
        "Arch":"\ud83e\uddf1 MPT",
        "Params (B)":1.31,
        "Open LLM Score (%)":"20.84 ",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.012,
        "Decode Throughput (tokens\/s)":85.3,
        "Allocated Memory (MB)":2834,
        "Energy (tokens\/kWh)":1137656,
        "E2E Latency (s)":3.0,
        "E2E Throughput (tokens\/s)":85.3,
        "Reserved Memory (MB)":2856,
        "Used Memory (MB)":4315
    },
    {
        "Model":"team-lucid\/mptk-1b",
        "Arch":"\ud83e\uddf1 MPT",
        "Params (B)":1.31,
        "Open LLM Score (%)":"20.84*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMV",
        "Prefill Latency (s)":0.0161,
        "Decode Throughput (tokens\/s)":84.2,
        "Allocated Memory (MB)":1046,
        "Energy (tokens\/kWh)":1250000,
        "E2E Latency (s)":3.05,
        "E2E Throughput (tokens\/s)":83.9,
        "Reserved Memory (MB)":1080,
        "Used Memory (MB)":2539
    },
    {
        "Model":"team-lucid\/mptk-1b",
        "Arch":"\ud83e\uddf1 MPT",
        "Params (B)":1.31,
        "Open LLM Score (%)":"20.84*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"AWQ.4bit+GEMM",
        "Prefill Latency (s)":0.0174,
        "Decode Throughput (tokens\/s)":76.6,
        "Allocated Memory (MB)":1046,
        "Energy (tokens\/kWh)":1114827,
        "E2E Latency (s)":3.35,
        "E2E Throughput (tokens\/s)":76.4,
        "Reserved Memory (MB)":1080,
        "Used Memory (MB)":2539
    },
    {
        "Model":"team-lucid\/mptk-1b",
        "Arch":"\ud83e\uddf1 MPT",
        "Params (B)":1.31,
        "Open LLM Score (%)":"20.84*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.8bit",
        "Prefill Latency (s)":0.0434,
        "Decode Throughput (tokens\/s)":22.8,
        "Allocated Memory (MB)":1628,
        "Energy (tokens\/kWh)":338983,
        "E2E Latency (s)":11.2,
        "E2E Throughput (tokens\/s)":22.9,
        "Reserved Memory (MB)":1658,
        "Used Memory (MB)":3126
    },
    {
        "Model":"team-lucid\/mptk-1b",
        "Arch":"\ud83e\uddf1 MPT",
        "Params (B)":1.31,
        "Open LLM Score (%)":"20.84 ",
        "DType":"pytorch",
        "Backend":"float32",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0508,
        "Decode Throughput (tokens\/s)":93.4,
        "Allocated Memory (MB)":5657,
        "Energy (tokens\/kWh)":1013171,
        "E2E Latency (s)":2.78,
        "E2E Throughput (tokens\/s)":92.1,
        "Reserved Memory (MB)":5697,
        "Used Memory (MB)":7149
    },
    {
        "Model":"team-lucid\/mptk-1b",
        "Arch":"\ud83e\uddf1 MPT",
        "Params (B)":1.31,
        "Open LLM Score (%)":"20.84*",
        "DType":"pytorch",
        "Backend":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0533,
        "Decode Throughput (tokens\/s)":47.0,
        "Allocated Memory (MB)":1099,
        "Energy (tokens\/kWh)":675675,
        "E2E Latency (s)":5.48,
        "E2E Throughput (tokens\/s)":46.7,
        "Reserved Memory (MB)":1151,
        "Used Memory (MB)":2610
    }
]