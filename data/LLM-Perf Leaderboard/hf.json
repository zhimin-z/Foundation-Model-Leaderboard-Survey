[
    {
        "Model":"01-ai\/Yi-34B",
        "Arch":"llama",
        "Params (B)":34.0,
        "Open LLM Score (%)":"69.42 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.125,
        "Decode Throughput (tokens\/s)":18.39,
        "Allocated Memory (MB)":69670,
        "Energy (tokens\/kWh)":165562.0,
        "E2E Latency (s)":54.5,
        "E2E Throughput (tokens\/s)":18.3,
        "Reserved Memory (MB)":69950,
        "Used Memory (MB)":71424
    },
    {
        "Model":"01-ai\/Yi-34B",
        "Arch":"llama",
        "Params (B)":34.0,
        "Open LLM Score (%)":"69.42 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.131,
        "Decode Throughput (tokens\/s)":18.36,
        "Allocated Memory (MB)":69670,
        "Energy (tokens\/kWh)":165289.0,
        "E2E Latency (s)":54.6,
        "E2E Throughput (tokens\/s)":18.3,
        "Reserved Memory (MB)":69950,
        "Used Memory (MB)":71424
    },
    {
        "Model":"01-ai\/Yi-34B",
        "Arch":"llama",
        "Params (B)":34.0,
        "Open LLM Score (%)":"69.42*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.16,
        "Decode Throughput (tokens\/s)":19.48,
        "Allocated Memory (MB)":20448,
        "Energy (tokens\/kWh)":208333.0,
        "E2E Latency (s)":51.5,
        "E2E Throughput (tokens\/s)":19.4,
        "Reserved Memory (MB)":20931,
        "Used Memory (MB)":22407
    },
    {
        "Model":"01-ai\/Yi-34B",
        "Arch":"llama",
        "Params (B)":34.0,
        "Open LLM Score (%)":"69.42*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.176,
        "Decode Throughput (tokens\/s)":15.52,
        "Allocated Memory (MB)":25613,
        "Energy (tokens\/kWh)":195312.0,
        "E2E Latency (s)":64.6,
        "E2E Throughput (tokens\/s)":15.5,
        "Reserved Memory (MB)":31715,
        "Used Memory (MB)":33191
    },
    {
        "Model":"01-ai\/Yi-34B",
        "Arch":"llama",
        "Params (B)":34.0,
        "Open LLM Score (%)":"69.42*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.192,
        "Decode Throughput (tokens\/s)":15.9,
        "Allocated Memory (MB)":21590,
        "Energy (tokens\/kWh)":168067.0,
        "E2E Latency (s)":63.1,
        "E2E Throughput (tokens\/s)":15.8,
        "Reserved Memory (MB)":21973,
        "Used Memory (MB)":23447
    },
    {
        "Model":"01-ai\/Yi-34B",
        "Arch":"llama",
        "Params (B)":34.0,
        "Open LLM Score (%)":"69.42*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.192,
        "Decode Throughput (tokens\/s)":15.57,
        "Allocated Memory (MB)":21590,
        "Energy (tokens\/kWh)":162866.0,
        "E2E Latency (s)":64.4,
        "E2E Throughput (tokens\/s)":15.5,
        "Reserved Memory (MB)":21973,
        "Used Memory (MB)":23447
    },
    {
        "Model":"meta-llama\/Llama-2-70b-hf",
        "Arch":"llama",
        "Params (B)":68.98,
        "Open LLM Score (%)":"67.87*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.321,
        "Decode Throughput (tokens\/s)":12.58,
        "Allocated Memory (MB)":38175,
        "Energy (tokens\/kWh)":116009.0,
        "E2E Latency (s)":79.8,
        "E2E Throughput (tokens\/s)":12.5,
        "Reserved Memory (MB)":38717,
        "Used Memory (MB)":40193
    },
    {
        "Model":"meta-llama\/Llama-2-70b-hf",
        "Arch":"llama",
        "Params (B)":68.98,
        "Open LLM Score (%)":"67.87*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.324,
        "Decode Throughput (tokens\/s)":13.21,
        "Allocated Memory (MB)":40080,
        "Energy (tokens\/kWh)":141643.0,
        "E2E Latency (s)":76.0,
        "E2E Throughput (tokens\/s)":13.2,
        "Reserved Memory (MB)":40621,
        "Used Memory (MB)":42097
    },
    {
        "Model":"meta-llama\/Llama-2-70b-hf",
        "Arch":"llama",
        "Params (B)":68.98,
        "Open LLM Score (%)":"67.87*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.382,
        "Decode Throughput (tokens\/s)":10.81,
        "Allocated Memory (MB)":40602,
        "Energy (tokens\/kWh)":94339.0,
        "E2E Latency (s)":92.9,
        "E2E Throughput (tokens\/s)":10.8,
        "Reserved Memory (MB)":41219,
        "Used Memory (MB)":42693
    },
    {
        "Model":"huggyllama\/llama-65b",
        "Arch":"llama",
        "Params (B)":65.29,
        "Open LLM Score (%)":"62.79*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.303,
        "Decode Throughput (tokens\/s)":12.77,
        "Allocated Memory (MB)":41896,
        "Energy (tokens\/kWh)":119474.0,
        "E2E Latency (s)":78.6,
        "E2E Throughput (tokens\/s)":12.7,
        "Reserved Memory (MB)":53676,
        "Used Memory (MB)":55152
    },
    {
        "Model":"huggyllama\/llama-65b",
        "Arch":"llama",
        "Params (B)":65.29,
        "Open LLM Score (%)":"62.79*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.31,
        "Decode Throughput (tokens\/s)":13.93,
        "Allocated Memory (MB)":43362,
        "Energy (tokens\/kWh)":150375.0,
        "E2E Latency (s)":72.1,
        "E2E Throughput (tokens\/s)":13.9,
        "Reserved Memory (MB)":55144,
        "Used Memory (MB)":56620
    },
    {
        "Model":"huggyllama\/llama-65b",
        "Arch":"llama",
        "Params (B)":65.29,
        "Open LLM Score (%)":"62.79*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.364,
        "Decode Throughput (tokens\/s)":11.52,
        "Allocated Memory (MB)":44280,
        "Energy (tokens\/kWh)":107066.0,
        "E2E Latency (s)":87.2,
        "E2E Throughput (tokens\/s)":11.5,
        "Reserved Memory (MB)":53389,
        "Used Memory (MB)":54863
    },
    {
        "Model":"huggingface\/llama-65b",
        "Arch":"llama",
        "Params (B)":65.29,
        "Open LLM Score (%)":"61.19*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.308,
        "Decode Throughput (tokens\/s)":12.69,
        "Allocated Memory (MB)":41896,
        "Energy (tokens\/kWh)":117647.0,
        "E2E Latency (s)":79.1,
        "E2E Throughput (tokens\/s)":12.6,
        "Reserved Memory (MB)":53676,
        "Used Memory (MB)":55152
    },
    {
        "Model":"huggingface\/llama-65b",
        "Arch":"llama",
        "Params (B)":65.29,
        "Open LLM Score (%)":"61.19*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.309,
        "Decode Throughput (tokens\/s)":13.93,
        "Allocated Memory (MB)":43362,
        "Energy (tokens\/kWh)":149700.0,
        "E2E Latency (s)":72.1,
        "E2E Throughput (tokens\/s)":13.9,
        "Reserved Memory (MB)":55144,
        "Used Memory (MB)":56620
    },
    {
        "Model":"huggingface\/llama-65b",
        "Arch":"llama",
        "Params (B)":65.29,
        "Open LLM Score (%)":"61.19*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.362,
        "Decode Throughput (tokens\/s)":11.32,
        "Allocated Memory (MB)":44280,
        "Energy (tokens\/kWh)":109051.0,
        "E2E Latency (s)":88.7,
        "E2E Throughput (tokens\/s)":11.3,
        "Reserved Memory (MB)":53389,
        "Used Memory (MB)":54863
    },
    {
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Arch":"mistral",
        "Params (B)":7.11,
        "Open LLM Score (%)":"60.97 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0364,
        "Decode Throughput (tokens\/s)":34.65,
        "Allocated Memory (MB)":15381,
        "Energy (tokens\/kWh)":383141.0,
        "E2E Latency (s)":28.9,
        "E2E Throughput (tokens\/s)":34.6,
        "Reserved Memory (MB)":15651,
        "Used Memory (MB)":17124
    },
    {
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Arch":"mistral",
        "Params (B)":7.11,
        "Open LLM Score (%)":"60.97 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0373,
        "Decode Throughput (tokens\/s)":35.13,
        "Allocated Memory (MB)":15381,
        "Energy (tokens\/kWh)":380228.0,
        "E2E Latency (s)":28.5,
        "E2E Throughput (tokens\/s)":35.1,
        "Reserved Memory (MB)":15651,
        "Used Memory (MB)":17124
    },
    {
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Arch":"mistral",
        "Params (B)":7.11,
        "Open LLM Score (%)":"60.97*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0453,
        "Decode Throughput (tokens\/s)":33.27,
        "Allocated Memory (MB)":5176,
        "Energy (tokens\/kWh)":413223.0,
        "E2E Latency (s)":30.1,
        "E2E Throughput (tokens\/s)":33.2,
        "Reserved Memory (MB)":5391,
        "Used Memory (MB)":6867
    },
    {
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Arch":"mistral",
        "Params (B)":7.11,
        "Open LLM Score (%)":"60.97*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0454,
        "Decode Throughput (tokens\/s)":32.94,
        "Allocated Memory (MB)":6120,
        "Energy (tokens\/kWh)":436681.0,
        "E2E Latency (s)":30.4,
        "E2E Throughput (tokens\/s)":32.9,
        "Reserved Memory (MB)":6337,
        "Used Memory (MB)":7813
    },
    {
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Arch":"mistral",
        "Params (B)":7.11,
        "Open LLM Score (%)":"60.97*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0519,
        "Decode Throughput (tokens\/s)":26.92,
        "Allocated Memory (MB)":5370,
        "Energy (tokens\/kWh)":358422.0,
        "E2E Latency (s)":37.2,
        "E2E Throughput (tokens\/s)":26.9,
        "Reserved Memory (MB)":5559,
        "Used Memory (MB)":7033
    },
    {
        "Model":"mistralai\/Mistral-7B-v0.1",
        "Arch":"mistral",
        "Params (B)":7.11,
        "Open LLM Score (%)":"60.97*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0532,
        "Decode Throughput (tokens\/s)":27.07,
        "Allocated Memory (MB)":5370,
        "Energy (tokens\/kWh)":331125.0,
        "E2E Latency (s)":37.0,
        "E2E Throughput (tokens\/s)":27.0,
        "Reserved Memory (MB)":5559,
        "Used Memory (MB)":7033
    },
    {
        "Model":"internlm\/internlm-20b",
        "Arch":"internlm",
        "Params (B)":20.0,
        "Open LLM Score (%)":"59.55 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0811,
        "Decode Throughput (tokens\/s)":18.11,
        "Allocated Memory (MB)":43749,
        "Energy (tokens\/kWh)":167785.0,
        "E2E Latency (s)":55.3,
        "E2E Throughput (tokens\/s)":18.1,
        "Reserved Memory (MB)":46898,
        "Used Memory (MB)":48372
    },
    {
        "Model":"internlm\/internlm-20b",
        "Arch":"internlm",
        "Params (B)":20.0,
        "Open LLM Score (%)":"59.55 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0837,
        "Decode Throughput (tokens\/s)":18.21,
        "Allocated Memory (MB)":43749,
        "Energy (tokens\/kWh)":167224.0,
        "E2E Latency (s)":55.0,
        "E2E Throughput (tokens\/s)":18.2,
        "Reserved Memory (MB)":46898,
        "Used Memory (MB)":48372
    },
    {
        "Model":"internlm\/internlm-20b",
        "Arch":"internlm",
        "Params (B)":20.0,
        "Open LLM Score (%)":"59.55*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.103,
        "Decode Throughput (tokens\/s)":17.21,
        "Allocated Memory (MB)":15676,
        "Energy (tokens\/kWh)":202429.0,
        "E2E Latency (s)":58.2,
        "E2E Throughput (tokens\/s)":17.2,
        "Reserved Memory (MB)":18918,
        "Used Memory (MB)":20394
    },
    {
        "Model":"internlm\/internlm-20b",
        "Arch":"internlm",
        "Params (B)":20.0,
        "Open LLM Score (%)":"59.55*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.107,
        "Decode Throughput (tokens\/s)":17.04,
        "Allocated Memory (MB)":16593,
        "Energy (tokens\/kWh)":206611.0,
        "E2E Latency (s)":58.8,
        "E2E Throughput (tokens\/s)":17.0,
        "Reserved Memory (MB)":19834,
        "Used Memory (MB)":21310
    },
    {
        "Model":"internlm\/internlm-20b",
        "Arch":"internlm",
        "Params (B)":20.0,
        "Open LLM Score (%)":"59.55*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.121,
        "Decode Throughput (tokens\/s)":14.29,
        "Allocated Memory (MB)":16273,
        "Energy (tokens\/kWh)":162601.0,
        "E2E Latency (s)":70.1,
        "E2E Throughput (tokens\/s)":14.3,
        "Reserved Memory (MB)":18679,
        "Used Memory (MB)":20153
    },
    {
        "Model":"internlm\/internlm-20b",
        "Arch":"internlm",
        "Params (B)":20.0,
        "Open LLM Score (%)":"59.55*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.122,
        "Decode Throughput (tokens\/s)":14.15,
        "Allocated Memory (MB)":16273,
        "Energy (tokens\/kWh)":165016.0,
        "E2E Latency (s)":70.8,
        "E2E Throughput (tokens\/s)":14.1,
        "Reserved Memory (MB)":18679,
        "Used Memory (MB)":20153
    },
    {
        "Model":"huggingface\/llama-30b",
        "Arch":"llama",
        "Params (B)":32.53,
        "Open LLM Score (%)":"56.94 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.126,
        "Decode Throughput (tokens\/s)":17.77,
        "Allocated Memory (MB)":69241,
        "Energy (tokens\/kWh)":161030.0,
        "E2E Latency (s)":56.4,
        "E2E Throughput (tokens\/s)":17.7,
        "Reserved Memory (MB)":73417,
        "Used Memory (MB)":74890
    },
    {
        "Model":"huggingface\/llama-30b",
        "Arch":"llama",
        "Params (B)":32.53,
        "Open LLM Score (%)":"56.94 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.127,
        "Decode Throughput (tokens\/s)":17.52,
        "Allocated Memory (MB)":69241,
        "Energy (tokens\/kWh)":157977.0,
        "E2E Latency (s)":57.2,
        "E2E Throughput (tokens\/s)":17.5,
        "Reserved Memory (MB)":73417,
        "Used Memory (MB)":74890
    },
    {
        "Model":"huggingface\/llama-30b",
        "Arch":"llama",
        "Params (B)":32.53,
        "Open LLM Score (%)":"56.94 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.13,
        "Decode Throughput (tokens\/s)":17.49,
        "Allocated Memory (MB)":69241,
        "Energy (tokens\/kWh)":157728.0,
        "E2E Latency (s)":57.3,
        "E2E Throughput (tokens\/s)":17.5,
        "Reserved Memory (MB)":73417,
        "Used Memory (MB)":74890
    },
    {
        "Model":"huggingface\/llama-30b",
        "Arch":"llama",
        "Params (B)":32.53,
        "Open LLM Score (%)":"56.94*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.16,
        "Decode Throughput (tokens\/s)":18.75,
        "Allocated Memory (MB)":22110,
        "Energy (tokens\/kWh)":190839.0,
        "E2E Latency (s)":53.5,
        "E2E Throughput (tokens\/s)":18.7,
        "Reserved Memory (MB)":26128,
        "Used Memory (MB)":27604
    },
    {
        "Model":"huggingface\/llama-30b",
        "Arch":"llama",
        "Params (B)":32.53,
        "Open LLM Score (%)":"56.94*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.164,
        "Decode Throughput (tokens\/s)":19.0,
        "Allocated Memory (MB)":23298,
        "Energy (tokens\/kWh)":218340.0,
        "E2E Latency (s)":52.8,
        "E2E Throughput (tokens\/s)":18.9,
        "Reserved Memory (MB)":27315,
        "Used Memory (MB)":28791
    },
    {
        "Model":"huggingface\/llama-30b",
        "Arch":"llama",
        "Params (B)":32.53,
        "Open LLM Score (%)":"56.94*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.185,
        "Decode Throughput (tokens\/s)":15.57,
        "Allocated Memory (MB)":23006,
        "Energy (tokens\/kWh)":167785.0,
        "E2E Latency (s)":64.4,
        "E2E Throughput (tokens\/s)":15.5,
        "Reserved Memory (MB)":26357,
        "Used Memory (MB)":27830
    },
    {
        "Model":"meta-llama\/Llama-2-13b-hf",
        "Arch":"llama",
        "Params (B)":13.02,
        "Open LLM Score (%)":"55.69 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0514,
        "Decode Throughput (tokens\/s)":33.62,
        "Allocated Memory (MB)":28305,
        "Energy (tokens\/kWh)":300300.0,
        "E2E Latency (s)":29.8,
        "E2E Throughput (tokens\/s)":33.6,
        "Reserved Memory (MB)":30104,
        "Used Memory (MB)":31578
    },
    {
        "Model":"meta-llama\/Llama-2-13b-hf",
        "Arch":"llama",
        "Params (B)":13.02,
        "Open LLM Score (%)":"55.69 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0539,
        "Decode Throughput (tokens\/s)":29.99,
        "Allocated Memory (MB)":28305,
        "Energy (tokens\/kWh)":277008.0,
        "E2E Latency (s)":33.4,
        "E2E Throughput (tokens\/s)":29.9,
        "Reserved Memory (MB)":30148,
        "Used Memory (MB)":31622
    },
    {
        "Model":"meta-llama\/Llama-2-13b-hf",
        "Arch":"llama",
        "Params (B)":13.02,
        "Open LLM Score (%)":"55.69 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0558,
        "Decode Throughput (tokens\/s)":29.72,
        "Allocated Memory (MB)":28305,
        "Energy (tokens\/kWh)":280112.0,
        "E2E Latency (s)":33.7,
        "E2E Throughput (tokens\/s)":29.7,
        "Reserved Memory (MB)":30148,
        "Used Memory (MB)":31622
    },
    {
        "Model":"meta-llama\/Llama-2-13b-hf",
        "Arch":"llama",
        "Params (B)":13.02,
        "Open LLM Score (%)":"55.69*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0692,
        "Decode Throughput (tokens\/s)":28.14,
        "Allocated Memory (MB)":9637,
        "Energy (tokens\/kWh)":323624.0,
        "E2E Latency (s)":35.6,
        "E2E Throughput (tokens\/s)":28.1,
        "Reserved Memory (MB)":11544,
        "Used Memory (MB)":13020
    },
    {
        "Model":"meta-llama\/Llama-2-13b-hf",
        "Arch":"llama",
        "Params (B)":13.02,
        "Open LLM Score (%)":"55.69*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0702,
        "Decode Throughput (tokens\/s)":27.01,
        "Allocated Memory (MB)":10550,
        "Energy (tokens\/kWh)":344827.0,
        "E2E Latency (s)":37.1,
        "E2E Throughput (tokens\/s)":27.0,
        "Reserved Memory (MB)":12457,
        "Used Memory (MB)":13932
    },
    {
        "Model":"meta-llama\/Llama-2-13b-hf",
        "Arch":"llama",
        "Params (B)":13.02,
        "Open LLM Score (%)":"55.69*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0793,
        "Decode Throughput (tokens\/s)":23.08,
        "Allocated Memory (MB)":9996,
        "Energy (tokens\/kWh)":284090.0,
        "E2E Latency (s)":43.4,
        "E2E Throughput (tokens\/s)":23.0,
        "Reserved Memory (MB)":11542,
        "Used Memory (MB)":13016
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Arch":"llama",
        "Params (B)":6.06,
        "Open LLM Score (%)":"54.08 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0286,
        "Decode Throughput (tokens\/s)":39.26,
        "Allocated Memory (MB)":12433,
        "Energy (tokens\/kWh)":450450.0,
        "E2E Latency (s)":25.5,
        "E2E Throughput (tokens\/s)":39.2,
        "Reserved Memory (MB)":12593,
        "Used Memory (MB)":14067
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Arch":"llama",
        "Params (B)":6.06,
        "Open LLM Score (%)":"54.08 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0345,
        "Decode Throughput (tokens\/s)":31.88,
        "Allocated Memory (MB)":13608,
        "Energy (tokens\/kWh)":373134.0,
        "E2E Latency (s)":31.4,
        "E2E Throughput (tokens\/s)":31.8,
        "Reserved Memory (MB)":13650,
        "Used Memory (MB)":15124
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Arch":"llama",
        "Params (B)":6.06,
        "Open LLM Score (%)":"54.08*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0359,
        "Decode Throughput (tokens\/s)":35.38,
        "Allocated Memory (MB)":4384,
        "Energy (tokens\/kWh)":462962.0,
        "E2E Latency (s)":28.3,
        "E2E Throughput (tokens\/s)":35.3,
        "Reserved Memory (MB)":4546,
        "Used Memory (MB)":6022
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Arch":"llama",
        "Params (B)":6.06,
        "Open LLM Score (%)":"54.08*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0447,
        "Decode Throughput (tokens\/s)":29.89,
        "Allocated Memory (MB)":6284,
        "Energy (tokens\/kWh)":404858.0,
        "E2E Latency (s)":33.5,
        "E2E Throughput (tokens\/s)":29.9,
        "Reserved Memory (MB)":6335,
        "Used Memory (MB)":7811
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Arch":"llama",
        "Params (B)":6.06,
        "Open LLM Score (%)":"54.08*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0453,
        "Decode Throughput (tokens\/s)":29.36,
        "Allocated Memory (MB)":4506,
        "Energy (tokens\/kWh)":401606.0,
        "E2E Latency (s)":34.1,
        "E2E Throughput (tokens\/s)":29.3,
        "Reserved Memory (MB)":4668,
        "Used Memory (MB)":6142
    },
    {
        "Model":"01-ai\/Yi-6B",
        "Arch":"llama",
        "Params (B)":6.06,
        "Open LLM Score (%)":"54.08*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0467,
        "Decode Throughput (tokens\/s)":28.94,
        "Allocated Memory (MB)":4506,
        "Energy (tokens\/kWh)":398406.0,
        "E2E Latency (s)":34.6,
        "E2E Throughput (tokens\/s)":28.9,
        "Reserved Memory (MB)":4668,
        "Used Memory (MB)":6142
    },
    {
        "Model":"TheBloke\/Llama-2-13B-fp16",
        "Arch":"llama",
        "Params (B)":12.85,
        "Open LLM Score (%)":"53.67 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0508,
        "Decode Throughput (tokens\/s)":33.17,
        "Allocated Memory (MB)":28305,
        "Energy (tokens\/kWh)":297619.0,
        "E2E Latency (s)":30.2,
        "E2E Throughput (tokens\/s)":33.1,
        "Reserved Memory (MB)":30104,
        "Used Memory (MB)":31578
    },
    {
        "Model":"TheBloke\/Llama-2-13B-fp16",
        "Arch":"llama",
        "Params (B)":12.85,
        "Open LLM Score (%)":"53.67 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0524,
        "Decode Throughput (tokens\/s)":29.11,
        "Allocated Memory (MB)":28305,
        "Energy (tokens\/kWh)":289017.0,
        "E2E Latency (s)":34.4,
        "E2E Throughput (tokens\/s)":29.1,
        "Reserved Memory (MB)":30148,
        "Used Memory (MB)":31622
    },
    {
        "Model":"TheBloke\/Llama-2-13B-fp16",
        "Arch":"llama",
        "Params (B)":12.85,
        "Open LLM Score (%)":"53.67 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0539,
        "Decode Throughput (tokens\/s)":29.55,
        "Allocated Memory (MB)":28305,
        "Energy (tokens\/kWh)":276243.0,
        "E2E Latency (s)":33.9,
        "E2E Throughput (tokens\/s)":29.5,
        "Reserved Memory (MB)":30148,
        "Used Memory (MB)":31622
    },
    {
        "Model":"TheBloke\/Llama-2-13B-fp16",
        "Arch":"llama",
        "Params (B)":12.85,
        "Open LLM Score (%)":"53.67*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0693,
        "Decode Throughput (tokens\/s)":28.14,
        "Allocated Memory (MB)":9637,
        "Energy (tokens\/kWh)":322580.0,
        "E2E Latency (s)":35.6,
        "E2E Throughput (tokens\/s)":28.1,
        "Reserved Memory (MB)":11544,
        "Used Memory (MB)":13020
    },
    {
        "Model":"TheBloke\/Llama-2-13B-fp16",
        "Arch":"llama",
        "Params (B)":12.85,
        "Open LLM Score (%)":"53.67*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0702,
        "Decode Throughput (tokens\/s)":28.88,
        "Allocated Memory (MB)":10550,
        "Energy (tokens\/kWh)":355871.0,
        "E2E Latency (s)":34.7,
        "E2E Throughput (tokens\/s)":28.8,
        "Reserved Memory (MB)":12457,
        "Used Memory (MB)":13932
    },
    {
        "Model":"TheBloke\/Llama-2-13B-fp16",
        "Arch":"llama",
        "Params (B)":12.85,
        "Open LLM Score (%)":"53.67*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0795,
        "Decode Throughput (tokens\/s)":23.46,
        "Allocated Memory (MB)":9996,
        "Energy (tokens\/kWh)":290697.0,
        "E2E Latency (s)":42.7,
        "E2E Throughput (tokens\/s)":23.4,
        "Reserved Memory (MB)":11542,
        "Used Memory (MB)":13016
    },
    {
        "Model":"TigerResearch\/tigerbot-13b-base",
        "Arch":"llama",
        "Params (B)":13.0,
        "Open LLM Score (%)":"53.42 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0871,
        "Decode Throughput (tokens\/s)":13.57,
        "Allocated Memory (MB)":28858,
        "Energy (tokens\/kWh)":156250.0,
        "E2E Latency (s)":73.8,
        "E2E Throughput (tokens\/s)":13.6,
        "Reserved Memory (MB)":30647,
        "Used Memory (MB)":32121
    },
    {
        "Model":"TigerResearch\/tigerbot-13b-base",
        "Arch":"llama",
        "Params (B)":13.0,
        "Open LLM Score (%)":"53.42 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0877,
        "Decode Throughput (tokens\/s)":12.82,
        "Allocated Memory (MB)":28858,
        "Energy (tokens\/kWh)":149925.0,
        "E2E Latency (s)":78.1,
        "E2E Throughput (tokens\/s)":12.8,
        "Reserved Memory (MB)":30664,
        "Used Memory (MB)":32138
    },
    {
        "Model":"TigerResearch\/tigerbot-13b-base",
        "Arch":"llama",
        "Params (B)":13.0,
        "Open LLM Score (%)":"53.42 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.089,
        "Decode Throughput (tokens\/s)":12.87,
        "Allocated Memory (MB)":28858,
        "Energy (tokens\/kWh)":151515.0,
        "E2E Latency (s)":77.8,
        "E2E Throughput (tokens\/s)":12.9,
        "Reserved Memory (MB)":30664,
        "Used Memory (MB)":32138
    },
    {
        "Model":"huggingface\/llama-13b",
        "Arch":"llama",
        "Params (B)":13.02,
        "Open LLM Score (%)":"51.36 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0512,
        "Decode Throughput (tokens\/s)":32.63,
        "Allocated Memory (MB)":28263,
        "Energy (tokens\/kWh)":300300.0,
        "E2E Latency (s)":30.7,
        "E2E Throughput (tokens\/s)":32.6,
        "Reserved Memory (MB)":30062,
        "Used Memory (MB)":31536
    },
    {
        "Model":"huggingface\/llama-13b",
        "Arch":"llama",
        "Params (B)":13.02,
        "Open LLM Score (%)":"51.36 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0534,
        "Decode Throughput (tokens\/s)":30.35,
        "Allocated Memory (MB)":28264,
        "Energy (tokens\/kWh)":282485.0,
        "E2E Latency (s)":33.0,
        "E2E Throughput (tokens\/s)":30.3,
        "Reserved Memory (MB)":30106,
        "Used Memory (MB)":31580
    },
    {
        "Model":"huggingface\/llama-13b",
        "Arch":"llama",
        "Params (B)":13.02,
        "Open LLM Score (%)":"51.36 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.054,
        "Decode Throughput (tokens\/s)":30.35,
        "Allocated Memory (MB)":28264,
        "Energy (tokens\/kWh)":289017.0,
        "E2E Latency (s)":33.0,
        "E2E Throughput (tokens\/s)":30.3,
        "Reserved Memory (MB)":30106,
        "Used Memory (MB)":31580
    },
    {
        "Model":"huggingface\/llama-13b",
        "Arch":"llama",
        "Params (B)":13.02,
        "Open LLM Score (%)":"51.36*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0694,
        "Decode Throughput (tokens\/s)":26.79,
        "Allocated Memory (MB)":9595,
        "Energy (tokens\/kWh)":324675.0,
        "E2E Latency (s)":37.4,
        "E2E Throughput (tokens\/s)":26.7,
        "Reserved Memory (MB)":11502,
        "Used Memory (MB)":12978
    },
    {
        "Model":"huggingface\/llama-13b",
        "Arch":"llama",
        "Params (B)":13.02,
        "Open LLM Score (%)":"51.36*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0699,
        "Decode Throughput (tokens\/s)":28.47,
        "Allocated Memory (MB)":10508,
        "Energy (tokens\/kWh)":353356.0,
        "E2E Latency (s)":35.2,
        "E2E Throughput (tokens\/s)":28.4,
        "Reserved Memory (MB)":12415,
        "Used Memory (MB)":13891
    },
    {
        "Model":"huggingface\/llama-13b",
        "Arch":"llama",
        "Params (B)":13.02,
        "Open LLM Score (%)":"51.36*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0791,
        "Decode Throughput (tokens\/s)":22.98,
        "Allocated Memory (MB)":9954,
        "Energy (tokens\/kWh)":287356.0,
        "E2E Latency (s)":43.6,
        "E2E Throughput (tokens\/s)":22.9,
        "Reserved Memory (MB)":11500,
        "Used Memory (MB)":12974
    },
    {
        "Model":"huggingface\/llama-13b",
        "Arch":"llama",
        "Params (B)":13.02,
        "Open LLM Score (%)":"51.36*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0807,
        "Decode Throughput (tokens\/s)":22.93,
        "Allocated Memory (MB)":9954,
        "Energy (tokens\/kWh)":271002.0,
        "E2E Latency (s)":43.7,
        "E2E Throughput (tokens\/s)":22.9,
        "Reserved Memory (MB)":11500,
        "Used Memory (MB)":12974
    },
    {
        "Model":"huggyllama\/llama-13b",
        "Arch":"llama",
        "Params (B)":13.02,
        "Open LLM Score (%)":"51.33 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.051,
        "Decode Throughput (tokens\/s)":32.95,
        "Allocated Memory (MB)":28263,
        "Energy (tokens\/kWh)":306748.0,
        "E2E Latency (s)":30.4,
        "E2E Throughput (tokens\/s)":32.9,
        "Reserved Memory (MB)":30062,
        "Used Memory (MB)":31536
    },
    {
        "Model":"huggyllama\/llama-13b",
        "Arch":"llama",
        "Params (B)":13.02,
        "Open LLM Score (%)":"51.33 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0532,
        "Decode Throughput (tokens\/s)":30.17,
        "Allocated Memory (MB)":28264,
        "Energy (tokens\/kWh)":279329.0,
        "E2E Latency (s)":33.2,
        "E2E Throughput (tokens\/s)":30.1,
        "Reserved Memory (MB)":30106,
        "Used Memory (MB)":31580
    },
    {
        "Model":"huggyllama\/llama-13b",
        "Arch":"llama",
        "Params (B)":13.02,
        "Open LLM Score (%)":"51.33 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.054,
        "Decode Throughput (tokens\/s)":30.63,
        "Allocated Memory (MB)":28264,
        "Energy (tokens\/kWh)":279329.0,
        "E2E Latency (s)":32.7,
        "E2E Throughput (tokens\/s)":30.6,
        "Reserved Memory (MB)":30106,
        "Used Memory (MB)":31580
    },
    {
        "Model":"huggyllama\/llama-13b",
        "Arch":"llama",
        "Params (B)":13.02,
        "Open LLM Score (%)":"51.33*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0706,
        "Decode Throughput (tokens\/s)":28.23,
        "Allocated Memory (MB)":9595,
        "Energy (tokens\/kWh)":324675.0,
        "E2E Latency (s)":35.5,
        "E2E Throughput (tokens\/s)":28.2,
        "Reserved Memory (MB)":11502,
        "Used Memory (MB)":12978
    },
    {
        "Model":"huggyllama\/llama-13b",
        "Arch":"llama",
        "Params (B)":13.02,
        "Open LLM Score (%)":"51.33*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0715,
        "Decode Throughput (tokens\/s)":27.76,
        "Allocated Memory (MB)":10508,
        "Energy (tokens\/kWh)":352112.0,
        "E2E Latency (s)":36.1,
        "E2E Throughput (tokens\/s)":27.7,
        "Reserved Memory (MB)":12415,
        "Used Memory (MB)":13891
    },
    {
        "Model":"huggyllama\/llama-13b",
        "Arch":"llama",
        "Params (B)":13.02,
        "Open LLM Score (%)":"51.33*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.079,
        "Decode Throughput (tokens\/s)":23.08,
        "Allocated Memory (MB)":9954,
        "Energy (tokens\/kWh)":288184.0,
        "E2E Latency (s)":43.4,
        "E2E Throughput (tokens\/s)":23.0,
        "Reserved Memory (MB)":11500,
        "Used Memory (MB)":12974
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"llama",
        "Params (B)":6.74,
        "Open LLM Score (%)":"50.97 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.032,
        "Decode Throughput (tokens\/s)":42.25,
        "Allocated Memory (MB)":14895,
        "Energy (tokens\/kWh)":444444.0,
        "E2E Latency (s)":23.7,
        "E2E Throughput (tokens\/s)":42.2,
        "Reserved Memory (MB)":14942,
        "Used Memory (MB)":16415
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"llama",
        "Params (B)":6.74,
        "Open LLM Score (%)":"50.97 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0332,
        "Decode Throughput (tokens\/s)":37.64,
        "Allocated Memory (MB)":14895,
        "Energy (tokens\/kWh)":423728.0,
        "E2E Latency (s)":26.6,
        "E2E Throughput (tokens\/s)":37.6,
        "Reserved Memory (MB)":14942,
        "Used Memory (MB)":16415
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"llama",
        "Params (B)":6.74,
        "Open LLM Score (%)":"50.97 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.034,
        "Decode Throughput (tokens\/s)":38.66,
        "Allocated Memory (MB)":14895,
        "Energy (tokens\/kWh)":395256.0,
        "E2E Latency (s)":25.9,
        "E2E Throughput (tokens\/s)":38.6,
        "Reserved Memory (MB)":14942,
        "Used Memory (MB)":16415
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"llama",
        "Params (B)":6.74,
        "Open LLM Score (%)":"50.97*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.042,
        "Decode Throughput (tokens\/s)":35.14,
        "Allocated Memory (MB)":5455,
        "Energy (tokens\/kWh)":421940.0,
        "E2E Latency (s)":28.5,
        "E2E Throughput (tokens\/s)":35.1,
        "Reserved Memory (MB)":5750,
        "Used Memory (MB)":7226
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"llama",
        "Params (B)":6.74,
        "Open LLM Score (%)":"50.97*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0433,
        "Decode Throughput (tokens\/s)":35.27,
        "Allocated Memory (MB)":6180,
        "Energy (tokens\/kWh)":462962.0,
        "E2E Latency (s)":28.4,
        "E2E Throughput (tokens\/s)":35.2,
        "Reserved Memory (MB)":6478,
        "Used Memory (MB)":7953
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"llama",
        "Params (B)":6.74,
        "Open LLM Score (%)":"50.97*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0456,
        "Decode Throughput (tokens\/s)":31.59,
        "Allocated Memory (MB)":5615,
        "Energy (tokens\/kWh)":401606.0,
        "E2E Latency (s)":31.7,
        "E2E Throughput (tokens\/s)":31.5,
        "Reserved Memory (MB)":5748,
        "Used Memory (MB)":7222
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"llama",
        "Params (B)":6.74,
        "Open LLM Score (%)":"50.97*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.047,
        "Decode Throughput (tokens\/s)":28.77,
        "Allocated Memory (MB)":5615,
        "Energy (tokens\/kWh)":387596.0,
        "E2E Latency (s)":34.8,
        "E2E Throughput (tokens\/s)":28.7,
        "Reserved Memory (MB)":5760,
        "Used Memory (MB)":7234
    },
    {
        "Model":"meta-llama\/Llama-2-7b-hf",
        "Arch":"llama",
        "Params (B)":6.74,
        "Open LLM Score (%)":"50.97*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0482,
        "Decode Throughput (tokens\/s)":29.03,
        "Allocated Memory (MB)":5615,
        "Energy (tokens\/kWh)":369003.0,
        "E2E Latency (s)":34.5,
        "E2E Throughput (tokens\/s)":29.0,
        "Reserved Memory (MB)":5760,
        "Used Memory (MB)":7234
    },
    {
        "Model":"microsoft\/phi-1_5",
        "Arch":"phi-msft",
        "Params (B)":0.0,
        "Open LLM Score (%)":"47.69 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0255,
        "Decode Throughput (tokens\/s)":38.8,
        "Allocated Memory (MB)":3329,
        "Energy (tokens\/kWh)":581395.0,
        "E2E Latency (s)":25.8,
        "E2E Throughput (tokens\/s)":38.8,
        "Reserved Memory (MB)":3399,
        "Used Memory (MB)":4873
    },
    {
        "Model":"microsoft\/phi-1_5",
        "Arch":"phi-msft",
        "Params (B)":0.0,
        "Open LLM Score (%)":"47.69 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0264,
        "Decode Throughput (tokens\/s)":37.77,
        "Allocated Memory (MB)":3329,
        "Energy (tokens\/kWh)":552486.0,
        "E2E Latency (s)":26.5,
        "E2E Throughput (tokens\/s)":37.7,
        "Reserved Memory (MB)":3399,
        "Used Memory (MB)":4873
    },
    {
        "Model":"microsoft\/phi-1_5",
        "Arch":"phi-msft",
        "Params (B)":0.0,
        "Open LLM Score (%)":"47.69*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0352,
        "Decode Throughput (tokens\/s)":33.6,
        "Allocated Memory (MB)":1600,
        "Energy (tokens\/kWh)":515463.0,
        "E2E Latency (s)":29.8,
        "E2E Throughput (tokens\/s)":33.6,
        "Reserved Memory (MB)":1656,
        "Used Memory (MB)":3130
    },
    {
        "Model":"microsoft\/phi-1_5",
        "Arch":"phi-msft",
        "Params (B)":0.0,
        "Open LLM Score (%)":"47.69*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0354,
        "Decode Throughput (tokens\/s)":33.37,
        "Allocated Memory (MB)":1600,
        "Energy (tokens\/kWh)":518134.0,
        "E2E Latency (s)":30.0,
        "E2E Throughput (tokens\/s)":33.3,
        "Reserved Memory (MB)":1656,
        "Used Memory (MB)":3130
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"llama",
        "Params (B)":6.76,
        "Open LLM Score (%)":"47.64 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0326,
        "Decode Throughput (tokens\/s)":42.43,
        "Allocated Memory (MB)":15456,
        "Energy (tokens\/kWh)":440528.0,
        "E2E Latency (s)":23.6,
        "E2E Throughput (tokens\/s)":42.4,
        "Reserved Memory (MB)":15497,
        "Used Memory (MB)":16971
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"llama",
        "Params (B)":6.76,
        "Open LLM Score (%)":"47.64 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0344,
        "Decode Throughput (tokens\/s)":38.22,
        "Allocated Memory (MB)":15456,
        "Energy (tokens\/kWh)":411522.0,
        "E2E Latency (s)":26.2,
        "E2E Throughput (tokens\/s)":38.2,
        "Reserved Memory (MB)":15497,
        "Used Memory (MB)":16971
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"llama",
        "Params (B)":6.76,
        "Open LLM Score (%)":"47.64 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0349,
        "Decode Throughput (tokens\/s)":38.37,
        "Allocated Memory (MB)":15456,
        "Energy (tokens\/kWh)":396825.0,
        "E2E Latency (s)":26.1,
        "E2E Throughput (tokens\/s)":38.3,
        "Reserved Memory (MB)":15497,
        "Used Memory (MB)":16971
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"llama",
        "Params (B)":6.76,
        "Open LLM Score (%)":"47.64*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0435,
        "Decode Throughput (tokens\/s)":34.3,
        "Allocated Memory (MB)":6017,
        "Energy (tokens\/kWh)":431034.0,
        "E2E Latency (s)":29.2,
        "E2E Throughput (tokens\/s)":34.2,
        "Reserved Memory (MB)":6327,
        "Used Memory (MB)":7802
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"llama",
        "Params (B)":6.76,
        "Open LLM Score (%)":"47.64*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0444,
        "Decode Throughput (tokens\/s)":35.27,
        "Allocated Memory (MB)":6743,
        "Energy (tokens\/kWh)":454545.0,
        "E2E Latency (s)":28.4,
        "E2E Throughput (tokens\/s)":35.2,
        "Reserved Memory (MB)":7054,
        "Used Memory (MB)":8530
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"llama",
        "Params (B)":6.76,
        "Open LLM Score (%)":"47.64*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0484,
        "Decode Throughput (tokens\/s)":28.45,
        "Allocated Memory (MB)":6178,
        "Energy (tokens\/kWh)":354609.0,
        "E2E Latency (s)":35.2,
        "E2E Throughput (tokens\/s)":28.4,
        "Reserved Memory (MB)":6327,
        "Used Memory (MB)":7800
    },
    {
        "Model":"golaxy\/gowizardlm",
        "Arch":"llama",
        "Params (B)":6.76,
        "Open LLM Score (%)":"47.64*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0485,
        "Decode Throughput (tokens\/s)":28.61,
        "Allocated Memory (MB)":6178,
        "Energy (tokens\/kWh)":383141.0,
        "E2E Latency (s)":35.0,
        "E2E Throughput (tokens\/s)":28.6,
        "Reserved Memory (MB)":6327,
        "Used Memory (MB)":7800
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"llama",
        "Params (B)":12.85,
        "Open LLM Score (%)":"47.26 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0524,
        "Decode Throughput (tokens\/s)":33.62,
        "Allocated Memory (MB)":28263,
        "Energy (tokens\/kWh)":298507.0,
        "E2E Latency (s)":29.8,
        "E2E Throughput (tokens\/s)":33.6,
        "Reserved Memory (MB)":30062,
        "Used Memory (MB)":31536
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"llama",
        "Params (B)":12.85,
        "Open LLM Score (%)":"47.26 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0529,
        "Decode Throughput (tokens\/s)":29.9,
        "Allocated Memory (MB)":28264,
        "Energy (tokens\/kWh)":287356.0,
        "E2E Latency (s)":33.5,
        "E2E Throughput (tokens\/s)":29.9,
        "Reserved Memory (MB)":30106,
        "Used Memory (MB)":31580
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"llama",
        "Params (B)":12.85,
        "Open LLM Score (%)":"47.26 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0546,
        "Decode Throughput (tokens\/s)":29.46,
        "Allocated Memory (MB)":28264,
        "Energy (tokens\/kWh)":278551.0,
        "E2E Latency (s)":34.0,
        "E2E Throughput (tokens\/s)":29.4,
        "Reserved Memory (MB)":30106,
        "Used Memory (MB)":31580
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"llama",
        "Params (B)":12.85,
        "Open LLM Score (%)":"47.26*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0695,
        "Decode Throughput (tokens\/s)":28.07,
        "Allocated Memory (MB)":9595,
        "Energy (tokens\/kWh)":327868.0,
        "E2E Latency (s)":35.7,
        "E2E Throughput (tokens\/s)":28.0,
        "Reserved Memory (MB)":11502,
        "Used Memory (MB)":12978
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"llama",
        "Params (B)":12.85,
        "Open LLM Score (%)":"47.26*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0713,
        "Decode Throughput (tokens\/s)":28.23,
        "Allocated Memory (MB)":10508,
        "Energy (tokens\/kWh)":358422.0,
        "E2E Latency (s)":35.5,
        "E2E Throughput (tokens\/s)":28.2,
        "Reserved Memory (MB)":12415,
        "Used Memory (MB)":13891
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"llama",
        "Params (B)":12.85,
        "Open LLM Score (%)":"47.26*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0775,
        "Decode Throughput (tokens\/s)":25.3,
        "Allocated Memory (MB)":9953,
        "Energy (tokens\/kWh)":295857.0,
        "E2E Latency (s)":39.6,
        "E2E Throughput (tokens\/s)":25.3,
        "Reserved Memory (MB)":11452,
        "Used Memory (MB)":12926
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"llama",
        "Params (B)":12.85,
        "Open LLM Score (%)":"47.26*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0794,
        "Decode Throughput (tokens\/s)":22.82,
        "Allocated Memory (MB)":9954,
        "Energy (tokens\/kWh)":281690.0,
        "E2E Latency (s)":43.9,
        "E2E Throughput (tokens\/s)":22.8,
        "Reserved Memory (MB)":11500,
        "Used Memory (MB)":12974
    },
    {
        "Model":"openlm-research\/open_llama_13b",
        "Arch":"llama",
        "Params (B)":12.85,
        "Open LLM Score (%)":"47.26*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0807,
        "Decode Throughput (tokens\/s)":22.77,
        "Allocated Memory (MB)":9954,
        "Energy (tokens\/kWh)":268817.0,
        "E2E Latency (s)":44.0,
        "E2E Throughput (tokens\/s)":22.7,
        "Reserved Memory (MB)":11500,
        "Used Memory (MB)":12974
    },
    {
        "Model":"stabilityai\/stablelm-3b-4e1t",
        "Arch":"stablelm_epoch",
        "Params (B)":2.8,
        "Open LLM Score (%)":"46.58 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0228,
        "Decode Throughput (tokens\/s)":42.78,
        "Allocated Memory (MB)":6458,
        "Energy (tokens\/kWh)":543478.0,
        "E2E Latency (s)":23.4,
        "E2E Throughput (tokens\/s)":42.7,
        "Reserved Memory (MB)":6750,
        "Used Memory (MB)":8224
    },
    {
        "Model":"stabilityai\/stablelm-3b-4e1t",
        "Arch":"stablelm_epoch",
        "Params (B)":2.8,
        "Open LLM Score (%)":"46.58 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0232,
        "Decode Throughput (tokens\/s)":42.24,
        "Allocated Memory (MB)":6458,
        "Energy (tokens\/kWh)":555555.0,
        "E2E Latency (s)":23.7,
        "E2E Throughput (tokens\/s)":42.2,
        "Reserved Memory (MB)":6750,
        "Used Memory (MB)":8224
    },
    {
        "Model":"stabilityai\/stablelm-3b-4e1t",
        "Arch":"stablelm_epoch",
        "Params (B)":2.8,
        "Open LLM Score (%)":"46.58*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0271,
        "Decode Throughput (tokens\/s)":40.7,
        "Allocated Memory (MB)":3172,
        "Energy (tokens\/kWh)":558659.0,
        "E2E Latency (s)":24.6,
        "E2E Throughput (tokens\/s)":40.7,
        "Reserved Memory (MB)":3336,
        "Used Memory (MB)":4812
    },
    {
        "Model":"stabilityai\/stablelm-3b-4e1t",
        "Arch":"stablelm_epoch",
        "Params (B)":2.8,
        "Open LLM Score (%)":"46.58*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0273,
        "Decode Throughput (tokens\/s)":40.37,
        "Allocated Memory (MB)":2716,
        "Energy (tokens\/kWh)":549450.0,
        "E2E Latency (s)":24.8,
        "E2E Throughput (tokens\/s)":40.3,
        "Reserved Memory (MB)":2879,
        "Used Memory (MB)":4355
    },
    {
        "Model":"stabilityai\/stablelm-3b-4e1t",
        "Arch":"stablelm_epoch",
        "Params (B)":2.8,
        "Open LLM Score (%)":"46.58*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0427,
        "Decode Throughput (tokens\/s)":32.3,
        "Allocated Memory (MB)":2627,
        "Energy (tokens\/kWh)":442477.0,
        "E2E Latency (s)":31.0,
        "E2E Throughput (tokens\/s)":32.3,
        "Reserved Memory (MB)":2755,
        "Used Memory (MB)":4229
    },
    {
        "Model":"stabilityai\/stablelm-3b-4e1t",
        "Arch":"stablelm_epoch",
        "Params (B)":2.8,
        "Open LLM Score (%)":"46.58*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0441,
        "Decode Throughput (tokens\/s)":31.89,
        "Allocated Memory (MB)":2627,
        "Energy (tokens\/kWh)":452488.0,
        "E2E Latency (s)":31.4,
        "E2E Throughput (tokens\/s)":31.8,
        "Reserved Memory (MB)":2755,
        "Used Memory (MB)":4229
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b-v2",
        "Arch":"stablelm_alpha",
        "Params (B)":6.89,
        "Open LLM Score (%)":"46.18 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0302,
        "Decode Throughput (tokens\/s)":42.79,
        "Allocated Memory (MB)":15178,
        "Energy (tokens\/kWh)":442477.0,
        "E2E Latency (s)":23.4,
        "E2E Throughput (tokens\/s)":42.7,
        "Reserved Memory (MB)":15210,
        "Used Memory (MB)":16684
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b-v2",
        "Arch":"stablelm_alpha",
        "Params (B)":6.89,
        "Open LLM Score (%)":"46.18 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0316,
        "Decode Throughput (tokens\/s)":43.54,
        "Allocated Memory (MB)":15178,
        "Energy (tokens\/kWh)":429184.0,
        "E2E Latency (s)":23.0,
        "E2E Throughput (tokens\/s)":43.5,
        "Reserved Memory (MB)":15210,
        "Used Memory (MB)":16684
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b-v2",
        "Arch":"stablelm_alpha",
        "Params (B)":6.89,
        "Open LLM Score (%)":"46.18*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0434,
        "Decode Throughput (tokens\/s)":34.65,
        "Allocated Memory (MB)":5869,
        "Energy (tokens\/kWh)":446428.0,
        "E2E Latency (s)":28.9,
        "E2E Throughput (tokens\/s)":34.6,
        "Reserved Memory (MB)":6069,
        "Used Memory (MB)":7542
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b-v2",
        "Arch":"stablelm_alpha",
        "Params (B)":6.89,
        "Open LLM Score (%)":"46.18*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0442,
        "Decode Throughput (tokens\/s)":35.9,
        "Allocated Memory (MB)":5869,
        "Energy (tokens\/kWh)":432900.0,
        "E2E Latency (s)":27.9,
        "E2E Throughput (tokens\/s)":35.8,
        "Reserved Memory (MB)":6069,
        "Used Memory (MB)":7542
    },
    {
        "Model":"huggingface\/llama-7b",
        "Arch":"llama",
        "Params (B)":6.74,
        "Open LLM Score (%)":"45.65 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.032,
        "Decode Throughput (tokens\/s)":42.07,
        "Allocated Memory (MB)":14861,
        "Energy (tokens\/kWh)":436681.0,
        "E2E Latency (s)":23.8,
        "E2E Throughput (tokens\/s)":42.0,
        "Reserved Memory (MB)":14908,
        "Used Memory (MB)":16382
    },
    {
        "Model":"huggingface\/llama-7b",
        "Arch":"llama",
        "Params (B)":6.74,
        "Open LLM Score (%)":"45.65 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0334,
        "Decode Throughput (tokens\/s)":37.93,
        "Allocated Memory (MB)":14861,
        "Energy (tokens\/kWh)":432900.0,
        "E2E Latency (s)":26.4,
        "E2E Throughput (tokens\/s)":37.9,
        "Reserved Memory (MB)":14908,
        "Used Memory (MB)":16382
    },
    {
        "Model":"huggingface\/llama-7b",
        "Arch":"llama",
        "Params (B)":6.74,
        "Open LLM Score (%)":"45.65 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.034,
        "Decode Throughput (tokens\/s)":38.66,
        "Allocated Memory (MB)":14861,
        "Energy (tokens\/kWh)":404858.0,
        "E2E Latency (s)":25.9,
        "E2E Throughput (tokens\/s)":38.6,
        "Reserved Memory (MB)":14908,
        "Used Memory (MB)":16382
    },
    {
        "Model":"huggingface\/llama-7b",
        "Arch":"llama",
        "Params (B)":6.74,
        "Open LLM Score (%)":"45.65*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0428,
        "Decode Throughput (tokens\/s)":35.9,
        "Allocated Memory (MB)":5421,
        "Energy (tokens\/kWh)":444444.0,
        "E2E Latency (s)":27.9,
        "E2E Throughput (tokens\/s)":35.8,
        "Reserved Memory (MB)":5716,
        "Used Memory (MB)":7192
    },
    {
        "Model":"huggingface\/llama-7b",
        "Arch":"llama",
        "Params (B)":6.74,
        "Open LLM Score (%)":"45.65*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0434,
        "Decode Throughput (tokens\/s)":34.53,
        "Allocated Memory (MB)":6147,
        "Energy (tokens\/kWh)":442477.0,
        "E2E Latency (s)":29.0,
        "E2E Throughput (tokens\/s)":34.5,
        "Reserved Memory (MB)":6444,
        "Used Memory (MB)":7920
    },
    {
        "Model":"huggingface\/llama-7b",
        "Arch":"llama",
        "Params (B)":6.74,
        "Open LLM Score (%)":"45.65*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0459,
        "Decode Throughput (tokens\/s)":30.81,
        "Allocated Memory (MB)":5582,
        "Energy (tokens\/kWh)":395256.0,
        "E2E Latency (s)":32.5,
        "E2E Throughput (tokens\/s)":30.8,
        "Reserved Memory (MB)":5714,
        "Used Memory (MB)":7188
    },
    {
        "Model":"huggingface\/llama-7b",
        "Arch":"llama",
        "Params (B)":6.74,
        "Open LLM Score (%)":"45.65*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.047,
        "Decode Throughput (tokens\/s)":29.11,
        "Allocated Memory (MB)":5581,
        "Energy (tokens\/kWh)":386100.0,
        "E2E Latency (s)":34.4,
        "E2E Throughput (tokens\/s)":29.1,
        "Reserved Memory (MB)":5727,
        "Used Memory (MB)":7201
    },
    {
        "Model":"huggingface\/llama-7b",
        "Arch":"llama",
        "Params (B)":6.74,
        "Open LLM Score (%)":"45.65*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0479,
        "Decode Throughput (tokens\/s)":28.53,
        "Allocated Memory (MB)":5581,
        "Energy (tokens\/kWh)":370370.0,
        "E2E Latency (s)":35.1,
        "E2E Throughput (tokens\/s)":28.5,
        "Reserved Memory (MB)":5727,
        "Used Memory (MB)":7201
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"llama",
        "Params (B)":6.61,
        "Open LLM Score (%)":"45.62 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0319,
        "Decode Throughput (tokens\/s)":42.98,
        "Allocated Memory (MB)":14861,
        "Energy (tokens\/kWh)":462962.0,
        "E2E Latency (s)":23.3,
        "E2E Throughput (tokens\/s)":42.9,
        "Reserved Memory (MB)":14908,
        "Used Memory (MB)":16382
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"llama",
        "Params (B)":6.61,
        "Open LLM Score (%)":"45.62 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0331,
        "Decode Throughput (tokens\/s)":38.07,
        "Allocated Memory (MB)":14861,
        "Energy (tokens\/kWh)":429184.0,
        "E2E Latency (s)":26.3,
        "E2E Throughput (tokens\/s)":38.0,
        "Reserved Memory (MB)":14908,
        "Used Memory (MB)":16382
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"llama",
        "Params (B)":6.61,
        "Open LLM Score (%)":"45.62 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0339,
        "Decode Throughput (tokens\/s)":38.81,
        "Allocated Memory (MB)":14861,
        "Energy (tokens\/kWh)":414937.0,
        "E2E Latency (s)":25.8,
        "E2E Throughput (tokens\/s)":38.8,
        "Reserved Memory (MB)":14908,
        "Used Memory (MB)":16382
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"llama",
        "Params (B)":6.61,
        "Open LLM Score (%)":"45.62*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0426,
        "Decode Throughput (tokens\/s)":34.65,
        "Allocated Memory (MB)":6147,
        "Energy (tokens\/kWh)":452488.0,
        "E2E Latency (s)":28.9,
        "E2E Throughput (tokens\/s)":34.6,
        "Reserved Memory (MB)":6444,
        "Used Memory (MB)":7920
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"llama",
        "Params (B)":6.61,
        "Open LLM Score (%)":"45.62*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0428,
        "Decode Throughput (tokens\/s)":34.77,
        "Allocated Memory (MB)":5421,
        "Energy (tokens\/kWh)":429184.0,
        "E2E Latency (s)":28.8,
        "E2E Throughput (tokens\/s)":34.7,
        "Reserved Memory (MB)":5716,
        "Used Memory (MB)":7192
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"llama",
        "Params (B)":6.61,
        "Open LLM Score (%)":"45.62*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0458,
        "Decode Throughput (tokens\/s)":30.91,
        "Allocated Memory (MB)":5582,
        "Energy (tokens\/kWh)":392156.0,
        "E2E Latency (s)":32.4,
        "E2E Throughput (tokens\/s)":30.9,
        "Reserved Memory (MB)":5714,
        "Used Memory (MB)":7188
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"llama",
        "Params (B)":6.61,
        "Open LLM Score (%)":"45.62*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0474,
        "Decode Throughput (tokens\/s)":28.45,
        "Allocated Memory (MB)":5581,
        "Energy (tokens\/kWh)":371747.0,
        "E2E Latency (s)":35.2,
        "E2E Throughput (tokens\/s)":28.4,
        "Reserved Memory (MB)":5727,
        "Used Memory (MB)":7201
    },
    {
        "Model":"DevaMalla\/llama-base-7b",
        "Arch":"llama",
        "Params (B)":6.61,
        "Open LLM Score (%)":"45.62*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0476,
        "Decode Throughput (tokens\/s)":28.29,
        "Allocated Memory (MB)":5581,
        "Energy (tokens\/kWh)":373134.0,
        "E2E Latency (s)":35.4,
        "E2E Throughput (tokens\/s)":28.2,
        "Reserved Memory (MB)":5727,
        "Used Memory (MB)":7201
    },
    {
        "Model":"mosaicml\/mpt-7b",
        "Arch":"mpt",
        "Params (B)":6.65,
        "Open LLM Score (%)":"44.28 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0277,
        "Decode Throughput (tokens\/s)":61.83,
        "Allocated Memory (MB)":14649,
        "Energy (tokens\/kWh)":568181.0,
        "E2E Latency (s)":16.2,
        "E2E Throughput (tokens\/s)":61.7,
        "Reserved Memory (MB)":14669,
        "Used Memory (MB)":16143
    },
    {
        "Model":"mosaicml\/mpt-7b",
        "Arch":"mpt",
        "Params (B)":6.65,
        "Open LLM Score (%)":"44.28 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0279,
        "Decode Throughput (tokens\/s)":61.08,
        "Allocated Memory (MB)":14649,
        "Energy (tokens\/kWh)":540540.0,
        "E2E Latency (s)":16.4,
        "E2E Throughput (tokens\/s)":61.0,
        "Reserved Memory (MB)":14669,
        "Used Memory (MB)":16143
    },
    {
        "Model":"mosaicml\/mpt-7b",
        "Arch":"mpt",
        "Params (B)":6.65,
        "Open LLM Score (%)":"44.28*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0402,
        "Decode Throughput (tokens\/s)":47.94,
        "Allocated Memory (MB)":5395,
        "Energy (tokens\/kWh)":564971.0,
        "E2E Latency (s)":20.9,
        "E2E Throughput (tokens\/s)":47.8,
        "Reserved Memory (MB)":5481,
        "Used Memory (MB)":6955
    },
    {
        "Model":"mosaicml\/mpt-7b",
        "Arch":"mpt",
        "Params (B)":6.65,
        "Open LLM Score (%)":"44.28*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0405,
        "Decode Throughput (tokens\/s)":48.88,
        "Allocated Memory (MB)":5395,
        "Energy (tokens\/kWh)":552486.0,
        "E2E Latency (s)":20.5,
        "E2E Throughput (tokens\/s)":48.8,
        "Reserved Memory (MB)":5481,
        "Used Memory (MB)":6955
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"llama",
        "Params (B)":6.61,
        "Open LLM Score (%)":"44.26 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.032,
        "Decode Throughput (tokens\/s)":42.98,
        "Allocated Memory (MB)":14861,
        "Energy (tokens\/kWh)":460829.0,
        "E2E Latency (s)":23.3,
        "E2E Throughput (tokens\/s)":42.9,
        "Reserved Memory (MB)":14908,
        "Used Memory (MB)":16382
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"llama",
        "Params (B)":6.61,
        "Open LLM Score (%)":"44.26 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0341,
        "Decode Throughput (tokens\/s)":37.93,
        "Allocated Memory (MB)":14861,
        "Energy (tokens\/kWh)":418410.0,
        "E2E Latency (s)":26.4,
        "E2E Throughput (tokens\/s)":37.9,
        "Reserved Memory (MB)":14908,
        "Used Memory (MB)":16382
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"llama",
        "Params (B)":6.61,
        "Open LLM Score (%)":"44.26 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0349,
        "Decode Throughput (tokens\/s)":38.96,
        "Allocated Memory (MB)":14861,
        "Energy (tokens\/kWh)":414937.0,
        "E2E Latency (s)":25.7,
        "E2E Throughput (tokens\/s)":38.9,
        "Reserved Memory (MB)":14908,
        "Used Memory (MB)":16382
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"llama",
        "Params (B)":6.61,
        "Open LLM Score (%)":"44.26*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0419,
        "Decode Throughput (tokens\/s)":35.02,
        "Allocated Memory (MB)":5421,
        "Energy (tokens\/kWh)":431034.0,
        "E2E Latency (s)":28.6,
        "E2E Throughput (tokens\/s)":35.0,
        "Reserved Memory (MB)":5716,
        "Used Memory (MB)":7192
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"llama",
        "Params (B)":6.61,
        "Open LLM Score (%)":"44.26*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0424,
        "Decode Throughput (tokens\/s)":34.41,
        "Allocated Memory (MB)":6147,
        "Energy (tokens\/kWh)":460829.0,
        "E2E Latency (s)":29.1,
        "E2E Throughput (tokens\/s)":34.4,
        "Reserved Memory (MB)":6444,
        "Used Memory (MB)":7920
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"llama",
        "Params (B)":6.61,
        "Open LLM Score (%)":"44.26*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0459,
        "Decode Throughput (tokens\/s)":31.29,
        "Allocated Memory (MB)":5582,
        "Energy (tokens\/kWh)":392156.0,
        "E2E Latency (s)":32.0,
        "E2E Throughput (tokens\/s)":31.2,
        "Reserved Memory (MB)":5714,
        "Used Memory (MB)":7188
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"llama",
        "Params (B)":6.61,
        "Open LLM Score (%)":"44.26*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0471,
        "Decode Throughput (tokens\/s)":28.69,
        "Allocated Memory (MB)":5581,
        "Energy (tokens\/kWh)":378787.0,
        "E2E Latency (s)":34.9,
        "E2E Throughput (tokens\/s)":28.7,
        "Reserved Memory (MB)":5727,
        "Used Memory (MB)":7201
    },
    {
        "Model":"openlm-research\/open_llama_7b_v2",
        "Arch":"llama",
        "Params (B)":6.61,
        "Open LLM Score (%)":"44.26*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0473,
        "Decode Throughput (tokens\/s)":28.94,
        "Allocated Memory (MB)":5581,
        "Energy (tokens\/kWh)":370370.0,
        "E2E Latency (s)":34.6,
        "E2E Throughput (tokens\/s)":28.9,
        "Reserved Memory (MB)":5727,
        "Used Memory (MB)":7201
    },
    {
        "Model":"tiiuae\/falcon-7b",
        "Arch":"falcon",
        "Params (B)":6.92,
        "Open LLM Score (%)":"44.17 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0348,
        "Decode Throughput (tokens\/s)":39.9,
        "Allocated Memory (MB)":13945,
        "Energy (tokens\/kWh)":448430.0,
        "E2E Latency (s)":25.1,
        "E2E Throughput (tokens\/s)":39.8,
        "Reserved Memory (MB)":14088,
        "Used Memory (MB)":15562
    },
    {
        "Model":"tiiuae\/falcon-7b",
        "Arch":"falcon",
        "Params (B)":6.92,
        "Open LLM Score (%)":"44.17 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.035,
        "Decode Throughput (tokens\/s)":39.58,
        "Allocated Memory (MB)":13945,
        "Energy (tokens\/kWh)":429184.0,
        "E2E Latency (s)":25.3,
        "E2E Throughput (tokens\/s)":39.5,
        "Reserved Memory (MB)":14088,
        "Used Memory (MB)":15562
    },
    {
        "Model":"tiiuae\/falcon-7b",
        "Arch":"falcon",
        "Params (B)":6.92,
        "Open LLM Score (%)":"44.17*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0519,
        "Decode Throughput (tokens\/s)":36.97,
        "Allocated Memory (MB)":4558,
        "Energy (tokens\/kWh)":456621.0,
        "E2E Latency (s)":27.1,
        "E2E Throughput (tokens\/s)":36.9,
        "Reserved Memory (MB)":4655,
        "Used Memory (MB)":6129
    },
    {
        "Model":"tiiuae\/falcon-7b",
        "Arch":"falcon",
        "Params (B)":6.92,
        "Open LLM Score (%)":"44.17*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0521,
        "Decode Throughput (tokens\/s)":36.84,
        "Allocated Memory (MB)":4558,
        "Energy (tokens\/kWh)":469483.0,
        "E2E Latency (s)":27.2,
        "E2E Throughput (tokens\/s)":36.8,
        "Reserved Memory (MB)":4655,
        "Used Memory (MB)":6129
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"llama",
        "Params (B)":13.02,
        "Open LLM Score (%)":"43.35 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0507,
        "Decode Throughput (tokens\/s)":32.21,
        "Allocated Memory (MB)":28557,
        "Energy (tokens\/kWh)":298507.0,
        "E2E Latency (s)":31.1,
        "E2E Throughput (tokens\/s)":32.2,
        "Reserved Memory (MB)":30356,
        "Used Memory (MB)":31830
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"llama",
        "Params (B)":13.02,
        "Open LLM Score (%)":"43.35 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0533,
        "Decode Throughput (tokens\/s)":29.72,
        "Allocated Memory (MB)":28557,
        "Energy (tokens\/kWh)":287356.0,
        "E2E Latency (s)":33.7,
        "E2E Throughput (tokens\/s)":29.7,
        "Reserved Memory (MB)":30400,
        "Used Memory (MB)":31874
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"llama",
        "Params (B)":13.02,
        "Open LLM Score (%)":"43.35 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0546,
        "Decode Throughput (tokens\/s)":28.95,
        "Allocated Memory (MB)":28557,
        "Energy (tokens\/kWh)":274725.0,
        "E2E Latency (s)":34.6,
        "E2E Throughput (tokens\/s)":28.9,
        "Reserved Memory (MB)":30400,
        "Used Memory (MB)":31874
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"llama",
        "Params (B)":13.02,
        "Open LLM Score (%)":"43.35*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0707,
        "Decode Throughput (tokens\/s)":28.63,
        "Allocated Memory (MB)":9889,
        "Energy (tokens\/kWh)":330033.0,
        "E2E Latency (s)":35.0,
        "E2E Throughput (tokens\/s)":28.6,
        "Reserved Memory (MB)":11771,
        "Used Memory (MB)":13247
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"llama",
        "Params (B)":13.02,
        "Open LLM Score (%)":"43.35*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0716,
        "Decode Throughput (tokens\/s)":27.99,
        "Allocated Memory (MB)":10802,
        "Energy (tokens\/kWh)":348432.0,
        "E2E Latency (s)":35.8,
        "E2E Throughput (tokens\/s)":27.9,
        "Reserved Memory (MB)":12683,
        "Used Memory (MB)":14159
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"llama",
        "Params (B)":13.02,
        "Open LLM Score (%)":"43.35*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0776,
        "Decode Throughput (tokens\/s)":25.17,
        "Allocated Memory (MB)":10251,
        "Energy (tokens\/kWh)":301204.0,
        "E2E Latency (s)":39.8,
        "E2E Throughput (tokens\/s)":25.1,
        "Reserved Memory (MB)":11794,
        "Used Memory (MB)":13268
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"llama",
        "Params (B)":13.02,
        "Open LLM Score (%)":"43.35*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0796,
        "Decode Throughput (tokens\/s)":22.72,
        "Allocated Memory (MB)":10251,
        "Energy (tokens\/kWh)":280112.0,
        "E2E Latency (s)":44.1,
        "E2E Throughput (tokens\/s)":22.7,
        "Reserved Memory (MB)":11794,
        "Used Memory (MB)":13268
    },
    {
        "Model":"codellama\/CodeLlama-13b-hf",
        "Arch":"llama",
        "Params (B)":13.02,
        "Open LLM Score (%)":"43.35*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0808,
        "Decode Throughput (tokens\/s)":23.52,
        "Allocated Memory (MB)":10251,
        "Energy (tokens\/kWh)":268817.0,
        "E2E Latency (s)":42.6,
        "E2E Throughput (tokens\/s)":23.5,
        "Reserved Memory (MB)":11794,
        "Used Memory (MB)":13268
    },
    {
        "Model":"facebook\/opt-66b",
        "Arch":"opt",
        "Params (B)":65.72,
        "Open LLM Score (%)":"42.78*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.278,
        "Decode Throughput (tokens\/s)":22.46,
        "Allocated Memory (MB)":43999,
        "Energy (tokens\/kWh)":207468.0,
        "E2E Latency (s)":44.8,
        "E2E Throughput (tokens\/s)":22.3,
        "Reserved Memory (MB)":63464,
        "Used Memory (MB)":64939
    },
    {
        "Model":"facebook\/opt-66b",
        "Arch":"opt",
        "Params (B)":65.72,
        "Open LLM Score (%)":"42.78*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.284,
        "Decode Throughput (tokens\/s)":14.0,
        "Allocated Memory (MB)":41562,
        "Energy (tokens\/kWh)":131233.0,
        "E2E Latency (s)":71.7,
        "E2E Throughput (tokens\/s)":13.9,
        "Reserved Memory (MB)":61022,
        "Used Memory (MB)":62498
    },
    {
        "Model":"facebook\/opt-66b",
        "Arch":"opt",
        "Params (B)":65.72,
        "Open LLM Score (%)":"42.78*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.339,
        "Decode Throughput (tokens\/s)":14.82,
        "Allocated Memory (MB)":43600,
        "Energy (tokens\/kWh)":133689.0,
        "E2E Latency (s)":67.8,
        "E2E Throughput (tokens\/s)":14.7,
        "Reserved Memory (MB)":58466,
        "Used Memory (MB)":59938
    },
    {
        "Model":"facebook\/opt-66b",
        "Arch":"opt",
        "Params (B)":65.72,
        "Open LLM Score (%)":"42.78*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.348,
        "Decode Throughput (tokens\/s)":13.08,
        "Allocated Memory (MB)":43601,
        "Energy (tokens\/kWh)":119331.0,
        "E2E Latency (s)":76.8,
        "E2E Throughput (tokens\/s)":13.0,
        "Reserved Memory (MB)":58466,
        "Used Memory (MB)":59940
    },
    {
        "Model":"facebook\/opt-66b",
        "Arch":"opt",
        "Params (B)":65.72,
        "Open LLM Score (%)":"42.78*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.358,
        "Decode Throughput (tokens\/s)":12.83,
        "Allocated Memory (MB)":43601,
        "Energy (tokens\/kWh)":112994.0,
        "E2E Latency (s)":78.3,
        "E2E Throughput (tokens\/s)":12.8,
        "Reserved Memory (MB)":58466,
        "Used Memory (MB)":59940
    },
    {
        "Model":"Salesforce\/codegen-16B-nl",
        "Arch":"codegen",
        "Params (B)":15.72,
        "Open LLM Score (%)":"42.59 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0612,
        "Decode Throughput (tokens\/s)":27.07,
        "Allocated Memory (MB)":34377,
        "Energy (tokens\/kWh)":246305.0,
        "E2E Latency (s)":37.0,
        "E2E Throughput (tokens\/s)":27.0,
        "Reserved Memory (MB)":36962,
        "Used Memory (MB)":38436
    },
    {
        "Model":"Salesforce\/codegen-16B-nl",
        "Arch":"codegen",
        "Params (B)":15.72,
        "Open LLM Score (%)":"42.59 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0634,
        "Decode Throughput (tokens\/s)":25.62,
        "Allocated Memory (MB)":34361,
        "Energy (tokens\/kWh)":240963.0,
        "E2E Latency (s)":39.1,
        "E2E Throughput (tokens\/s)":25.6,
        "Reserved Memory (MB)":36951,
        "Used Memory (MB)":38425
    },
    {
        "Model":"Salesforce\/codegen-16B-nl",
        "Arch":"codegen",
        "Params (B)":15.72,
        "Open LLM Score (%)":"42.59 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0648,
        "Decode Throughput (tokens\/s)":25.17,
        "Allocated Memory (MB)":34361,
        "Energy (tokens\/kWh)":231481.0,
        "E2E Latency (s)":39.8,
        "E2E Throughput (tokens\/s)":25.1,
        "Reserved Memory (MB)":36951,
        "Used Memory (MB)":38425
    },
    {
        "Model":"Salesforce\/codegen-16B-nl",
        "Arch":"codegen",
        "Params (B)":15.72,
        "Open LLM Score (%)":"42.59*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0814,
        "Decode Throughput (tokens\/s)":25.3,
        "Allocated Memory (MB)":11871,
        "Energy (tokens\/kWh)":293255.0,
        "E2E Latency (s)":39.6,
        "E2E Throughput (tokens\/s)":25.3,
        "Reserved Memory (MB)":14487,
        "Used Memory (MB)":15962
    },
    {
        "Model":"Salesforce\/codegen-16B-nl",
        "Arch":"codegen",
        "Params (B)":15.72,
        "Open LLM Score (%)":"42.59*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0821,
        "Decode Throughput (tokens\/s)":25.63,
        "Allocated Memory (MB)":13487,
        "Energy (tokens\/kWh)":323624.0,
        "E2E Latency (s)":39.1,
        "E2E Throughput (tokens\/s)":25.6,
        "Reserved Memory (MB)":16106,
        "Used Memory (MB)":17581
    },
    {
        "Model":"Salesforce\/codegen-16B-nl",
        "Arch":"codegen",
        "Params (B)":15.72,
        "Open LLM Score (%)":"42.59*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0936,
        "Decode Throughput (tokens\/s)":24.21,
        "Allocated Memory (MB)":12250,
        "Energy (tokens\/kWh)":270270.0,
        "E2E Latency (s)":41.4,
        "E2E Throughput (tokens\/s)":24.2,
        "Reserved Memory (MB)":13929,
        "Used Memory (MB)":15403
    },
    {
        "Model":"Salesforce\/codegen-16B-nl",
        "Arch":"codegen",
        "Params (B)":15.72,
        "Open LLM Score (%)":"42.59*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0978,
        "Decode Throughput (tokens\/s)":22.93,
        "Allocated Memory (MB)":12235,
        "Energy (tokens\/kWh)":263157.0,
        "E2E Latency (s)":43.7,
        "E2E Throughput (tokens\/s)":22.9,
        "Reserved Memory (MB)":13885,
        "Used Memory (MB)":15358
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"llama",
        "Params (B)":6.61,
        "Open LLM Score (%)":"42.31 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0322,
        "Decode Throughput (tokens\/s)":40.21,
        "Allocated Memory (MB)":14861,
        "Energy (tokens\/kWh)":452488.0,
        "E2E Latency (s)":24.9,
        "E2E Throughput (tokens\/s)":40.2,
        "Reserved Memory (MB)":14908,
        "Used Memory (MB)":16382
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"llama",
        "Params (B)":6.61,
        "Open LLM Score (%)":"42.31 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0334,
        "Decode Throughput (tokens\/s)":38.51,
        "Allocated Memory (MB)":14861,
        "Energy (tokens\/kWh)":431034.0,
        "E2E Latency (s)":26.0,
        "E2E Throughput (tokens\/s)":38.5,
        "Reserved Memory (MB)":14908,
        "Used Memory (MB)":16382
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"llama",
        "Params (B)":6.61,
        "Open LLM Score (%)":"42.31 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0338,
        "Decode Throughput (tokens\/s)":37.93,
        "Allocated Memory (MB)":14861,
        "Energy (tokens\/kWh)":411522.0,
        "E2E Latency (s)":26.4,
        "E2E Throughput (tokens\/s)":37.9,
        "Reserved Memory (MB)":14908,
        "Used Memory (MB)":16382
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"llama",
        "Params (B)":6.61,
        "Open LLM Score (%)":"42.31*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0419,
        "Decode Throughput (tokens\/s)":35.64,
        "Allocated Memory (MB)":5421,
        "Energy (tokens\/kWh)":454545.0,
        "E2E Latency (s)":28.1,
        "E2E Throughput (tokens\/s)":35.6,
        "Reserved Memory (MB)":5716,
        "Used Memory (MB)":7192
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"llama",
        "Params (B)":6.61,
        "Open LLM Score (%)":"42.31*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0427,
        "Decode Throughput (tokens\/s)":34.77,
        "Allocated Memory (MB)":6147,
        "Energy (tokens\/kWh)":480769.0,
        "E2E Latency (s)":28.8,
        "E2E Throughput (tokens\/s)":34.7,
        "Reserved Memory (MB)":6444,
        "Used Memory (MB)":7920
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"llama",
        "Params (B)":6.61,
        "Open LLM Score (%)":"42.31*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0458,
        "Decode Throughput (tokens\/s)":31.69,
        "Allocated Memory (MB)":5582,
        "Energy (tokens\/kWh)":396825.0,
        "E2E Latency (s)":31.6,
        "E2E Throughput (tokens\/s)":31.6,
        "Reserved Memory (MB)":5714,
        "Used Memory (MB)":7188
    },
    {
        "Model":"openlm-research\/open_llama_7b",
        "Arch":"llama",
        "Params (B)":6.61,
        "Open LLM Score (%)":"42.31*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0474,
        "Decode Throughput (tokens\/s)":29.03,
        "Allocated Memory (MB)":5581,
        "Energy (tokens\/kWh)":373134.0,
        "E2E Latency (s)":34.5,
        "E2E Throughput (tokens\/s)":29.0,
        "Reserved Memory (MB)":5727,
        "Used Memory (MB)":7201
    },
    {
        "Model":"Writer\/palmyra-large",
        "Arch":"gpt2",
        "Params (B)":20.26,
        "Open LLM Score (%)":"42.09*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0577,
        "Decode Throughput (tokens\/s)":27.9,
        "Allocated Memory (MB)":43419,
        "Energy (tokens\/kWh)":289855.0,
        "E2E Latency (s)":35.9,
        "E2E Throughput (tokens\/s)":27.9,
        "Reserved Memory (MB)":46948,
        "Used Memory (MB)":48420
    },
    {
        "Model":"RWKV\/rwkv-raven-14b",
        "Arch":"rwkv",
        "Params (B)":13.89,
        "Open LLM Score (%)":"42.09 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0582,
        "Decode Throughput (tokens\/s)":23.4,
        "Allocated Memory (MB)":28350,
        "Energy (tokens\/kWh)":241545.0,
        "E2E Latency (s)":42.8,
        "E2E Throughput (tokens\/s)":23.4,
        "Reserved Memory (MB)":28393,
        "Used Memory (MB)":29867
    },
    {
        "Model":"RWKV\/rwkv-raven-14b",
        "Arch":"rwkv",
        "Params (B)":13.89,
        "Open LLM Score (%)":"42.09 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.059,
        "Decode Throughput (tokens\/s)":23.9,
        "Allocated Memory (MB)":28350,
        "Energy (tokens\/kWh)":249376.0,
        "E2E Latency (s)":41.9,
        "E2E Throughput (tokens\/s)":23.9,
        "Reserved Memory (MB)":28393,
        "Used Memory (MB)":29867
    },
    {
        "Model":"Writer\/palmyra-large",
        "Arch":"gpt2",
        "Params (B)":20.26,
        "Open LLM Score (%)":"42.09*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0594,
        "Decode Throughput (tokens\/s)":26.08,
        "Allocated Memory (MB)":43420,
        "Energy (tokens\/kWh)":277008.0,
        "E2E Latency (s)":38.4,
        "E2E Throughput (tokens\/s)":26.0,
        "Reserved Memory (MB)":46925,
        "Used Memory (MB)":48399
    },
    {
        "Model":"Writer\/palmyra-large",
        "Arch":"gpt2",
        "Params (B)":20.26,
        "Open LLM Score (%)":"42.09 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0712,
        "Decode Throughput (tokens\/s)":25.82,
        "Allocated Memory (MB)":43420,
        "Energy (tokens\/kWh)":234192.0,
        "E2E Latency (s)":38.8,
        "E2E Throughput (tokens\/s)":25.8,
        "Reserved Memory (MB)":46925,
        "Used Memory (MB)":48399
    },
    {
        "Model":"Writer\/palmyra-large",
        "Arch":"gpt2",
        "Params (B)":20.26,
        "Open LLM Score (%)":"42.09 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0718,
        "Decode Throughput (tokens\/s)":27.99,
        "Allocated Memory (MB)":43419,
        "Energy (tokens\/kWh)":256410.0,
        "E2E Latency (s)":35.8,
        "E2E Throughput (tokens\/s)":27.9,
        "Reserved Memory (MB)":46948,
        "Used Memory (MB)":48420
    },
    {
        "Model":"Writer\/palmyra-large",
        "Arch":"gpt2",
        "Params (B)":20.26,
        "Open LLM Score (%)":"42.09 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0718,
        "Decode Throughput (tokens\/s)":26.09,
        "Allocated Memory (MB)":43420,
        "Energy (tokens\/kWh)":239234.0,
        "E2E Latency (s)":38.4,
        "E2E Throughput (tokens\/s)":26.0,
        "Reserved Memory (MB)":46925,
        "Used Memory (MB)":48399
    },
    {
        "Model":"RWKV\/rwkv-raven-14b",
        "Arch":"rwkv",
        "Params (B)":13.89,
        "Open LLM Score (%)":"42.09*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.088,
        "Decode Throughput (tokens\/s)":17.6,
        "Allocated Memory (MB)":8714,
        "Energy (tokens\/kWh)":228310.0,
        "E2E Latency (s)":56.9,
        "E2E Throughput (tokens\/s)":17.6,
        "Reserved Memory (MB)":9024,
        "Used Memory (MB)":10497
    },
    {
        "Model":"RWKV\/rwkv-raven-14b",
        "Arch":"rwkv",
        "Params (B)":13.89,
        "Open LLM Score (%)":"42.09*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0893,
        "Decode Throughput (tokens\/s)":17.24,
        "Allocated Memory (MB)":8714,
        "Energy (tokens\/kWh)":206185.0,
        "E2E Latency (s)":58.1,
        "E2E Throughput (tokens\/s)":17.2,
        "Reserved Memory (MB)":9024,
        "Used Memory (MB)":10497
    },
    {
        "Model":"Writer\/palmyra-large",
        "Arch":"gpt2",
        "Params (B)":20.26,
        "Open LLM Score (%)":"42.09*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0957,
        "Decode Throughput (tokens\/s)":33.33,
        "Allocated Memory (MB)":14228,
        "Energy (tokens\/kWh)":346020.0,
        "E2E Latency (s)":30.1,
        "E2E Throughput (tokens\/s)":33.2,
        "Reserved Memory (MB)":17758,
        "Used Memory (MB)":19234
    },
    {
        "Model":"Writer\/palmyra-large",
        "Arch":"gpt2",
        "Params (B)":20.26,
        "Open LLM Score (%)":"42.09*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0973,
        "Decode Throughput (tokens\/s)":40.81,
        "Allocated Memory (MB)":15846,
        "Energy (tokens\/kWh)":450450.0,
        "E2E Latency (s)":24.6,
        "E2E Throughput (tokens\/s)":40.7,
        "Reserved Memory (MB)":19379,
        "Used Memory (MB)":20855
    },
    {
        "Model":"facebook\/opt-30b",
        "Arch":"opt",
        "Params (B)":29.98,
        "Open LLM Score (%)":"42.00 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.108,
        "Decode Throughput (tokens\/s)":21.33,
        "Allocated Memory (MB)":63508,
        "Energy (tokens\/kWh)":196850.0,
        "E2E Latency (s)":47.0,
        "E2E Throughput (tokens\/s)":21.3,
        "Reserved Memory (MB)":68209,
        "Used Memory (MB)":69681
    },
    {
        "Model":"facebook\/opt-30b",
        "Arch":"opt",
        "Params (B)":29.98,
        "Open LLM Score (%)":"42.00 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.115,
        "Decode Throughput (tokens\/s)":19.69,
        "Allocated Memory (MB)":63498,
        "Energy (tokens\/kWh)":181488.0,
        "E2E Latency (s)":50.9,
        "E2E Throughput (tokens\/s)":19.6,
        "Reserved Memory (MB)":68010,
        "Used Memory (MB)":69484
    },
    {
        "Model":"facebook\/opt-30b",
        "Arch":"opt",
        "Params (B)":29.98,
        "Open LLM Score (%)":"42.00 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.12,
        "Decode Throughput (tokens\/s)":19.54,
        "Allocated Memory (MB)":63498,
        "Energy (tokens\/kWh)":179856.0,
        "E2E Latency (s)":51.3,
        "E2E Throughput (tokens\/s)":19.5,
        "Reserved Memory (MB)":68010,
        "Used Memory (MB)":69484
    },
    {
        "Model":"facebook\/opt-30b",
        "Arch":"opt",
        "Params (B)":29.98,
        "Open LLM Score (%)":"42.00*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.144,
        "Decode Throughput (tokens\/s)":35.14,
        "Allocated Memory (MB)":22002,
        "Energy (tokens\/kWh)":364963.0,
        "E2E Latency (s)":28.6,
        "E2E Throughput (tokens\/s)":35.0,
        "Reserved Memory (MB)":26925,
        "Used Memory (MB)":28401
    },
    {
        "Model":"facebook\/opt-30b",
        "Arch":"opt",
        "Params (B)":29.98,
        "Open LLM Score (%)":"42.00*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.144,
        "Decode Throughput (tokens\/s)":25.28,
        "Allocated Memory (MB)":20110,
        "Energy (tokens\/kWh)":250626.0,
        "E2E Latency (s)":39.7,
        "E2E Throughput (tokens\/s)":25.2,
        "Reserved Memory (MB)":25052,
        "Used Memory (MB)":26528
    },
    {
        "Model":"facebook\/opt-30b",
        "Arch":"opt",
        "Params (B)":29.98,
        "Open LLM Score (%)":"42.00*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.17,
        "Decode Throughput (tokens\/s)":27.91,
        "Allocated Memory (MB)":20948,
        "Energy (tokens\/kWh)":242130.0,
        "E2E Latency (s)":36.0,
        "E2E Throughput (tokens\/s)":27.8,
        "Reserved Memory (MB)":24519,
        "Used Memory (MB)":25993
    },
    {
        "Model":"facebook\/opt-30b",
        "Arch":"opt",
        "Params (B)":29.98,
        "Open LLM Score (%)":"42.00*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.178,
        "Decode Throughput (tokens\/s)":22.51,
        "Allocated Memory (MB)":20948,
        "Energy (tokens\/kWh)":213219.0,
        "E2E Latency (s)":44.6,
        "E2E Throughput (tokens\/s)":22.4,
        "Reserved Memory (MB)":24519,
        "Used Memory (MB)":25993
    },
    {
        "Model":"EleutherAI\/gpt-neox-20b",
        "Arch":"gpt_neox",
        "Params (B)":20.74,
        "Open LLM Score (%)":"41.69 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0825,
        "Decode Throughput (tokens\/s)":24.38,
        "Allocated Memory (MB)":44027,
        "Energy (tokens\/kWh)":218818.0,
        "E2E Latency (s)":41.1,
        "E2E Throughput (tokens\/s)":24.3,
        "Reserved Memory (MB)":47603,
        "Used Memory (MB)":49077
    },
    {
        "Model":"EleutherAI\/gpt-neox-20b",
        "Arch":"gpt_neox",
        "Params (B)":20.74,
        "Open LLM Score (%)":"41.69 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0828,
        "Decode Throughput (tokens\/s)":23.91,
        "Allocated Memory (MB)":44027,
        "Energy (tokens\/kWh)":214592.0,
        "E2E Latency (s)":41.9,
        "E2E Throughput (tokens\/s)":23.9,
        "Reserved Memory (MB)":47603,
        "Used Memory (MB)":49077
    },
    {
        "Model":"EleutherAI\/gpt-neox-20b",
        "Arch":"gpt_neox",
        "Params (B)":20.74,
        "Open LLM Score (%)":"41.69 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0833,
        "Decode Throughput (tokens\/s)":23.8,
        "Allocated Memory (MB)":44027,
        "Energy (tokens\/kWh)":214132.0,
        "E2E Latency (s)":42.1,
        "E2E Throughput (tokens\/s)":23.8,
        "Reserved Memory (MB)":47603,
        "Used Memory (MB)":49077
    },
    {
        "Model":"EleutherAI\/gpt-neox-20b",
        "Arch":"gpt_neox",
        "Params (B)":20.74,
        "Open LLM Score (%)":"41.69*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.104,
        "Decode Throughput (tokens\/s)":26.96,
        "Allocated Memory (MB)":14830,
        "Energy (tokens\/kWh)":293255.0,
        "E2E Latency (s)":37.2,
        "E2E Throughput (tokens\/s)":26.9,
        "Reserved Memory (MB)":18433,
        "Used Memory (MB)":19909
    },
    {
        "Model":"EleutherAI\/gpt-neox-20b",
        "Arch":"gpt_neox",
        "Params (B)":20.74,
        "Open LLM Score (%)":"41.69*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.105,
        "Decode Throughput (tokens\/s)":26.6,
        "Allocated Memory (MB)":16448,
        "Energy (tokens\/kWh)":322580.0,
        "E2E Latency (s)":37.7,
        "E2E Throughput (tokens\/s)":26.5,
        "Reserved Memory (MB)":20055,
        "Used Memory (MB)":21530
    },
    {
        "Model":"EleutherAI\/gpt-neox-20b",
        "Arch":"gpt_neox",
        "Params (B)":20.74,
        "Open LLM Score (%)":"41.69*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.122,
        "Decode Throughput (tokens\/s)":23.27,
        "Allocated Memory (MB)":15392,
        "Energy (tokens\/kWh)":253164.0,
        "E2E Latency (s)":43.1,
        "E2E Throughput (tokens\/s)":23.2,
        "Reserved Memory (MB)":17318,
        "Used Memory (MB)":18792
    },
    {
        "Model":"EleutherAI\/gpt-neox-20b",
        "Arch":"gpt_neox",
        "Params (B)":20.74,
        "Open LLM Score (%)":"41.69*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.123,
        "Decode Throughput (tokens\/s)":22.23,
        "Allocated Memory (MB)":15392,
        "Energy (tokens\/kWh)":242130.0,
        "E2E Latency (s)":45.1,
        "E2E Throughput (tokens\/s)":22.2,
        "Reserved Memory (MB)":17341,
        "Used Memory (MB)":18815
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"gpt_neox",
        "Params (B)":6.65,
        "Open LLM Score (%)":"41.49 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0298,
        "Decode Throughput (tokens\/s)":46.36,
        "Allocated Memory (MB)":15233,
        "Energy (tokens\/kWh)":476190.0,
        "E2E Latency (s)":21.6,
        "E2E Throughput (tokens\/s)":46.3,
        "Reserved Memory (MB)":15267,
        "Used Memory (MB)":16738
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"gpt_neox",
        "Params (B)":6.65,
        "Open LLM Score (%)":"41.49 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0312,
        "Decode Throughput (tokens\/s)":40.05,
        "Allocated Memory (MB)":15234,
        "Energy (tokens\/kWh)":436681.0,
        "E2E Latency (s)":25.0,
        "E2E Throughput (tokens\/s)":40.0,
        "Reserved Memory (MB)":15267,
        "Used Memory (MB)":16741
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"gpt_neox",
        "Params (B)":6.65,
        "Open LLM Score (%)":"41.49 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0318,
        "Decode Throughput (tokens\/s)":39.42,
        "Allocated Memory (MB)":15234,
        "Energy (tokens\/kWh)":423728.0,
        "E2E Latency (s)":25.4,
        "E2E Throughput (tokens\/s)":39.4,
        "Reserved Memory (MB)":15267,
        "Used Memory (MB)":16741
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"gpt_neox",
        "Params (B)":6.65,
        "Open LLM Score (%)":"41.49*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0409,
        "Decode Throughput (tokens\/s)":41.56,
        "Allocated Memory (MB)":5832,
        "Energy (tokens\/kWh)":512820.0,
        "E2E Latency (s)":24.1,
        "E2E Throughput (tokens\/s)":41.5,
        "Reserved Memory (MB)":5848,
        "Used Memory (MB)":7324
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"gpt_neox",
        "Params (B)":6.65,
        "Open LLM Score (%)":"41.49*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.041,
        "Decode Throughput (tokens\/s)":41.39,
        "Allocated Memory (MB)":6910,
        "Energy (tokens\/kWh)":543478.0,
        "E2E Latency (s)":24.2,
        "E2E Throughput (tokens\/s)":41.3,
        "Reserved Memory (MB)":6928,
        "Used Memory (MB)":8404
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"gpt_neox",
        "Params (B)":6.65,
        "Open LLM Score (%)":"41.49*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0466,
        "Decode Throughput (tokens\/s)":36.96,
        "Allocated Memory (MB)":5999,
        "Energy (tokens\/kWh)":450450.0,
        "E2E Latency (s)":27.1,
        "E2E Throughput (tokens\/s)":36.9,
        "Reserved Memory (MB)":6062,
        "Used Memory (MB)":7534
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-7B-Base",
        "Arch":"gpt_neox",
        "Params (B)":6.65,
        "Open LLM Score (%)":"41.49*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.049,
        "Decode Throughput (tokens\/s)":33.61,
        "Allocated Memory (MB)":5998,
        "Energy (tokens\/kWh)":418410.0,
        "E2E Latency (s)":29.8,
        "E2E Throughput (tokens\/s)":33.6,
        "Reserved Memory (MB)":6041,
        "Used Memory (MB)":7515
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"llama",
        "Params (B)":3.0,
        "Open LLM Score (%)":"41.44 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0182,
        "Decode Throughput (tokens\/s)":55.61,
        "Allocated Memory (MB)":6840,
        "Energy (tokens\/kWh)":689655.0,
        "E2E Latency (s)":18.0,
        "E2E Throughput (tokens\/s)":55.6,
        "Reserved Memory (MB)":7119,
        "Used Memory (MB)":8593
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"llama",
        "Params (B)":3.0,
        "Open LLM Score (%)":"41.44 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0201,
        "Decode Throughput (tokens\/s)":49.31,
        "Allocated Memory (MB)":6840,
        "Energy (tokens\/kWh)":609756.0,
        "E2E Latency (s)":20.3,
        "E2E Throughput (tokens\/s)":49.3,
        "Reserved Memory (MB)":7119,
        "Used Memory (MB)":8593
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"llama",
        "Params (B)":3.0,
        "Open LLM Score (%)":"41.44 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0206,
        "Decode Throughput (tokens\/s)":48.59,
        "Allocated Memory (MB)":6840,
        "Energy (tokens\/kWh)":632911.0,
        "E2E Latency (s)":20.6,
        "E2E Throughput (tokens\/s)":48.5,
        "Reserved Memory (MB)":7119,
        "Used Memory (MB)":8593
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"llama",
        "Params (B)":3.0,
        "Open LLM Score (%)":"41.44*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0231,
        "Decode Throughput (tokens\/s)":46.56,
        "Allocated Memory (MB)":3410,
        "Energy (tokens\/kWh)":662251.0,
        "E2E Latency (s)":21.5,
        "E2E Throughput (tokens\/s)":46.5,
        "Reserved Memory (MB)":3743,
        "Used Memory (MB)":5219
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"llama",
        "Params (B)":3.0,
        "Open LLM Score (%)":"41.44*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0235,
        "Decode Throughput (tokens\/s)":46.13,
        "Allocated Memory (MB)":2870,
        "Energy (tokens\/kWh)":632911.0,
        "E2E Latency (s)":21.7,
        "E2E Throughput (tokens\/s)":46.1,
        "Reserved Memory (MB)":3200,
        "Used Memory (MB)":4676
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"llama",
        "Params (B)":3.0,
        "Open LLM Score (%)":"41.44*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0329,
        "Decode Throughput (tokens\/s)":40.7,
        "Allocated Memory (MB)":2933,
        "Energy (tokens\/kWh)":561797.0,
        "E2E Latency (s)":24.6,
        "E2E Throughput (tokens\/s)":40.7,
        "Reserved Memory (MB)":3229,
        "Used Memory (MB)":4703
    },
    {
        "Model":"GeneZC\/MiniMA-3B",
        "Arch":"llama",
        "Params (B)":3.0,
        "Open LLM Score (%)":"41.44*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0353,
        "Decode Throughput (tokens\/s)":37.79,
        "Allocated Memory (MB)":2933,
        "Energy (tokens\/kWh)":518134.0,
        "E2E Latency (s)":26.5,
        "E2E Throughput (tokens\/s)":37.7,
        "Reserved Memory (MB)":3219,
        "Used Memory (MB)":4692
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"gpt_neox",
        "Params (B)":6.65,
        "Open LLM Score (%)":"41.25 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0292,
        "Decode Throughput (tokens\/s)":45.72,
        "Allocated Memory (MB)":15233,
        "Energy (tokens\/kWh)":473933.0,
        "E2E Latency (s)":21.9,
        "E2E Throughput (tokens\/s)":45.7,
        "Reserved Memory (MB)":15267,
        "Used Memory (MB)":16738
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"gpt_neox",
        "Params (B)":6.65,
        "Open LLM Score (%)":"41.25 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0315,
        "Decode Throughput (tokens\/s)":39.89,
        "Allocated Memory (MB)":15234,
        "Energy (tokens\/kWh)":432900.0,
        "E2E Latency (s)":25.1,
        "E2E Throughput (tokens\/s)":39.8,
        "Reserved Memory (MB)":15267,
        "Used Memory (MB)":16741
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"gpt_neox",
        "Params (B)":6.65,
        "Open LLM Score (%)":"41.25 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0321,
        "Decode Throughput (tokens\/s)":38.51,
        "Allocated Memory (MB)":15234,
        "Energy (tokens\/kWh)":423728.0,
        "E2E Latency (s)":26.0,
        "E2E Throughput (tokens\/s)":38.5,
        "Reserved Memory (MB)":15267,
        "Used Memory (MB)":16741
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"gpt_neox",
        "Params (B)":6.65,
        "Open LLM Score (%)":"41.25*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0399,
        "Decode Throughput (tokens\/s)":41.91,
        "Allocated Memory (MB)":5832,
        "Energy (tokens\/kWh)":523560.0,
        "E2E Latency (s)":23.9,
        "E2E Throughput (tokens\/s)":41.8,
        "Reserved Memory (MB)":5848,
        "Used Memory (MB)":7324
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"gpt_neox",
        "Params (B)":6.65,
        "Open LLM Score (%)":"41.25*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0419,
        "Decode Throughput (tokens\/s)":41.74,
        "Allocated Memory (MB)":6910,
        "Energy (tokens\/kWh)":561797.0,
        "E2E Latency (s)":24.0,
        "E2E Throughput (tokens\/s)":41.7,
        "Reserved Memory (MB)":6928,
        "Used Memory (MB)":8404
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"gpt_neox",
        "Params (B)":6.65,
        "Open LLM Score (%)":"41.25*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0466,
        "Decode Throughput (tokens\/s)":37.1,
        "Allocated Memory (MB)":5999,
        "Energy (tokens\/kWh)":452488.0,
        "E2E Latency (s)":27.0,
        "E2E Throughput (tokens\/s)":37.0,
        "Reserved Memory (MB)":6062,
        "Used Memory (MB)":7534
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-7B-v0.1",
        "Arch":"gpt_neox",
        "Params (B)":6.65,
        "Open LLM Score (%)":"41.25*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0489,
        "Decode Throughput (tokens\/s)":33.28,
        "Allocated Memory (MB)":5998,
        "Energy (tokens\/kWh)":413223.0,
        "E2E Latency (s)":30.1,
        "E2E Throughput (tokens\/s)":33.2,
        "Reserved Memory (MB)":6041,
        "Used Memory (MB)":7515
    },
    {
        "Model":"openlm-research\/open_llama_3b_v2",
        "Arch":"llama",
        "Params (B)":3.32,
        "Open LLM Score (%)":"40.28 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0222,
        "Decode Throughput (tokens\/s)":45.71,
        "Allocated Memory (MB)":7770,
        "Energy (tokens\/kWh)":561797.0,
        "E2E Latency (s)":21.9,
        "E2E Throughput (tokens\/s)":45.7,
        "Reserved Memory (MB)":8155,
        "Used Memory (MB)":9629
    },
    {
        "Model":"openlm-research\/open_llama_3b_v2",
        "Arch":"llama",
        "Params (B)":3.32,
        "Open LLM Score (%)":"40.28 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0226,
        "Decode Throughput (tokens\/s)":47.22,
        "Allocated Memory (MB)":7779,
        "Energy (tokens\/kWh)":588235.0,
        "E2E Latency (s)":21.2,
        "E2E Throughput (tokens\/s)":47.2,
        "Reserved Memory (MB)":8172,
        "Used Memory (MB)":9646
    },
    {
        "Model":"openlm-research\/open_llama_3b_v2",
        "Arch":"llama",
        "Params (B)":3.32,
        "Open LLM Score (%)":"40.28 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0226,
        "Decode Throughput (tokens\/s)":45.5,
        "Allocated Memory (MB)":7770,
        "Energy (tokens\/kWh)":574712.0,
        "E2E Latency (s)":22.0,
        "E2E Throughput (tokens\/s)":45.5,
        "Reserved Memory (MB)":8155,
        "Used Memory (MB)":9629
    },
    {
        "Model":"openlm-research\/open_llama_3b_v2",
        "Arch":"llama",
        "Params (B)":3.32,
        "Open LLM Score (%)":"40.28*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0383,
        "Decode Throughput (tokens\/s)":34.53,
        "Allocated Memory (MB)":3114,
        "Energy (tokens\/kWh)":465116.0,
        "E2E Latency (s)":29.0,
        "E2E Throughput (tokens\/s)":34.5,
        "Reserved Memory (MB)":3422,
        "Used Memory (MB)":4896
    },
    {
        "Model":"openlm-research\/open_llama_3b_v2",
        "Arch":"llama",
        "Params (B)":3.32,
        "Open LLM Score (%)":"40.28*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0388,
        "Decode Throughput (tokens\/s)":35.38,
        "Allocated Memory (MB)":3122,
        "Energy (tokens\/kWh)":487804.0,
        "E2E Latency (s)":28.3,
        "E2E Throughput (tokens\/s)":35.3,
        "Reserved Memory (MB)":3458,
        "Used Memory (MB)":4931
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"gptj",
        "Params (B)":5.84,
        "Open LLM Score (%)":"40.10 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0305,
        "Decode Throughput (tokens\/s)":33.15,
        "Allocated Memory (MB)":13448,
        "Energy (tokens\/kWh)":392156.0,
        "E2E Latency (s)":30.2,
        "E2E Throughput (tokens\/s)":33.1,
        "Reserved Memory (MB)":13503,
        "Used Memory (MB)":14977
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"gptj",
        "Params (B)":5.84,
        "Open LLM Score (%)":"40.10 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0333,
        "Decode Throughput (tokens\/s)":31.48,
        "Allocated Memory (MB)":13438,
        "Energy (tokens\/kWh)":370370.0,
        "E2E Latency (s)":31.8,
        "E2E Throughput (tokens\/s)":31.4,
        "Reserved Memory (MB)":13482,
        "Used Memory (MB)":14956
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"gptj",
        "Params (B)":5.84,
        "Open LLM Score (%)":"40.10 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0338,
        "Decode Throughput (tokens\/s)":31.38,
        "Allocated Memory (MB)":13438,
        "Energy (tokens\/kWh)":371747.0,
        "E2E Latency (s)":31.9,
        "E2E Throughput (tokens\/s)":31.3,
        "Reserved Memory (MB)":13482,
        "Used Memory (MB)":14956
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"gptj",
        "Params (B)":5.84,
        "Open LLM Score (%)":"40.10*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0401,
        "Decode Throughput (tokens\/s)":30.71,
        "Allocated Memory (MB)":5231,
        "Energy (tokens\/kWh)":413223.0,
        "E2E Latency (s)":32.6,
        "E2E Throughput (tokens\/s)":30.7,
        "Reserved Memory (MB)":5385,
        "Used Memory (MB)":6861
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"gptj",
        "Params (B)":5.84,
        "Open LLM Score (%)":"40.10*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0409,
        "Decode Throughput (tokens\/s)":30.62,
        "Allocated Memory (MB)":6309,
        "Energy (tokens\/kWh)":432900.0,
        "E2E Latency (s)":32.7,
        "E2E Throughput (tokens\/s)":30.6,
        "Reserved Memory (MB)":6465,
        "Used Memory (MB)":7941
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"gptj",
        "Params (B)":5.84,
        "Open LLM Score (%)":"40.10*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0443,
        "Decode Throughput (tokens\/s)":27.89,
        "Allocated Memory (MB)":5341,
        "Energy (tokens\/kWh)":367647.0,
        "E2E Latency (s)":35.9,
        "E2E Throughput (tokens\/s)":27.9,
        "Reserved Memory (MB)":5429,
        "Used Memory (MB)":6903
    },
    {
        "Model":"EleutherAI\/gpt-j-6b",
        "Arch":"gptj",
        "Params (B)":5.84,
        "Open LLM Score (%)":"40.10*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0486,
        "Decode Throughput (tokens\/s)":26.42,
        "Allocated Memory (MB)":5331,
        "Energy (tokens\/kWh)":347222.0,
        "E2E Latency (s)":37.9,
        "E2E Throughput (tokens\/s)":26.4,
        "Reserved Memory (MB)":5387,
        "Used Memory (MB)":6861
    },
    {
        "Model":"facebook\/opt-13b",
        "Arch":"opt",
        "Params (B)":12.85,
        "Open LLM Score (%)":"40.06 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0451,
        "Decode Throughput (tokens\/s)":43.19,
        "Allocated Memory (MB)":27772,
        "Energy (tokens\/kWh)":393700.0,
        "E2E Latency (s)":23.2,
        "E2E Throughput (tokens\/s)":43.1,
        "Reserved Memory (MB)":29855,
        "Used Memory (MB)":31326
    },
    {
        "Model":"facebook\/opt-13b",
        "Arch":"opt",
        "Params (B)":12.85,
        "Open LLM Score (%)":"40.06 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0496,
        "Decode Throughput (tokens\/s)":35.91,
        "Allocated Memory (MB)":27772,
        "Energy (tokens\/kWh)":324675.0,
        "E2E Latency (s)":27.9,
        "E2E Throughput (tokens\/s)":35.8,
        "Reserved Memory (MB)":29582,
        "Used Memory (MB)":31056
    },
    {
        "Model":"facebook\/opt-13b",
        "Arch":"opt",
        "Params (B)":12.85,
        "Open LLM Score (%)":"40.06 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0502,
        "Decode Throughput (tokens\/s)":35.65,
        "Allocated Memory (MB)":27772,
        "Energy (tokens\/kWh)":324675.0,
        "E2E Latency (s)":28.1,
        "E2E Throughput (tokens\/s)":35.6,
        "Reserved Memory (MB)":29582,
        "Used Memory (MB)":31056
    },
    {
        "Model":"facebook\/opt-13b",
        "Arch":"opt",
        "Params (B)":12.85,
        "Open LLM Score (%)":"40.06*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0643,
        "Decode Throughput (tokens\/s)":40.76,
        "Allocated Memory (MB)":9360,
        "Energy (tokens\/kWh)":438596.0,
        "E2E Latency (s)":24.6,
        "E2E Throughput (tokens\/s)":40.7,
        "Reserved Memory (MB)":11444,
        "Used Memory (MB)":12920
    },
    {
        "Model":"facebook\/opt-13b",
        "Arch":"opt",
        "Params (B)":12.85,
        "Open LLM Score (%)":"40.06*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0664,
        "Decode Throughput (tokens\/s)":43.8,
        "Allocated Memory (MB)":10709,
        "Energy (tokens\/kWh)":515463.0,
        "E2E Latency (s)":22.9,
        "E2E Throughput (tokens\/s)":43.7,
        "Reserved Memory (MB)":12794,
        "Used Memory (MB)":14270
    },
    {
        "Model":"facebook\/opt-13b",
        "Arch":"opt",
        "Params (B)":12.85,
        "Open LLM Score (%)":"40.06*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0726,
        "Decode Throughput (tokens\/s)":35.3,
        "Allocated Memory (MB)":9685,
        "Energy (tokens\/kWh)":377358.0,
        "E2E Latency (s)":28.4,
        "E2E Throughput (tokens\/s)":35.2,
        "Reserved Memory (MB)":11150,
        "Used Memory (MB)":12622
    },
    {
        "Model":"facebook\/opt-13b",
        "Arch":"opt",
        "Params (B)":12.85,
        "Open LLM Score (%)":"40.06*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0786,
        "Decode Throughput (tokens\/s)":30.56,
        "Allocated Memory (MB)":9686,
        "Energy (tokens\/kWh)":344827.0,
        "E2E Latency (s)":32.8,
        "E2E Throughput (tokens\/s)":30.5,
        "Reserved Memory (MB)":11177,
        "Used Memory (MB)":12651
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"codegen",
        "Params (B)":6.85,
        "Open LLM Score (%)":"40.00 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0343,
        "Decode Throughput (tokens\/s)":28.85,
        "Allocated Memory (MB)":15707,
        "Energy (tokens\/kWh)":332225.0,
        "E2E Latency (s)":34.7,
        "E2E Throughput (tokens\/s)":28.8,
        "Reserved Memory (MB)":15762,
        "Used Memory (MB)":17235
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"codegen",
        "Params (B)":6.85,
        "Open LLM Score (%)":"40.00 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0383,
        "Decode Throughput (tokens\/s)":26.55,
        "Allocated Memory (MB)":15697,
        "Energy (tokens\/kWh)":317460.0,
        "E2E Latency (s)":37.7,
        "E2E Throughput (tokens\/s)":26.5,
        "Reserved Memory (MB)":15741,
        "Used Memory (MB)":17214
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"codegen",
        "Params (B)":6.85,
        "Open LLM Score (%)":"40.00 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0384,
        "Decode Throughput (tokens\/s)":26.69,
        "Allocated Memory (MB)":15697,
        "Energy (tokens\/kWh)":320512.0,
        "E2E Latency (s)":37.5,
        "E2E Throughput (tokens\/s)":26.7,
        "Reserved Memory (MB)":15741,
        "Used Memory (MB)":17214
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"codegen",
        "Params (B)":6.85,
        "Open LLM Score (%)":"40.00*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0456,
        "Decode Throughput (tokens\/s)":26.35,
        "Allocated Memory (MB)":6000,
        "Energy (tokens\/kWh)":350877.0,
        "E2E Latency (s)":38.0,
        "E2E Throughput (tokens\/s)":26.3,
        "Reserved Memory (MB)":6039,
        "Used Memory (MB)":7515
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"codegen",
        "Params (B)":6.85,
        "Open LLM Score (%)":"40.00*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0478,
        "Decode Throughput (tokens\/s)":26.56,
        "Allocated Memory (MB)":7077,
        "Energy (tokens\/kWh)":375939.0,
        "E2E Latency (s)":37.7,
        "E2E Throughput (tokens\/s)":26.5,
        "Reserved Memory (MB)":7119,
        "Used Memory (MB)":8595
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"codegen",
        "Params (B)":6.85,
        "Open LLM Score (%)":"40.00*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0499,
        "Decode Throughput (tokens\/s)":25.54,
        "Allocated Memory (MB)":6188,
        "Energy (tokens\/kWh)":338983.0,
        "E2E Latency (s)":39.2,
        "E2E Throughput (tokens\/s)":25.5,
        "Reserved Memory (MB)":6285,
        "Used Memory (MB)":7758
    },
    {
        "Model":"Salesforce\/codegen-6B-nl",
        "Arch":"codegen",
        "Params (B)":6.85,
        "Open LLM Score (%)":"40.00*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0541,
        "Decode Throughput (tokens\/s)":23.78,
        "Allocated Memory (MB)":6176,
        "Energy (tokens\/kWh)":321543.0,
        "E2E Latency (s)":42.1,
        "E2E Throughput (tokens\/s)":23.8,
        "Reserved Memory (MB)":6243,
        "Used Memory (MB)":7716
    },
    {
        "Model":"RWKV\/rwkv-4-14b-pile",
        "Arch":"rwkv",
        "Params (B)":13.89,
        "Open LLM Score (%)":"39.92 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0583,
        "Decode Throughput (tokens\/s)":23.4,
        "Allocated Memory (MB)":28350,
        "Energy (tokens\/kWh)":236406.0,
        "E2E Latency (s)":42.8,
        "E2E Throughput (tokens\/s)":23.4,
        "Reserved Memory (MB)":28393,
        "Used Memory (MB)":29867
    },
    {
        "Model":"RWKV\/rwkv-4-14b-pile",
        "Arch":"rwkv",
        "Params (B)":13.89,
        "Open LLM Score (%)":"39.92 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0583,
        "Decode Throughput (tokens\/s)":23.13,
        "Allocated Memory (MB)":28350,
        "Energy (tokens\/kWh)":242130.0,
        "E2E Latency (s)":43.3,
        "E2E Throughput (tokens\/s)":23.1,
        "Reserved Memory (MB)":28393,
        "Used Memory (MB)":29867
    },
    {
        "Model":"RWKV\/rwkv-4-14b-pile",
        "Arch":"rwkv",
        "Params (B)":13.89,
        "Open LLM Score (%)":"39.92*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0879,
        "Decode Throughput (tokens\/s)":17.6,
        "Allocated Memory (MB)":8714,
        "Energy (tokens\/kWh)":226244.0,
        "E2E Latency (s)":56.9,
        "E2E Throughput (tokens\/s)":17.6,
        "Reserved Memory (MB)":9024,
        "Used Memory (MB)":10497
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"llama",
        "Params (B)":6.74,
        "Open LLM Score (%)":"39.81 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.032,
        "Decode Throughput (tokens\/s)":42.07,
        "Allocated Memory (MB)":15095,
        "Energy (tokens\/kWh)":444444.0,
        "E2E Latency (s)":23.8,
        "E2E Throughput (tokens\/s)":42.0,
        "Reserved Memory (MB)":15109,
        "Used Memory (MB)":16583
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"llama",
        "Params (B)":6.74,
        "Open LLM Score (%)":"39.81 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0336,
        "Decode Throughput (tokens\/s)":38.36,
        "Allocated Memory (MB)":15095,
        "Energy (tokens\/kWh)":421940.0,
        "E2E Latency (s)":26.1,
        "E2E Throughput (tokens\/s)":38.3,
        "Reserved Memory (MB)":15109,
        "Used Memory (MB)":16583
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"llama",
        "Params (B)":6.74,
        "Open LLM Score (%)":"39.81 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0343,
        "Decode Throughput (tokens\/s)":38.66,
        "Allocated Memory (MB)":15095,
        "Energy (tokens\/kWh)":396825.0,
        "E2E Latency (s)":25.9,
        "E2E Throughput (tokens\/s)":38.6,
        "Reserved Memory (MB)":15109,
        "Used Memory (MB)":16583
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"llama",
        "Params (B)":6.74,
        "Open LLM Score (%)":"39.81*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0414,
        "Decode Throughput (tokens\/s)":34.18,
        "Allocated Memory (MB)":5657,
        "Energy (tokens\/kWh)":460829.0,
        "E2E Latency (s)":29.3,
        "E2E Throughput (tokens\/s)":34.1,
        "Reserved Memory (MB)":5708,
        "Used Memory (MB)":7184
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"llama",
        "Params (B)":6.74,
        "Open LLM Score (%)":"39.81*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0427,
        "Decode Throughput (tokens\/s)":34.65,
        "Allocated Memory (MB)":6382,
        "Energy (tokens\/kWh)":476190.0,
        "E2E Latency (s)":28.9,
        "E2E Throughput (tokens\/s)":34.6,
        "Reserved Memory (MB)":6436,
        "Used Memory (MB)":7912
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"llama",
        "Params (B)":6.74,
        "Open LLM Score (%)":"39.81*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0454,
        "Decode Throughput (tokens\/s)":31.0,
        "Allocated Memory (MB)":5821,
        "Energy (tokens\/kWh)":399999.0,
        "E2E Latency (s)":32.3,
        "E2E Throughput (tokens\/s)":31.0,
        "Reserved Memory (MB)":5939,
        "Used Memory (MB)":7412
    },
    {
        "Model":"codellama\/CodeLlama-7b-hf",
        "Arch":"llama",
        "Params (B)":6.74,
        "Open LLM Score (%)":"39.81*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0474,
        "Decode Throughput (tokens\/s)":28.45,
        "Allocated Memory (MB)":5822,
        "Energy (tokens\/kWh)":380228.0,
        "E2E Latency (s)":35.2,
        "E2E Throughput (tokens\/s)":28.4,
        "Reserved Memory (MB)":5939,
        "Used Memory (MB)":7412
    },
    {
        "Model":"EleutherAI\/pythia-12b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":11.59,
        "Open LLM Score (%)":"39.70 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.046,
        "Decode Throughput (tokens\/s)":38.09,
        "Allocated Memory (MB)":25714,
        "Energy (tokens\/kWh)":342465.0,
        "E2E Latency (s)":26.3,
        "E2E Throughput (tokens\/s)":38.0,
        "Reserved Memory (MB)":27856,
        "Used Memory (MB)":29328
    },
    {
        "Model":"EleutherAI\/pythia-12b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":11.59,
        "Open LLM Score (%)":"39.70 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0479,
        "Decode Throughput (tokens\/s)":35.02,
        "Allocated Memory (MB)":25714,
        "Energy (tokens\/kWh)":325732.0,
        "E2E Latency (s)":28.6,
        "E2E Throughput (tokens\/s)":35.0,
        "Reserved Memory (MB)":27812,
        "Used Memory (MB)":29286
    },
    {
        "Model":"EleutherAI\/pythia-12b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":11.59,
        "Open LLM Score (%)":"39.70 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0481,
        "Decode Throughput (tokens\/s)":32.73,
        "Allocated Memory (MB)":25714,
        "Energy (tokens\/kWh)":317460.0,
        "E2E Latency (s)":30.6,
        "E2E Throughput (tokens\/s)":32.7,
        "Reserved Memory (MB)":27812,
        "Used Memory (MB)":29286
    },
    {
        "Model":"EleutherAI\/pythia-12b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":11.59,
        "Open LLM Score (%)":"39.70*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.062,
        "Decode Throughput (tokens\/s)":36.05,
        "Allocated Memory (MB)":10548,
        "Energy (tokens\/kWh)":454545.0,
        "E2E Latency (s)":27.8,
        "E2E Throughput (tokens\/s)":36.0,
        "Reserved Memory (MB)":12637,
        "Used Memory (MB)":14113
    },
    {
        "Model":"EleutherAI\/pythia-12b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":11.59,
        "Open LLM Score (%)":"39.70*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0711,
        "Decode Throughput (tokens\/s)":32.86,
        "Allocated Memory (MB)":9441,
        "Energy (tokens\/kWh)":373134.0,
        "E2E Latency (s)":30.5,
        "E2E Throughput (tokens\/s)":32.8,
        "Reserved Memory (MB)":10557,
        "Used Memory (MB)":12028
    },
    {
        "Model":"EleutherAI\/pythia-12b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":11.59,
        "Open LLM Score (%)":"39.70*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0738,
        "Decode Throughput (tokens\/s)":29.83,
        "Allocated Memory (MB)":9441,
        "Energy (tokens\/kWh)":348432.0,
        "E2E Latency (s)":33.6,
        "E2E Throughput (tokens\/s)":29.8,
        "Reserved Memory (MB)":10529,
        "Used Memory (MB)":12003
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":6.65,
        "Open LLM Score (%)":"39.30 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0289,
        "Decode Throughput (tokens\/s)":45.93,
        "Allocated Memory (MB)":15208,
        "Energy (tokens\/kWh)":467289.0,
        "E2E Latency (s)":21.8,
        "E2E Throughput (tokens\/s)":45.9,
        "Reserved Memory (MB)":15242,
        "Used Memory (MB)":16713
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":6.65,
        "Open LLM Score (%)":"39.30 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0314,
        "Decode Throughput (tokens\/s)":40.37,
        "Allocated Memory (MB)":15208,
        "Energy (tokens\/kWh)":431034.0,
        "E2E Latency (s)":24.8,
        "E2E Throughput (tokens\/s)":40.3,
        "Reserved Memory (MB)":15242,
        "Used Memory (MB)":16715
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":6.65,
        "Open LLM Score (%)":"39.30 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0315,
        "Decode Throughput (tokens\/s)":40.7,
        "Allocated Memory (MB)":15208,
        "Energy (tokens\/kWh)":425531.0,
        "E2E Latency (s)":24.6,
        "E2E Throughput (tokens\/s)":40.7,
        "Reserved Memory (MB)":15242,
        "Used Memory (MB)":16715
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":6.65,
        "Open LLM Score (%)":"39.30*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0392,
        "Decode Throughput (tokens\/s)":41.73,
        "Allocated Memory (MB)":5807,
        "Energy (tokens\/kWh)":520833.0,
        "E2E Latency (s)":24.0,
        "E2E Throughput (tokens\/s)":41.7,
        "Reserved Memory (MB)":5825,
        "Used Memory (MB)":7301
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":6.65,
        "Open LLM Score (%)":"39.30*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0404,
        "Decode Throughput (tokens\/s)":40.88,
        "Allocated Memory (MB)":6884,
        "Energy (tokens\/kWh)":555555.0,
        "E2E Latency (s)":24.5,
        "E2E Throughput (tokens\/s)":40.8,
        "Reserved Memory (MB)":6905,
        "Used Memory (MB)":8381
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":6.65,
        "Open LLM Score (%)":"39.30*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0453,
        "Decode Throughput (tokens\/s)":36.83,
        "Allocated Memory (MB)":5974,
        "Energy (tokens\/kWh)":454545.0,
        "E2E Latency (s)":27.2,
        "E2E Throughput (tokens\/s)":36.8,
        "Reserved Memory (MB)":6037,
        "Used Memory (MB)":7509
    },
    {
        "Model":"EleutherAI\/pythia-6.9b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":6.65,
        "Open LLM Score (%)":"39.30*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0478,
        "Decode Throughput (tokens\/s)":33.5,
        "Allocated Memory (MB)":5973,
        "Energy (tokens\/kWh)":431034.0,
        "E2E Latency (s)":29.9,
        "E2E Throughput (tokens\/s)":33.4,
        "Reserved Memory (MB)":6037,
        "Used Memory (MB)":7511
    },
    {
        "Model":"bigscience\/bloom-7b1",
        "Arch":"bloom",
        "Params (B)":7.07,
        "Open LLM Score (%)":"39.18 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0285,
        "Decode Throughput (tokens\/s)":54.43,
        "Allocated Memory (MB)":15404,
        "Energy (tokens\/kWh)":507614.0,
        "E2E Latency (s)":18.4,
        "E2E Throughput (tokens\/s)":54.3,
        "Reserved Memory (MB)":15424,
        "Used Memory (MB)":16898
    },
    {
        "Model":"bigscience\/bloom-7b1",
        "Arch":"bloom",
        "Params (B)":7.07,
        "Open LLM Score (%)":"39.18 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.03,
        "Decode Throughput (tokens\/s)":52.44,
        "Allocated Memory (MB)":15404,
        "Energy (tokens\/kWh)":495049.0,
        "E2E Latency (s)":19.1,
        "E2E Throughput (tokens\/s)":52.4,
        "Reserved Memory (MB)":15424,
        "Used Memory (MB)":16898
    },
    {
        "Model":"bigscience\/bloom-7b1",
        "Arch":"bloom",
        "Params (B)":7.07,
        "Open LLM Score (%)":"39.18 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0302,
        "Decode Throughput (tokens\/s)":52.17,
        "Allocated Memory (MB)":15404,
        "Energy (tokens\/kWh)":502512.0,
        "E2E Latency (s)":19.2,
        "E2E Throughput (tokens\/s)":52.1,
        "Reserved Memory (MB)":15424,
        "Used Memory (MB)":16898
    },
    {
        "Model":"bigscience\/bloom-7b1",
        "Arch":"bloom",
        "Params (B)":7.07,
        "Open LLM Score (%)":"39.18*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0356,
        "Decode Throughput (tokens\/s)":54.16,
        "Allocated Memory (MB)":6599,
        "Energy (tokens\/kWh)":632911.0,
        "E2E Latency (s)":18.5,
        "E2E Throughput (tokens\/s)":54.1,
        "Reserved Memory (MB)":6704,
        "Used Memory (MB)":8180
    },
    {
        "Model":"bigscience\/bloom-7b1",
        "Arch":"bloom",
        "Params (B)":7.07,
        "Open LLM Score (%)":"39.18*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0364,
        "Decode Throughput (tokens\/s)":53.58,
        "Allocated Memory (MB)":7677,
        "Energy (tokens\/kWh)":666666.0,
        "E2E Latency (s)":18.7,
        "E2E Throughput (tokens\/s)":53.5,
        "Reserved Memory (MB)":7782,
        "Used Memory (MB)":9258
    },
    {
        "Model":"bigscience\/bloom-7b1",
        "Arch":"bloom",
        "Params (B)":7.07,
        "Open LLM Score (%)":"39.18*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0403,
        "Decode Throughput (tokens\/s)":43.55,
        "Allocated Memory (MB)":6730,
        "Energy (tokens\/kWh)":510204.0,
        "E2E Latency (s)":23.0,
        "E2E Throughput (tokens\/s)":43.5,
        "Reserved Memory (MB)":6836,
        "Used Memory (MB)":8310
    },
    {
        "Model":"bigscience\/bloom-7b1",
        "Arch":"bloom",
        "Params (B)":7.07,
        "Open LLM Score (%)":"39.18*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0413,
        "Decode Throughput (tokens\/s)":42.27,
        "Allocated Memory (MB)":6731,
        "Energy (tokens\/kWh)":502512.0,
        "E2E Latency (s)":23.7,
        "E2E Throughput (tokens\/s)":42.2,
        "Reserved Memory (MB)":6836,
        "Used Memory (MB)":8310
    },
    {
        "Model":"facebook\/opt-6.7b",
        "Arch":"opt",
        "Params (B)":6.66,
        "Open LLM Score (%)":"39.08 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0282,
        "Decode Throughput (tokens\/s)":65.48,
        "Allocated Memory (MB)":14668,
        "Energy (tokens\/kWh)":584795.0,
        "E2E Latency (s)":15.3,
        "E2E Throughput (tokens\/s)":65.4,
        "Reserved Memory (MB)":14692,
        "Used Memory (MB)":16164
    },
    {
        "Model":"facebook\/opt-6.7b",
        "Arch":"opt",
        "Params (B)":6.66,
        "Open LLM Score (%)":"39.08 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0307,
        "Decode Throughput (tokens\/s)":51.1,
        "Allocated Memory (MB)":14668,
        "Energy (tokens\/kWh)":512820.0,
        "E2E Latency (s)":19.6,
        "E2E Throughput (tokens\/s)":51.0,
        "Reserved Memory (MB)":14692,
        "Used Memory (MB)":16166
    },
    {
        "Model":"facebook\/opt-6.7b",
        "Arch":"opt",
        "Params (B)":6.66,
        "Open LLM Score (%)":"39.08 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.031,
        "Decode Throughput (tokens\/s)":53.0,
        "Allocated Memory (MB)":14668,
        "Energy (tokens\/kWh)":495049.0,
        "E2E Latency (s)":18.9,
        "E2E Throughput (tokens\/s)":52.9,
        "Reserved Memory (MB)":14692,
        "Used Memory (MB)":16166
    },
    {
        "Model":"facebook\/opt-6.7b",
        "Arch":"opt",
        "Params (B)":6.66,
        "Open LLM Score (%)":"39.08*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0384,
        "Decode Throughput (tokens\/s)":55.37,
        "Allocated Memory (MB)":5268,
        "Energy (tokens\/kWh)":653594.0,
        "E2E Latency (s)":18.1,
        "E2E Throughput (tokens\/s)":55.2,
        "Reserved Memory (MB)":5561,
        "Used Memory (MB)":7037
    },
    {
        "Model":"facebook\/opt-6.7b",
        "Arch":"opt",
        "Params (B)":6.66,
        "Open LLM Score (%)":"39.08*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0393,
        "Decode Throughput (tokens\/s)":54.76,
        "Allocated Memory (MB)":6347,
        "Energy (tokens\/kWh)":699300.0,
        "E2E Latency (s)":18.3,
        "E2E Throughput (tokens\/s)":54.6,
        "Reserved Memory (MB)":6641,
        "Used Memory (MB)":8117
    },
    {
        "Model":"facebook\/opt-6.7b",
        "Arch":"opt",
        "Params (B)":6.66,
        "Open LLM Score (%)":"39.08*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0417,
        "Decode Throughput (tokens\/s)":44.33,
        "Allocated Memory (MB)":5403,
        "Energy (tokens\/kWh)":515463.0,
        "E2E Latency (s)":22.6,
        "E2E Throughput (tokens\/s)":44.2,
        "Reserved Memory (MB)":5463,
        "Used Memory (MB)":6934
    },
    {
        "Model":"facebook\/opt-6.7b",
        "Arch":"opt",
        "Params (B)":6.66,
        "Open LLM Score (%)":"39.08*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0476,
        "Decode Throughput (tokens\/s)":37.8,
        "Allocated Memory (MB)":5402,
        "Energy (tokens\/kWh)":471698.0,
        "E2E Latency (s)":26.5,
        "E2E Throughput (tokens\/s)":37.7,
        "Reserved Memory (MB)":5454,
        "Used Memory (MB)":6928
    },
    {
        "Model":"EleutherAI\/pythia-12b",
        "Arch":"gpt_neox",
        "Params (B)":11.59,
        "Open LLM Score (%)":"38.82 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0459,
        "Decode Throughput (tokens\/s)":38.09,
        "Allocated Memory (MB)":25714,
        "Energy (tokens\/kWh)":341296.0,
        "E2E Latency (s)":26.3,
        "E2E Throughput (tokens\/s)":38.0,
        "Reserved Memory (MB)":27856,
        "Used Memory (MB)":29328
    },
    {
        "Model":"EleutherAI\/pythia-12b",
        "Arch":"gpt_neox",
        "Params (B)":11.59,
        "Open LLM Score (%)":"38.82 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0479,
        "Decode Throughput (tokens\/s)":35.4,
        "Allocated Memory (MB)":25714,
        "Energy (tokens\/kWh)":325732.0,
        "E2E Latency (s)":28.3,
        "E2E Throughput (tokens\/s)":35.3,
        "Reserved Memory (MB)":27812,
        "Used Memory (MB)":29286
    },
    {
        "Model":"EleutherAI\/pythia-12b",
        "Arch":"gpt_neox",
        "Params (B)":11.59,
        "Open LLM Score (%)":"38.82 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0492,
        "Decode Throughput (tokens\/s)":35.15,
        "Allocated Memory (MB)":25714,
        "Energy (tokens\/kWh)":324675.0,
        "E2E Latency (s)":28.5,
        "E2E Throughput (tokens\/s)":35.1,
        "Reserved Memory (MB)":27812,
        "Used Memory (MB)":29286
    },
    {
        "Model":"EleutherAI\/pythia-12b",
        "Arch":"gpt_neox",
        "Params (B)":11.59,
        "Open LLM Score (%)":"38.82*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0606,
        "Decode Throughput (tokens\/s)":36.31,
        "Allocated Memory (MB)":9201,
        "Energy (tokens\/kWh)":429184.0,
        "E2E Latency (s)":27.6,
        "E2E Throughput (tokens\/s)":36.2,
        "Reserved Memory (MB)":11286,
        "Used Memory (MB)":12762
    },
    {
        "Model":"EleutherAI\/pythia-12b",
        "Arch":"gpt_neox",
        "Params (B)":11.59,
        "Open LLM Score (%)":"38.82*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.063,
        "Decode Throughput (tokens\/s)":36.05,
        "Allocated Memory (MB)":10548,
        "Energy (tokens\/kWh)":465116.0,
        "E2E Latency (s)":27.8,
        "E2E Throughput (tokens\/s)":36.0,
        "Reserved Memory (MB)":12637,
        "Used Memory (MB)":14113
    },
    {
        "Model":"EleutherAI\/pythia-12b",
        "Arch":"gpt_neox",
        "Params (B)":11.59,
        "Open LLM Score (%)":"38.82*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0716,
        "Decode Throughput (tokens\/s)":30.84,
        "Allocated Memory (MB)":9441,
        "Energy (tokens\/kWh)":366300.0,
        "E2E Latency (s)":32.5,
        "E2E Throughput (tokens\/s)":30.8,
        "Reserved Memory (MB)":10557,
        "Used Memory (MB)":12028
    },
    {
        "Model":"EleutherAI\/pythia-12b",
        "Arch":"gpt_neox",
        "Params (B)":11.59,
        "Open LLM Score (%)":"38.82*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0735,
        "Decode Throughput (tokens\/s)":29.3,
        "Allocated Memory (MB)":9441,
        "Energy (tokens\/kWh)":347222.0,
        "E2E Latency (s)":34.2,
        "E2E Throughput (tokens\/s)":29.2,
        "Reserved Memory (MB)":10529,
        "Used Memory (MB)":12003
    },
    {
        "Model":"matsuo-lab\/weblab-10b",
        "Arch":"gpt_neox",
        "Params (B)":10.47,
        "Open LLM Score (%)":"38.59 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0427,
        "Decode Throughput (tokens\/s)":40.23,
        "Allocated Memory (MB)":23434,
        "Energy (tokens\/kWh)":361010.0,
        "E2E Latency (s)":24.9,
        "E2E Throughput (tokens\/s)":40.2,
        "Reserved Memory (MB)":24184,
        "Used Memory (MB)":25656
    },
    {
        "Model":"matsuo-lab\/weblab-10b",
        "Arch":"gpt_neox",
        "Params (B)":10.47,
        "Open LLM Score (%)":"38.59 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0456,
        "Decode Throughput (tokens\/s)":35.77,
        "Allocated Memory (MB)":23434,
        "Energy (tokens\/kWh)":340136.0,
        "E2E Latency (s)":28.0,
        "E2E Throughput (tokens\/s)":35.7,
        "Reserved Memory (MB)":24184,
        "Used Memory (MB)":25658
    },
    {
        "Model":"matsuo-lab\/weblab-10b",
        "Arch":"gpt_neox",
        "Params (B)":10.47,
        "Open LLM Score (%)":"38.59*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0564,
        "Decode Throughput (tokens\/s)":37.53,
        "Allocated Memory (MB)":8544,
        "Energy (tokens\/kWh)":446428.0,
        "E2E Latency (s)":26.7,
        "E2E Throughput (tokens\/s)":37.5,
        "Reserved Memory (MB)":9177,
        "Used Memory (MB)":10652
    },
    {
        "Model":"matsuo-lab\/weblab-10b",
        "Arch":"gpt_neox",
        "Params (B)":10.47,
        "Open LLM Score (%)":"38.59*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0591,
        "Decode Throughput (tokens\/s)":36.18,
        "Allocated Memory (MB)":9824,
        "Energy (tokens\/kWh)":450450.0,
        "E2E Latency (s)":27.7,
        "E2E Throughput (tokens\/s)":36.1,
        "Reserved Memory (MB)":10458,
        "Used Memory (MB)":11934
    },
    {
        "Model":"matsuo-lab\/weblab-10b",
        "Arch":"gpt_neox",
        "Params (B)":10.47,
        "Open LLM Score (%)":"38.59*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0667,
        "Decode Throughput (tokens\/s)":30.27,
        "Allocated Memory (MB)":8714,
        "Energy (tokens\/kWh)":363636.0,
        "E2E Latency (s)":33.1,
        "E2E Throughput (tokens\/s)":30.2,
        "Reserved Memory (MB)":9147,
        "Used Memory (MB)":10619
    },
    {
        "Model":"matsuo-lab\/weblab-10b",
        "Arch":"gpt_neox",
        "Params (B)":10.47,
        "Open LLM Score (%)":"38.59*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0688,
        "Decode Throughput (tokens\/s)":29.73,
        "Allocated Memory (MB)":8714,
        "Energy (tokens\/kWh)":354609.0,
        "E2E Latency (s)":33.7,
        "E2E Throughput (tokens\/s)":29.7,
        "Reserved Memory (MB)":9147,
        "Used Memory (MB)":10621
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"gpt_neox",
        "Params (B)":2.65,
        "Open LLM Score (%)":"38.54 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0211,
        "Decode Throughput (tokens\/s)":44.89,
        "Allocated Memory (MB)":6555,
        "Energy (tokens\/kWh)":591715.0,
        "E2E Latency (s)":22.3,
        "E2E Throughput (tokens\/s)":44.8,
        "Reserved Memory (MB)":6769,
        "Used Memory (MB)":8243
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"gpt_neox",
        "Params (B)":2.65,
        "Open LLM Score (%)":"38.54 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0252,
        "Decode Throughput (tokens\/s)":40.36,
        "Allocated Memory (MB)":6555,
        "Energy (tokens\/kWh)":512820.0,
        "E2E Latency (s)":24.8,
        "E2E Throughput (tokens\/s)":40.3,
        "Reserved Memory (MB)":6769,
        "Used Memory (MB)":8243
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"gpt_neox",
        "Params (B)":2.65,
        "Open LLM Score (%)":"38.54 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0253,
        "Decode Throughput (tokens\/s)":39.41,
        "Allocated Memory (MB)":6555,
        "Energy (tokens\/kWh)":520833.0,
        "E2E Latency (s)":25.4,
        "E2E Throughput (tokens\/s)":39.4,
        "Reserved Memory (MB)":6769,
        "Used Memory (MB)":8243
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"gpt_neox",
        "Params (B)":2.65,
        "Open LLM Score (%)":"38.54*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0262,
        "Decode Throughput (tokens\/s)":41.37,
        "Allocated Memory (MB)":2874,
        "Energy (tokens\/kWh)":584795.0,
        "E2E Latency (s)":24.2,
        "E2E Throughput (tokens\/s)":41.3,
        "Reserved Memory (MB)":3099,
        "Used Memory (MB)":4575
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"gpt_neox",
        "Params (B)":2.65,
        "Open LLM Score (%)":"38.54*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0262,
        "Decode Throughput (tokens\/s)":41.03,
        "Allocated Memory (MB)":3548,
        "Energy (tokens\/kWh)":571428.0,
        "E2E Latency (s)":24.4,
        "E2E Throughput (tokens\/s)":41.0,
        "Reserved Memory (MB)":3776,
        "Used Memory (MB)":5252
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"gpt_neox",
        "Params (B)":2.65,
        "Open LLM Score (%)":"38.54*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0328,
        "Decode Throughput (tokens\/s)":36.41,
        "Allocated Memory (MB)":2933,
        "Energy (tokens\/kWh)":512820.0,
        "E2E Latency (s)":27.5,
        "E2E Throughput (tokens\/s)":36.4,
        "Reserved Memory (MB)":3042,
        "Used Memory (MB)":4516
    },
    {
        "Model":"togethercomputer\/RedPajama-INCITE-Base-3B-v1",
        "Arch":"gpt_neox",
        "Params (B)":2.65,
        "Open LLM Score (%)":"38.54*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0377,
        "Decode Throughput (tokens\/s)":33.38,
        "Allocated Memory (MB)":2933,
        "Energy (tokens\/kWh)":467289.0,
        "E2E Latency (s)":30.0,
        "E2E Throughput (tokens\/s)":33.3,
        "Reserved Memory (MB)":3042,
        "Used Memory (MB)":4516
    },
    {
        "Model":"openlm-research\/open_llama_3b",
        "Arch":"llama",
        "Params (B)":3.32,
        "Open LLM Score (%)":"38.26 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0221,
        "Decode Throughput (tokens\/s)":45.71,
        "Allocated Memory (MB)":7770,
        "Energy (tokens\/kWh)":578034.0,
        "E2E Latency (s)":21.9,
        "E2E Throughput (tokens\/s)":45.7,
        "Reserved Memory (MB)":8155,
        "Used Memory (MB)":9629
    },
    {
        "Model":"openlm-research\/open_llama_3b",
        "Arch":"llama",
        "Params (B)":3.32,
        "Open LLM Score (%)":"38.26 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0221,
        "Decode Throughput (tokens\/s)":44.49,
        "Allocated Memory (MB)":7770,
        "Energy (tokens\/kWh)":555555.0,
        "E2E Latency (s)":22.5,
        "E2E Throughput (tokens\/s)":44.4,
        "Reserved Memory (MB)":8155,
        "Used Memory (MB)":9629
    },
    {
        "Model":"openlm-research\/open_llama_3b",
        "Arch":"llama",
        "Params (B)":3.32,
        "Open LLM Score (%)":"38.26 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0228,
        "Decode Throughput (tokens\/s)":47.0,
        "Allocated Memory (MB)":7779,
        "Energy (tokens\/kWh)":595238.0,
        "E2E Latency (s)":21.3,
        "E2E Throughput (tokens\/s)":46.9,
        "Reserved Memory (MB)":8172,
        "Used Memory (MB)":9646
    },
    {
        "Model":"openlm-research\/open_llama_3b",
        "Arch":"llama",
        "Params (B)":3.32,
        "Open LLM Score (%)":"38.26*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0382,
        "Decode Throughput (tokens\/s)":35.01,
        "Allocated Memory (MB)":3114,
        "Energy (tokens\/kWh)":476190.0,
        "E2E Latency (s)":28.6,
        "E2E Throughput (tokens\/s)":35.0,
        "Reserved Memory (MB)":3422,
        "Used Memory (MB)":4896
    },
    {
        "Model":"openlm-research\/open_llama_3b",
        "Arch":"llama",
        "Params (B)":3.32,
        "Open LLM Score (%)":"38.26*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0389,
        "Decode Throughput (tokens\/s)":35.76,
        "Allocated Memory (MB)":3122,
        "Energy (tokens\/kWh)":492610.0,
        "E2E Latency (s)":28.0,
        "E2E Throughput (tokens\/s)":35.7,
        "Reserved Memory (MB)":3458,
        "Used Memory (MB)":4931
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"gpt_neox",
        "Params (B)":6.65,
        "Open LLM Score (%)":"38.06 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0292,
        "Decode Throughput (tokens\/s)":46.79,
        "Allocated Memory (MB)":15208,
        "Energy (tokens\/kWh)":478468.0,
        "E2E Latency (s)":21.4,
        "E2E Throughput (tokens\/s)":46.7,
        "Reserved Memory (MB)":15242,
        "Used Memory (MB)":16713
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"gpt_neox",
        "Params (B)":6.65,
        "Open LLM Score (%)":"38.06 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0312,
        "Decode Throughput (tokens\/s)":40.54,
        "Allocated Memory (MB)":15208,
        "Energy (tokens\/kWh)":434782.0,
        "E2E Latency (s)":24.7,
        "E2E Throughput (tokens\/s)":40.5,
        "Reserved Memory (MB)":15242,
        "Used Memory (MB)":16715
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"gpt_neox",
        "Params (B)":6.65,
        "Open LLM Score (%)":"38.06 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0319,
        "Decode Throughput (tokens\/s)":40.05,
        "Allocated Memory (MB)":15208,
        "Energy (tokens\/kWh)":418410.0,
        "E2E Latency (s)":25.0,
        "E2E Throughput (tokens\/s)":40.0,
        "Reserved Memory (MB)":15242,
        "Used Memory (MB)":16715
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"gpt_neox",
        "Params (B)":6.65,
        "Open LLM Score (%)":"38.06*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0391,
        "Decode Throughput (tokens\/s)":42.62,
        "Allocated Memory (MB)":5807,
        "Energy (tokens\/kWh)":540540.0,
        "E2E Latency (s)":23.5,
        "E2E Throughput (tokens\/s)":42.6,
        "Reserved Memory (MB)":5825,
        "Used Memory (MB)":7301
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"gpt_neox",
        "Params (B)":6.65,
        "Open LLM Score (%)":"38.06*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0415,
        "Decode Throughput (tokens\/s)":40.72,
        "Allocated Memory (MB)":6884,
        "Energy (tokens\/kWh)":526315.0,
        "E2E Latency (s)":24.6,
        "E2E Throughput (tokens\/s)":40.7,
        "Reserved Memory (MB)":6905,
        "Used Memory (MB)":8381
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"gpt_neox",
        "Params (B)":6.65,
        "Open LLM Score (%)":"38.06*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0454,
        "Decode Throughput (tokens\/s)":36.16,
        "Allocated Memory (MB)":5974,
        "Energy (tokens\/kWh)":456621.0,
        "E2E Latency (s)":27.7,
        "E2E Throughput (tokens\/s)":36.1,
        "Reserved Memory (MB)":6037,
        "Used Memory (MB)":7509
    },
    {
        "Model":"EleutherAI\/pythia-6.7b",
        "Arch":"gpt_neox",
        "Params (B)":6.65,
        "Open LLM Score (%)":"38.06*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0479,
        "Decode Throughput (tokens\/s)":32.52,
        "Allocated Memory (MB)":5973,
        "Energy (tokens\/kWh)":416666.0,
        "E2E Latency (s)":30.8,
        "E2E Throughput (tokens\/s)":32.5,
        "Reserved Memory (MB)":6037,
        "Used Memory (MB)":7511
    },
    {
        "Model":"RWKV\/rwkv-4-7b-pile",
        "Arch":"rwkv",
        "Params (B)":7.19,
        "Open LLM Score (%)":"37.95 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0359,
        "Decode Throughput (tokens\/s)":29.71,
        "Allocated Memory (MB)":14829,
        "Energy (tokens\/kWh)":352112.0,
        "E2E Latency (s)":33.7,
        "E2E Throughput (tokens\/s)":29.7,
        "Reserved Memory (MB)":14881,
        "Used Memory (MB)":16355
    },
    {
        "Model":"RWKV\/rwkv-4-7b-pile",
        "Arch":"rwkv",
        "Params (B)":7.19,
        "Open LLM Score (%)":"37.95*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0581,
        "Decode Throughput (tokens\/s)":22.2,
        "Allocated Memory (MB)":4799,
        "Energy (tokens\/kWh)":295857.0,
        "E2E Latency (s)":45.1,
        "E2E Throughput (tokens\/s)":22.2,
        "Reserved Memory (MB)":5012,
        "Used Memory (MB)":6485
    },
    {
        "Model":"Devio\/test-22B",
        "Arch":"llama",
        "Params (B)":21.83,
        "Open LLM Score (%)":"37.71 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0809,
        "Decode Throughput (tokens\/s)":26.44,
        "Allocated Memory (MB)":46447,
        "Energy (tokens\/kWh)":239234.0,
        "E2E Latency (s)":37.9,
        "E2E Throughput (tokens\/s)":26.4,
        "Reserved Memory (MB)":49234,
        "Used Memory (MB)":50708
    },
    {
        "Model":"Devio\/test-22B",
        "Arch":"llama",
        "Params (B)":21.83,
        "Open LLM Score (%)":"37.71 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0826,
        "Decode Throughput (tokens\/s)":26.1,
        "Allocated Memory (MB)":46448,
        "Energy (tokens\/kWh)":234741.0,
        "E2E Latency (s)":38.4,
        "E2E Throughput (tokens\/s)":26.0,
        "Reserved Memory (MB)":49234,
        "Used Memory (MB)":50708
    },
    {
        "Model":"Devio\/test-22B",
        "Arch":"llama",
        "Params (B)":21.83,
        "Open LLM Score (%)":"37.71*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.105,
        "Decode Throughput (tokens\/s)":29.07,
        "Allocated Memory (MB)":15106,
        "Energy (tokens\/kWh)":309597.0,
        "E2E Latency (s)":34.5,
        "E2E Throughput (tokens\/s)":29.0,
        "Reserved Memory (MB)":17788,
        "Used Memory (MB)":19263
    },
    {
        "Model":"Devio\/test-22B",
        "Arch":"llama",
        "Params (B)":21.83,
        "Open LLM Score (%)":"37.71*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.11,
        "Decode Throughput (tokens\/s)":28.34,
        "Allocated Memory (MB)":16290,
        "Energy (tokens\/kWh)":322580.0,
        "E2E Latency (s)":35.4,
        "E2E Throughput (tokens\/s)":28.2,
        "Reserved Memory (MB)":18970,
        "Used Memory (MB)":20446
    },
    {
        "Model":"Devio\/test-22B",
        "Arch":"llama",
        "Params (B)":21.83,
        "Open LLM Score (%)":"37.71*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.122,
        "Decode Throughput (tokens\/s)":24.77,
        "Allocated Memory (MB)":15625,
        "Energy (tokens\/kWh)":233100.0,
        "E2E Latency (s)":40.5,
        "E2E Throughput (tokens\/s)":24.7,
        "Reserved Memory (MB)":17802,
        "Used Memory (MB)":19276
    },
    {
        "Model":"Devio\/test-22B",
        "Arch":"llama",
        "Params (B)":21.83,
        "Open LLM Score (%)":"37.71*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.125,
        "Decode Throughput (tokens\/s)":23.32,
        "Allocated Memory (MB)":15625,
        "Energy (tokens\/kWh)":240384.0,
        "E2E Latency (s)":43.0,
        "E2E Throughput (tokens\/s)":23.3,
        "Reserved Memory (MB)":17714,
        "Used Memory (MB)":19188
    },
    {
        "Model":"cerebras\/Cerebras-GPT-13B",
        "Arch":"gpt2",
        "Params (B)":12.85,
        "Open LLM Score (%)":"37.40*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0395,
        "Decode Throughput (tokens\/s)":37.79,
        "Allocated Memory (MB)":27939,
        "Energy (tokens\/kWh)":393700.0,
        "E2E Latency (s)":26.5,
        "E2E Throughput (tokens\/s)":37.7,
        "Reserved Memory (MB)":30282,
        "Used Memory (MB)":31754
    },
    {
        "Model":"cerebras\/Cerebras-GPT-13B",
        "Arch":"gpt2",
        "Params (B)":12.85,
        "Open LLM Score (%)":"37.40*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0442,
        "Decode Throughput (tokens\/s)":35.27,
        "Allocated Memory (MB)":27939,
        "Energy (tokens\/kWh)":387596.0,
        "E2E Latency (s)":28.4,
        "E2E Throughput (tokens\/s)":35.2,
        "Reserved Memory (MB)":30282,
        "Used Memory (MB)":31756
    },
    {
        "Model":"cerebras\/Cerebras-GPT-13B",
        "Arch":"gpt2",
        "Params (B)":12.85,
        "Open LLM Score (%)":"37.40 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0501,
        "Decode Throughput (tokens\/s)":38.68,
        "Allocated Memory (MB)":27939,
        "Energy (tokens\/kWh)":348432.0,
        "E2E Latency (s)":25.9,
        "E2E Throughput (tokens\/s)":38.6,
        "Reserved Memory (MB)":30282,
        "Used Memory (MB)":31754
    },
    {
        "Model":"cerebras\/Cerebras-GPT-13B",
        "Arch":"gpt2",
        "Params (B)":12.85,
        "Open LLM Score (%)":"37.40 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0501,
        "Decode Throughput (tokens\/s)":35.52,
        "Allocated Memory (MB)":27939,
        "Energy (tokens\/kWh)":320512.0,
        "E2E Latency (s)":28.2,
        "E2E Throughput (tokens\/s)":35.5,
        "Reserved Memory (MB)":30282,
        "Used Memory (MB)":31756
    },
    {
        "Model":"cerebras\/Cerebras-GPT-13B",
        "Arch":"gpt2",
        "Params (B)":12.85,
        "Open LLM Score (%)":"37.40*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0661,
        "Decode Throughput (tokens\/s)":42.86,
        "Allocated Memory (MB)":9568,
        "Energy (tokens\/kWh)":462962.0,
        "E2E Latency (s)":23.4,
        "E2E Throughput (tokens\/s)":42.7,
        "Reserved Memory (MB)":11867,
        "Used Memory (MB)":13343
    },
    {
        "Model":"cerebras\/Cerebras-GPT-13B",
        "Arch":"gpt2",
        "Params (B)":12.85,
        "Open LLM Score (%)":"37.40*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0668,
        "Decode Throughput (tokens\/s)":40.43,
        "Allocated Memory (MB)":10916,
        "Energy (tokens\/kWh)":352112.0,
        "E2E Latency (s)":24.8,
        "E2E Throughput (tokens\/s)":40.3,
        "Reserved Memory (MB)":13218,
        "Used Memory (MB)":14694
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"gpt_neox",
        "Params (B)":3.83,
        "Open LLM Score (%)":"37.31 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0312,
        "Decode Throughput (tokens\/s)":30.7,
        "Allocated Memory (MB)":9381,
        "Energy (tokens\/kWh)":403225.0,
        "E2E Latency (s)":32.6,
        "E2E Throughput (tokens\/s)":30.7,
        "Reserved Memory (MB)":9684,
        "Used Memory (MB)":11158
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"gpt_neox",
        "Params (B)":3.83,
        "Open LLM Score (%)":"37.31 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0366,
        "Decode Throughput (tokens\/s)":27.2,
        "Allocated Memory (MB)":9382,
        "Energy (tokens\/kWh)":358422.0,
        "E2E Latency (s)":36.8,
        "E2E Throughput (tokens\/s)":27.2,
        "Reserved Memory (MB)":9684,
        "Used Memory (MB)":11158
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"gpt_neox",
        "Params (B)":3.83,
        "Open LLM Score (%)":"37.31*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0374,
        "Decode Throughput (tokens\/s)":28.77,
        "Allocated Memory (MB)":3951,
        "Energy (tokens\/kWh)":406504.0,
        "E2E Latency (s)":34.8,
        "E2E Throughput (tokens\/s)":28.7,
        "Reserved Memory (MB)":4265,
        "Used Memory (MB)":5741
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"gpt_neox",
        "Params (B)":3.83,
        "Open LLM Score (%)":"37.31 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0375,
        "Decode Throughput (tokens\/s)":27.43,
        "Allocated Memory (MB)":9382,
        "Energy (tokens\/kWh)":362318.0,
        "E2E Latency (s)":36.5,
        "E2E Throughput (tokens\/s)":27.4,
        "Reserved Memory (MB)":9684,
        "Used Memory (MB)":11158
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"gpt_neox",
        "Params (B)":3.83,
        "Open LLM Score (%)":"37.31*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0387,
        "Decode Throughput (tokens\/s)":27.73,
        "Allocated Memory (MB)":4626,
        "Energy (tokens\/kWh)":386100.0,
        "E2E Latency (s)":36.1,
        "E2E Throughput (tokens\/s)":27.7,
        "Reserved Memory (MB)":4942,
        "Used Memory (MB)":6418
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"gpt_neox",
        "Params (B)":3.83,
        "Open LLM Score (%)":"37.31*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0488,
        "Decode Throughput (tokens\/s)":24.97,
        "Allocated Memory (MB)":4062,
        "Energy (tokens\/kWh)":343642.0,
        "E2E Latency (s)":40.1,
        "E2E Throughput (tokens\/s)":24.9,
        "Reserved Memory (MB)":4198,
        "Used Memory (MB)":5672
    },
    {
        "Model":"Dampish\/StellarX-4B-V0",
        "Arch":"gpt_neox",
        "Params (B)":3.83,
        "Open LLM Score (%)":"37.31*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0544,
        "Decode Throughput (tokens\/s)":23.12,
        "Allocated Memory (MB)":4062,
        "Energy (tokens\/kWh)":320512.0,
        "E2E Latency (s)":43.3,
        "E2E Throughput (tokens\/s)":23.1,
        "Reserved Memory (MB)":4198,
        "Used Memory (MB)":5672
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"gpt_neox",
        "Params (B)":2.91,
        "Open LLM Score (%)":"37.09 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0212,
        "Decode Throughput (tokens\/s)":44.49,
        "Allocated Memory (MB)":6539,
        "Energy (tokens\/kWh)":584795.0,
        "E2E Latency (s)":22.5,
        "E2E Throughput (tokens\/s)":44.4,
        "Reserved Memory (MB)":6750,
        "Used Memory (MB)":8224
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"gpt_neox",
        "Params (B)":2.91,
        "Open LLM Score (%)":"37.09 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0254,
        "Decode Throughput (tokens\/s)":40.36,
        "Allocated Memory (MB)":6539,
        "Energy (tokens\/kWh)":531914.0,
        "E2E Latency (s)":24.8,
        "E2E Throughput (tokens\/s)":40.3,
        "Reserved Memory (MB)":6750,
        "Used Memory (MB)":8224
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"gpt_neox",
        "Params (B)":2.91,
        "Open LLM Score (%)":"37.09 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.026,
        "Decode Throughput (tokens\/s)":40.53,
        "Allocated Memory (MB)":6539,
        "Energy (tokens\/kWh)":523560.0,
        "E2E Latency (s)":24.7,
        "E2E Throughput (tokens\/s)":40.5,
        "Reserved Memory (MB)":6750,
        "Used Memory (MB)":8224
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"gpt_neox",
        "Params (B)":2.91,
        "Open LLM Score (%)":"37.09*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0262,
        "Decode Throughput (tokens\/s)":41.03,
        "Allocated Memory (MB)":2858,
        "Energy (tokens\/kWh)":578034.0,
        "E2E Latency (s)":24.4,
        "E2E Throughput (tokens\/s)":41.0,
        "Reserved Memory (MB)":3080,
        "Used Memory (MB)":4556
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"gpt_neox",
        "Params (B)":2.91,
        "Open LLM Score (%)":"37.09*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0274,
        "Decode Throughput (tokens\/s)":40.37,
        "Allocated Memory (MB)":3532,
        "Energy (tokens\/kWh)":552486.0,
        "E2E Latency (s)":24.8,
        "E2E Throughput (tokens\/s)":40.3,
        "Reserved Memory (MB)":3755,
        "Used Memory (MB)":5231
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"gpt_neox",
        "Params (B)":2.91,
        "Open LLM Score (%)":"37.09*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0326,
        "Decode Throughput (tokens\/s)":36.81,
        "Allocated Memory (MB)":2918,
        "Energy (tokens\/kWh)":512820.0,
        "E2E Latency (s)":27.2,
        "E2E Throughput (tokens\/s)":36.8,
        "Reserved Memory (MB)":3032,
        "Used Memory (MB)":4506
    },
    {
        "Model":"EleutherAI\/pythia-2.7b",
        "Arch":"gpt_neox",
        "Params (B)":2.91,
        "Open LLM Score (%)":"37.09*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0372,
        "Decode Throughput (tokens\/s)":33.37,
        "Allocated Memory (MB)":2918,
        "Energy (tokens\/kWh)":469483.0,
        "E2E Latency (s)":30.0,
        "E2E Throughput (tokens\/s)":33.3,
        "Reserved Memory (MB)":3032,
        "Used Memory (MB)":4506
    },
    {
        "Model":"tiiuae\/falcon-rw-1b",
        "Arch":"falcon",
        "Params (B)":1.31,
        "Open LLM Score (%)":"37.07 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0154,
        "Decode Throughput (tokens\/s)":66.29,
        "Allocated Memory (MB)":3135,
        "Energy (tokens\/kWh)":869565.0,
        "E2E Latency (s)":15.1,
        "E2E Throughput (tokens\/s)":66.2,
        "Reserved Memory (MB)":3214,
        "Used Memory (MB)":4688
    },
    {
        "Model":"tiiuae\/falcon-rw-1b",
        "Arch":"falcon",
        "Params (B)":1.31,
        "Open LLM Score (%)":"37.07*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0158,
        "Decode Throughput (tokens\/s)":67.64,
        "Allocated Memory (MB)":1382,
        "Energy (tokens\/kWh)":943396.0,
        "E2E Latency (s)":14.8,
        "E2E Throughput (tokens\/s)":67.6,
        "Reserved Memory (MB)":1457,
        "Used Memory (MB)":2933
    },
    {
        "Model":"tiiuae\/falcon-rw-1b",
        "Arch":"falcon",
        "Params (B)":1.31,
        "Open LLM Score (%)":"37.07 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0163,
        "Decode Throughput (tokens\/s)":65.43,
        "Allocated Memory (MB)":3135,
        "Energy (tokens\/kWh)":869565.0,
        "E2E Latency (s)":15.3,
        "E2E Throughput (tokens\/s)":65.4,
        "Reserved Memory (MB)":3214,
        "Used Memory (MB)":4688
    },
    {
        "Model":"tiiuae\/falcon-rw-1b",
        "Arch":"falcon",
        "Params (B)":1.31,
        "Open LLM Score (%)":"37.07*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0192,
        "Decode Throughput (tokens\/s)":60.68,
        "Allocated Memory (MB)":1920,
        "Energy (tokens\/kWh)":869565.0,
        "E2E Latency (s)":16.5,
        "E2E Throughput (tokens\/s)":60.6,
        "Reserved Memory (MB)":1977,
        "Used Memory (MB)":3453
    },
    {
        "Model":"tiiuae\/falcon-rw-1b",
        "Arch":"falcon",
        "Params (B)":1.31,
        "Open LLM Score (%)":"37.07*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0236,
        "Decode Throughput (tokens\/s)":52.98,
        "Allocated Memory (MB)":1397,
        "Energy (tokens\/kWh)":740740.0,
        "E2E Latency (s)":18.9,
        "E2E Throughput (tokens\/s)":52.9,
        "Reserved Memory (MB)":1455,
        "Used Memory (MB)":2929
    },
    {
        "Model":"facebook\/opt-2.7b",
        "Arch":"opt",
        "Params (B)":2.65,
        "Open LLM Score (%)":"36.74 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0156,
        "Decode Throughput (tokens\/s)":62.56,
        "Allocated Memory (MB)":6135,
        "Energy (tokens\/kWh)":763358.0,
        "E2E Latency (s)":16.0,
        "E2E Throughput (tokens\/s)":62.5,
        "Reserved Memory (MB)":6438,
        "Used Memory (MB)":7909
    },
    {
        "Model":"facebook\/opt-2.7b",
        "Arch":"opt",
        "Params (B)":2.65,
        "Open LLM Score (%)":"36.74 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0196,
        "Decode Throughput (tokens\/s)":54.11,
        "Allocated Memory (MB)":6135,
        "Energy (tokens\/kWh)":675675.0,
        "E2E Latency (s)":18.5,
        "E2E Throughput (tokens\/s)":54.1,
        "Reserved Memory (MB)":6438,
        "Used Memory (MB)":7912
    },
    {
        "Model":"facebook\/opt-2.7b",
        "Arch":"opt",
        "Params (B)":2.65,
        "Open LLM Score (%)":"36.74 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0198,
        "Decode Throughput (tokens\/s)":53.82,
        "Allocated Memory (MB)":6135,
        "Energy (tokens\/kWh)":662251.0,
        "E2E Latency (s)":18.6,
        "E2E Throughput (tokens\/s)":53.8,
        "Reserved Memory (MB)":6438,
        "Used Memory (MB)":7912
    },
    {
        "Model":"facebook\/opt-2.7b",
        "Arch":"opt",
        "Params (B)":2.65,
        "Open LLM Score (%)":"36.74*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0225,
        "Decode Throughput (tokens\/s)":53.83,
        "Allocated Memory (MB)":2464,
        "Energy (tokens\/kWh)":675675.0,
        "E2E Latency (s)":18.6,
        "E2E Throughput (tokens\/s)":53.8,
        "Reserved Memory (MB)":2684,
        "Used Memory (MB)":4160
    },
    {
        "Model":"facebook\/opt-2.7b",
        "Arch":"opt",
        "Params (B)":2.65,
        "Open LLM Score (%)":"36.74*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0255,
        "Decode Throughput (tokens\/s)":45.93,
        "Allocated Memory (MB)":3138,
        "Energy (tokens\/kWh)":636942.0,
        "E2E Latency (s)":21.8,
        "E2E Throughput (tokens\/s)":45.9,
        "Reserved Memory (MB)":3359,
        "Used Memory (MB)":4835
    },
    {
        "Model":"facebook\/opt-2.7b",
        "Arch":"opt",
        "Params (B)":2.65,
        "Open LLM Score (%)":"36.74*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0325,
        "Decode Throughput (tokens\/s)":41.72,
        "Allocated Memory (MB)":2517,
        "Energy (tokens\/kWh)":571428.0,
        "E2E Latency (s)":24.0,
        "E2E Throughput (tokens\/s)":41.7,
        "Reserved Memory (MB)":2629,
        "Used Memory (MB)":4103
    },
    {
        "Model":"facebook\/opt-2.7b",
        "Arch":"opt",
        "Params (B)":2.65,
        "Open LLM Score (%)":"36.74*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0378,
        "Decode Throughput (tokens\/s)":36.95,
        "Allocated Memory (MB)":2518,
        "Energy (tokens\/kWh)":505050.0,
        "E2E Latency (s)":27.1,
        "E2E Throughput (tokens\/s)":36.9,
        "Reserved Memory (MB)":2634,
        "Used Memory (MB)":4107
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":2.91,
        "Open LLM Score (%)":"36.72 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0209,
        "Decode Throughput (tokens\/s)":45.09,
        "Allocated Memory (MB)":6539,
        "Energy (tokens\/kWh)":578034.0,
        "E2E Latency (s)":22.2,
        "E2E Throughput (tokens\/s)":45.0,
        "Reserved Memory (MB)":6750,
        "Used Memory (MB)":8224
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":2.91,
        "Open LLM Score (%)":"36.72 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0252,
        "Decode Throughput (tokens\/s)":40.53,
        "Allocated Memory (MB)":6539,
        "Energy (tokens\/kWh)":526315.0,
        "E2E Latency (s)":24.7,
        "E2E Throughput (tokens\/s)":40.5,
        "Reserved Memory (MB)":6750,
        "Used Memory (MB)":8224
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":2.91,
        "Open LLM Score (%)":"36.72 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0252,
        "Decode Throughput (tokens\/s)":40.36,
        "Allocated Memory (MB)":6539,
        "Energy (tokens\/kWh)":537634.0,
        "E2E Latency (s)":24.8,
        "E2E Throughput (tokens\/s)":40.3,
        "Reserved Memory (MB)":6750,
        "Used Memory (MB)":8224
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":2.91,
        "Open LLM Score (%)":"36.72*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0261,
        "Decode Throughput (tokens\/s)":40.69,
        "Allocated Memory (MB)":2858,
        "Energy (tokens\/kWh)":555555.0,
        "E2E Latency (s)":24.6,
        "E2E Throughput (tokens\/s)":40.7,
        "Reserved Memory (MB)":3080,
        "Used Memory (MB)":4556
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":2.91,
        "Open LLM Score (%)":"36.72*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0272,
        "Decode Throughput (tokens\/s)":37.21,
        "Allocated Memory (MB)":3532,
        "Energy (tokens\/kWh)":561797.0,
        "E2E Latency (s)":26.9,
        "E2E Throughput (tokens\/s)":37.2,
        "Reserved Memory (MB)":3755,
        "Used Memory (MB)":5231
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":2.91,
        "Open LLM Score (%)":"36.72*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0329,
        "Decode Throughput (tokens\/s)":36.54,
        "Allocated Memory (MB)":2918,
        "Energy (tokens\/kWh)":500000.0,
        "E2E Latency (s)":27.4,
        "E2E Throughput (tokens\/s)":36.5,
        "Reserved Memory (MB)":3032,
        "Used Memory (MB)":4506
    },
    {
        "Model":"EleutherAI\/pythia-2.8b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":2.91,
        "Open LLM Score (%)":"36.72*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0379,
        "Decode Throughput (tokens\/s)":33.94,
        "Allocated Memory (MB)":2918,
        "Energy (tokens\/kWh)":462962.0,
        "E2E Latency (s)":29.5,
        "E2E Throughput (tokens\/s)":33.9,
        "Reserved Memory (MB)":3032,
        "Used Memory (MB)":4506
    },
    {
        "Model":"facebook\/xglm-7.5B",
        "Arch":"xglm",
        "Params (B)":7.49,
        "Open LLM Score (%)":"36.38 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0331,
        "Decode Throughput (tokens\/s)":50.33,
        "Allocated Memory (MB)":16352,
        "Energy (tokens\/kWh)":497512.0,
        "E2E Latency (s)":19.9,
        "E2E Throughput (tokens\/s)":50.3,
        "Reserved Memory (MB)":16399,
        "Used Memory (MB)":17873
    },
    {
        "Model":"facebook\/xglm-7.5B",
        "Arch":"xglm",
        "Params (B)":7.49,
        "Open LLM Score (%)":"36.38 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0333,
        "Decode Throughput (tokens\/s)":50.59,
        "Allocated Memory (MB)":16352,
        "Energy (tokens\/kWh)":492610.0,
        "E2E Latency (s)":19.8,
        "E2E Throughput (tokens\/s)":50.5,
        "Reserved Memory (MB)":16399,
        "Used Memory (MB)":17873
    },
    {
        "Model":"facebook\/xglm-7.5B",
        "Arch":"xglm",
        "Params (B)":7.49,
        "Open LLM Score (%)":"36.38*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0402,
        "Decode Throughput (tokens\/s)":53.31,
        "Allocated Memory (MB)":6952,
        "Energy (tokens\/kWh)":617283.0,
        "E2E Latency (s)":18.8,
        "E2E Throughput (tokens\/s)":53.2,
        "Reserved Memory (MB)":7247,
        "Used Memory (MB)":8723
    },
    {
        "Model":"facebook\/xglm-7.5B",
        "Arch":"xglm",
        "Params (B)":7.49,
        "Open LLM Score (%)":"36.38*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0421,
        "Decode Throughput (tokens\/s)":51.13,
        "Allocated Memory (MB)":8031,
        "Energy (tokens\/kWh)":625000.0,
        "E2E Latency (s)":19.6,
        "E2E Throughput (tokens\/s)":51.0,
        "Reserved Memory (MB)":8327,
        "Used Memory (MB)":9803
    },
    {
        "Model":"facebook\/xglm-7.5B",
        "Arch":"xglm",
        "Params (B)":7.49,
        "Open LLM Score (%)":"36.38*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0505,
        "Decode Throughput (tokens\/s)":37.11,
        "Allocated Memory (MB)":7089,
        "Energy (tokens\/kWh)":442477.0,
        "E2E Latency (s)":27.0,
        "E2E Throughput (tokens\/s)":37.0,
        "Reserved Memory (MB)":7140,
        "Used Memory (MB)":8614
    },
    {
        "Model":"cerebras\/Cerebras-GPT-6.7B",
        "Arch":"gpt2",
        "Params (B)":6.66,
        "Open LLM Score (%)":"36.27*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0231,
        "Decode Throughput (tokens\/s)":62.59,
        "Allocated Memory (MB)":14803,
        "Energy (tokens\/kWh)":689655.0,
        "E2E Latency (s)":16.0,
        "E2E Throughput (tokens\/s)":62.5,
        "Reserved Memory (MB)":14858,
        "Used Memory (MB)":16329
    },
    {
        "Model":"cerebras\/Cerebras-GPT-6.7B",
        "Arch":"gpt2",
        "Params (B)":6.66,
        "Open LLM Score (%)":"36.27*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0259,
        "Decode Throughput (tokens\/s)":53.55,
        "Allocated Memory (MB)":14803,
        "Energy (tokens\/kWh)":606060.0,
        "E2E Latency (s)":18.7,
        "E2E Throughput (tokens\/s)":53.5,
        "Reserved Memory (MB)":14858,
        "Used Memory (MB)":16332
    },
    {
        "Model":"cerebras\/Cerebras-GPT-6.7B",
        "Arch":"gpt2",
        "Params (B)":6.66,
        "Open LLM Score (%)":"36.27 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0274,
        "Decode Throughput (tokens\/s)":62.61,
        "Allocated Memory (MB)":14803,
        "Energy (tokens\/kWh)":568181.0,
        "E2E Latency (s)":16.0,
        "E2E Throughput (tokens\/s)":62.5,
        "Reserved Memory (MB)":14858,
        "Used Memory (MB)":16329
    },
    {
        "Model":"cerebras\/Cerebras-GPT-6.7B",
        "Arch":"gpt2",
        "Params (B)":6.66,
        "Open LLM Score (%)":"36.27 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0284,
        "Decode Throughput (tokens\/s)":53.85,
        "Allocated Memory (MB)":14803,
        "Energy (tokens\/kWh)":531914.0,
        "E2E Latency (s)":18.6,
        "E2E Throughput (tokens\/s)":53.8,
        "Reserved Memory (MB)":14858,
        "Used Memory (MB)":16332
    },
    {
        "Model":"cerebras\/Cerebras-GPT-6.7B",
        "Arch":"gpt2",
        "Params (B)":6.66,
        "Open LLM Score (%)":"36.27 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0288,
        "Decode Throughput (tokens\/s)":53.56,
        "Allocated Memory (MB)":14803,
        "Energy (tokens\/kWh)":507614.0,
        "E2E Latency (s)":18.7,
        "E2E Throughput (tokens\/s)":53.5,
        "Reserved Memory (MB)":14858,
        "Used Memory (MB)":16332
    },
    {
        "Model":"cerebras\/Cerebras-GPT-6.7B",
        "Arch":"gpt2",
        "Params (B)":6.66,
        "Open LLM Score (%)":"36.27*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0378,
        "Decode Throughput (tokens\/s)":56.94,
        "Allocated Memory (MB)":5401,
        "Energy (tokens\/kWh)":641025.0,
        "E2E Latency (s)":17.6,
        "E2E Throughput (tokens\/s)":56.8,
        "Reserved Memory (MB)":5419,
        "Used Memory (MB)":6894
    },
    {
        "Model":"cerebras\/Cerebras-GPT-6.7B",
        "Arch":"gpt2",
        "Params (B)":6.66,
        "Open LLM Score (%)":"36.27*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0392,
        "Decode Throughput (tokens\/s)":55.99,
        "Allocated Memory (MB)":6478,
        "Energy (tokens\/kWh)":694444.0,
        "E2E Latency (s)":17.9,
        "E2E Throughput (tokens\/s)":55.9,
        "Reserved Memory (MB)":6499,
        "Used Memory (MB)":7974
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"gpt_neo",
        "Params (B)":2.72,
        "Open LLM Score (%)":"36.20 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0217,
        "Decode Throughput (tokens\/s)":44.49,
        "Allocated Memory (MB)":6269,
        "Energy (tokens\/kWh)":574712.0,
        "E2E Latency (s)":22.5,
        "E2E Throughput (tokens\/s)":44.4,
        "Reserved Memory (MB)":6631,
        "Used Memory (MB)":8104
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"gpt_neo",
        "Params (B)":2.72,
        "Open LLM Score (%)":"36.20 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0225,
        "Decode Throughput (tokens\/s)":45.09,
        "Allocated Memory (MB)":6281,
        "Energy (tokens\/kWh)":568181.0,
        "E2E Latency (s)":22.2,
        "E2E Throughput (tokens\/s)":45.0,
        "Reserved Memory (MB)":6727,
        "Used Memory (MB)":8201
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"gpt_neo",
        "Params (B)":2.72,
        "Open LLM Score (%)":"36.20 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0227,
        "Decode Throughput (tokens\/s)":43.33,
        "Allocated Memory (MB)":6281,
        "Energy (tokens\/kWh)":578034.0,
        "E2E Latency (s)":23.1,
        "E2E Throughput (tokens\/s)":43.3,
        "Reserved Memory (MB)":6727,
        "Used Memory (MB)":8201
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"gpt_neo",
        "Params (B)":2.72,
        "Open LLM Score (%)":"36.20*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0258,
        "Decode Throughput (tokens\/s)":43.91,
        "Allocated Memory (MB)":2624,
        "Energy (tokens\/kWh)":574712.0,
        "E2E Latency (s)":22.8,
        "E2E Throughput (tokens\/s)":43.9,
        "Reserved Memory (MB)":2908,
        "Used Memory (MB)":4384
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"gpt_neo",
        "Params (B)":2.72,
        "Open LLM Score (%)":"36.20*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0269,
        "Decode Throughput (tokens\/s)":44.7,
        "Allocated Memory (MB)":3298,
        "Energy (tokens\/kWh)":581395.0,
        "E2E Latency (s)":22.4,
        "E2E Throughput (tokens\/s)":44.6,
        "Reserved Memory (MB)":3571,
        "Used Memory (MB)":5047
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"gpt_neo",
        "Params (B)":2.72,
        "Open LLM Score (%)":"36.20*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0354,
        "Decode Throughput (tokens\/s)":38.66,
        "Allocated Memory (MB)":2674,
        "Energy (tokens\/kWh)":537634.0,
        "E2E Latency (s)":25.9,
        "E2E Throughput (tokens\/s)":38.6,
        "Reserved Memory (MB)":2797,
        "Used Memory (MB)":4271
    },
    {
        "Model":"EleutherAI\/gpt-neo-2.7B",
        "Arch":"gpt_neo",
        "Params (B)":2.72,
        "Open LLM Score (%)":"36.20*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0396,
        "Decode Throughput (tokens\/s)":34.53,
        "Allocated Memory (MB)":2686,
        "Energy (tokens\/kWh)":476190.0,
        "E2E Latency (s)":29.0,
        "E2E Throughput (tokens\/s)":34.5,
        "Reserved Memory (MB)":2900,
        "Used Memory (MB)":4374
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"gpt_neox",
        "Params (B)":2.65,
        "Open LLM Score (%)":"36.15 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0213,
        "Decode Throughput (tokens\/s)":44.89,
        "Allocated Memory (MB)":6555,
        "Energy (tokens\/kWh)":584795.0,
        "E2E Latency (s)":22.3,
        "E2E Throughput (tokens\/s)":44.8,
        "Reserved Memory (MB)":6769,
        "Used Memory (MB)":8243
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"gpt_neox",
        "Params (B)":2.65,
        "Open LLM Score (%)":"36.15 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0251,
        "Decode Throughput (tokens\/s)":40.53,
        "Allocated Memory (MB)":6555,
        "Energy (tokens\/kWh)":540540.0,
        "E2E Latency (s)":24.7,
        "E2E Throughput (tokens\/s)":40.5,
        "Reserved Memory (MB)":6769,
        "Used Memory (MB)":8243
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"gpt_neox",
        "Params (B)":2.65,
        "Open LLM Score (%)":"36.15 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0253,
        "Decode Throughput (tokens\/s)":40.69,
        "Allocated Memory (MB)":6555,
        "Energy (tokens\/kWh)":523560.0,
        "E2E Latency (s)":24.6,
        "E2E Throughput (tokens\/s)":40.7,
        "Reserved Memory (MB)":6769,
        "Used Memory (MB)":8243
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"gpt_neox",
        "Params (B)":2.65,
        "Open LLM Score (%)":"36.15*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0264,
        "Decode Throughput (tokens\/s)":39.41,
        "Allocated Memory (MB)":3548,
        "Energy (tokens\/kWh)":568181.0,
        "E2E Latency (s)":25.4,
        "E2E Throughput (tokens\/s)":39.4,
        "Reserved Memory (MB)":3776,
        "Used Memory (MB)":5252
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"gpt_neox",
        "Params (B)":2.65,
        "Open LLM Score (%)":"36.15*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.027,
        "Decode Throughput (tokens\/s)":41.71,
        "Allocated Memory (MB)":2874,
        "Energy (tokens\/kWh)":552486.0,
        "E2E Latency (s)":24.0,
        "E2E Throughput (tokens\/s)":41.7,
        "Reserved Memory (MB)":3099,
        "Used Memory (MB)":4575
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"gpt_neox",
        "Params (B)":2.65,
        "Open LLM Score (%)":"36.15*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0337,
        "Decode Throughput (tokens\/s)":37.08,
        "Allocated Memory (MB)":2933,
        "Energy (tokens\/kWh)":512820.0,
        "E2E Latency (s)":27.0,
        "E2E Throughput (tokens\/s)":37.0,
        "Reserved Memory (MB)":3042,
        "Used Memory (MB)":4516
    },
    {
        "Model":"Dampish\/StellarX-4B-V0.2",
        "Arch":"gpt_neox",
        "Params (B)":2.65,
        "Open LLM Score (%)":"36.15*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0371,
        "Decode Throughput (tokens\/s)":33.49,
        "Allocated Memory (MB)":2933,
        "Energy (tokens\/kWh)":467289.0,
        "E2E Latency (s)":29.9,
        "E2E Throughput (tokens\/s)":33.4,
        "Reserved Memory (MB)":3042,
        "Used Memory (MB)":4516
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"bloom",
        "Params (B)":3.0,
        "Open LLM Score (%)":"36.07 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.017,
        "Decode Throughput (tokens\/s)":55.3,
        "Allocated Memory (MB)":6802,
        "Energy (tokens\/kWh)":680272.0,
        "E2E Latency (s)":18.1,
        "E2E Throughput (tokens\/s)":55.2,
        "Reserved Memory (MB)":6937,
        "Used Memory (MB)":8411
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"bloom",
        "Params (B)":3.0,
        "Open LLM Score (%)":"36.07 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0196,
        "Decode Throughput (tokens\/s)":52.96,
        "Allocated Memory (MB)":6803,
        "Energy (tokens\/kWh)":662251.0,
        "E2E Latency (s)":18.9,
        "E2E Throughput (tokens\/s)":52.9,
        "Reserved Memory (MB)":6937,
        "Used Memory (MB)":8411
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"bloom",
        "Params (B)":3.0,
        "Open LLM Score (%)":"36.07*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0204,
        "Decode Throughput (tokens\/s)":54.71,
        "Allocated Memory (MB)":4021,
        "Energy (tokens\/kWh)":719424.0,
        "E2E Latency (s)":18.3,
        "E2E Throughput (tokens\/s)":54.6,
        "Reserved Memory (MB)":4250,
        "Used Memory (MB)":5726
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"bloom",
        "Params (B)":3.0,
        "Open LLM Score (%)":"36.07 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0204,
        "Decode Throughput (tokens\/s)":51.87,
        "Allocated Memory (MB)":6803,
        "Energy (tokens\/kWh)":649350.0,
        "E2E Latency (s)":19.3,
        "E2E Throughput (tokens\/s)":51.8,
        "Reserved Memory (MB)":6937,
        "Used Memory (MB)":8411
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"bloom",
        "Params (B)":3.0,
        "Open LLM Score (%)":"36.07*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0209,
        "Decode Throughput (tokens\/s)":51.34,
        "Allocated Memory (MB)":3348,
        "Energy (tokens\/kWh)":680272.0,
        "E2E Latency (s)":19.5,
        "E2E Throughput (tokens\/s)":51.3,
        "Reserved Memory (MB)":3554,
        "Used Memory (MB)":5030
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"bloom",
        "Params (B)":3.0,
        "Open LLM Score (%)":"36.07*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0284,
        "Decode Throughput (tokens\/s)":44.7,
        "Allocated Memory (MB)":3408,
        "Energy (tokens\/kWh)":598802.0,
        "E2E Latency (s)":22.4,
        "E2E Throughput (tokens\/s)":44.6,
        "Reserved Memory (MB)":3491,
        "Used Memory (MB)":4965
    },
    {
        "Model":"bigscience\/bloom-3b",
        "Arch":"bloom",
        "Params (B)":3.0,
        "Open LLM Score (%)":"36.07*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0311,
        "Decode Throughput (tokens\/s)":42.43,
        "Allocated Memory (MB)":3407,
        "Energy (tokens\/kWh)":558659.0,
        "E2E Latency (s)":23.6,
        "E2E Throughput (tokens\/s)":42.4,
        "Reserved Memory (MB)":3495,
        "Used Memory (MB)":4969
    },
    {
        "Model":"RWKV\/rwkv-4-3b-pile",
        "Arch":"rwkv",
        "Params (B)":2.86,
        "Open LLM Score (%)":"35.25 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.034,
        "Decode Throughput (tokens\/s)":29.1,
        "Allocated Memory (MB)":6007,
        "Energy (tokens\/kWh)":411522.0,
        "E2E Latency (s)":34.4,
        "E2E Throughput (tokens\/s)":29.1,
        "Reserved Memory (MB)":6272,
        "Used Memory (MB)":7746
    },
    {
        "Model":"RWKV\/rwkv-4-3b-pile",
        "Arch":"rwkv",
        "Params (B)":2.86,
        "Open LLM Score (%)":"35.25 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":2.07,
        "Decode Throughput (tokens\/s)":29.3,
        "Allocated Memory (MB)":6007,
        "Energy (tokens\/kWh)":390625.0,
        "E2E Latency (s)":36.2,
        "E2E Throughput (tokens\/s)":27.6,
        "Reserved Memory (MB)":6272,
        "Used Memory (MB)":7746
    },
    {
        "Model":"RWKV\/rwkv-4-3b-pile",
        "Arch":"rwkv",
        "Params (B)":2.86,
        "Open LLM Score (%)":"35.25*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":2.23,
        "Decode Throughput (tokens\/s)":21.85,
        "Allocated Memory (MB)":2082,
        "Energy (tokens\/kWh)":306748.0,
        "E2E Latency (s)":48.0,
        "E2E Throughput (tokens\/s)":20.8,
        "Reserved Memory (MB)":2170,
        "Used Memory (MB)":3644
    },
    {
        "Model":"Writer\/palmyra-base",
        "Arch":"gpt2",
        "Params (B)":5.05,
        "Open LLM Score (%)":"35.18*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0183,
        "Decode Throughput (tokens\/s)":82.77,
        "Allocated Memory (MB)":11212,
        "Energy (tokens\/kWh)":900900.0,
        "E2E Latency (s)":12.1,
        "E2E Throughput (tokens\/s)":82.6,
        "Reserved Memory (MB)":11257,
        "Used Memory (MB)":12729
    },
    {
        "Model":"Writer\/palmyra-base",
        "Arch":"gpt2",
        "Params (B)":5.05,
        "Open LLM Score (%)":"35.18*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.02,
        "Decode Throughput (tokens\/s)":71.53,
        "Allocated Memory (MB)":11211,
        "Energy (tokens\/kWh)":813008.0,
        "E2E Latency (s)":14.0,
        "E2E Throughput (tokens\/s)":71.4,
        "Reserved Memory (MB)":11236,
        "Used Memory (MB)":12710
    },
    {
        "Model":"Writer\/palmyra-base",
        "Arch":"gpt2",
        "Params (B)":5.05,
        "Open LLM Score (%)":"35.18 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0204,
        "Decode Throughput (tokens\/s)":82.78,
        "Allocated Memory (MB)":11212,
        "Energy (tokens\/kWh)":751879.0,
        "E2E Latency (s)":12.1,
        "E2E Throughput (tokens\/s)":82.6,
        "Reserved Memory (MB)":11257,
        "Used Memory (MB)":12729
    },
    {
        "Model":"Writer\/palmyra-base",
        "Arch":"gpt2",
        "Params (B)":5.05,
        "Open LLM Score (%)":"35.18 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0217,
        "Decode Throughput (tokens\/s)":71.54,
        "Allocated Memory (MB)":11212,
        "Energy (tokens\/kWh)":709219.0,
        "E2E Latency (s)":14.0,
        "E2E Throughput (tokens\/s)":71.4,
        "Reserved Memory (MB)":11257,
        "Used Memory (MB)":12731
    },
    {
        "Model":"Writer\/palmyra-base",
        "Arch":"gpt2",
        "Params (B)":5.05,
        "Open LLM Score (%)":"35.18 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0219,
        "Decode Throughput (tokens\/s)":72.06,
        "Allocated Memory (MB)":11212,
        "Energy (tokens\/kWh)":675675.0,
        "E2E Latency (s)":13.9,
        "E2E Throughput (tokens\/s)":71.9,
        "Reserved Memory (MB)":11257,
        "Used Memory (MB)":12731
    },
    {
        "Model":"Writer\/palmyra-base",
        "Arch":"gpt2",
        "Params (B)":5.05,
        "Open LLM Score (%)":"35.18*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0292,
        "Decode Throughput (tokens\/s)":70.07,
        "Allocated Memory (MB)":4194,
        "Energy (tokens\/kWh)":813008.0,
        "E2E Latency (s)":14.3,
        "E2E Throughput (tokens\/s)":69.9,
        "Reserved Memory (MB)":4227,
        "Used Memory (MB)":5703
    },
    {
        "Model":"Writer\/palmyra-base",
        "Arch":"gpt2",
        "Params (B)":5.05,
        "Open LLM Score (%)":"35.18*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0297,
        "Decode Throughput (tokens\/s)":74.24,
        "Allocated Memory (MB)":5270,
        "Energy (tokens\/kWh)":917431.0,
        "E2E Latency (s)":13.5,
        "E2E Throughput (tokens\/s)":74.1,
        "Reserved Memory (MB)":5307,
        "Used Memory (MB)":6783
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":1.31,
        "Open LLM Score (%)":"35.00 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0157,
        "Decode Throughput (tokens\/s)":61.79,
        "Allocated Memory (MB)":3450,
        "Energy (tokens\/kWh)":854700.0,
        "E2E Latency (s)":16.2,
        "E2E Throughput (tokens\/s)":61.7,
        "Reserved Memory (MB)":3516,
        "Used Memory (MB)":4988
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":1.31,
        "Open LLM Score (%)":"35.00 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0189,
        "Decode Throughput (tokens\/s)":52.96,
        "Allocated Memory (MB)":3450,
        "Energy (tokens\/kWh)":746268.0,
        "E2E Latency (s)":18.9,
        "E2E Throughput (tokens\/s)":52.9,
        "Reserved Memory (MB)":3516,
        "Used Memory (MB)":4990
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":1.31,
        "Open LLM Score (%)":"35.00 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.019,
        "Decode Throughput (tokens\/s)":53.25,
        "Allocated Memory (MB)":3450,
        "Energy (tokens\/kWh)":729927.0,
        "E2E Latency (s)":18.8,
        "E2E Throughput (tokens\/s)":53.2,
        "Reserved Memory (MB)":3516,
        "Used Memory (MB)":4990
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":1.31,
        "Open LLM Score (%)":"35.00*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0195,
        "Decode Throughput (tokens\/s)":54.11,
        "Allocated Memory (MB)":2232,
        "Energy (tokens\/kWh)":775193.0,
        "E2E Latency (s)":18.5,
        "E2E Throughput (tokens\/s)":54.1,
        "Reserved Memory (MB)":2298,
        "Used Memory (MB)":3774
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":1.31,
        "Open LLM Score (%)":"35.00*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0203,
        "Decode Throughput (tokens\/s)":53.82,
        "Allocated Memory (MB)":1694,
        "Energy (tokens\/kWh)":735294.0,
        "E2E Latency (s)":18.6,
        "E2E Throughput (tokens\/s)":53.8,
        "Reserved Memory (MB)":1757,
        "Used Memory (MB)":3233
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":1.31,
        "Open LLM Score (%)":"35.00*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0247,
        "Decode Throughput (tokens\/s)":50.06,
        "Allocated Memory (MB)":1710,
        "Energy (tokens\/kWh)":729927.0,
        "E2E Latency (s)":20.0,
        "E2E Throughput (tokens\/s)":50.0,
        "Reserved Memory (MB)":1786,
        "Used Memory (MB)":3258
    },
    {
        "Model":"EleutherAI\/pythia-1.4b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":1.31,
        "Open LLM Score (%)":"35.00*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0276,
        "Decode Throughput (tokens\/s)":44.3,
        "Allocated Memory (MB)":1710,
        "Energy (tokens\/kWh)":641025.0,
        "E2E Latency (s)":22.6,
        "E2E Throughput (tokens\/s)":44.2,
        "Reserved Memory (MB)":1786,
        "Used Memory (MB)":3260
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"gpt_neox",
        "Params (B)":1.31,
        "Open LLM Score (%)":"34.46 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.016,
        "Decode Throughput (tokens\/s)":61.04,
        "Allocated Memory (MB)":3450,
        "Energy (tokens\/kWh)":840336.0,
        "E2E Latency (s)":16.4,
        "E2E Throughput (tokens\/s)":61.0,
        "Reserved Memory (MB)":3516,
        "Used Memory (MB)":4988
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"gpt_neox",
        "Params (B)":1.31,
        "Open LLM Score (%)":"34.46 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0188,
        "Decode Throughput (tokens\/s)":53.24,
        "Allocated Memory (MB)":3450,
        "Energy (tokens\/kWh)":751879.0,
        "E2E Latency (s)":18.8,
        "E2E Throughput (tokens\/s)":53.2,
        "Reserved Memory (MB)":3516,
        "Used Memory (MB)":4990
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"gpt_neox",
        "Params (B)":1.31,
        "Open LLM Score (%)":"34.46 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0188,
        "Decode Throughput (tokens\/s)":53.24,
        "Allocated Memory (MB)":3450,
        "Energy (tokens\/kWh)":735294.0,
        "E2E Latency (s)":18.8,
        "E2E Throughput (tokens\/s)":53.2,
        "Reserved Memory (MB)":3516,
        "Used Memory (MB)":4990
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"gpt_neox",
        "Params (B)":1.31,
        "Open LLM Score (%)":"34.46*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0194,
        "Decode Throughput (tokens\/s)":54.11,
        "Allocated Memory (MB)":2232,
        "Energy (tokens\/kWh)":769230.0,
        "E2E Latency (s)":18.5,
        "E2E Throughput (tokens\/s)":54.1,
        "Reserved Memory (MB)":2298,
        "Used Memory (MB)":3774
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"gpt_neox",
        "Params (B)":1.31,
        "Open LLM Score (%)":"34.46*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.02,
        "Decode Throughput (tokens\/s)":54.7,
        "Allocated Memory (MB)":1694,
        "Energy (tokens\/kWh)":729927.0,
        "E2E Latency (s)":18.3,
        "E2E Throughput (tokens\/s)":54.6,
        "Reserved Memory (MB)":1757,
        "Used Memory (MB)":3233
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"gpt_neox",
        "Params (B)":1.31,
        "Open LLM Score (%)":"34.46*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0247,
        "Decode Throughput (tokens\/s)":49.32,
        "Allocated Memory (MB)":1710,
        "Energy (tokens\/kWh)":719424.0,
        "E2E Latency (s)":20.3,
        "E2E Throughput (tokens\/s)":49.3,
        "Reserved Memory (MB)":1786,
        "Used Memory (MB)":3258
    },
    {
        "Model":"EleutherAI\/pythia-1.3b",
        "Arch":"gpt_neox",
        "Params (B)":1.31,
        "Open LLM Score (%)":"34.46*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0273,
        "Decode Throughput (tokens\/s)":44.7,
        "Allocated Memory (MB)":1710,
        "Energy (tokens\/kWh)":649350.0,
        "E2E Latency (s)":22.4,
        "E2E Throughput (tokens\/s)":44.6,
        "Reserved Memory (MB)":1786,
        "Used Memory (MB)":3260
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"gpt_neox",
        "Params (B)":7.06,
        "Open LLM Score (%)":"34.42 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0302,
        "Decode Throughput (tokens\/s)":44.7,
        "Allocated Memory (MB)":16864,
        "Energy (tokens\/kWh)":452488.0,
        "E2E Latency (s)":22.4,
        "E2E Throughput (tokens\/s)":44.6,
        "Reserved Memory (MB)":16886,
        "Used Memory (MB)":18357
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"gpt_neox",
        "Params (B)":7.06,
        "Open LLM Score (%)":"34.42 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0323,
        "Decode Throughput (tokens\/s)":39.58,
        "Allocated Memory (MB)":16864,
        "Energy (tokens\/kWh)":438596.0,
        "E2E Latency (s)":25.3,
        "E2E Throughput (tokens\/s)":39.5,
        "Reserved Memory (MB)":16886,
        "Used Memory (MB)":18359
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"gpt_neox",
        "Params (B)":7.06,
        "Open LLM Score (%)":"34.42 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0329,
        "Decode Throughput (tokens\/s)":39.89,
        "Allocated Memory (MB)":16864,
        "Energy (tokens\/kWh)":414937.0,
        "E2E Latency (s)":25.1,
        "E2E Throughput (tokens\/s)":39.8,
        "Reserved Memory (MB)":16886,
        "Used Memory (MB)":18360
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"gpt_neox",
        "Params (B)":7.06,
        "Open LLM Score (%)":"34.42*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0418,
        "Decode Throughput (tokens\/s)":40.72,
        "Allocated Memory (MB)":8541,
        "Energy (tokens\/kWh)":515463.0,
        "E2E Latency (s)":24.6,
        "E2E Throughput (tokens\/s)":40.7,
        "Reserved Memory (MB)":8589,
        "Used Memory (MB)":10065
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"gpt_neox",
        "Params (B)":7.06,
        "Open LLM Score (%)":"34.42*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0438,
        "Decode Throughput (tokens\/s)":34.9,
        "Allocated Memory (MB)":7464,
        "Energy (tokens\/kWh)":384615.0,
        "E2E Latency (s)":28.7,
        "E2E Throughput (tokens\/s)":34.8,
        "Reserved Memory (MB)":7509,
        "Used Memory (MB)":8985
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"gpt_neox",
        "Params (B)":7.06,
        "Open LLM Score (%)":"34.42*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0467,
        "Decode Throughput (tokens\/s)":36.56,
        "Allocated Memory (MB)":7630,
        "Energy (tokens\/kWh)":452488.0,
        "E2E Latency (s)":27.4,
        "E2E Throughput (tokens\/s)":36.5,
        "Reserved Memory (MB)":7673,
        "Used Memory (MB)":9145
    },
    {
        "Model":"NYTK\/PULI-GPTrio",
        "Arch":"gpt_neox",
        "Params (B)":7.06,
        "Open LLM Score (%)":"34.42*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.05,
        "Decode Throughput (tokens\/s)":32.84,
        "Allocated Memory (MB)":7631,
        "Energy (tokens\/kWh)":404858.0,
        "E2E Latency (s)":30.5,
        "E2E Throughput (tokens\/s)":32.8,
        "Reserved Memory (MB)":7715,
        "Used Memory (MB)":9189
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"llama",
        "Params (B)":1.03,
        "Open LLM Score (%)":"34.37 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0181,
        "Decode Throughput (tokens\/s)":53.24,
        "Allocated Memory (MB)":2289,
        "Energy (tokens\/kWh)":775193.0,
        "E2E Latency (s)":18.8,
        "E2E Throughput (tokens\/s)":53.2,
        "Reserved Memory (MB)":2443,
        "Used Memory (MB)":3916
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"llama",
        "Params (B)":1.03,
        "Open LLM Score (%)":"34.37 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0198,
        "Decode Throughput (tokens\/s)":51.33,
        "Allocated Memory (MB)":2289,
        "Energy (tokens\/kWh)":746268.0,
        "E2E Latency (s)":19.5,
        "E2E Throughput (tokens\/s)":51.3,
        "Reserved Memory (MB)":2443,
        "Used Memory (MB)":3916
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"llama",
        "Params (B)":1.03,
        "Open LLM Score (%)":"34.37 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0201,
        "Decode Throughput (tokens\/s)":50.56,
        "Allocated Memory (MB)":2289,
        "Energy (tokens\/kWh)":719424.0,
        "E2E Latency (s)":19.8,
        "E2E Throughput (tokens\/s)":50.5,
        "Reserved Memory (MB)":2443,
        "Used Memory (MB)":3916
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"llama",
        "Params (B)":1.03,
        "Open LLM Score (%)":"34.37*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0229,
        "Decode Throughput (tokens\/s)":46.56,
        "Allocated Memory (MB)":1258,
        "Energy (tokens\/kWh)":675675.0,
        "E2E Latency (s)":21.5,
        "E2E Throughput (tokens\/s)":46.5,
        "Reserved Memory (MB)":1348,
        "Used Memory (MB)":2824
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b",
        "Arch":"gpt_neox",
        "Params (B)":7.56,
        "Open LLM Score (%)":"34.37 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0276,
        "Decode Throughput (tokens\/s)":68.62,
        "Allocated Memory (MB)":17012,
        "Energy (tokens\/kWh)":625000.0,
        "E2E Latency (s)":14.6,
        "E2E Throughput (tokens\/s)":68.5,
        "Reserved Memory (MB)":18324,
        "Used Memory (MB)":19796
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b",
        "Arch":"gpt_neox",
        "Params (B)":7.56,
        "Open LLM Score (%)":"34.37 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0277,
        "Decode Throughput (tokens\/s)":65.48,
        "Allocated Memory (MB)":17012,
        "Energy (tokens\/kWh)":584795.0,
        "E2E Latency (s)":15.3,
        "E2E Throughput (tokens\/s)":65.4,
        "Reserved Memory (MB)":18278,
        "Used Memory (MB)":19752
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"llama",
        "Params (B)":1.03,
        "Open LLM Score (%)":"34.37*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0282,
        "Decode Throughput (tokens\/s)":40.53,
        "Allocated Memory (MB)":887,
        "Energy (tokens\/kWh)":613496.0,
        "E2E Latency (s)":24.7,
        "E2E Throughput (tokens\/s)":40.5,
        "Reserved Memory (MB)":977,
        "Used Memory (MB)":2453
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"llama",
        "Params (B)":1.03,
        "Open LLM Score (%)":"34.37*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0317,
        "Decode Throughput (tokens\/s)":40.87,
        "Allocated Memory (MB)":898,
        "Energy (tokens\/kWh)":621118.0,
        "E2E Latency (s)":24.5,
        "E2E Throughput (tokens\/s)":40.8,
        "Reserved Memory (MB)":1010,
        "Used Memory (MB)":2484
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-480k-1T",
        "Arch":"llama",
        "Params (B)":1.03,
        "Open LLM Score (%)":"34.37*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0341,
        "Decode Throughput (tokens\/s)":39.58,
        "Allocated Memory (MB)":898,
        "Energy (tokens\/kWh)":584795.0,
        "E2E Latency (s)":25.3,
        "E2E Throughput (tokens\/s)":39.5,
        "Reserved Memory (MB)":1010,
        "Used Memory (MB)":2484
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b",
        "Arch":"gpt_neox",
        "Params (B)":7.56,
        "Open LLM Score (%)":"34.37*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0359,
        "Decode Throughput (tokens\/s)":63.04,
        "Allocated Memory (MB)":6586,
        "Energy (tokens\/kWh)":540540.0,
        "E2E Latency (s)":15.9,
        "E2E Throughput (tokens\/s)":62.9,
        "Reserved Memory (MB)":7897,
        "Used Memory (MB)":9373
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b",
        "Arch":"gpt_neox",
        "Params (B)":7.56,
        "Open LLM Score (%)":"34.37*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0371,
        "Decode Throughput (tokens\/s)":80.24,
        "Allocated Memory (MB)":8200,
        "Energy (tokens\/kWh)":900900.0,
        "E2E Latency (s)":12.5,
        "E2E Throughput (tokens\/s)":80.0,
        "Reserved Memory (MB)":9512,
        "Used Memory (MB)":10988
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b",
        "Arch":"gpt_neox",
        "Params (B)":7.56,
        "Open LLM Score (%)":"34.37*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0422,
        "Decode Throughput (tokens\/s)":70.63,
        "Allocated Memory (MB)":6593,
        "Energy (tokens\/kWh)":719424.0,
        "E2E Latency (s)":14.2,
        "E2E Throughput (tokens\/s)":70.4,
        "Reserved Memory (MB)":6989,
        "Used Memory (MB)":8461
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-7b",
        "Arch":"gpt_neox",
        "Params (B)":7.56,
        "Open LLM Score (%)":"34.37*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0438,
        "Decode Throughput (tokens\/s)":62.67,
        "Allocated Memory (MB)":6593,
        "Energy (tokens\/kWh)":671140.0,
        "E2E Latency (s)":16.0,
        "E2E Throughput (tokens\/s)":62.5,
        "Reserved Memory (MB)":6949,
        "Used Memory (MB)":8423
    },
    {
        "Model":"facebook\/xglm-4.5B",
        "Arch":"xglm",
        "Params (B)":5.08,
        "Open LLM Score (%)":"34.31 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0316,
        "Decode Throughput (tokens\/s)":35.75,
        "Allocated Memory (MB)":10128,
        "Energy (tokens\/kWh)":421940.0,
        "E2E Latency (s)":28.0,
        "E2E Throughput (tokens\/s)":35.7,
        "Reserved Memory (MB)":10695,
        "Used Memory (MB)":12169
    },
    {
        "Model":"facebook\/xglm-4.5B",
        "Arch":"xglm",
        "Params (B)":5.08,
        "Open LLM Score (%)":"34.31 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.032,
        "Decode Throughput (tokens\/s)":35.38,
        "Allocated Memory (MB)":10128,
        "Energy (tokens\/kWh)":431034.0,
        "E2E Latency (s)":28.3,
        "E2E Throughput (tokens\/s)":35.3,
        "Reserved Memory (MB)":10695,
        "Used Memory (MB)":12169
    },
    {
        "Model":"facebook\/xglm-4.5B",
        "Arch":"xglm",
        "Params (B)":5.08,
        "Open LLM Score (%)":"34.31*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0373,
        "Decode Throughput (tokens\/s)":35.51,
        "Allocated Memory (MB)":4238,
        "Energy (tokens\/kWh)":465116.0,
        "E2E Latency (s)":28.2,
        "E2E Throughput (tokens\/s)":35.5,
        "Reserved Memory (MB)":4397,
        "Used Memory (MB)":5873
    },
    {
        "Model":"facebook\/xglm-4.5B",
        "Arch":"xglm",
        "Params (B)":5.08,
        "Open LLM Score (%)":"34.31*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0376,
        "Decode Throughput (tokens\/s)":36.41,
        "Allocated Memory (MB)":5317,
        "Energy (tokens\/kWh)":483091.0,
        "E2E Latency (s)":27.5,
        "E2E Throughput (tokens\/s)":36.4,
        "Reserved Memory (MB)":5479,
        "Used Memory (MB)":6955
    },
    {
        "Model":"facebook\/xglm-4.5B",
        "Arch":"xglm",
        "Params (B)":5.08,
        "Open LLM Score (%)":"34.31*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0646,
        "Decode Throughput (tokens\/s)":25.23,
        "Allocated Memory (MB)":4338,
        "Energy (tokens\/kWh)":337837.0,
        "E2E Latency (s)":39.7,
        "E2E Throughput (tokens\/s)":25.2,
        "Reserved Memory (MB)":4471,
        "Used Memory (MB)":5944
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"llama",
        "Params (B)":1.1,
        "Open LLM Score (%)":"33.72 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0183,
        "Decode Throughput (tokens\/s)":54.4,
        "Allocated Memory (MB)":2289,
        "Energy (tokens\/kWh)":769230.0,
        "E2E Latency (s)":18.4,
        "E2E Throughput (tokens\/s)":54.3,
        "Reserved Memory (MB)":2443,
        "Used Memory (MB)":3916
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"llama",
        "Params (B)":1.1,
        "Open LLM Score (%)":"33.72 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.02,
        "Decode Throughput (tokens\/s)":51.6,
        "Allocated Memory (MB)":2289,
        "Energy (tokens\/kWh)":746268.0,
        "E2E Latency (s)":19.4,
        "E2E Throughput (tokens\/s)":51.5,
        "Reserved Memory (MB)":2443,
        "Used Memory (MB)":3916
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"llama",
        "Params (B)":1.1,
        "Open LLM Score (%)":"33.72 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0215,
        "Decode Throughput (tokens\/s)":48.59,
        "Allocated Memory (MB)":2289,
        "Energy (tokens\/kWh)":729927.0,
        "E2E Latency (s)":20.6,
        "E2E Throughput (tokens\/s)":48.5,
        "Reserved Memory (MB)":2443,
        "Used Memory (MB)":3916
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"llama",
        "Params (B)":1.1,
        "Open LLM Score (%)":"33.72*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0228,
        "Decode Throughput (tokens\/s)":46.78,
        "Allocated Memory (MB)":1258,
        "Energy (tokens\/kWh)":675675.0,
        "E2E Latency (s)":21.4,
        "E2E Throughput (tokens\/s)":46.7,
        "Reserved Memory (MB)":1348,
        "Used Memory (MB)":2824
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"llama",
        "Params (B)":1.1,
        "Open LLM Score (%)":"33.72*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0245,
        "Decode Throughput (tokens\/s)":47.22,
        "Allocated Memory (MB)":887,
        "Energy (tokens\/kWh)":645161.0,
        "E2E Latency (s)":21.2,
        "E2E Throughput (tokens\/s)":47.2,
        "Reserved Memory (MB)":977,
        "Used Memory (MB)":2453
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"llama",
        "Params (B)":1.1,
        "Open LLM Score (%)":"33.72*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0313,
        "Decode Throughput (tokens\/s)":41.38,
        "Allocated Memory (MB)":898,
        "Energy (tokens\/kWh)":621118.0,
        "E2E Latency (s)":24.2,
        "E2E Throughput (tokens\/s)":41.3,
        "Reserved Memory (MB)":1010,
        "Used Memory (MB)":2484
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-intermediate-step-240k-503b",
        "Arch":"llama",
        "Params (B)":1.1,
        "Open LLM Score (%)":"33.72*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0336,
        "Decode Throughput (tokens\/s)":39.27,
        "Allocated Memory (MB)":898,
        "Energy (tokens\/kWh)":588235.0,
        "E2E Latency (s)":25.5,
        "E2E Throughput (tokens\/s)":39.2,
        "Reserved Memory (MB)":1010,
        "Used Memory (MB)":2484
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"gpt_neo",
        "Params (B)":1.37,
        "Open LLM Score (%)":"33.58 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0162,
        "Decode Throughput (tokens\/s)":58.88,
        "Allocated Memory (MB)":3244,
        "Energy (tokens\/kWh)":819672.0,
        "E2E Latency (s)":17.0,
        "E2E Throughput (tokens\/s)":58.8,
        "Reserved Memory (MB)":3437,
        "Used Memory (MB)":4911
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"gpt_neo",
        "Params (B)":1.37,
        "Open LLM Score (%)":"33.58 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0165,
        "Decode Throughput (tokens\/s)":61.04,
        "Allocated Memory (MB)":3254,
        "Energy (tokens\/kWh)":826446.0,
        "E2E Latency (s)":16.4,
        "E2E Throughput (tokens\/s)":61.0,
        "Reserved Memory (MB)":3437,
        "Used Memory (MB)":4910
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"gpt_neo",
        "Params (B)":1.37,
        "Open LLM Score (%)":"33.58 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0168,
        "Decode Throughput (tokens\/s)":59.94,
        "Allocated Memory (MB)":3254,
        "Energy (tokens\/kWh)":806451.0,
        "E2E Latency (s)":16.7,
        "E2E Throughput (tokens\/s)":59.9,
        "Reserved Memory (MB)":3437,
        "Used Memory (MB)":4911
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"gpt_neo",
        "Params (B)":1.37,
        "Open LLM Score (%)":"33.58*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0188,
        "Decode Throughput (tokens\/s)":56.56,
        "Allocated Memory (MB)":2040,
        "Energy (tokens\/kWh)":806451.0,
        "E2E Latency (s)":17.7,
        "E2E Throughput (tokens\/s)":56.5,
        "Reserved Memory (MB)":2132,
        "Used Memory (MB)":3608
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"gpt_neo",
        "Params (B)":1.37,
        "Open LLM Score (%)":"33.58*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0191,
        "Decode Throughput (tokens\/s)":56.24,
        "Allocated Memory (MB)":1501,
        "Energy (tokens\/kWh)":799999.0,
        "E2E Latency (s)":17.8,
        "E2E Throughput (tokens\/s)":56.2,
        "Reserved Memory (MB)":1591,
        "Used Memory (MB)":3067
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"gpt_neo",
        "Params (B)":1.37,
        "Open LLM Score (%)":"33.58*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0294,
        "Decode Throughput (tokens\/s)":47.01,
        "Allocated Memory (MB)":1507,
        "Energy (tokens\/kWh)":666666.0,
        "E2E Latency (s)":21.3,
        "E2E Throughput (tokens\/s)":46.9,
        "Reserved Memory (MB)":1606,
        "Used Memory (MB)":3080
    },
    {
        "Model":"EleutherAI\/gpt-neo-1.3B",
        "Arch":"gpt_neo",
        "Params (B)":1.37,
        "Open LLM Score (%)":"33.58*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0316,
        "Decode Throughput (tokens\/s)":45.31,
        "Allocated Memory (MB)":1517,
        "Energy (tokens\/kWh)":636942.0,
        "E2E Latency (s)":22.1,
        "E2E Throughput (tokens\/s)":45.2,
        "Reserved Memory (MB)":1606,
        "Used Memory (MB)":3080
    },
    {
        "Model":"EleutherAI\/polyglot-ko-12.8b",
        "Arch":"gpt_neox",
        "Params (B)":13.06,
        "Open LLM Score (%)":"33.33 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0507,
        "Decode Throughput (tokens\/s)":34.07,
        "Allocated Memory (MB)":28041,
        "Energy (tokens\/kWh)":305810.0,
        "E2E Latency (s)":29.4,
        "E2E Throughput (tokens\/s)":34.0,
        "Reserved Memory (MB)":30410,
        "Used Memory (MB)":31882
    },
    {
        "Model":"EleutherAI\/polyglot-ko-12.8b",
        "Arch":"gpt_neox",
        "Params (B)":13.06,
        "Open LLM Score (%)":"33.33 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0526,
        "Decode Throughput (tokens\/s)":31.7,
        "Allocated Memory (MB)":28041,
        "Energy (tokens\/kWh)":304878.0,
        "E2E Latency (s)":31.6,
        "E2E Throughput (tokens\/s)":31.6,
        "Reserved Memory (MB)":30410,
        "Used Memory (MB)":31884
    },
    {
        "Model":"EleutherAI\/polyglot-ko-12.8b",
        "Arch":"gpt_neox",
        "Params (B)":13.06,
        "Open LLM Score (%)":"33.33*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0688,
        "Decode Throughput (tokens\/s)":32.43,
        "Allocated Memory (MB)":11018,
        "Energy (tokens\/kWh)":393700.0,
        "E2E Latency (s)":30.9,
        "E2E Throughput (tokens\/s)":32.4,
        "Reserved Memory (MB)":13373,
        "Used Memory (MB)":14849
    },
    {
        "Model":"EleutherAI\/polyglot-ko-12.8b",
        "Arch":"gpt_neox",
        "Params (B)":13.06,
        "Open LLM Score (%)":"33.33*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0689,
        "Decode Throughput (tokens\/s)":32.54,
        "Allocated Memory (MB)":9670,
        "Energy (tokens\/kWh)":366300.0,
        "E2E Latency (s)":30.8,
        "E2E Throughput (tokens\/s)":32.5,
        "Reserved Memory (MB)":12002,
        "Used Memory (MB)":13477
    },
    {
        "Model":"EleutherAI\/polyglot-ko-12.8b",
        "Arch":"gpt_neox",
        "Params (B)":13.06,
        "Open LLM Score (%)":"33.33*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.079,
        "Decode Throughput (tokens\/s)":29.83,
        "Allocated Memory (MB)":9966,
        "Energy (tokens\/kWh)":335570.0,
        "E2E Latency (s)":33.6,
        "E2E Throughput (tokens\/s)":29.8,
        "Reserved Memory (MB)":11234,
        "Used Memory (MB)":12706
    },
    {
        "Model":"EleutherAI\/polyglot-ko-12.8b",
        "Arch":"gpt_neox",
        "Params (B)":13.06,
        "Open LLM Score (%)":"33.33*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0825,
        "Decode Throughput (tokens\/s)":27.09,
        "Allocated Memory (MB)":9966,
        "Energy (tokens\/kWh)":307692.0,
        "E2E Latency (s)":37.0,
        "E2E Throughput (tokens\/s)":27.0,
        "Reserved Memory (MB)":11261,
        "Used Memory (MB)":12735
    },
    {
        "Model":"cerebras\/Cerebras-GPT-2.7B",
        "Arch":"gpt2",
        "Params (B)":2.65,
        "Open LLM Score (%)":"33.25*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0153,
        "Decode Throughput (tokens\/s)":62.95,
        "Allocated Memory (MB)":6286,
        "Energy (tokens\/kWh)":833333.0,
        "E2E Latency (s)":15.9,
        "E2E Throughput (tokens\/s)":62.9,
        "Reserved Memory (MB)":6496,
        "Used Memory (MB)":7970
    },
    {
        "Model":"cerebras\/Cerebras-GPT-2.7B",
        "Arch":"gpt2",
        "Params (B)":2.65,
        "Open LLM Score (%)":"33.25 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0158,
        "Decode Throughput (tokens\/s)":62.96,
        "Allocated Memory (MB)":6286,
        "Energy (tokens\/kWh)":787401.0,
        "E2E Latency (s)":15.9,
        "E2E Throughput (tokens\/s)":62.9,
        "Reserved Memory (MB)":6496,
        "Used Memory (MB)":7970
    },
    {
        "Model":"cerebras\/Cerebras-GPT-2.7B",
        "Arch":"gpt2",
        "Params (B)":2.65,
        "Open LLM Score (%)":"33.25*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0188,
        "Decode Throughput (tokens\/s)":55.61,
        "Allocated Memory (MB)":6286,
        "Energy (tokens\/kWh)":746268.0,
        "E2E Latency (s)":18.0,
        "E2E Throughput (tokens\/s)":55.6,
        "Reserved Memory (MB)":6496,
        "Used Memory (MB)":7970
    },
    {
        "Model":"cerebras\/Cerebras-GPT-2.7B",
        "Arch":"gpt2",
        "Params (B)":2.65,
        "Open LLM Score (%)":"33.25 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0188,
        "Decode Throughput (tokens\/s)":55.31,
        "Allocated Memory (MB)":6286,
        "Energy (tokens\/kWh)":709219.0,
        "E2E Latency (s)":18.1,
        "E2E Throughput (tokens\/s)":55.2,
        "Reserved Memory (MB)":6496,
        "Used Memory (MB)":7970
    },
    {
        "Model":"cerebras\/Cerebras-GPT-2.7B",
        "Arch":"gpt2",
        "Params (B)":2.65,
        "Open LLM Score (%)":"33.25 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0193,
        "Decode Throughput (tokens\/s)":54.7,
        "Allocated Memory (MB)":6286,
        "Energy (tokens\/kWh)":684931.0,
        "E2E Latency (s)":18.3,
        "E2E Throughput (tokens\/s)":54.6,
        "Reserved Memory (MB)":6496,
        "Used Memory (MB)":7970
    },
    {
        "Model":"cerebras\/Cerebras-GPT-2.7B",
        "Arch":"gpt2",
        "Params (B)":2.65,
        "Open LLM Score (%)":"33.25*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0229,
        "Decode Throughput (tokens\/s)":56.25,
        "Allocated Memory (MB)":3279,
        "Energy (tokens\/kWh)":751879.0,
        "E2E Latency (s)":17.8,
        "E2E Throughput (tokens\/s)":56.2,
        "Reserved Memory (MB)":3481,
        "Used Memory (MB)":4957
    },
    {
        "Model":"cerebras\/Cerebras-GPT-2.7B",
        "Arch":"gpt2",
        "Params (B)":2.65,
        "Open LLM Score (%)":"33.25*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0236,
        "Decode Throughput (tokens\/s)":55.63,
        "Allocated Memory (MB)":2605,
        "Energy (tokens\/kWh)":719424.0,
        "E2E Latency (s)":18.0,
        "E2E Throughput (tokens\/s)":55.6,
        "Reserved Memory (MB)":2805,
        "Used Memory (MB)":4281
    },
    {
        "Model":"RWKV\/rwkv-4-1b5-pile",
        "Arch":"rwkv",
        "Params (B)":1.41,
        "Open LLM Score (%)":"33.25 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0248,
        "Decode Throughput (tokens\/s)":40.53,
        "Allocated Memory (MB)":3066,
        "Energy (tokens\/kWh)":591715.0,
        "E2E Latency (s)":24.7,
        "E2E Throughput (tokens\/s)":40.5,
        "Reserved Memory (MB)":3344,
        "Used Memory (MB)":4818
    },
    {
        "Model":"RWKV\/rwkv-4-1b5-pile",
        "Arch":"rwkv",
        "Params (B)":1.41,
        "Open LLM Score (%)":"33.25*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":1.6,
        "Decode Throughput (tokens\/s)":29.5,
        "Allocated Memory (MB)":1181,
        "Energy (tokens\/kWh)":418410.0,
        "E2E Latency (s)":35.5,
        "E2E Throughput (tokens\/s)":28.2,
        "Reserved Memory (MB)":1207,
        "Used Memory (MB)":2681
    },
    {
        "Model":"RWKV\/rwkv-4-1b5-pile",
        "Arch":"rwkv",
        "Params (B)":1.41,
        "Open LLM Score (%)":"33.25 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":1.65,
        "Decode Throughput (tokens\/s)":40.24,
        "Allocated Memory (MB)":3066,
        "Energy (tokens\/kWh)":534759.0,
        "E2E Latency (s)":26.5,
        "E2E Throughput (tokens\/s)":37.7,
        "Reserved Memory (MB)":3344,
        "Used Memory (MB)":4818
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-13B",
        "Arch":"bloom",
        "Params (B)":13.26,
        "Open LLM Score (%)":"32.95 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0512,
        "Decode Throughput (tokens\/s)":37.95,
        "Allocated Memory (MB)":28578,
        "Energy (tokens\/kWh)":338983.0,
        "E2E Latency (s)":26.4,
        "E2E Throughput (tokens\/s)":37.9,
        "Reserved Memory (MB)":30945,
        "Used Memory (MB)":32419
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-13B",
        "Arch":"bloom",
        "Params (B)":13.26,
        "Open LLM Score (%)":"32.95 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0522,
        "Decode Throughput (tokens\/s)":38.99,
        "Allocated Memory (MB)":28579,
        "Energy (tokens\/kWh)":349650.0,
        "E2E Latency (s)":25.7,
        "E2E Throughput (tokens\/s)":38.9,
        "Reserved Memory (MB)":30945,
        "Used Memory (MB)":32419
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-13B",
        "Arch":"bloom",
        "Params (B)":13.26,
        "Open LLM Score (%)":"32.95 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0529,
        "Decode Throughput (tokens\/s)":38.25,
        "Allocated Memory (MB)":28579,
        "Energy (tokens\/kWh)":337837.0,
        "E2E Latency (s)":26.2,
        "E2E Throughput (tokens\/s)":38.2,
        "Reserved Memory (MB)":30945,
        "Used Memory (MB)":32419
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-13B",
        "Arch":"bloom",
        "Params (B)":13.26,
        "Open LLM Score (%)":"32.95*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.066,
        "Decode Throughput (tokens\/s)":40.93,
        "Allocated Memory (MB)":10194,
        "Energy (tokens\/kWh)":421940.0,
        "E2E Latency (s)":24.5,
        "E2E Throughput (tokens\/s)":40.8,
        "Reserved Memory (MB)":12561,
        "Used Memory (MB)":14037
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-13B",
        "Arch":"bloom",
        "Params (B)":13.26,
        "Open LLM Score (%)":"32.95*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0671,
        "Decode Throughput (tokens\/s)":40.6,
        "Allocated Memory (MB)":11542,
        "Energy (tokens\/kWh)":473933.0,
        "E2E Latency (s)":24.7,
        "E2E Throughput (tokens\/s)":40.5,
        "Reserved Memory (MB)":13912,
        "Used Memory (MB)":15388
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-13B",
        "Arch":"bloom",
        "Params (B)":13.26,
        "Open LLM Score (%)":"32.95*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0761,
        "Decode Throughput (tokens\/s)":33.31,
        "Allocated Memory (MB)":10490,
        "Energy (tokens\/kWh)":359712.0,
        "E2E Latency (s)":30.1,
        "E2E Throughput (tokens\/s)":33.2,
        "Reserved Memory (MB)":11769,
        "Used Memory (MB)":13242
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-13B",
        "Arch":"bloom",
        "Params (B)":13.26,
        "Open LLM Score (%)":"32.95*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.079,
        "Decode Throughput (tokens\/s)":32.13,
        "Allocated Memory (MB)":10491,
        "Energy (tokens\/kWh)":349650.0,
        "E2E Latency (s)":31.2,
        "E2E Throughput (tokens\/s)":32.1,
        "Reserved Memory (MB)":11769,
        "Used Memory (MB)":13242
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":1.08,
        "Open LLM Score (%)":"32.78 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0108,
        "Decode Throughput (tokens\/s)":90.18,
        "Allocated Memory (MB)":2443,
        "Energy (tokens\/kWh)":1226993.0,
        "E2E Latency (s)":11.1,
        "E2E Throughput (tokens\/s)":90.1,
        "Reserved Memory (MB)":2497,
        "Used Memory (MB)":3969
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":1.08,
        "Open LLM Score (%)":"32.78 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0126,
        "Decode Throughput (tokens\/s)":79.44,
        "Allocated Memory (MB)":2443,
        "Energy (tokens\/kWh)":1119820.0,
        "E2E Latency (s)":12.6,
        "E2E Throughput (tokens\/s)":79.4,
        "Reserved Memory (MB)":2499,
        "Used Memory (MB)":3973
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":1.08,
        "Open LLM Score (%)":"32.78 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0127,
        "Decode Throughput (tokens\/s)":78.82,
        "Allocated Memory (MB)":2443,
        "Energy (tokens\/kWh)":1101321.0,
        "E2E Latency (s)":12.7,
        "E2E Throughput (tokens\/s)":78.7,
        "Reserved Memory (MB)":2499,
        "Used Memory (MB)":3973
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":1.08,
        "Open LLM Score (%)":"32.78*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0132,
        "Decode Throughput (tokens\/s)":80.73,
        "Allocated Memory (MB)":1824,
        "Energy (tokens\/kWh)":1104972.0,
        "E2E Latency (s)":12.4,
        "E2E Throughput (tokens\/s)":80.6,
        "Reserved Memory (MB)":1885,
        "Used Memory (MB)":3361
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":1.08,
        "Open LLM Score (%)":"32.78*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0134,
        "Decode Throughput (tokens\/s)":78.21,
        "Allocated Memory (MB)":1286,
        "Energy (tokens\/kWh)":1077586.0,
        "E2E Latency (s)":12.8,
        "E2E Throughput (tokens\/s)":78.1,
        "Reserved Memory (MB)":1344,
        "Used Memory (MB)":2820
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":1.08,
        "Open LLM Score (%)":"32.78*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0165,
        "Decode Throughput (tokens\/s)":74.16,
        "Allocated Memory (MB)":1284,
        "Energy (tokens\/kWh)":1070663.0,
        "E2E Latency (s)":13.5,
        "E2E Throughput (tokens\/s)":74.1,
        "Reserved Memory (MB)":1342,
        "Used Memory (MB)":2813
    },
    {
        "Model":"EleutherAI\/pythia-1b-deduped",
        "Arch":"gpt_neox",
        "Params (B)":1.08,
        "Open LLM Score (%)":"32.78*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0188,
        "Decode Throughput (tokens\/s)":64.18,
        "Allocated Memory (MB)":1284,
        "Energy (tokens\/kWh)":943396.0,
        "E2E Latency (s)":15.6,
        "E2E Throughput (tokens\/s)":64.1,
        "Reserved Memory (MB)":1344,
        "Used Memory (MB)":2818
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"llama",
        "Params (B)":5.87,
        "Open LLM Score (%)":"32.44 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0294,
        "Decode Throughput (tokens\/s)":37.35,
        "Allocated Memory (MB)":12576,
        "Energy (tokens\/kWh)":444444.0,
        "E2E Latency (s)":26.8,
        "E2E Throughput (tokens\/s)":37.3,
        "Reserved Memory (MB)":12792,
        "Used Memory (MB)":14266
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"llama",
        "Params (B)":5.87,
        "Open LLM Score (%)":"32.44 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0306,
        "Decode Throughput (tokens\/s)":34.52,
        "Allocated Memory (MB)":12576,
        "Energy (tokens\/kWh)":416666.0,
        "E2E Latency (s)":29.0,
        "E2E Throughput (tokens\/s)":34.5,
        "Reserved Memory (MB)":12792,
        "Used Memory (MB)":14266
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"llama",
        "Params (B)":5.87,
        "Open LLM Score (%)":"32.44 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0333,
        "Decode Throughput (tokens\/s)":33.94,
        "Allocated Memory (MB)":12576,
        "Energy (tokens\/kWh)":395256.0,
        "E2E Latency (s)":29.5,
        "E2E Throughput (tokens\/s)":33.9,
        "Reserved Memory (MB)":12792,
        "Used Memory (MB)":14266
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"llama",
        "Params (B)":5.87,
        "Open LLM Score (%)":"32.44*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0385,
        "Decode Throughput (tokens\/s)":32.72,
        "Allocated Memory (MB)":4331,
        "Energy (tokens\/kWh)":413223.0,
        "E2E Latency (s)":30.6,
        "E2E Throughput (tokens\/s)":32.7,
        "Reserved Memory (MB)":4494,
        "Used Memory (MB)":5970
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"llama",
        "Params (B)":5.87,
        "Open LLM Score (%)":"32.44*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.04,
        "Decode Throughput (tokens\/s)":32.4,
        "Allocated Memory (MB)":5057,
        "Energy (tokens\/kWh)":432900.0,
        "E2E Latency (s)":30.9,
        "E2E Throughput (tokens\/s)":32.4,
        "Reserved Memory (MB)":5221,
        "Used Memory (MB)":6697
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"llama",
        "Params (B)":5.87,
        "Open LLM Score (%)":"32.44*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.046,
        "Decode Throughput (tokens\/s)":29.02,
        "Allocated Memory (MB)":4453,
        "Energy (tokens\/kWh)":371747.0,
        "E2E Latency (s)":34.5,
        "E2E Throughput (tokens\/s)":29.0,
        "Reserved Memory (MB)":4643,
        "Used Memory (MB)":6116
    },
    {
        "Model":"Kunhao\/pile-7b-250b-tokens",
        "Arch":"llama",
        "Params (B)":5.87,
        "Open LLM Score (%)":"32.44*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0494,
        "Decode Throughput (tokens\/s)":27.21,
        "Allocated Memory (MB)":4453,
        "Energy (tokens\/kWh)":346020.0,
        "E2E Latency (s)":36.8,
        "E2E Throughput (tokens\/s)":27.2,
        "Reserved Memory (MB)":4643,
        "Used Memory (MB)":6116
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"codegen",
        "Params (B)":6.85,
        "Open LLM Score (%)":"32.43 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0341,
        "Decode Throughput (tokens\/s)":28.93,
        "Allocated Memory (MB)":15707,
        "Energy (tokens\/kWh)":331125.0,
        "E2E Latency (s)":34.6,
        "E2E Throughput (tokens\/s)":28.9,
        "Reserved Memory (MB)":15762,
        "Used Memory (MB)":17235
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"codegen",
        "Params (B)":6.85,
        "Open LLM Score (%)":"32.43 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0383,
        "Decode Throughput (tokens\/s)":26.91,
        "Allocated Memory (MB)":15697,
        "Energy (tokens\/kWh)":330033.0,
        "E2E Latency (s)":37.2,
        "E2E Throughput (tokens\/s)":26.9,
        "Reserved Memory (MB)":15741,
        "Used Memory (MB)":17214
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"codegen",
        "Params (B)":6.85,
        "Open LLM Score (%)":"32.43 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.039,
        "Decode Throughput (tokens\/s)":26.84,
        "Allocated Memory (MB)":15697,
        "Energy (tokens\/kWh)":316455.0,
        "E2E Latency (s)":37.3,
        "E2E Throughput (tokens\/s)":26.8,
        "Reserved Memory (MB)":15741,
        "Used Memory (MB)":17214
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"codegen",
        "Params (B)":6.85,
        "Open LLM Score (%)":"32.43*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0468,
        "Decode Throughput (tokens\/s)":26.42,
        "Allocated Memory (MB)":7077,
        "Energy (tokens\/kWh)":353356.0,
        "E2E Latency (s)":37.9,
        "E2E Throughput (tokens\/s)":26.4,
        "Reserved Memory (MB)":7119,
        "Used Memory (MB)":8595
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"codegen",
        "Params (B)":6.85,
        "Open LLM Score (%)":"32.43*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0481,
        "Decode Throughput (tokens\/s)":26.7,
        "Allocated Memory (MB)":6000,
        "Energy (tokens\/kWh)":343642.0,
        "E2E Latency (s)":37.5,
        "E2E Throughput (tokens\/s)":26.7,
        "Reserved Memory (MB)":6039,
        "Used Memory (MB)":7515
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"codegen",
        "Params (B)":6.85,
        "Open LLM Score (%)":"32.43*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0502,
        "Decode Throughput (tokens\/s)":25.09,
        "Allocated Memory (MB)":6188,
        "Energy (tokens\/kWh)":343642.0,
        "E2E Latency (s)":39.9,
        "E2E Throughput (tokens\/s)":25.1,
        "Reserved Memory (MB)":6285,
        "Used Memory (MB)":7758
    },
    {
        "Model":"Salesforce\/codegen-6B-multi",
        "Arch":"codegen",
        "Params (B)":6.85,
        "Open LLM Score (%)":"32.43*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0542,
        "Decode Throughput (tokens\/s)":23.62,
        "Allocated Memory (MB)":6176,
        "Energy (tokens\/kWh)":319488.0,
        "E2E Latency (s)":42.4,
        "E2E Throughput (tokens\/s)":23.6,
        "Reserved Memory (MB)":6243,
        "Used Memory (MB)":7716
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"gpt_neox",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.23 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0248,
        "Decode Throughput (tokens\/s)":40.53,
        "Allocated Memory (MB)":8864,
        "Energy (tokens\/kWh)":505050.0,
        "E2E Latency (s)":24.7,
        "E2E Throughput (tokens\/s)":40.5,
        "Reserved Memory (MB)":9472,
        "Used Memory (MB)":10944
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"gpt_neox",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.23 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0278,
        "Decode Throughput (tokens\/s)":36.53,
        "Allocated Memory (MB)":8864,
        "Energy (tokens\/kWh)":485436.0,
        "E2E Latency (s)":27.4,
        "E2E Throughput (tokens\/s)":36.5,
        "Reserved Memory (MB)":9472,
        "Used Memory (MB)":10946
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"gpt_neox",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.23 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0287,
        "Decode Throughput (tokens\/s)":35.25,
        "Allocated Memory (MB)":8864,
        "Energy (tokens\/kWh)":450450.0,
        "E2E Latency (s)":28.4,
        "E2E Throughput (tokens\/s)":35.2,
        "Reserved Memory (MB)":9472,
        "Used Memory (MB)":10946
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"gpt_neox",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.23*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.03,
        "Decode Throughput (tokens\/s)":35.88,
        "Allocated Memory (MB)":3901,
        "Energy (tokens\/kWh)":478468.0,
        "E2E Latency (s)":27.9,
        "E2E Throughput (tokens\/s)":35.8,
        "Reserved Memory (MB)":4399,
        "Used Memory (MB)":5875
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"gpt_neox",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.23*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0303,
        "Decode Throughput (tokens\/s)":36.4,
        "Allocated Memory (MB)":4642,
        "Energy (tokens\/kWh)":490196.0,
        "E2E Latency (s)":27.5,
        "E2E Throughput (tokens\/s)":36.4,
        "Reserved Memory (MB)":5142,
        "Used Memory (MB)":6618
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"gpt_neox",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.23*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0371,
        "Decode Throughput (tokens\/s)":34.29,
        "Allocated Memory (MB)":3892,
        "Energy (tokens\/kWh)":456621.0,
        "E2E Latency (s)":29.2,
        "E2E Throughput (tokens\/s)":34.2,
        "Reserved Memory (MB)":4330,
        "Used Memory (MB)":5802
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b-8k",
        "Arch":"gpt_neox",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.23*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0412,
        "Decode Throughput (tokens\/s)":30.07,
        "Allocated Memory (MB)":3892,
        "Energy (tokens\/kWh)":403225.0,
        "E2E Latency (s)":33.3,
        "E2E Throughput (tokens\/s)":30.0,
        "Reserved Memory (MB)":4351,
        "Used Memory (MB)":5825
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"gpt_neox",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.14 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0237,
        "Decode Throughput (tokens\/s)":40.52,
        "Allocated Memory (MB)":8864,
        "Energy (tokens\/kWh)":510204.0,
        "E2E Latency (s)":24.7,
        "E2E Throughput (tokens\/s)":40.5,
        "Reserved Memory (MB)":9472,
        "Used Memory (MB)":10944
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"gpt_neox",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.14 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0275,
        "Decode Throughput (tokens\/s)":36.94,
        "Allocated Memory (MB)":8864,
        "Energy (tokens\/kWh)":480769.0,
        "E2E Latency (s)":27.1,
        "E2E Throughput (tokens\/s)":36.9,
        "Reserved Memory (MB)":9472,
        "Used Memory (MB)":10946
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"gpt_neox",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.14 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0278,
        "Decode Throughput (tokens\/s)":36.14,
        "Allocated Memory (MB)":8864,
        "Energy (tokens\/kWh)":458715.0,
        "E2E Latency (s)":27.7,
        "E2E Throughput (tokens\/s)":36.1,
        "Reserved Memory (MB)":9472,
        "Used Memory (MB)":10946
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"gpt_neox",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.14*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.03,
        "Decode Throughput (tokens\/s)":35.0,
        "Allocated Memory (MB)":3901,
        "Energy (tokens\/kWh)":465116.0,
        "E2E Latency (s)":28.6,
        "E2E Throughput (tokens\/s)":35.0,
        "Reserved Memory (MB)":4399,
        "Used Memory (MB)":5875
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"gpt_neox",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.14*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0303,
        "Decode Throughput (tokens\/s)":37.08,
        "Allocated Memory (MB)":4642,
        "Energy (tokens\/kWh)":507614.0,
        "E2E Latency (s)":27.0,
        "E2E Throughput (tokens\/s)":37.0,
        "Reserved Memory (MB)":5142,
        "Used Memory (MB)":6618
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"gpt_neox",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.14*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0372,
        "Decode Throughput (tokens\/s)":33.26,
        "Allocated Memory (MB)":3892,
        "Energy (tokens\/kWh)":448430.0,
        "E2E Latency (s)":30.1,
        "E2E Throughput (tokens\/s)":33.2,
        "Reserved Memory (MB)":4330,
        "Used Memory (MB)":5802
    },
    {
        "Model":"rinna\/bilingual-gpt-neox-4b",
        "Arch":"gpt_neox",
        "Params (B)":3.95,
        "Open LLM Score (%)":"32.14*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0413,
        "Decode Throughput (tokens\/s)":30.16,
        "Allocated Memory (MB)":3892,
        "Energy (tokens\/kWh)":408163.0,
        "E2E Latency (s)":33.2,
        "E2E Throughput (tokens\/s)":30.1,
        "Reserved Memory (MB)":4351,
        "Used Memory (MB)":5825
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"llama",
        "Params (B)":1.1,
        "Open LLM Score (%)":"31.86 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0179,
        "Decode Throughput (tokens\/s)":54.11,
        "Allocated Memory (MB)":2289,
        "Energy (tokens\/kWh)":769230.0,
        "E2E Latency (s)":18.5,
        "E2E Throughput (tokens\/s)":54.1,
        "Reserved Memory (MB)":2443,
        "Used Memory (MB)":3916
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"llama",
        "Params (B)":1.1,
        "Open LLM Score (%)":"31.86 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0198,
        "Decode Throughput (tokens\/s)":51.33,
        "Allocated Memory (MB)":2289,
        "Energy (tokens\/kWh)":751879.0,
        "E2E Latency (s)":19.5,
        "E2E Throughput (tokens\/s)":51.3,
        "Reserved Memory (MB)":2443,
        "Used Memory (MB)":3916
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"llama",
        "Params (B)":1.1,
        "Open LLM Score (%)":"31.86 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0199,
        "Decode Throughput (tokens\/s)":51.87,
        "Allocated Memory (MB)":2289,
        "Energy (tokens\/kWh)":729927.0,
        "E2E Latency (s)":19.3,
        "E2E Throughput (tokens\/s)":51.8,
        "Reserved Memory (MB)":2443,
        "Used Memory (MB)":3916
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"llama",
        "Params (B)":1.1,
        "Open LLM Score (%)":"31.86*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0231,
        "Decode Throughput (tokens\/s)":47.45,
        "Allocated Memory (MB)":887,
        "Energy (tokens\/kWh)":641025.0,
        "E2E Latency (s)":21.1,
        "E2E Throughput (tokens\/s)":47.4,
        "Reserved Memory (MB)":977,
        "Used Memory (MB)":2453
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"llama",
        "Params (B)":1.1,
        "Open LLM Score (%)":"31.86*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0231,
        "Decode Throughput (tokens\/s)":46.56,
        "Allocated Memory (MB)":1258,
        "Energy (tokens\/kWh)":657894.0,
        "E2E Latency (s)":21.5,
        "E2E Throughput (tokens\/s)":46.5,
        "Reserved Memory (MB)":1348,
        "Used Memory (MB)":2824
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"llama",
        "Params (B)":1.1,
        "Open LLM Score (%)":"31.86*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.031,
        "Decode Throughput (tokens\/s)":41.72,
        "Allocated Memory (MB)":898,
        "Energy (tokens\/kWh)":625000.0,
        "E2E Latency (s)":24.0,
        "E2E Throughput (tokens\/s)":41.7,
        "Reserved Memory (MB)":1010,
        "Used Memory (MB)":2484
    },
    {
        "Model":"PY007\/TinyLlama-1.1B-step-50K-105b",
        "Arch":"llama",
        "Params (B)":1.1,
        "Open LLM Score (%)":"31.86*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0333,
        "Decode Throughput (tokens\/s)":39.42,
        "Allocated Memory (MB)":898,
        "Energy (tokens\/kWh)":588235.0,
        "E2E Latency (s)":25.4,
        "E2E Throughput (tokens\/s)":39.4,
        "Reserved Memory (MB)":1010,
        "Used Memory (MB)":2484
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"gpt_neox",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.55 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0159,
        "Decode Throughput (tokens\/s)":59.58,
        "Allocated Memory (MB)":1175,
        "Energy (tokens\/kWh)":934579.0,
        "E2E Latency (s)":16.8,
        "E2E Throughput (tokens\/s)":59.5,
        "Reserved Memory (MB)":1310,
        "Used Memory (MB)":2784
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"gpt_neox",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.55 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0185,
        "Decode Throughput (tokens\/s)":54.7,
        "Allocated Memory (MB)":1175,
        "Energy (tokens\/kWh)":847457.0,
        "E2E Latency (s)":18.3,
        "E2E Throughput (tokens\/s)":54.6,
        "Reserved Memory (MB)":1312,
        "Used Memory (MB)":2786
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"gpt_neox",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.55 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0187,
        "Decode Throughput (tokens\/s)":54.11,
        "Allocated Memory (MB)":1175,
        "Energy (tokens\/kWh)":826446.0,
        "E2E Latency (s)":18.5,
        "E2E Throughput (tokens\/s)":54.1,
        "Reserved Memory (MB)":1312,
        "Used Memory (MB)":2786
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"gpt_neox",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.55*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0196,
        "Decode Throughput (tokens\/s)":55.31,
        "Allocated Memory (MB)":1017,
        "Energy (tokens\/kWh)":793650.0,
        "E2E Latency (s)":18.1,
        "E2E Throughput (tokens\/s)":55.2,
        "Reserved Memory (MB)":1147,
        "Used Memory (MB)":2623
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"gpt_neox",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.55*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0196,
        "Decode Throughput (tokens\/s)":55.0,
        "Allocated Memory (MB)":748,
        "Energy (tokens\/kWh)":781250.0,
        "E2E Latency (s)":18.2,
        "E2E Throughput (tokens\/s)":54.9,
        "Reserved Memory (MB)":889,
        "Used Memory (MB)":2365
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"gpt_neox",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.55*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0244,
        "Decode Throughput (tokens\/s)":48.6,
        "Allocated Memory (MB)":754,
        "Energy (tokens\/kWh)":751879.0,
        "E2E Latency (s)":20.6,
        "E2E Throughput (tokens\/s)":48.5,
        "Reserved Memory (MB)":901,
        "Used Memory (MB)":2375
    },
    {
        "Model":"EleutherAI\/pythia-410m",
        "Arch":"gpt_neox",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.55*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0284,
        "Decode Throughput (tokens\/s)":44.7,
        "Allocated Memory (MB)":754,
        "Energy (tokens\/kWh)":684931.0,
        "E2E Latency (s)":22.4,
        "E2E Throughput (tokens\/s)":44.6,
        "Reserved Memory (MB)":901,
        "Used Memory (MB)":2375
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"gpt_neox",
        "Params (B)":3.43,
        "Open LLM Score (%)":"31.50 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0149,
        "Decode Throughput (tokens\/s)":88.61,
        "Allocated Memory (MB)":8232,
        "Energy (tokens\/kWh)":934579.0,
        "E2E Latency (s)":11.3,
        "E2E Throughput (tokens\/s)":88.5,
        "Reserved Memory (MB)":8252,
        "Used Memory (MB)":9723
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"gpt_neox",
        "Params (B)":3.43,
        "Open LLM Score (%)":"31.50 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0159,
        "Decode Throughput (tokens\/s)":79.47,
        "Allocated Memory (MB)":8232,
        "Energy (tokens\/kWh)":877192.0,
        "E2E Latency (s)":12.6,
        "E2E Throughput (tokens\/s)":79.4,
        "Reserved Memory (MB)":8273,
        "Used Memory (MB)":9746
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"gpt_neox",
        "Params (B)":3.43,
        "Open LLM Score (%)":"31.50 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0162,
        "Decode Throughput (tokens\/s)":76.43,
        "Allocated Memory (MB)":8232,
        "Energy (tokens\/kWh)":826446.0,
        "E2E Latency (s)":13.1,
        "E2E Throughput (tokens\/s)":76.3,
        "Reserved Memory (MB)":8273,
        "Used Memory (MB)":9747
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"gpt_neox",
        "Params (B)":3.43,
        "Open LLM Score (%)":"31.50*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0206,
        "Decode Throughput (tokens\/s)":81.44,
        "Allocated Memory (MB)":3598,
        "Energy (tokens\/kWh)":961538.0,
        "E2E Latency (s)":12.3,
        "E2E Throughput (tokens\/s)":81.3,
        "Reserved Memory (MB)":3674,
        "Used Memory (MB)":5150
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"gpt_neox",
        "Params (B)":3.43,
        "Open LLM Score (%)":"31.50*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0206,
        "Decode Throughput (tokens\/s)":77.64,
        "Allocated Memory (MB)":4674,
        "Energy (tokens\/kWh)":990099.0,
        "E2E Latency (s)":12.9,
        "E2E Throughput (tokens\/s)":77.5,
        "Reserved Memory (MB)":4752,
        "Used Memory (MB)":6228
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"gpt_neox",
        "Params (B)":3.43,
        "Open LLM Score (%)":"31.50*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0228,
        "Decode Throughput (tokens\/s)":73.65,
        "Allocated Memory (MB)":3607,
        "Energy (tokens\/kWh)":900900.0,
        "E2E Latency (s)":13.6,
        "E2E Throughput (tokens\/s)":73.5,
        "Reserved Memory (MB)":3682,
        "Used Memory (MB)":5154
    },
    {
        "Model":"stabilityai\/stablelm-base-alpha-3b",
        "Arch":"gpt_neox",
        "Params (B)":3.43,
        "Open LLM Score (%)":"31.50*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0245,
        "Decode Throughput (tokens\/s)":65.04,
        "Allocated Memory (MB)":3607,
        "Energy (tokens\/kWh)":813008.0,
        "E2E Latency (s)":15.4,
        "E2E Throughput (tokens\/s)":64.9,
        "Reserved Memory (MB)":3682,
        "Used Memory (MB)":5156
    },
    {
        "Model":"cerebras\/Cerebras-GPT-1.3B",
        "Arch":"gpt2",
        "Params (B)":1.32,
        "Open LLM Score (%)":"31.30 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0113,
        "Decode Throughput (tokens\/s)":84.83,
        "Allocated Memory (MB)":3244,
        "Energy (tokens\/kWh)":1148105.0,
        "E2E Latency (s)":11.8,
        "E2E Throughput (tokens\/s)":84.7,
        "Reserved Memory (MB)":3277,
        "Used Memory (MB)":4749
    },
    {
        "Model":"cerebras\/Cerebras-GPT-1.3B",
        "Arch":"gpt2",
        "Params (B)":1.32,
        "Open LLM Score (%)":"31.30*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0116,
        "Decode Throughput (tokens\/s)":85.55,
        "Allocated Memory (MB)":3244,
        "Energy (tokens\/kWh)":1194743.0,
        "E2E Latency (s)":11.7,
        "E2E Throughput (tokens\/s)":85.5,
        "Reserved Memory (MB)":3277,
        "Used Memory (MB)":4749
    },
    {
        "Model":"cerebras\/Cerebras-GPT-1.3B",
        "Arch":"gpt2",
        "Params (B)":1.32,
        "Open LLM Score (%)":"31.30 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0143,
        "Decode Throughput (tokens\/s)":72.02,
        "Allocated Memory (MB)":3244,
        "Energy (tokens\/kWh)":990099.0,
        "E2E Latency (s)":13.9,
        "E2E Throughput (tokens\/s)":71.9,
        "Reserved Memory (MB)":3277,
        "Used Memory (MB)":4751
    },
    {
        "Model":"cerebras\/Cerebras-GPT-1.3B",
        "Arch":"gpt2",
        "Params (B)":1.32,
        "Open LLM Score (%)":"31.30*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0143,
        "Decode Throughput (tokens\/s)":71.5,
        "Allocated Memory (MB)":3244,
        "Energy (tokens\/kWh)":990099.0,
        "E2E Latency (s)":14.0,
        "E2E Throughput (tokens\/s)":71.4,
        "Reserved Memory (MB)":3277,
        "Used Memory (MB)":4751
    },
    {
        "Model":"cerebras\/Cerebras-GPT-1.3B",
        "Arch":"gpt2",
        "Params (B)":1.32,
        "Open LLM Score (%)":"31.30 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0144,
        "Decode Throughput (tokens\/s)":70.99,
        "Allocated Memory (MB)":3244,
        "Energy (tokens\/kWh)":943396.0,
        "E2E Latency (s)":14.1,
        "E2E Throughput (tokens\/s)":70.9,
        "Reserved Memory (MB)":3277,
        "Used Memory (MB)":4751
    },
    {
        "Model":"cerebras\/Cerebras-GPT-1.3B",
        "Arch":"gpt2",
        "Params (B)":1.32,
        "Open LLM Score (%)":"31.30*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0151,
        "Decode Throughput (tokens\/s)":74.16,
        "Allocated Memory (MB)":1490,
        "Energy (tokens\/kWh)":990099.0,
        "E2E Latency (s)":13.5,
        "E2E Throughput (tokens\/s)":74.1,
        "Reserved Memory (MB)":1520,
        "Used Memory (MB)":2996
    },
    {
        "Model":"cerebras\/Cerebras-GPT-1.3B",
        "Arch":"gpt2",
        "Params (B)":1.32,
        "Open LLM Score (%)":"31.30*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0151,
        "Decode Throughput (tokens\/s)":73.61,
        "Allocated Memory (MB)":2028,
        "Energy (tokens\/kWh)":1019367.0,
        "E2E Latency (s)":13.6,
        "E2E Throughput (tokens\/s)":73.5,
        "Reserved Memory (MB)":2061,
        "Used Memory (MB)":3537
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"gpt_neox",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.29 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.016,
        "Decode Throughput (tokens\/s)":59.58,
        "Allocated Memory (MB)":1175,
        "Energy (tokens\/kWh)":925925.0,
        "E2E Latency (s)":16.8,
        "E2E Throughput (tokens\/s)":59.5,
        "Reserved Memory (MB)":1310,
        "Used Memory (MB)":2784
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"gpt_neox",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.29 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0185,
        "Decode Throughput (tokens\/s)":55.31,
        "Allocated Memory (MB)":1175,
        "Energy (tokens\/kWh)":833333.0,
        "E2E Latency (s)":18.1,
        "E2E Throughput (tokens\/s)":55.2,
        "Reserved Memory (MB)":1312,
        "Used Memory (MB)":2786
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"gpt_neox",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.29 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0185,
        "Decode Throughput (tokens\/s)":54.7,
        "Allocated Memory (MB)":1175,
        "Energy (tokens\/kWh)":847457.0,
        "E2E Latency (s)":18.3,
        "E2E Throughput (tokens\/s)":54.6,
        "Reserved Memory (MB)":1312,
        "Used Memory (MB)":2786
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"gpt_neox",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.29*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0194,
        "Decode Throughput (tokens\/s)":53.82,
        "Allocated Memory (MB)":748,
        "Energy (tokens\/kWh)":769230.0,
        "E2E Latency (s)":18.6,
        "E2E Throughput (tokens\/s)":53.8,
        "Reserved Memory (MB)":889,
        "Used Memory (MB)":2365
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"gpt_neox",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.29*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0196,
        "Decode Throughput (tokens\/s)":51.33,
        "Allocated Memory (MB)":1017,
        "Energy (tokens\/kWh)":799999.0,
        "E2E Latency (s)":19.5,
        "E2E Throughput (tokens\/s)":51.3,
        "Reserved Memory (MB)":1147,
        "Used Memory (MB)":2623
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"gpt_neox",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.29*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0243,
        "Decode Throughput (tokens\/s)":48.84,
        "Allocated Memory (MB)":754,
        "Energy (tokens\/kWh)":769230.0,
        "E2E Latency (s)":20.5,
        "E2E Throughput (tokens\/s)":48.8,
        "Reserved Memory (MB)":901,
        "Used Memory (MB)":2375
    },
    {
        "Model":"EleutherAI\/pythia-410m-deduped",
        "Arch":"gpt_neox",
        "Params (B)":0.51,
        "Open LLM Score (%)":"31.29*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0273,
        "Decode Throughput (tokens\/s)":44.7,
        "Allocated Memory (MB)":754,
        "Energy (tokens\/kWh)":684931.0,
        "E2E Latency (s)":22.4,
        "E2E Throughput (tokens\/s)":44.6,
        "Reserved Memory (MB)":901,
        "Used Memory (MB)":2375
    },
    {
        "Model":"RWKV\/rwkv-4-430m-pile",
        "Arch":"rwkv",
        "Params (B)":0.38,
        "Open LLM Score (%)":"30.45 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0247,
        "Decode Throughput (tokens\/s)":39.56,
        "Allocated Memory (MB)":895,
        "Energy (tokens\/kWh)":625000.0,
        "E2E Latency (s)":25.3,
        "E2E Throughput (tokens\/s)":39.5,
        "Reserved Memory (MB)":918,
        "Used Memory (MB)":2392
    },
    {
        "Model":"RWKV\/rwkv-4-430m-pile",
        "Arch":"rwkv",
        "Params (B)":0.38,
        "Open LLM Score (%)":"30.45 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":1.58,
        "Decode Throughput (tokens\/s)":40.62,
        "Allocated Memory (MB)":895,
        "Energy (tokens\/kWh)":602409.0,
        "E2E Latency (s)":26.2,
        "E2E Throughput (tokens\/s)":38.2,
        "Reserved Memory (MB)":914,
        "Used Memory (MB)":2388
    },
    {
        "Model":"RWKV\/rwkv-4-430m-pile",
        "Arch":"rwkv",
        "Params (B)":0.38,
        "Open LLM Score (%)":"30.45*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":1.58,
        "Decode Throughput (tokens\/s)":29.48,
        "Allocated Memory (MB)":419,
        "Energy (tokens\/kWh)":440528.0,
        "E2E Latency (s)":35.5,
        "E2E Throughput (tokens\/s)":28.2,
        "Reserved Memory (MB)":452,
        "Used Memory (MB)":1926
    },
    {
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Arch":"llama",
        "Params (B)":0.41,
        "Open LLM Score (%)":"30.17 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.02,
        "Decode Throughput (tokens\/s)":49.31,
        "Allocated Memory (MB)":1020,
        "Energy (tokens\/kWh)":775193.0,
        "E2E Latency (s)":20.3,
        "E2E Throughput (tokens\/s)":49.3,
        "Reserved Memory (MB)":1126,
        "Used Memory (MB)":2599
    },
    {
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Arch":"llama",
        "Params (B)":0.41,
        "Open LLM Score (%)":"30.17 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0215,
        "Decode Throughput (tokens\/s)":47.44,
        "Allocated Memory (MB)":1020,
        "Energy (tokens\/kWh)":746268.0,
        "E2E Latency (s)":21.1,
        "E2E Throughput (tokens\/s)":47.4,
        "Reserved Memory (MB)":1126,
        "Used Memory (MB)":2599
    },
    {
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Arch":"llama",
        "Params (B)":0.41,
        "Open LLM Score (%)":"30.17 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0215,
        "Decode Throughput (tokens\/s)":47.22,
        "Allocated Memory (MB)":1020,
        "Energy (tokens\/kWh)":729927.0,
        "E2E Latency (s)":21.2,
        "E2E Throughput (tokens\/s)":47.2,
        "Reserved Memory (MB)":1126,
        "Used Memory (MB)":2599
    },
    {
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Arch":"llama",
        "Params (B)":0.41,
        "Open LLM Score (%)":"30.17*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0249,
        "Decode Throughput (tokens\/s)":42.96,
        "Allocated Memory (MB)":768,
        "Energy (tokens\/kWh)":636942.0,
        "E2E Latency (s)":23.3,
        "E2E Throughput (tokens\/s)":42.9,
        "Reserved Memory (MB)":843,
        "Used Memory (MB)":2318
    },
    {
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Arch":"llama",
        "Params (B)":0.41,
        "Open LLM Score (%)":"30.17*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0252,
        "Decode Throughput (tokens\/s)":42.78,
        "Allocated Memory (MB)":499,
        "Energy (tokens\/kWh)":621118.0,
        "E2E Latency (s)":23.4,
        "E2E Throughput (tokens\/s)":42.7,
        "Reserved Memory (MB)":562,
        "Used Memory (MB)":2037
    },
    {
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Arch":"llama",
        "Params (B)":0.41,
        "Open LLM Score (%)":"30.17*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0344,
        "Decode Throughput (tokens\/s)":38.22,
        "Allocated Memory (MB)":504,
        "Energy (tokens\/kWh)":595238.0,
        "E2E Latency (s)":26.2,
        "E2E Throughput (tokens\/s)":38.2,
        "Reserved Memory (MB)":578,
        "Used Memory (MB)":2052
    },
    {
        "Model":"ahxt\/llama2_xs_460M_experimental",
        "Arch":"llama",
        "Params (B)":0.41,
        "Open LLM Score (%)":"30.17*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0374,
        "Decode Throughput (tokens\/s)":35.76,
        "Allocated Memory (MB)":504,
        "Energy (tokens\/kWh)":543478.0,
        "E2E Latency (s)":28.0,
        "E2E Throughput (tokens\/s)":35.7,
        "Reserved Memory (MB)":578,
        "Used Memory (MB)":2052
    },
    {
        "Model":"facebook\/opt-350m",
        "Arch":"opt",
        "Params (B)":0.33,
        "Open LLM Score (%)":"30.01 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0124,
        "Decode Throughput (tokens\/s)":86.3,
        "Allocated Memory (MB)":924,
        "Energy (tokens\/kWh)":1291989.0,
        "E2E Latency (s)":11.6,
        "E2E Throughput (tokens\/s)":86.2,
        "Reserved Memory (MB)":1048,
        "Used Memory (MB)":2522
    },
    {
        "Model":"facebook\/opt-350m",
        "Arch":"opt",
        "Params (B)":0.33,
        "Open LLM Score (%)":"30.01 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.015,
        "Decode Throughput (tokens\/s)":75.27,
        "Allocated Memory (MB)":924,
        "Energy (tokens\/kWh)":1168224.0,
        "E2E Latency (s)":13.3,
        "E2E Throughput (tokens\/s)":75.2,
        "Reserved Memory (MB)":1048,
        "Used Memory (MB)":2522
    },
    {
        "Model":"facebook\/opt-350m",
        "Arch":"opt",
        "Params (B)":0.33,
        "Open LLM Score (%)":"30.01 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0154,
        "Decode Throughput (tokens\/s)":74.71,
        "Allocated Memory (MB)":924,
        "Energy (tokens\/kWh)":1119820.0,
        "E2E Latency (s)":13.4,
        "E2E Throughput (tokens\/s)":74.6,
        "Reserved Memory (MB)":1048,
        "Used Memory (MB)":2522
    },
    {
        "Model":"facebook\/opt-350m",
        "Arch":"opt",
        "Params (B)":0.33,
        "Open LLM Score (%)":"30.01*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0158,
        "Decode Throughput (tokens\/s)":72.55,
        "Allocated Memory (MB)":755,
        "Energy (tokens\/kWh)":1028806.0,
        "E2E Latency (s)":13.8,
        "E2E Throughput (tokens\/s)":72.5,
        "Reserved Memory (MB)":901,
        "Used Memory (MB)":2377
    },
    {
        "Model":"facebook\/opt-350m",
        "Arch":"opt",
        "Params (B)":0.33,
        "Open LLM Score (%)":"30.01*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0166,
        "Decode Throughput (tokens\/s)":70.5,
        "Allocated Memory (MB)":486,
        "Energy (tokens\/kWh)":1000000.0,
        "E2E Latency (s)":14.2,
        "E2E Throughput (tokens\/s)":70.4,
        "Reserved Memory (MB)":620,
        "Used Memory (MB)":2096
    },
    {
        "Model":"facebook\/opt-350m",
        "Arch":"opt",
        "Params (B)":0.33,
        "Open LLM Score (%)":"30.01*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0257,
        "Decode Throughput (tokens\/s)":54.13,
        "Allocated Memory (MB)":488,
        "Energy (tokens\/kWh)":840336.0,
        "E2E Latency (s)":18.5,
        "E2E Throughput (tokens\/s)":54.1,
        "Reserved Memory (MB)":612,
        "Used Memory (MB)":2086
    },
    {
        "Model":"facebook\/opt-350m",
        "Arch":"opt",
        "Params (B)":0.33,
        "Open LLM Score (%)":"30.01*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0282,
        "Decode Throughput (tokens\/s)":49.82,
        "Allocated Memory (MB)":488,
        "Energy (tokens\/kWh)":757575.0,
        "E2E Latency (s)":20.1,
        "E2E Throughput (tokens\/s)":49.8,
        "Reserved Memory (MB)":612,
        "Used Memory (MB)":2086
    },
    {
        "Model":"facebook\/xglm-564M",
        "Arch":"xglm",
        "Params (B)":0.56,
        "Open LLM Score (%)":"29.55 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0154,
        "Decode Throughput (tokens\/s)":74.71,
        "Allocated Memory (MB)":1392,
        "Energy (tokens\/kWh)":1050420.0,
        "E2E Latency (s)":13.4,
        "E2E Throughput (tokens\/s)":74.6,
        "Reserved Memory (MB)":1543,
        "Used Memory (MB)":3017
    },
    {
        "Model":"facebook\/xglm-564M",
        "Arch":"xglm",
        "Params (B)":0.56,
        "Open LLM Score (%)":"29.55 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0156,
        "Decode Throughput (tokens\/s)":74.16,
        "Allocated Memory (MB)":1392,
        "Energy (tokens\/kWh)":1083423.0,
        "E2E Latency (s)":13.5,
        "E2E Throughput (tokens\/s)":74.1,
        "Reserved Memory (MB)":1543,
        "Used Memory (MB)":3017
    },
    {
        "Model":"facebook\/xglm-564M",
        "Arch":"xglm",
        "Params (B)":0.56,
        "Open LLM Score (%)":"29.55*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0162,
        "Decode Throughput (tokens\/s)":72.55,
        "Allocated Memory (MB)":1223,
        "Energy (tokens\/kWh)":1001001.0,
        "E2E Latency (s)":13.8,
        "E2E Throughput (tokens\/s)":72.5,
        "Reserved Memory (MB)":1375,
        "Used Memory (MB)":2851
    },
    {
        "Model":"facebook\/xglm-564M",
        "Arch":"xglm",
        "Params (B)":0.56,
        "Open LLM Score (%)":"29.55*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0169,
        "Decode Throughput (tokens\/s)":68.11,
        "Allocated Memory (MB)":954,
        "Energy (tokens\/kWh)":980392.0,
        "E2E Latency (s)":14.7,
        "E2E Throughput (tokens\/s)":68.0,
        "Reserved Memory (MB)":1094,
        "Used Memory (MB)":2570
    },
    {
        "Model":"facebook\/xglm-564M",
        "Arch":"xglm",
        "Params (B)":0.56,
        "Open LLM Score (%)":"29.55*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0287,
        "Decode Throughput (tokens\/s)":50.84,
        "Allocated Memory (MB)":958,
        "Energy (tokens\/kWh)":746268.0,
        "E2E Latency (s)":19.7,
        "E2E Throughput (tokens\/s)":50.8,
        "Reserved Memory (MB)":1107,
        "Used Memory (MB)":2581
    },
    {
        "Model":"winglian\/Llama-2-3b-hf",
        "Arch":"llama",
        "Params (B)":3.37,
        "Open LLM Score (%)":"29.53 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0162,
        "Decode Throughput (tokens\/s)":82.76,
        "Allocated Memory (MB)":7714,
        "Energy (tokens\/kWh)":877192.0,
        "E2E Latency (s)":12.1,
        "E2E Throughput (tokens\/s)":82.6,
        "Reserved Memory (MB)":7761,
        "Used Memory (MB)":9235
    },
    {
        "Model":"winglian\/Llama-2-3b-hf",
        "Arch":"llama",
        "Params (B)":3.37,
        "Open LLM Score (%)":"29.53 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0168,
        "Decode Throughput (tokens\/s)":74.72,
        "Allocated Memory (MB)":7714,
        "Energy (tokens\/kWh)":854700.0,
        "E2E Latency (s)":13.4,
        "E2E Throughput (tokens\/s)":74.6,
        "Reserved Memory (MB)":7761,
        "Used Memory (MB)":9235
    },
    {
        "Model":"winglian\/Llama-2-3b-hf",
        "Arch":"llama",
        "Params (B)":3.37,
        "Open LLM Score (%)":"29.53 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0181,
        "Decode Throughput (tokens\/s)":75.29,
        "Allocated Memory (MB)":7714,
        "Energy (tokens\/kWh)":819672.0,
        "E2E Latency (s)":13.3,
        "E2E Throughput (tokens\/s)":75.2,
        "Reserved Memory (MB)":7761,
        "Used Memory (MB)":9235
    },
    {
        "Model":"winglian\/Llama-2-3b-hf",
        "Arch":"llama",
        "Params (B)":3.37,
        "Open LLM Score (%)":"29.53*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0215,
        "Decode Throughput (tokens\/s)":66.76,
        "Allocated Memory (MB)":3039,
        "Energy (tokens\/kWh)":847457.0,
        "E2E Latency (s)":15.0,
        "E2E Throughput (tokens\/s)":66.7,
        "Reserved Memory (MB)":3200,
        "Used Memory (MB)":4676
    },
    {
        "Model":"winglian\/Llama-2-3b-hf",
        "Arch":"llama",
        "Params (B)":3.37,
        "Open LLM Score (%)":"29.53*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0233,
        "Decode Throughput (tokens\/s)":61.44,
        "Allocated Memory (MB)":3072,
        "Energy (tokens\/kWh)":769230.0,
        "E2E Latency (s)":16.3,
        "E2E Throughput (tokens\/s)":61.3,
        "Reserved Memory (MB)":3164,
        "Used Memory (MB)":4638
    },
    {
        "Model":"winglian\/Llama-2-3b-hf",
        "Arch":"llama",
        "Params (B)":3.37,
        "Open LLM Score (%)":"29.53*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0241,
        "Decode Throughput (tokens\/s)":57.88,
        "Allocated Memory (MB)":3073,
        "Energy (tokens\/kWh)":719424.0,
        "E2E Latency (s)":17.3,
        "E2E Throughput (tokens\/s)":57.8,
        "Reserved Memory (MB)":3170,
        "Used Memory (MB)":4644
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"gpt_neo",
        "Params (B)":0.15,
        "Open LLM Score (%)":"29.47 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00818,
        "Decode Throughput (tokens\/s)":116.39,
        "Allocated Memory (MB)":408,
        "Energy (tokens\/kWh)":1862197.0,
        "E2E Latency (s)":8.6,
        "E2E Throughput (tokens\/s)":116.0,
        "Reserved Memory (MB)":499,
        "Used Memory (MB)":1972
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"gpt_neo",
        "Params (B)":0.15,
        "Open LLM Score (%)":"29.47 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00839,
        "Decode Throughput (tokens\/s)":118.74,
        "Allocated Memory (MB)":411,
        "Energy (tokens\/kWh)":1872659.0,
        "E2E Latency (s)":8.43,
        "E2E Throughput (tokens\/s)":119.0,
        "Reserved Memory (MB)":499,
        "Used Memory (MB)":1972
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"gpt_neo",
        "Params (B)":0.15,
        "Open LLM Score (%)":"29.47 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00848,
        "Decode Throughput (tokens\/s)":117.63,
        "Allocated Memory (MB)":411,
        "Energy (tokens\/kWh)":1814882.0,
        "E2E Latency (s)":8.51,
        "E2E Throughput (tokens\/s)":118.0,
        "Reserved Memory (MB)":499,
        "Used Memory (MB)":1972
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"gpt_neo",
        "Params (B)":0.15,
        "Open LLM Score (%)":"29.47*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00929,
        "Decode Throughput (tokens\/s)":114.15,
        "Allocated Memory (MB)":489,
        "Energy (tokens\/kWh)":1642036.0,
        "E2E Latency (s)":8.77,
        "E2E Throughput (tokens\/s)":114.0,
        "Reserved Memory (MB)":572,
        "Used Memory (MB)":2048
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"gpt_neo",
        "Params (B)":0.15,
        "Open LLM Score (%)":"29.47*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00958,
        "Decode Throughput (tokens\/s)":112.99,
        "Allocated Memory (MB)":286,
        "Energy (tokens\/kWh)":1584786.0,
        "E2E Latency (s)":8.86,
        "E2E Throughput (tokens\/s)":113.0,
        "Reserved Memory (MB)":364,
        "Used Memory (MB)":1840
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"gpt_neo",
        "Params (B)":0.15,
        "Open LLM Score (%)":"29.47*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0144,
        "Decode Throughput (tokens\/s)":87.07,
        "Allocated Memory (MB)":287,
        "Energy (tokens\/kWh)":1388888.0,
        "E2E Latency (s)":11.5,
        "E2E Throughput (tokens\/s)":87.0,
        "Reserved Memory (MB)":369,
        "Used Memory (MB)":1842
    },
    {
        "Model":"EleutherAI\/gpt-neo-125m",
        "Arch":"gpt_neo",
        "Params (B)":0.15,
        "Open LLM Score (%)":"29.47*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.015,
        "Decode Throughput (tokens\/s)":87.07,
        "Allocated Memory (MB)":291,
        "Energy (tokens\/kWh)":1347708.0,
        "E2E Latency (s)":11.5,
        "E2E Throughput (tokens\/s)":87.0,
        "Reserved Memory (MB)":367,
        "Used Memory (MB)":1840
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"gpt_bigcode",
        "Params (B)":0.16,
        "Open LLM Score (%)":"29.41 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00755,
        "Decode Throughput (tokens\/s)":119.3,
        "Allocated Memory (MB)":446,
        "Energy (tokens\/kWh)":1923076.0,
        "E2E Latency (s)":8.39,
        "E2E Throughput (tokens\/s)":119.0,
        "Reserved Memory (MB)":471,
        "Used Memory (MB)":1943
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"gpt_bigcode",
        "Params (B)":0.16,
        "Open LLM Score (%)":"29.41 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00936,
        "Decode Throughput (tokens\/s)":103.41,
        "Allocated Memory (MB)":446,
        "Energy (tokens\/kWh)":1626016.0,
        "E2E Latency (s)":9.68,
        "E2E Throughput (tokens\/s)":103.0,
        "Reserved Memory (MB)":471,
        "Used Memory (MB)":1945
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"gpt_bigcode",
        "Params (B)":0.16,
        "Open LLM Score (%)":"29.41 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00977,
        "Decode Throughput (tokens\/s)":101.62,
        "Allocated Memory (MB)":446,
        "Energy (tokens\/kWh)":1615508.0,
        "E2E Latency (s)":9.85,
        "E2E Throughput (tokens\/s)":102.0,
        "Reserved Memory (MB)":471,
        "Used Memory (MB)":1945
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"gpt_bigcode",
        "Params (B)":0.16,
        "Open LLM Score (%)":"29.41*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00995,
        "Decode Throughput (tokens\/s)":100.91,
        "Allocated Memory (MB)":470,
        "Energy (tokens\/kWh)":1533742.0,
        "E2E Latency (s)":9.92,
        "E2E Throughput (tokens\/s)":101.0,
        "Reserved Memory (MB)":505,
        "Used Memory (MB)":1981
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"gpt_bigcode",
        "Params (B)":0.16,
        "Open LLM Score (%)":"29.41*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00999,
        "Decode Throughput (tokens\/s)":99.11,
        "Allocated Memory (MB)":269,
        "Energy (tokens\/kWh)":1447178.0,
        "E2E Latency (s)":10.1,
        "E2E Throughput (tokens\/s)":99.0,
        "Reserved Memory (MB)":297,
        "Used Memory (MB)":1773
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"gpt_bigcode",
        "Params (B)":0.16,
        "Open LLM Score (%)":"29.41*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0157,
        "Decode Throughput (tokens\/s)":86.32,
        "Allocated Memory (MB)":269,
        "Energy (tokens\/kWh)":1322751.0,
        "E2E Latency (s)":11.6,
        "E2E Throughput (tokens\/s)":86.2,
        "Reserved Memory (MB)":301,
        "Used Memory (MB)":1773
    },
    {
        "Model":"bigcode\/tiny_starcoder_py",
        "Arch":"gpt_bigcode",
        "Params (B)":0.16,
        "Open LLM Score (%)":"29.41*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.017,
        "Decode Throughput (tokens\/s)":73.08,
        "Allocated Memory (MB)":269,
        "Energy (tokens\/kWh)":1164144.0,
        "E2E Latency (s)":13.7,
        "E2E Throughput (tokens\/s)":73.0,
        "Reserved Memory (MB)":301,
        "Used Memory (MB)":1775
    },
    {
        "Model":"cerebras\/Cerebras-GPT-256M",
        "Arch":"gpt2",
        "Params (B)":0.26,
        "Open LLM Score (%)":"29.38*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00673,
        "Decode Throughput (tokens\/s)":129.82,
        "Allocated Memory (MB)":737,
        "Energy (tokens\/kWh)":2079002.0,
        "E2E Latency (s)":7.71,
        "E2E Throughput (tokens\/s)":130.0,
        "Reserved Memory (MB)":853,
        "Used Memory (MB)":2327
    },
    {
        "Model":"cerebras\/Cerebras-GPT-256M",
        "Arch":"gpt2",
        "Params (B)":0.26,
        "Open LLM Score (%)":"29.38 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00675,
        "Decode Throughput (tokens\/s)":130.66,
        "Allocated Memory (MB)":737,
        "Energy (tokens\/kWh)":1980198.0,
        "E2E Latency (s)":7.66,
        "E2E Throughput (tokens\/s)":131.0,
        "Reserved Memory (MB)":853,
        "Used Memory (MB)":2327
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"gpt_neox",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.38 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00803,
        "Decode Throughput (tokens\/s)":114.0,
        "Allocated Memory (MB)":483,
        "Energy (tokens\/kWh)":1824817.0,
        "E2E Latency (s)":8.78,
        "E2E Throughput (tokens\/s)":114.0,
        "Reserved Memory (MB)":574,
        "Used Memory (MB)":2048
    },
    {
        "Model":"cerebras\/Cerebras-GPT-256M",
        "Arch":"gpt2",
        "Params (B)":0.26,
        "Open LLM Score (%)":"29.38 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00843,
        "Decode Throughput (tokens\/s)":117.49,
        "Allocated Memory (MB)":737,
        "Energy (tokens\/kWh)":1757469.0,
        "E2E Latency (s)":8.52,
        "E2E Throughput (tokens\/s)":117.0,
        "Reserved Memory (MB)":853,
        "Used Memory (MB)":2327
    },
    {
        "Model":"cerebras\/Cerebras-GPT-256M",
        "Arch":"gpt2",
        "Params (B)":0.26,
        "Open LLM Score (%)":"29.38*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00845,
        "Decode Throughput (tokens\/s)":114.66,
        "Allocated Memory (MB)":737,
        "Energy (tokens\/kWh)":1792114.0,
        "E2E Latency (s)":8.73,
        "E2E Throughput (tokens\/s)":115.0,
        "Reserved Memory (MB)":853,
        "Used Memory (MB)":2327
    },
    {
        "Model":"cerebras\/Cerebras-GPT-256M",
        "Arch":"gpt2",
        "Params (B)":0.26,
        "Open LLM Score (%)":"29.38 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00848,
        "Decode Throughput (tokens\/s)":115.85,
        "Allocated Memory (MB)":737,
        "Energy (tokens\/kWh)":1754385.0,
        "E2E Latency (s)":8.64,
        "E2E Throughput (tokens\/s)":116.0,
        "Reserved Memory (MB)":853,
        "Used Memory (MB)":2327
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"gpt_neox",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.38 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0094,
        "Decode Throughput (tokens\/s)":106.26,
        "Allocated Memory (MB)":483,
        "Energy (tokens\/kWh)":1675041.0,
        "E2E Latency (s)":9.42,
        "E2E Throughput (tokens\/s)":106.0,
        "Reserved Memory (MB)":576,
        "Used Memory (MB)":2050
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"gpt_neox",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.38 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0098,
        "Decode Throughput (tokens\/s)":105.15,
        "Allocated Memory (MB)":483,
        "Energy (tokens\/kWh)":1663893.0,
        "E2E Latency (s)":9.52,
        "E2E Throughput (tokens\/s)":105.0,
        "Reserved Memory (MB)":576,
        "Used Memory (MB)":2050
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"gpt_neox",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.38*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00991,
        "Decode Throughput (tokens\/s)":104.49,
        "Allocated Memory (MB)":358,
        "Energy (tokens\/kWh)":1477104.0,
        "E2E Latency (s)":9.58,
        "E2E Throughput (tokens\/s)":104.0,
        "Reserved Memory (MB)":444,
        "Used Memory (MB)":1920
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"gpt_neox",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.38*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0125,
        "Decode Throughput (tokens\/s)":94.45,
        "Allocated Memory (MB)":362,
        "Energy (tokens\/kWh)":1464128.0,
        "E2E Latency (s)":10.6,
        "E2E Throughput (tokens\/s)":94.3,
        "Reserved Memory (MB)":448,
        "Used Memory (MB)":1922
    },
    {
        "Model":"EleutherAI\/pythia-160m-deduped",
        "Arch":"gpt_neox",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.38*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.014,
        "Decode Throughput (tokens\/s)":86.31,
        "Allocated Memory (MB)":362,
        "Energy (tokens\/kWh)":1338688.0,
        "E2E Latency (s)":11.6,
        "E2E Throughput (tokens\/s)":86.2,
        "Reserved Memory (MB)":448,
        "Used Memory (MB)":1922
    },
    {
        "Model":"Deci\/DeciCoder-1b",
        "Arch":"llama",
        "Params (B)":1.11,
        "Open LLM Score (%)":"29.37 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0162,
        "Decode Throughput (tokens\/s)":65.0,
        "Allocated Memory (MB)":2391,
        "Energy (tokens\/kWh)":934579.0,
        "E2E Latency (s)":15.4,
        "E2E Throughput (tokens\/s)":64.9,
        "Reserved Memory (MB)":2541,
        "Used Memory (MB)":4015
    },
    {
        "Model":"Deci\/DeciCoder-1b",
        "Arch":"llama",
        "Params (B)":1.11,
        "Open LLM Score (%)":"29.37 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0164,
        "Decode Throughput (tokens\/s)":64.58,
        "Allocated Memory (MB)":2391,
        "Energy (tokens\/kWh)":925925.0,
        "E2E Latency (s)":15.5,
        "E2E Throughput (tokens\/s)":64.5,
        "Reserved Memory (MB)":2541,
        "Used Memory (MB)":4015
    },
    {
        "Model":"Deci\/DeciCoder-1b",
        "Arch":"llama",
        "Params (B)":1.11,
        "Open LLM Score (%)":"29.37 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0166,
        "Decode Throughput (tokens\/s)":63.76,
        "Allocated Memory (MB)":2391,
        "Energy (tokens\/kWh)":900900.0,
        "E2E Latency (s)":15.7,
        "E2E Throughput (tokens\/s)":63.7,
        "Reserved Memory (MB)":2541,
        "Used Memory (MB)":4015
    },
    {
        "Model":"Deci\/DeciCoder-1b",
        "Arch":"llama",
        "Params (B)":1.11,
        "Open LLM Score (%)":"29.37*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0187,
        "Decode Throughput (tokens\/s)":59.59,
        "Allocated Memory (MB)":1407,
        "Energy (tokens\/kWh)":877192.0,
        "E2E Latency (s)":16.8,
        "E2E Throughput (tokens\/s)":59.5,
        "Reserved Memory (MB)":1476,
        "Used Memory (MB)":2952
    },
    {
        "Model":"Deci\/DeciCoder-1b",
        "Arch":"llama",
        "Params (B)":1.11,
        "Open LLM Score (%)":"29.37*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.02,
        "Decode Throughput (tokens\/s)":58.89,
        "Allocated Memory (MB)":1020,
        "Energy (tokens\/kWh)":819672.0,
        "E2E Latency (s)":17.0,
        "E2E Throughput (tokens\/s)":58.8,
        "Reserved Memory (MB)":1086,
        "Used Memory (MB)":2562
    },
    {
        "Model":"Deci\/DeciCoder-1b",
        "Arch":"llama",
        "Params (B)":1.11,
        "Open LLM Score (%)":"29.37*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0284,
        "Decode Throughput (tokens\/s)":48.85,
        "Allocated Memory (MB)":1031,
        "Energy (tokens\/kWh)":709219.0,
        "E2E Latency (s)":20.5,
        "E2E Throughput (tokens\/s)":48.8,
        "Reserved Memory (MB)":1111,
        "Used Memory (MB)":2585
    },
    {
        "Model":"Deci\/DeciCoder-1b",
        "Arch":"llama",
        "Params (B)":1.11,
        "Open LLM Score (%)":"29.37*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0285,
        "Decode Throughput (tokens\/s)":48.85,
        "Allocated Memory (MB)":1031,
        "Energy (tokens\/kWh)":724637.0,
        "E2E Latency (s)":20.5,
        "E2E Throughput (tokens\/s)":48.8,
        "Reserved Memory (MB)":1111,
        "Used Memory (MB)":2585
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"29.15 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00413,
        "Decode Throughput (tokens\/s)":219.02,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3610108.0,
        "E2E Latency (s)":4.57,
        "E2E Throughput (tokens\/s)":219.0,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"29.15 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00476,
        "Decode Throughput (tokens\/s)":208.54,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3378378.0,
        "E2E Latency (s)":4.8,
        "E2E Throughput (tokens\/s)":208.0,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"29.15 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00483,
        "Decode Throughput (tokens\/s)":204.28,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3215434.0,
        "E2E Latency (s)":4.9,
        "E2E Throughput (tokens\/s)":204.0,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"29.15*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00496,
        "Decode Throughput (tokens\/s)":197.82,
        "Allocated Memory (MB)":186,
        "Energy (tokens\/kWh)":3067484.0,
        "E2E Latency (s)":5.06,
        "E2E Throughput (tokens\/s)":198.0,
        "Reserved Memory (MB)":216,
        "Used Memory (MB)":1691
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"29.15*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00499,
        "Decode Throughput (tokens\/s)":199.8,
        "Allocated Memory (MB)":119,
        "Energy (tokens\/kWh)":2762430.0,
        "E2E Latency (s)":5.01,
        "E2E Throughput (tokens\/s)":200.0,
        "Reserved Memory (MB)":146,
        "Used Memory (MB)":1622
    },
    {
        "Model":"facebook\/opt-125m",
        "Arch":"opt",
        "Params (B)":0.12,
        "Open LLM Score (%)":"29.15 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00613,
        "Decode Throughput (tokens\/s)":166.01,
        "Allocated Memory (MB)":360,
        "Energy (tokens\/kWh)":2570694.0,
        "E2E Latency (s)":6.03,
        "E2E Throughput (tokens\/s)":166.0,
        "Reserved Memory (MB)":455,
        "Used Memory (MB)":1928
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"29.15*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00632,
        "Decode Throughput (tokens\/s)":177.5,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2702702.0,
        "E2E Latency (s)":5.64,
        "E2E Throughput (tokens\/s)":177.0,
        "Reserved Memory (MB)":146,
        "Used Memory (MB)":1620
    },
    {
        "Model":"pszemraj\/pythia-31m-KI_v1-2048-scratch",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"29.15*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00714,
        "Decode Throughput (tokens\/s)":163.86,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2544529.0,
        "E2E Latency (s)":6.11,
        "E2E Throughput (tokens\/s)":164.0,
        "Reserved Memory (MB)":146,
        "Used Memory (MB)":1620
    },
    {
        "Model":"facebook\/opt-125m",
        "Arch":"opt",
        "Params (B)":0.12,
        "Open LLM Score (%)":"29.15 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00756,
        "Decode Throughput (tokens\/s)":144.88,
        "Allocated Memory (MB)":360,
        "Energy (tokens\/kWh)":2217294.0,
        "E2E Latency (s)":6.91,
        "E2E Throughput (tokens\/s)":145.0,
        "Reserved Memory (MB)":455,
        "Used Memory (MB)":1928
    },
    {
        "Model":"facebook\/opt-125m",
        "Arch":"opt",
        "Params (B)":0.12,
        "Open LLM Score (%)":"29.15 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00759,
        "Decode Throughput (tokens\/s)":141.59,
        "Allocated Memory (MB)":360,
        "Energy (tokens\/kWh)":2123142.0,
        "E2E Latency (s)":7.07,
        "E2E Throughput (tokens\/s)":141.0,
        "Reserved Memory (MB)":455,
        "Used Memory (MB)":1928
    },
    {
        "Model":"facebook\/opt-125m",
        "Arch":"opt",
        "Params (B)":0.12,
        "Open LLM Score (%)":"29.15*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00805,
        "Decode Throughput (tokens\/s)":139.82,
        "Allocated Memory (MB)":433,
        "Energy (tokens\/kWh)":2016129.0,
        "E2E Latency (s)":7.16,
        "E2E Throughput (tokens\/s)":140.0,
        "Reserved Memory (MB)":532,
        "Used Memory (MB)":2008
    },
    {
        "Model":"facebook\/opt-125m",
        "Arch":"opt",
        "Params (B)":0.12,
        "Open LLM Score (%)":"29.15*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00814,
        "Decode Throughput (tokens\/s)":136.39,
        "Allocated Memory (MB)":232,
        "Energy (tokens\/kWh)":1908396.0,
        "E2E Latency (s)":7.34,
        "E2E Throughput (tokens\/s)":136.0,
        "Reserved Memory (MB)":322,
        "Used Memory (MB)":1798
    },
    {
        "Model":"facebook\/opt-125m",
        "Arch":"opt",
        "Params (B)":0.12,
        "Open LLM Score (%)":"29.15*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0129,
        "Decode Throughput (tokens\/s)":107.1,
        "Allocated Memory (MB)":232,
        "Energy (tokens\/kWh)":1686340.0,
        "E2E Latency (s)":9.35,
        "E2E Throughput (tokens\/s)":107.0,
        "Reserved Memory (MB)":325,
        "Used Memory (MB)":1798
    },
    {
        "Model":"facebook\/opt-125m",
        "Arch":"opt",
        "Params (B)":0.12,
        "Open LLM Score (%)":"29.15*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0157,
        "Decode Throughput (tokens\/s)":92.73,
        "Allocated Memory (MB)":232,
        "Energy (tokens\/kWh)":1490312.0,
        "E2E Latency (s)":10.8,
        "E2E Throughput (tokens\/s)":92.6,
        "Reserved Memory (MB)":325,
        "Used Memory (MB)":1798
    },
    {
        "Model":"roneneldan\/TinyStories-1M",
        "Arch":"gpt_neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.14 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00545,
        "Decode Throughput (tokens\/s)":177.79,
        "Allocated Memory (MB)":77,
        "Energy (tokens\/kWh)":2941176.0,
        "E2E Latency (s)":5.63,
        "E2E Throughput (tokens\/s)":178.0,
        "Reserved Memory (MB)":98,
        "Used Memory (MB)":1572
    },
    {
        "Model":"roneneldan\/TinyStories-1M",
        "Arch":"gpt_neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.14 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00567,
        "Decode Throughput (tokens\/s)":168.23,
        "Allocated Memory (MB)":77,
        "Energy (tokens\/kWh)":2652519.0,
        "E2E Latency (s)":5.95,
        "E2E Throughput (tokens\/s)":168.0,
        "Reserved Memory (MB)":98,
        "Used Memory (MB)":1572
    },
    {
        "Model":"roneneldan\/TinyStories-1M",
        "Arch":"gpt_neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.14 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00591,
        "Decode Throughput (tokens\/s)":163.56,
        "Allocated Memory (MB)":77,
        "Energy (tokens\/kWh)":2754820.0,
        "E2E Latency (s)":6.12,
        "E2E Throughput (tokens\/s)":163.0,
        "Reserved Memory (MB)":100,
        "Used Memory (MB)":1574
    },
    {
        "Model":"roneneldan\/TinyStories-1M",
        "Arch":"gpt_neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.14*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0103,
        "Decode Throughput (tokens\/s)":125.48,
        "Allocated Memory (MB)":75,
        "Energy (tokens\/kWh)":2100840.0,
        "E2E Latency (s)":7.98,
        "E2E Throughput (tokens\/s)":125.0,
        "Reserved Memory (MB)":98,
        "Used Memory (MB)":1572
    },
    {
        "Model":"roneneldan\/TinyStories-1M",
        "Arch":"gpt_neo",
        "Params (B)":0.0,
        "Open LLM Score (%)":"29.14*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0103,
        "Decode Throughput (tokens\/s)":122.25,
        "Allocated Memory (MB)":75,
        "Energy (tokens\/kWh)":2004008.0,
        "E2E Latency (s)":8.19,
        "E2E Throughput (tokens\/s)":122.0,
        "Reserved Memory (MB)":98,
        "Used Memory (MB)":1572
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"bloom",
        "Params (B)":0.88,
        "Open LLM Score (%)":"29.11 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0129,
        "Decode Throughput (tokens\/s)":68.55,
        "Allocated Memory (MB)":2143,
        "Energy (tokens\/kWh)":1029866.0,
        "E2E Latency (s)":14.6,
        "E2E Throughput (tokens\/s)":68.5,
        "Reserved Memory (MB)":2357,
        "Used Memory (MB)":3830
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"bloom",
        "Params (B)":0.88,
        "Open LLM Score (%)":"29.11 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0149,
        "Decode Throughput (tokens\/s)":68.56,
        "Allocated Memory (MB)":2143,
        "Energy (tokens\/kWh)":980392.0,
        "E2E Latency (s)":14.6,
        "E2E Throughput (tokens\/s)":68.5,
        "Reserved Memory (MB)":2357,
        "Used Memory (MB)":3830
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"bloom",
        "Params (B)":0.88,
        "Open LLM Score (%)":"29.11 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.015,
        "Decode Throughput (tokens\/s)":67.64,
        "Allocated Memory (MB)":2143,
        "Energy (tokens\/kWh)":980392.0,
        "E2E Latency (s)":14.8,
        "E2E Throughput (tokens\/s)":67.6,
        "Reserved Memory (MB)":2357,
        "Used Memory (MB)":3830
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"bloom",
        "Params (B)":0.88,
        "Open LLM Score (%)":"29.11*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0156,
        "Decode Throughput (tokens\/s)":70.01,
        "Allocated Memory (MB)":1170,
        "Energy (tokens\/kWh)":934579.0,
        "E2E Latency (s)":14.3,
        "E2E Throughput (tokens\/s)":69.9,
        "Reserved Memory (MB)":1342,
        "Used Memory (MB)":2818
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"bloom",
        "Params (B)":0.88,
        "Open LLM Score (%)":"29.11*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0157,
        "Decode Throughput (tokens\/s)":67.64,
        "Allocated Memory (MB)":1574,
        "Energy (tokens\/kWh)":943396.0,
        "E2E Latency (s)":14.8,
        "E2E Throughput (tokens\/s)":67.6,
        "Reserved Memory (MB)":1749,
        "Used Memory (MB)":3224
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"bloom",
        "Params (B)":0.88,
        "Open LLM Score (%)":"29.11*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0213,
        "Decode Throughput (tokens\/s)":56.89,
        "Allocated Memory (MB)":1166,
        "Energy (tokens\/kWh)":840336.0,
        "E2E Latency (s)":17.6,
        "E2E Throughput (tokens\/s)":56.8,
        "Reserved Memory (MB)":1344,
        "Used Memory (MB)":2818
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-large",
        "Arch":"bloom",
        "Params (B)":0.88,
        "Open LLM Score (%)":"29.11*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.024,
        "Decode Throughput (tokens\/s)":53.54,
        "Allocated Memory (MB)":1166,
        "Energy (tokens\/kWh)":787401.0,
        "E2E Latency (s)":18.7,
        "E2E Throughput (tokens\/s)":53.5,
        "Reserved Memory (MB)":1344,
        "Used Memory (MB)":2818
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"gpt_neox",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.02 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00797,
        "Decode Throughput (tokens\/s)":114.13,
        "Allocated Memory (MB)":483,
        "Energy (tokens\/kWh)":1872659.0,
        "E2E Latency (s)":8.77,
        "E2E Throughput (tokens\/s)":114.0,
        "Reserved Memory (MB)":574,
        "Used Memory (MB)":2048
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"gpt_neox",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.02 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00948,
        "Decode Throughput (tokens\/s)":104.82,
        "Allocated Memory (MB)":483,
        "Energy (tokens\/kWh)":1652892.0,
        "E2E Latency (s)":9.55,
        "E2E Throughput (tokens\/s)":105.0,
        "Reserved Memory (MB)":576,
        "Used Memory (MB)":2050
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"gpt_neox",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.02 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00956,
        "Decode Throughput (tokens\/s)":105.93,
        "Allocated Memory (MB)":483,
        "Energy (tokens\/kWh)":1652892.0,
        "E2E Latency (s)":9.45,
        "E2E Throughput (tokens\/s)":106.0,
        "Reserved Memory (MB)":576,
        "Used Memory (MB)":2050
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"gpt_neox",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.02*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00965,
        "Decode Throughput (tokens\/s)":106.27,
        "Allocated Memory (MB)":561,
        "Energy (tokens\/kWh)":1599999.0,
        "E2E Latency (s)":9.42,
        "E2E Throughput (tokens\/s)":106.0,
        "Reserved Memory (MB)":652,
        "Used Memory (MB)":2128
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"gpt_neox",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.02*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0101,
        "Decode Throughput (tokens\/s)":104.39,
        "Allocated Memory (MB)":358,
        "Energy (tokens\/kWh)":1483679.0,
        "E2E Latency (s)":9.59,
        "E2E Throughput (tokens\/s)":104.0,
        "Reserved Memory (MB)":444,
        "Used Memory (MB)":1920
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"gpt_neox",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.02*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0127,
        "Decode Throughput (tokens\/s)":95.35,
        "Allocated Memory (MB)":362,
        "Energy (tokens\/kWh)":1503759.0,
        "E2E Latency (s)":10.5,
        "E2E Throughput (tokens\/s)":95.2,
        "Reserved Memory (MB)":448,
        "Used Memory (MB)":1922
    },
    {
        "Model":"EleutherAI\/pythia-160m",
        "Arch":"gpt_neox",
        "Params (B)":0.21,
        "Open LLM Score (%)":"29.02*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0139,
        "Decode Throughput (tokens\/s)":86.31,
        "Allocated Memory (MB)":362,
        "Energy (tokens\/kWh)":1360544.0,
        "E2E Latency (s)":11.6,
        "E2E Throughput (tokens\/s)":86.2,
        "Reserved Memory (MB)":448,
        "Used Memory (MB)":1922
    },
    {
        "Model":"EleutherAI\/pythia-70m",
        "Arch":"gpt_neox",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.93 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00418,
        "Decode Throughput (tokens\/s)":219.5,
        "Allocated Memory (MB)":216,
        "Energy (tokens\/kWh)":3436426.0,
        "E2E Latency (s)":4.56,
        "E2E Throughput (tokens\/s)":219.0,
        "Reserved Memory (MB)":251,
        "Used Memory (MB)":1725
    },
    {
        "Model":"EleutherAI\/pythia-70m",
        "Arch":"gpt_neox",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.93 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00478,
        "Decode Throughput (tokens\/s)":203.04,
        "Allocated Memory (MB)":216,
        "Energy (tokens\/kWh)":3225806.0,
        "E2E Latency (s)":4.93,
        "E2E Throughput (tokens\/s)":203.0,
        "Reserved Memory (MB)":251,
        "Used Memory (MB)":1725
    },
    {
        "Model":"EleutherAI\/pythia-70m",
        "Arch":"gpt_neox",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.93 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0049,
        "Decode Throughput (tokens\/s)":201.81,
        "Allocated Memory (MB)":216,
        "Energy (tokens\/kWh)":3215434.0,
        "E2E Latency (s)":4.96,
        "E2E Throughput (tokens\/s)":202.0,
        "Reserved Memory (MB)":251,
        "Used Memory (MB)":1725
    },
    {
        "Model":"EleutherAI\/pythia-70m",
        "Arch":"gpt_neox",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.93*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00511,
        "Decode Throughput (tokens\/s)":197.05,
        "Allocated Memory (MB)":186,
        "Energy (tokens\/kWh)":2881844.0,
        "E2E Latency (s)":5.08,
        "E2E Throughput (tokens\/s)":197.0,
        "Reserved Memory (MB)":234,
        "Used Memory (MB)":1710
    },
    {
        "Model":"EleutherAI\/pythia-70m",
        "Arch":"gpt_neox",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.93*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00513,
        "Decode Throughput (tokens\/s)":193.24,
        "Allocated Memory (MB)":321,
        "Energy (tokens\/kWh)":3030303.0,
        "E2E Latency (s)":5.18,
        "E2E Throughput (tokens\/s)":193.0,
        "Reserved Memory (MB)":373,
        "Used Memory (MB)":1849
    },
    {
        "Model":"EleutherAI\/pythia-70m",
        "Arch":"gpt_neox",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.93*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0063,
        "Decode Throughput (tokens\/s)":173.2,
        "Allocated Memory (MB)":185,
        "Energy (tokens\/kWh)":2688172.0,
        "E2E Latency (s)":5.78,
        "E2E Throughput (tokens\/s)":173.0,
        "Reserved Memory (MB)":216,
        "Used Memory (MB)":1689
    },
    {
        "Model":"EleutherAI\/pythia-70m",
        "Arch":"gpt_neox",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.93*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00721,
        "Decode Throughput (tokens\/s)":164.4,
        "Allocated Memory (MB)":185,
        "Energy (tokens\/kWh)":2583979.0,
        "E2E Latency (s)":6.09,
        "E2E Throughput (tokens\/s)":164.0,
        "Reserved Memory (MB)":213,
        "Used Memory (MB)":1687
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"gpt_neox",
        "Params (B)":0.76,
        "Open LLM Score (%)":"28.88 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.016,
        "Decode Throughput (tokens\/s)":57.86,
        "Allocated Memory (MB)":2193,
        "Energy (tokens\/kWh)":884955.0,
        "E2E Latency (s)":17.3,
        "E2E Throughput (tokens\/s)":57.8,
        "Reserved Memory (MB)":2384,
        "Used Memory (MB)":3858
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"gpt_neox",
        "Params (B)":0.76,
        "Open LLM Score (%)":"28.88 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0192,
        "Decode Throughput (tokens\/s)":51.07,
        "Allocated Memory (MB)":2193,
        "Energy (tokens\/kWh)":787401.0,
        "E2E Latency (s)":19.6,
        "E2E Throughput (tokens\/s)":51.0,
        "Reserved Memory (MB)":2384,
        "Used Memory (MB)":3858
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"gpt_neox",
        "Params (B)":0.76,
        "Open LLM Score (%)":"28.88*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0194,
        "Decode Throughput (tokens\/s)":55.31,
        "Allocated Memory (MB)":1602,
        "Energy (tokens\/kWh)":819672.0,
        "E2E Latency (s)":18.1,
        "E2E Throughput (tokens\/s)":55.2,
        "Reserved Memory (MB)":1753,
        "Used Memory (MB)":3229
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"gpt_neox",
        "Params (B)":0.76,
        "Open LLM Score (%)":"28.88 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0195,
        "Decode Throughput (tokens\/s)":53.25,
        "Allocated Memory (MB)":2193,
        "Energy (tokens\/kWh)":769230.0,
        "E2E Latency (s)":18.8,
        "E2E Throughput (tokens\/s)":53.2,
        "Reserved Memory (MB)":2384,
        "Used Memory (MB)":3858
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"gpt_neox",
        "Params (B)":0.76,
        "Open LLM Score (%)":"28.88*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0198,
        "Decode Throughput (tokens\/s)":54.11,
        "Allocated Memory (MB)":1198,
        "Energy (tokens\/kWh)":757575.0,
        "E2E Latency (s)":18.5,
        "E2E Throughput (tokens\/s)":54.1,
        "Reserved Memory (MB)":1346,
        "Used Memory (MB)":2822
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"gpt_neox",
        "Params (B)":0.76,
        "Open LLM Score (%)":"28.88*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0245,
        "Decode Throughput (tokens\/s)":48.84,
        "Allocated Memory (MB)":1216,
        "Energy (tokens\/kWh)":751879.0,
        "E2E Latency (s)":20.5,
        "E2E Throughput (tokens\/s)":48.8,
        "Reserved Memory (MB)":1377,
        "Used Memory (MB)":2851
    },
    {
        "Model":"cyberagent\/open-calm-large",
        "Arch":"gpt_neox",
        "Params (B)":0.76,
        "Open LLM Score (%)":"28.88*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0278,
        "Decode Throughput (tokens\/s)":44.7,
        "Allocated Memory (MB)":1216,
        "Energy (tokens\/kWh)":662251.0,
        "E2E Latency (s)":22.4,
        "E2E Throughput (tokens\/s)":44.6,
        "Reserved Memory (MB)":1377,
        "Used Memory (MB)":2851
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.85 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00414,
        "Decode Throughput (tokens\/s)":220.47,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3584229.0,
        "E2E Latency (s)":4.54,
        "E2E Throughput (tokens\/s)":220.0,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.85 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00479,
        "Decode Throughput (tokens\/s)":206.39,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3300330.0,
        "E2E Latency (s)":4.85,
        "E2E Throughput (tokens\/s)":206.0,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.85 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0048,
        "Decode Throughput (tokens\/s)":205.54,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3311258.0,
        "E2E Latency (s)":4.87,
        "E2E Throughput (tokens\/s)":205.0,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.85*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.005,
        "Decode Throughput (tokens\/s)":198.61,
        "Allocated Memory (MB)":119,
        "Energy (tokens\/kWh)":2923976.0,
        "E2E Latency (s)":5.04,
        "E2E Throughput (tokens\/s)":198.0,
        "Reserved Memory (MB)":146,
        "Used Memory (MB)":1622
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.85*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00501,
        "Decode Throughput (tokens\/s)":197.82,
        "Allocated Memory (MB)":186,
        "Energy (tokens\/kWh)":3048780.0,
        "E2E Latency (s)":5.06,
        "E2E Throughput (tokens\/s)":198.0,
        "Reserved Memory (MB)":216,
        "Used Memory (MB)":1691
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.85*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0063,
        "Decode Throughput (tokens\/s)":178.77,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2890173.0,
        "E2E Latency (s)":5.6,
        "E2E Throughput (tokens\/s)":179.0,
        "Reserved Memory (MB)":146,
        "Used Memory (MB)":1620
    },
    {
        "Model":"pszemraj\/pythia-31m-goodwiki-deduped-2048-scratch",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.85*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00701,
        "Decode Throughput (tokens\/s)":165.48,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2583979.0,
        "E2E Latency (s)":6.05,
        "E2E Throughput (tokens\/s)":165.0,
        "Reserved Memory (MB)":146,
        "Used Memory (MB)":1620
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.81 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00406,
        "Decode Throughput (tokens\/s)":229.05,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3649635.0,
        "E2E Latency (s)":4.37,
        "E2E Throughput (tokens\/s)":229.0,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.81 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00477,
        "Decode Throughput (tokens\/s)":207.67,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3278688.0,
        "E2E Latency (s)":4.82,
        "E2E Throughput (tokens\/s)":207.0,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.81 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0048,
        "Decode Throughput (tokens\/s)":206.39,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3246753.0,
        "E2E Latency (s)":4.85,
        "E2E Throughput (tokens\/s)":206.0,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.81*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00505,
        "Decode Throughput (tokens\/s)":198.22,
        "Allocated Memory (MB)":186,
        "Energy (tokens\/kWh)":3012048.0,
        "E2E Latency (s)":5.05,
        "E2E Throughput (tokens\/s)":198.0,
        "Reserved Memory (MB)":216,
        "Used Memory (MB)":1691
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.81*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00506,
        "Decode Throughput (tokens\/s)":198.61,
        "Allocated Memory (MB)":119,
        "Energy (tokens\/kWh)":2958579.0,
        "E2E Latency (s)":5.04,
        "E2E Throughput (tokens\/s)":198.0,
        "Reserved Memory (MB)":146,
        "Used Memory (MB)":1622
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.81*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00639,
        "Decode Throughput (tokens\/s)":180.06,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2915451.0,
        "E2E Latency (s)":5.56,
        "E2E Throughput (tokens\/s)":180.0,
        "Reserved Memory (MB)":146,
        "Used Memory (MB)":1620
    },
    {
        "Model":"ethzanalytics\/pythia-31m",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.81*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00709,
        "Decode Throughput (tokens\/s)":166.31,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2617801.0,
        "E2E Latency (s)":6.02,
        "E2E Throughput (tokens\/s)":166.0,
        "Reserved Memory (MB)":146,
        "Used Memory (MB)":1620
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"llama",
        "Params (B)":0.06,
        "Open LLM Score (%)":"28.70 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00484,
        "Decode Throughput (tokens\/s)":186.74,
        "Allocated Memory (MB)":180,
        "Energy (tokens\/kWh)":3058103.0,
        "E2E Latency (s)":5.36,
        "E2E Throughput (tokens\/s)":187.0,
        "Reserved Memory (MB)":224,
        "Used Memory (MB)":1698
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"llama",
        "Params (B)":0.06,
        "Open LLM Score (%)":"28.70 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0054,
        "Decode Throughput (tokens\/s)":176.53,
        "Allocated Memory (MB)":180,
        "Energy (tokens\/kWh)":2857142.0,
        "E2E Latency (s)":5.67,
        "E2E Throughput (tokens\/s)":176.0,
        "Reserved Memory (MB)":224,
        "Used Memory (MB)":1698
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"llama",
        "Params (B)":0.06,
        "Open LLM Score (%)":"28.70 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00567,
        "Decode Throughput (tokens\/s)":174.08,
        "Allocated Memory (MB)":180,
        "Energy (tokens\/kWh)":2717391.0,
        "E2E Latency (s)":5.75,
        "E2E Throughput (tokens\/s)":174.0,
        "Reserved Memory (MB)":224,
        "Used Memory (MB)":1698
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"llama",
        "Params (B)":0.06,
        "Open LLM Score (%)":"28.70*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00613,
        "Decode Throughput (tokens\/s)":168.81,
        "Allocated Memory (MB)":279,
        "Energy (tokens\/kWh)":2544529.0,
        "E2E Latency (s)":5.93,
        "E2E Throughput (tokens\/s)":169.0,
        "Reserved Memory (MB)":320,
        "Used Memory (MB)":1796
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"llama",
        "Params (B)":0.06,
        "Open LLM Score (%)":"28.70*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00618,
        "Decode Throughput (tokens\/s)":166.28,
        "Allocated Memory (MB)":145,
        "Energy (tokens\/kWh)":2624671.0,
        "E2E Latency (s)":6.02,
        "E2E Throughput (tokens\/s)":166.0,
        "Reserved Memory (MB)":182,
        "Used Memory (MB)":1658
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"llama",
        "Params (B)":0.06,
        "Open LLM Score (%)":"28.70*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00845,
        "Decode Throughput (tokens\/s)":150.79,
        "Allocated Memory (MB)":144,
        "Energy (tokens\/kWh)":2341920.0,
        "E2E Latency (s)":6.64,
        "E2E Throughput (tokens\/s)":151.0,
        "Reserved Memory (MB)":182,
        "Used Memory (MB)":1656
    },
    {
        "Model":"BEE-spoke-data\/verysmol_llama-v11-KIx2",
        "Arch":"llama",
        "Params (B)":0.06,
        "Open LLM Score (%)":"28.70*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00908,
        "Decode Throughput (tokens\/s)":140.83,
        "Allocated Memory (MB)":144,
        "Energy (tokens\/kWh)":2232142.0,
        "E2E Latency (s)":7.11,
        "E2E Throughput (tokens\/s)":141.0,
        "Reserved Memory (MB)":182,
        "Used Memory (MB)":1656
    },
    {
        "Model":"RWKV\/rwkv-4-169m-pile",
        "Arch":"rwkv",
        "Params (B)":0.13,
        "Open LLM Score (%)":"28.64 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0128,
        "Decode Throughput (tokens\/s)":77.0,
        "Allocated Memory (MB)":381,
        "Energy (tokens\/kWh)":1162790.0,
        "E2E Latency (s)":13.0,
        "E2E Throughput (tokens\/s)":76.9,
        "Reserved Memory (MB)":400,
        "Used Memory (MB)":1874
    },
    {
        "Model":"RWKV\/rwkv-4-169m-pile",
        "Arch":"rwkv",
        "Params (B)":0.13,
        "Open LLM Score (%)":"28.64 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.777,
        "Decode Throughput (tokens\/s)":77.98,
        "Allocated Memory (MB)":381,
        "Energy (tokens\/kWh)":1168224.0,
        "E2E Latency (s)":13.6,
        "E2E Throughput (tokens\/s)":73.5,
        "Reserved Memory (MB)":398,
        "Used Memory (MB)":1872
    },
    {
        "Model":"RWKV\/rwkv-4-169m-pile",
        "Arch":"rwkv",
        "Params (B)":0.13,
        "Open LLM Score (%)":"28.64*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.818,
        "Decode Throughput (tokens\/s)":58.2,
        "Allocated Memory (MB)":241,
        "Energy (tokens\/kWh)":877192.0,
        "E2E Latency (s)":18.0,
        "E2E Throughput (tokens\/s)":55.6,
        "Reserved Memory (MB)":274,
        "Used Memory (MB)":1748
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.61 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00415,
        "Decode Throughput (tokens\/s)":220.95,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3610108.0,
        "E2E Latency (s)":4.53,
        "E2E Throughput (tokens\/s)":221.0,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.61 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00478,
        "Decode Throughput (tokens\/s)":205.12,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3378378.0,
        "E2E Latency (s)":4.88,
        "E2E Throughput (tokens\/s)":205.0,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.61 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00489,
        "Decode Throughput (tokens\/s)":203.87,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3115264.0,
        "E2E Latency (s)":4.91,
        "E2E Throughput (tokens\/s)":204.0,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.61*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00504,
        "Decode Throughput (tokens\/s)":200.2,
        "Allocated Memory (MB)":119,
        "Energy (tokens\/kWh)":2967359.0,
        "E2E Latency (s)":5.0,
        "E2E Throughput (tokens\/s)":200.0,
        "Reserved Memory (MB)":146,
        "Used Memory (MB)":1622
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.61*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00508,
        "Decode Throughput (tokens\/s)":195.51,
        "Allocated Memory (MB)":186,
        "Energy (tokens\/kWh)":3039513.0,
        "E2E Latency (s)":5.12,
        "E2E Throughput (tokens\/s)":195.0,
        "Reserved Memory (MB)":216,
        "Used Memory (MB)":1691
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.61*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00631,
        "Decode Throughput (tokens\/s)":179.09,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2898550.0,
        "E2E Latency (s)":5.59,
        "E2E Throughput (tokens\/s)":179.0,
        "Reserved Memory (MB)":146,
        "Used Memory (MB)":1620
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-scratch-bf16",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.61*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00702,
        "Decode Throughput (tokens\/s)":166.58,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2577319.0,
        "E2E Latency (s)":6.01,
        "E2E Throughput (tokens\/s)":166.0,
        "Reserved Memory (MB)":146,
        "Used Memory (MB)":1620
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.60 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00413,
        "Decode Throughput (tokens\/s)":223.42,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3676470.0,
        "E2E Latency (s)":4.48,
        "E2E Throughput (tokens\/s)":223.0,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.60 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00495,
        "Decode Throughput (tokens\/s)":205.55,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3289473.0,
        "E2E Latency (s)":4.87,
        "E2E Throughput (tokens\/s)":205.0,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.60 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00495,
        "Decode Throughput (tokens\/s)":199.0,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3174603.0,
        "E2E Latency (s)":5.03,
        "E2E Throughput (tokens\/s)":199.0,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.60*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00503,
        "Decode Throughput (tokens\/s)":197.83,
        "Allocated Memory (MB)":119,
        "Energy (tokens\/kWh)":2923976.0,
        "E2E Latency (s)":5.06,
        "E2E Throughput (tokens\/s)":198.0,
        "Reserved Memory (MB)":146,
        "Used Memory (MB)":1622
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.60*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00503,
        "Decode Throughput (tokens\/s)":197.05,
        "Allocated Memory (MB)":186,
        "Energy (tokens\/kWh)":3021148.0,
        "E2E Latency (s)":5.08,
        "E2E Throughput (tokens\/s)":197.0,
        "Reserved Memory (MB)":216,
        "Used Memory (MB)":1691
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.60*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00634,
        "Decode Throughput (tokens\/s)":180.06,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2857142.0,
        "E2E Latency (s)":5.56,
        "E2E Throughput (tokens\/s)":180.0,
        "Reserved Memory (MB)":146,
        "Used Memory (MB)":1620
    },
    {
        "Model":"pszemraj\/pythia-31m-simplepile-lite-2048-scratch-2e",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.60*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.007,
        "Decode Throughput (tokens\/s)":168.27,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2617801.0,
        "E2E Latency (s)":5.95,
        "E2E Throughput (tokens\/s)":168.0,
        "Reserved Memory (MB)":146,
        "Used Memory (MB)":1620
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"gpt_bigcode",
        "Params (B)":1.12,
        "Open LLM Score (%)":"28.49 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00886,
        "Decode Throughput (tokens\/s)":107.75,
        "Allocated Memory (MB)":2329,
        "Energy (tokens\/kWh)":1418439.0,
        "E2E Latency (s)":9.29,
        "E2E Throughput (tokens\/s)":108.0,
        "Reserved Memory (MB)":2426,
        "Used Memory (MB)":3898
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"gpt_bigcode",
        "Params (B)":1.12,
        "Open LLM Score (%)":"28.49 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0117,
        "Decode Throughput (tokens\/s)":82.72,
        "Allocated Memory (MB)":2329,
        "Energy (tokens\/kWh)":1152073.0,
        "E2E Latency (s)":12.1,
        "E2E Throughput (tokens\/s)":82.6,
        "Reserved Memory (MB)":2426,
        "Used Memory (MB)":3900
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"gpt_bigcode",
        "Params (B)":1.12,
        "Open LLM Score (%)":"28.49*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0121,
        "Decode Throughput (tokens\/s)":85.56,
        "Allocated Memory (MB)":1395,
        "Energy (tokens\/kWh)":1256281.0,
        "E2E Latency (s)":11.7,
        "E2E Throughput (tokens\/s)":85.5,
        "Reserved Memory (MB)":1451,
        "Used Memory (MB)":2927
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"gpt_bigcode",
        "Params (B)":1.12,
        "Open LLM Score (%)":"28.49 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0122,
        "Decode Throughput (tokens\/s)":82.73,
        "Allocated Memory (MB)":2329,
        "Energy (tokens\/kWh)":1122334.0,
        "E2E Latency (s)":12.1,
        "E2E Throughput (tokens\/s)":82.6,
        "Reserved Memory (MB)":2426,
        "Used Memory (MB)":3900
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"gpt_bigcode",
        "Params (B)":1.12,
        "Open LLM Score (%)":"28.49*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0135,
        "Decode Throughput (tokens\/s)":82.06,
        "Allocated Memory (MB)":856,
        "Energy (tokens\/kWh)":1156069.0,
        "E2E Latency (s)":12.2,
        "E2E Throughput (tokens\/s)":82.0,
        "Reserved Memory (MB)":912,
        "Used Memory (MB)":2388
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"gpt_bigcode",
        "Params (B)":1.12,
        "Open LLM Score (%)":"28.49*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0175,
        "Decode Throughput (tokens\/s)":74.72,
        "Allocated Memory (MB)":901,
        "Energy (tokens\/kWh)":1072961.0,
        "E2E Latency (s)":13.4,
        "E2E Throughput (tokens\/s)":74.6,
        "Reserved Memory (MB)":952,
        "Used Memory (MB)":2423
    },
    {
        "Model":"bigcode\/gpt_bigcode-santacoder",
        "Arch":"gpt_bigcode",
        "Params (B)":1.12,
        "Open LLM Score (%)":"28.49*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0204,
        "Decode Throughput (tokens\/s)":62.97,
        "Allocated Memory (MB)":901,
        "Energy (tokens\/kWh)":909090.0,
        "E2E Latency (s)":15.9,
        "E2E Throughput (tokens\/s)":62.9,
        "Reserved Memory (MB)":954,
        "Used Memory (MB)":2427
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"gpt_neox",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.44 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00419,
        "Decode Throughput (tokens\/s)":216.18,
        "Allocated Memory (MB)":216,
        "Energy (tokens\/kWh)":3623188.0,
        "E2E Latency (s)":4.63,
        "E2E Throughput (tokens\/s)":216.0,
        "Reserved Memory (MB)":251,
        "Used Memory (MB)":1725
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"llama",
        "Params (B)":0.94,
        "Open LLM Score (%)":"28.44 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00466,
        "Decode Throughput (tokens\/s)":282.86,
        "Allocated Memory (MB)":2328,
        "Energy (tokens\/kWh)":3154574.0,
        "E2E Latency (s)":3.54,
        "E2E Throughput (tokens\/s)":282.0,
        "Reserved Memory (MB)":2355,
        "Used Memory (MB)":3828
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"llama",
        "Params (B)":0.94,
        "Open LLM Score (%)":"28.44 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00483,
        "Decode Throughput (tokens\/s)":256.73,
        "Allocated Memory (MB)":2328,
        "Energy (tokens\/kWh)":2967359.0,
        "E2E Latency (s)":3.9,
        "E2E Throughput (tokens\/s)":256.0,
        "Reserved Memory (MB)":2355,
        "Used Memory (MB)":3828
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"gpt_neox",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.44 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00484,
        "Decode Throughput (tokens\/s)":203.87,
        "Allocated Memory (MB)":216,
        "Energy (tokens\/kWh)":3115264.0,
        "E2E Latency (s)":4.91,
        "E2E Throughput (tokens\/s)":204.0,
        "Reserved Memory (MB)":251,
        "Used Memory (MB)":1725
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"llama",
        "Params (B)":0.94,
        "Open LLM Score (%)":"28.44 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00486,
        "Decode Throughput (tokens\/s)":258.72,
        "Allocated Memory (MB)":2328,
        "Energy (tokens\/kWh)":2898550.0,
        "E2E Latency (s)":3.87,
        "E2E Throughput (tokens\/s)":258.0,
        "Reserved Memory (MB)":2355,
        "Used Memory (MB)":3828
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"gpt_neox",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.44 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00491,
        "Decode Throughput (tokens\/s)":199.8,
        "Allocated Memory (MB)":216,
        "Energy (tokens\/kWh)":3134796.0,
        "E2E Latency (s)":5.01,
        "E2E Throughput (tokens\/s)":200.0,
        "Reserved Memory (MB)":251,
        "Used Memory (MB)":1725
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"gpt_neox",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.44*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00499,
        "Decode Throughput (tokens\/s)":199.8,
        "Allocated Memory (MB)":321,
        "Energy (tokens\/kWh)":3012048.0,
        "E2E Latency (s)":5.01,
        "E2E Throughput (tokens\/s)":200.0,
        "Reserved Memory (MB)":373,
        "Used Memory (MB)":1849
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"gpt_neox",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.44*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00502,
        "Decode Throughput (tokens\/s)":199.01,
        "Allocated Memory (MB)":186,
        "Energy (tokens\/kWh)":2857142.0,
        "E2E Latency (s)":5.03,
        "E2E Throughput (tokens\/s)":199.0,
        "Reserved Memory (MB)":234,
        "Used Memory (MB)":1710
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"gpt_neo",
        "Params (B)":0.05,
        "Open LLM Score (%)":"28.44 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00544,
        "Decode Throughput (tokens\/s)":171.69,
        "Allocated Memory (MB)":191,
        "Energy (tokens\/kWh)":2680965.0,
        "E2E Latency (s)":5.83,
        "E2E Throughput (tokens\/s)":172.0,
        "Reserved Memory (MB)":241,
        "Used Memory (MB)":1714
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"gpt_neo",
        "Params (B)":0.05,
        "Open LLM Score (%)":"28.44 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00569,
        "Decode Throughput (tokens\/s)":176.23,
        "Allocated Memory (MB)":192,
        "Energy (tokens\/kWh)":2762430.0,
        "E2E Latency (s)":5.68,
        "E2E Throughput (tokens\/s)":176.0,
        "Reserved Memory (MB)":262,
        "Used Memory (MB)":1735
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"gpt_neo",
        "Params (B)":0.05,
        "Open LLM Score (%)":"28.44 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00578,
        "Decode Throughput (tokens\/s)":170.24,
        "Allocated Memory (MB)":192,
        "Energy (tokens\/kWh)":2624671.0,
        "E2E Latency (s)":5.88,
        "E2E Throughput (tokens\/s)":170.0,
        "Reserved Memory (MB)":262,
        "Used Memory (MB)":1735
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"llama",
        "Params (B)":0.94,
        "Open LLM Score (%)":"28.44*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00589,
        "Decode Throughput (tokens\/s)":245.45,
        "Allocated Memory (MB)":1227,
        "Energy (tokens\/kWh)":3225806.0,
        "E2E Latency (s)":4.08,
        "E2E Throughput (tokens\/s)":245.0,
        "Reserved Memory (MB)":1287,
        "Used Memory (MB)":2763
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"llama",
        "Params (B)":0.94,
        "Open LLM Score (%)":"28.44*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.006,
        "Decode Throughput (tokens\/s)":236.74,
        "Allocated Memory (MB)":1949,
        "Energy (tokens\/kWh)":3333333.0,
        "E2E Latency (s)":4.23,
        "E2E Throughput (tokens\/s)":236.0,
        "Reserved Memory (MB)":2011,
        "Used Memory (MB)":3487
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"gpt_neo",
        "Params (B)":0.05,
        "Open LLM Score (%)":"28.44*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00634,
        "Decode Throughput (tokens\/s)":166.29,
        "Allocated Memory (MB)":157,
        "Energy (tokens\/kWh)":2403846.0,
        "E2E Latency (s)":6.02,
        "E2E Throughput (tokens\/s)":166.0,
        "Reserved Memory (MB)":218,
        "Used Memory (MB)":1693
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"gpt_neox",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.44*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00635,
        "Decode Throughput (tokens\/s)":174.11,
        "Allocated Memory (MB)":185,
        "Energy (tokens\/kWh)":2824858.0,
        "E2E Latency (s)":5.75,
        "E2E Throughput (tokens\/s)":174.0,
        "Reserved Memory (MB)":216,
        "Used Memory (MB)":1689
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"gpt_neo",
        "Params (B)":0.05,
        "Open LLM Score (%)":"28.44*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00636,
        "Decode Throughput (tokens\/s)":165.74,
        "Allocated Memory (MB)":293,
        "Energy (tokens\/kWh)":2415458.0,
        "E2E Latency (s)":6.04,
        "E2E Throughput (tokens\/s)":166.0,
        "Reserved Memory (MB)":354,
        "Used Memory (MB)":1830
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"llama",
        "Params (B)":0.94,
        "Open LLM Score (%)":"28.44*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00653,
        "Decode Throughput (tokens\/s)":216.76,
        "Allocated Memory (MB)":1166,
        "Energy (tokens\/kWh)":2840909.0,
        "E2E Latency (s)":4.62,
        "E2E Throughput (tokens\/s)":216.0,
        "Reserved Memory (MB)":1220,
        "Used Memory (MB)":2694
    },
    {
        "Model":"budecosystem\/boomer-1b",
        "Arch":"llama",
        "Params (B)":0.94,
        "Open LLM Score (%)":"28.44*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0068,
        "Decode Throughput (tokens\/s)":201.08,
        "Allocated Memory (MB)":1166,
        "Energy (tokens\/kWh)":2652519.0,
        "E2E Latency (s)":4.98,
        "E2E Throughput (tokens\/s)":201.0,
        "Reserved Memory (MB)":1233,
        "Used Memory (MB)":2706
    },
    {
        "Model":"EleutherAI\/pythia-70m-deduped",
        "Arch":"gpt_neox",
        "Params (B)":0.1,
        "Open LLM Score (%)":"28.44*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00719,
        "Decode Throughput (tokens\/s)":162.26,
        "Allocated Memory (MB)":185,
        "Energy (tokens\/kWh)":2544529.0,
        "E2E Latency (s)":6.17,
        "E2E Throughput (tokens\/s)":162.0,
        "Reserved Memory (MB)":213,
        "Used Memory (MB)":1687
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"gpt_neo",
        "Params (B)":0.05,
        "Open LLM Score (%)":"28.44*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00941,
        "Decode Throughput (tokens\/s)":134.76,
        "Allocated Memory (MB)":154,
        "Energy (tokens\/kWh)":2164502.0,
        "E2E Latency (s)":7.43,
        "E2E Throughput (tokens\/s)":135.0,
        "Reserved Memory (MB)":218,
        "Used Memory (MB)":1691
    },
    {
        "Model":"roneneldan\/TinyStories-28M",
        "Arch":"gpt_neo",
        "Params (B)":0.05,
        "Open LLM Score (%)":"28.44*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.01,
        "Decode Throughput (tokens\/s)":127.06,
        "Allocated Memory (MB)":157,
        "Energy (tokens\/kWh)":2024291.0,
        "E2E Latency (s)":7.88,
        "E2E Throughput (tokens\/s)":127.0,
        "Reserved Memory (MB)":216,
        "Used Memory (MB)":1689
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"gpt_neo",
        "Params (B)":0.07,
        "Open LLM Score (%)":"28.41 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00312,
        "Decode Throughput (tokens\/s)":301.49,
        "Allocated Memory (MB)":197,
        "Energy (tokens\/kWh)":4784688.0,
        "E2E Latency (s)":3.32,
        "E2E Throughput (tokens\/s)":301.0,
        "Reserved Memory (MB)":234,
        "Used Memory (MB)":1708
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"gpt_neo",
        "Params (B)":0.07,
        "Open LLM Score (%)":"28.41 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00324,
        "Decode Throughput (tokens\/s)":306.11,
        "Allocated Memory (MB)":200,
        "Energy (tokens\/kWh)":4739336.0,
        "E2E Latency (s)":3.27,
        "E2E Throughput (tokens\/s)":306.0,
        "Reserved Memory (MB)":234,
        "Used Memory (MB)":1708
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"gpt_neo",
        "Params (B)":0.07,
        "Open LLM Score (%)":"28.41 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00337,
        "Decode Throughput (tokens\/s)":304.26,
        "Allocated Memory (MB)":200,
        "Energy (tokens\/kWh)":4761904.0,
        "E2E Latency (s)":3.29,
        "E2E Throughput (tokens\/s)":304.0,
        "Reserved Memory (MB)":234,
        "Used Memory (MB)":1708
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"gpt_neo",
        "Params (B)":0.07,
        "Open LLM Score (%)":"28.41*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0037,
        "Decode Throughput (tokens\/s)":291.86,
        "Allocated Memory (MB)":362,
        "Energy (tokens\/kWh)":4405286.0,
        "E2E Latency (s)":3.43,
        "E2E Throughput (tokens\/s)":292.0,
        "Reserved Memory (MB)":402,
        "Used Memory (MB)":1878
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"gpt_neo",
        "Params (B)":0.07,
        "Open LLM Score (%)":"28.41*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00371,
        "Decode Throughput (tokens\/s)":294.44,
        "Allocated Memory (MB)":162,
        "Energy (tokens\/kWh)":4201680.0,
        "E2E Latency (s)":3.4,
        "E2E Throughput (tokens\/s)":294.0,
        "Reserved Memory (MB)":216,
        "Used Memory (MB)":1691
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"gpt_neo",
        "Params (B)":0.07,
        "Open LLM Score (%)":"28.41*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00503,
        "Decode Throughput (tokens\/s)":248.45,
        "Allocated Memory (MB)":157,
        "Energy (tokens\/kWh)":3952569.0,
        "E2E Latency (s)":4.03,
        "E2E Throughput (tokens\/s)":248.0,
        "Reserved Memory (MB)":197,
        "Used Memory (MB)":1670
    },
    {
        "Model":"roneneldan\/TinyStories-33M",
        "Arch":"gpt_neo",
        "Params (B)":0.07,
        "Open LLM Score (%)":"28.41*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00539,
        "Decode Throughput (tokens\/s)":228.07,
        "Allocated Memory (MB)":161,
        "Energy (tokens\/kWh)":3649635.0,
        "E2E Latency (s)":4.39,
        "E2E Throughput (tokens\/s)":228.0,
        "Reserved Memory (MB)":197,
        "Used Memory (MB)":1670
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"gpt_neo",
        "Params (B)":0.02,
        "Open LLM Score (%)":"28.31 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00555,
        "Decode Throughput (tokens\/s)":172.28,
        "Allocated Memory (MB)":112,
        "Energy (tokens\/kWh)":2873563.0,
        "E2E Latency (s)":5.81,
        "E2E Throughput (tokens\/s)":172.0,
        "Reserved Memory (MB)":157,
        "Used Memory (MB)":1631
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"gpt_neo",
        "Params (B)":0.02,
        "Open LLM Score (%)":"28.31 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00567,
        "Decode Throughput (tokens\/s)":177.48,
        "Allocated Memory (MB)":112,
        "Energy (tokens\/kWh)":2898550.0,
        "E2E Latency (s)":5.64,
        "E2E Throughput (tokens\/s)":177.0,
        "Reserved Memory (MB)":157,
        "Used Memory (MB)":1631
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"gpt_neo",
        "Params (B)":0.02,
        "Open LLM Score (%)":"28.31 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00581,
        "Decode Throughput (tokens\/s)":174.39,
        "Allocated Memory (MB)":112,
        "Energy (tokens\/kWh)":2793296.0,
        "E2E Latency (s)":5.74,
        "E2E Throughput (tokens\/s)":174.0,
        "Reserved Memory (MB)":157,
        "Used Memory (MB)":1630
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"gpt_neo",
        "Params (B)":0.02,
        "Open LLM Score (%)":"28.31*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0063,
        "Decode Throughput (tokens\/s)":165.19,
        "Allocated Memory (MB)":170,
        "Energy (tokens\/kWh)":2557544.0,
        "E2E Latency (s)":6.06,
        "E2E Throughput (tokens\/s)":165.0,
        "Reserved Memory (MB)":218,
        "Used Memory (MB)":1693
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"gpt_neo",
        "Params (B)":0.02,
        "Open LLM Score (%)":"28.31*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00636,
        "Decode Throughput (tokens\/s)":167.12,
        "Allocated Memory (MB)":103,
        "Energy (tokens\/kWh)":2531645.0,
        "E2E Latency (s)":5.99,
        "E2E Throughput (tokens\/s)":167.0,
        "Reserved Memory (MB)":148,
        "Used Memory (MB)":1624
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"gpt_neo",
        "Params (B)":0.02,
        "Open LLM Score (%)":"28.31*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00944,
        "Decode Throughput (tokens\/s)":135.86,
        "Allocated Memory (MB)":102,
        "Energy (tokens\/kWh)":2169197.0,
        "E2E Latency (s)":7.37,
        "E2E Throughput (tokens\/s)":136.0,
        "Reserved Memory (MB)":148,
        "Used Memory (MB)":1622
    },
    {
        "Model":"roneneldan\/TinyStories-8M",
        "Arch":"gpt_neo",
        "Params (B)":0.02,
        "Open LLM Score (%)":"28.31*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0101,
        "Decode Throughput (tokens\/s)":129.54,
        "Allocated Memory (MB)":102,
        "Energy (tokens\/kWh)":2020202.0,
        "E2E Latency (s)":7.73,
        "E2E Throughput (tokens\/s)":129.0,
        "Reserved Memory (MB)":148,
        "Used Memory (MB)":1622
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.27 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00409,
        "Decode Throughput (tokens\/s)":225.43,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3663003.0,
        "E2E Latency (s)":4.44,
        "E2E Throughput (tokens\/s)":225.0,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.27 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00487,
        "Decode Throughput (tokens\/s)":205.54,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3300330.0,
        "E2E Latency (s)":4.87,
        "E2E Throughput (tokens\/s)":205.0,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.27 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00503,
        "Decode Throughput (tokens\/s)":195.89,
        "Allocated Memory (MB)":126,
        "Energy (tokens\/kWh)":3144654.0,
        "E2E Latency (s)":5.11,
        "E2E Throughput (tokens\/s)":196.0,
        "Reserved Memory (MB)":155,
        "Used Memory (MB)":1628
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.27*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00507,
        "Decode Throughput (tokens\/s)":202.23,
        "Allocated Memory (MB)":186,
        "Energy (tokens\/kWh)":3125000.0,
        "E2E Latency (s)":4.95,
        "E2E Throughput (tokens\/s)":202.0,
        "Reserved Memory (MB)":216,
        "Used Memory (MB)":1691
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.27*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00624,
        "Decode Throughput (tokens\/s)":179.41,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2865329.0,
        "E2E Latency (s)":5.58,
        "E2E Throughput (tokens\/s)":179.0,
        "Reserved Memory (MB)":146,
        "Used Memory (MB)":1620
    },
    {
        "Model":"pszemraj\/pythia-31m-simplewiki-2048",
        "Arch":"gpt_neox",
        "Params (B)":0.03,
        "Open LLM Score (%)":"28.27*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00704,
        "Decode Throughput (tokens\/s)":165.76,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2617801.0,
        "E2E Latency (s)":6.04,
        "E2E Throughput (tokens\/s)":166.0,
        "Reserved Memory (MB)":146,
        "Used Memory (MB)":1620
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"gpt_neo",
        "Params (B)":0.01,
        "Open LLM Score (%)":"28.19 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00557,
        "Decode Throughput (tokens\/s)":171.1,
        "Allocated Memory (MB)":87,
        "Energy (tokens\/kWh)":2832861.0,
        "E2E Latency (s)":5.85,
        "E2E Throughput (tokens\/s)":171.0,
        "Reserved Memory (MB)":123,
        "Used Memory (MB)":1597
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"gpt_neo",
        "Params (B)":0.01,
        "Open LLM Score (%)":"28.19 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00563,
        "Decode Throughput (tokens\/s)":178.43,
        "Allocated Memory (MB)":87,
        "Energy (tokens\/kWh)":2923976.0,
        "E2E Latency (s)":5.61,
        "E2E Throughput (tokens\/s)":178.0,
        "Reserved Memory (MB)":123,
        "Used Memory (MB)":1597
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"gpt_neo",
        "Params (B)":0.01,
        "Open LLM Score (%)":"28.19 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00588,
        "Decode Throughput (tokens\/s)":174.09,
        "Allocated Memory (MB)":87,
        "Energy (tokens\/kWh)":2777777.0,
        "E2E Latency (s)":5.75,
        "E2E Throughput (tokens\/s)":174.0,
        "Reserved Memory (MB)":123,
        "Used Memory (MB)":1597
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"gpt_neo",
        "Params (B)":0.01,
        "Open LLM Score (%)":"28.19*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00621,
        "Decode Throughput (tokens\/s)":168.24,
        "Allocated Memory (MB)":118,
        "Energy (tokens\/kWh)":2590673.0,
        "E2E Latency (s)":5.95,
        "E2E Throughput (tokens\/s)":168.0,
        "Reserved Memory (MB)":157,
        "Used Memory (MB)":1633
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"gpt_neo",
        "Params (B)":0.01,
        "Open LLM Score (%)":"28.19*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00642,
        "Decode Throughput (tokens\/s)":165.74,
        "Allocated Memory (MB)":84,
        "Energy (tokens\/kWh)":2347417.0,
        "E2E Latency (s)":6.04,
        "E2E Throughput (tokens\/s)":166.0,
        "Reserved Memory (MB)":121,
        "Used Memory (MB)":1597
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"gpt_neo",
        "Params (B)":0.01,
        "Open LLM Score (%)":"28.19*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00928,
        "Decode Throughput (tokens\/s)":137.73,
        "Allocated Memory (MB)":84,
        "Energy (tokens\/kWh)":2197802.0,
        "E2E Latency (s)":7.27,
        "E2E Throughput (tokens\/s)":138.0,
        "Reserved Memory (MB)":121,
        "Used Memory (MB)":1595
    },
    {
        "Model":"roneneldan\/TinyStories-3M",
        "Arch":"gpt_neo",
        "Params (B)":0.01,
        "Open LLM Score (%)":"28.19*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0102,
        "Decode Throughput (tokens\/s)":129.87,
        "Allocated Memory (MB)":84,
        "Energy (tokens\/kWh)":2024291.0,
        "E2E Latency (s)":7.71,
        "E2E Throughput (tokens\/s)":130.0,
        "Reserved Memory (MB)":121,
        "Used Memory (MB)":1595
    },
    {
        "Model":"beomi\/KoRWKV-6B",
        "Arch":"rwkv",
        "Params (B)":6.53,
        "Open LLM Score (%)":"28.19 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0305,
        "Decode Throughput (tokens\/s)":34.05,
        "Allocated Memory (MB)":13112,
        "Energy (tokens\/kWh)":399999.0,
        "E2E Latency (s)":29.4,
        "E2E Throughput (tokens\/s)":34.0,
        "Reserved Memory (MB)":13165,
        "Used Memory (MB)":14639
    },
    {
        "Model":"beomi\/KoRWKV-6B",
        "Arch":"rwkv",
        "Params (B)":6.53,
        "Open LLM Score (%)":"28.19*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0496,
        "Decode Throughput (tokens\/s)":25.16,
        "Allocated Memory (MB)":4352,
        "Energy (tokens\/kWh)":343642.0,
        "E2E Latency (s)":39.8,
        "E2E Throughput (tokens\/s)":25.1,
        "Reserved Memory (MB)":4548,
        "Used Memory (MB)":6022
    },
    {
        "Model":"beomi\/KoRWKV-6B",
        "Arch":"rwkv",
        "Params (B)":6.53,
        "Open LLM Score (%)":"28.19 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":1.89,
        "Decode Throughput (tokens\/s)":34.23,
        "Allocated Memory (MB)":13112,
        "Energy (tokens\/kWh)":380228.0,
        "E2E Latency (s)":31.1,
        "E2E Throughput (tokens\/s)":32.2,
        "Reserved Memory (MB)":13165,
        "Used Memory (MB)":14639
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"bloom",
        "Params (B)":0.19,
        "Open LLM Score (%)":"27.95 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00667,
        "Decode Throughput (tokens\/s)":138.25,
        "Allocated Memory (MB)":480,
        "Energy (tokens\/kWh)":2118644.0,
        "E2E Latency (s)":7.24,
        "E2E Throughput (tokens\/s)":138.0,
        "Reserved Memory (MB)":555,
        "Used Memory (MB)":2029
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"bloom",
        "Params (B)":0.19,
        "Open LLM Score (%)":"27.95 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00762,
        "Decode Throughput (tokens\/s)":132.94,
        "Allocated Memory (MB)":480,
        "Energy (tokens\/kWh)":2000000.0,
        "E2E Latency (s)":7.53,
        "E2E Throughput (tokens\/s)":133.0,
        "Reserved Memory (MB)":555,
        "Used Memory (MB)":2029
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"bloom",
        "Params (B)":0.19,
        "Open LLM Score (%)":"27.95 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00764,
        "Decode Throughput (tokens\/s)":132.06,
        "Allocated Memory (MB)":480,
        "Energy (tokens\/kWh)":2000000.0,
        "E2E Latency (s)":7.58,
        "E2E Throughput (tokens\/s)":132.0,
        "Reserved Memory (MB)":555,
        "Used Memory (MB)":2029
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"bloom",
        "Params (B)":0.19,
        "Open LLM Score (%)":"27.95*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00804,
        "Decode Throughput (tokens\/s)":130.34,
        "Allocated Memory (MB)":555,
        "Energy (tokens\/kWh)":1923076.0,
        "E2E Latency (s)":7.68,
        "E2E Throughput (tokens\/s)":130.0,
        "Reserved Memory (MB)":652,
        "Used Memory (MB)":2128
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"bloom",
        "Params (B)":0.19,
        "Open LLM Score (%)":"27.95*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00807,
        "Decode Throughput (tokens\/s)":133.66,
        "Allocated Memory (MB)":354,
        "Energy (tokens\/kWh)":1897533.0,
        "E2E Latency (s)":7.49,
        "E2E Throughput (tokens\/s)":134.0,
        "Reserved Memory (MB)":444,
        "Used Memory (MB)":1920
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"bloom",
        "Params (B)":0.19,
        "Open LLM Score (%)":"27.95*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.011,
        "Decode Throughput (tokens\/s)":107.54,
        "Allocated Memory (MB)":353,
        "Energy (tokens\/kWh)":1658374.0,
        "E2E Latency (s)":9.31,
        "E2E Throughput (tokens\/s)":107.0,
        "Reserved Memory (MB)":427,
        "Used Memory (MB)":1901
    },
    {
        "Model":"TurkuNLP\/gpt3-finnish-small",
        "Arch":"bloom",
        "Params (B)":0.19,
        "Open LLM Score (%)":"27.95*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.012,
        "Decode Throughput (tokens\/s)":104.41,
        "Allocated Memory (MB)":354,
        "Energy (tokens\/kWh)":1582278.0,
        "E2E Latency (s)":9.59,
        "E2E Throughput (tokens\/s)":104.0,
        "Reserved Memory (MB)":427,
        "Used Memory (MB)":1901
    },
    {
        "Model":"cerebras\/Cerebras-GPT-111M",
        "Arch":"gpt2",
        "Params (B)":0.11,
        "Open LLM Score (%)":"27.75*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00475,
        "Decode Throughput (tokens\/s)":184.66,
        "Allocated Memory (MB)":354,
        "Energy (tokens\/kWh)":2941176.0,
        "E2E Latency (s)":5.42,
        "E2E Throughput (tokens\/s)":185.0,
        "Reserved Memory (MB)":427,
        "Used Memory (MB)":1901
    },
    {
        "Model":"cerebras\/Cerebras-GPT-111M",
        "Arch":"gpt2",
        "Params (B)":0.11,
        "Open LLM Score (%)":"27.75 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.00494,
        "Decode Throughput (tokens\/s)":180.67,
        "Allocated Memory (MB)":354,
        "Energy (tokens\/kWh)":2865329.0,
        "E2E Latency (s)":5.54,
        "E2E Throughput (tokens\/s)":181.0,
        "Reserved Memory (MB)":427,
        "Used Memory (MB)":1901
    },
    {
        "Model":"cerebras\/Cerebras-GPT-111M",
        "Arch":"gpt2",
        "Params (B)":0.11,
        "Open LLM Score (%)":"27.75 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.00602,
        "Decode Throughput (tokens\/s)":160.67,
        "Allocated Memory (MB)":354,
        "Energy (tokens\/kWh)":2409638.0,
        "E2E Latency (s)":6.23,
        "E2E Throughput (tokens\/s)":161.0,
        "Reserved Memory (MB)":425,
        "Used Memory (MB)":1899
    },
    {
        "Model":"cerebras\/Cerebras-GPT-111M",
        "Arch":"gpt2",
        "Params (B)":0.11,
        "Open LLM Score (%)":"27.75 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.00604,
        "Decode Throughput (tokens\/s)":160.41,
        "Allocated Memory (MB)":354,
        "Energy (tokens\/kWh)":2487562.0,
        "E2E Latency (s)":6.24,
        "E2E Throughput (tokens\/s)":160.0,
        "Reserved Memory (MB)":425,
        "Used Memory (MB)":1899
    },
    {
        "Model":"cerebras\/Cerebras-GPT-111M",
        "Arch":"gpt2",
        "Params (B)":0.11,
        "Open LLM Score (%)":"27.75*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.00608,
        "Decode Throughput (tokens\/s)":163.56,
        "Allocated Memory (MB)":354,
        "Energy (tokens\/kWh)":2531645.0,
        "E2E Latency (s)":6.12,
        "E2E Throughput (tokens\/s)":163.0,
        "Reserved Memory (MB)":427,
        "Used Memory (MB)":1901
    },
    {
        "Model":"cerebras\/Cerebras-GPT-111M",
        "Arch":"gpt2",
        "Params (B)":0.11,
        "Open LLM Score (%)":"27.75*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.00621,
        "Decode Throughput (tokens\/s)":168.53,
        "Allocated Memory (MB)":453,
        "Energy (tokens\/kWh)":2518891.0,
        "E2E Latency (s)":5.94,
        "E2E Throughput (tokens\/s)":168.0,
        "Reserved Memory (MB)":520,
        "Used Memory (MB)":1995
    },
    {
        "Model":"cerebras\/Cerebras-GPT-111M",
        "Arch":"gpt2",
        "Params (B)":0.11,
        "Open LLM Score (%)":"27.75*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.00628,
        "Decode Throughput (tokens\/s)":168.81,
        "Allocated Memory (MB)":251,
        "Energy (tokens\/kWh)":2409638.0,
        "E2E Latency (s)":5.93,
        "E2E Throughput (tokens\/s)":169.0,
        "Reserved Memory (MB)":331,
        "Used Memory (MB)":1807
    },
    {
        "Model":"FabbriSimo01\/Facebook_opt_1.3b_Quantized",
        "Arch":"opt",
        "Params (B)":1.32,
        "Open LLM Score (%)":"21.78 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"None",
        "Prefill Latency (s)":0.0118,
        "Decode Throughput (tokens\/s)":79.44,
        "Allocated Memory (MB)":3144,
        "Energy (tokens\/kWh)":1070663.0,
        "E2E Latency (s)":12.6,
        "E2E Throughput (tokens\/s)":79.4,
        "Reserved Memory (MB)":3416,
        "Used Memory (MB)":4890
    },
    {
        "Model":"FabbriSimo01\/Facebook_opt_1.3b_Quantized",
        "Arch":"opt",
        "Params (B)":1.32,
        "Open LLM Score (%)":"21.78 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0147,
        "Decode Throughput (tokens\/s)":70.0,
        "Allocated Memory (MB)":3144,
        "Energy (tokens\/kWh)":943396.0,
        "E2E Latency (s)":14.3,
        "E2E Throughput (tokens\/s)":69.9,
        "Reserved Memory (MB)":3416,
        "Used Memory (MB)":4889
    },
    {
        "Model":"FabbriSimo01\/Facebook_opt_1.3b_Quantized",
        "Arch":"opt",
        "Params (B)":1.32,
        "Open LLM Score (%)":"21.78 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0149,
        "Decode Throughput (tokens\/s)":71.5,
        "Allocated Memory (MB)":3144,
        "Energy (tokens\/kWh)":917431.0,
        "E2E Latency (s)":14.0,
        "E2E Throughput (tokens\/s)":71.4,
        "Reserved Memory (MB)":3416,
        "Used Memory (MB)":4890
    },
    {
        "Model":"FabbriSimo01\/Facebook_opt_1.3b_Quantized",
        "Arch":"opt",
        "Params (B)":1.32,
        "Open LLM Score (%)":"21.78*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV1",
        "Prefill Latency (s)":0.0164,
        "Decode Throughput (tokens\/s)":72.55,
        "Allocated Memory (MB)":1390,
        "Energy (tokens\/kWh)":990099.0,
        "E2E Latency (s)":13.8,
        "E2E Throughput (tokens\/s)":72.5,
        "Reserved Memory (MB)":1486,
        "Used Memory (MB)":2962
    },
    {
        "Model":"FabbriSimo01\/Facebook_opt_1.3b_Quantized",
        "Arch":"opt",
        "Params (B)":1.32,
        "Open LLM Score (%)":"21.78*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"GPTQ.4bit+ExllamaV2",
        "Prefill Latency (s)":0.0167,
        "Decode Throughput (tokens\/s)":71.01,
        "Allocated Memory (MB)":1929,
        "Energy (tokens\/kWh)":1017293.0,
        "E2E Latency (s)":14.1,
        "E2E Throughput (tokens\/s)":70.9,
        "Reserved Memory (MB)":2027,
        "Used Memory (MB)":3503
    },
    {
        "Model":"FabbriSimo01\/Facebook_opt_1.3b_Quantized",
        "Arch":"opt",
        "Params (B)":1.32,
        "Open LLM Score (%)":"21.78*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"BetterTransformer",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0254,
        "Decode Throughput (tokens\/s)":56.26,
        "Allocated Memory (MB)":1407,
        "Energy (tokens\/kWh)":787401.0,
        "E2E Latency (s)":17.8,
        "E2E Throughput (tokens\/s)":56.2,
        "Reserved Memory (MB)":1497,
        "Used Memory (MB)":2971
    },
    {
        "Model":"FabbriSimo01\/Facebook_opt_1.3b_Quantized",
        "Arch":"opt",
        "Params (B)":1.32,
        "Open LLM Score (%)":"21.78*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0292,
        "Decode Throughput (tokens\/s)":50.07,
        "Allocated Memory (MB)":1408,
        "Energy (tokens\/kWh)":704225.0,
        "E2E Latency (s)":20.0,
        "E2E Throughput (tokens\/s)":50.0,
        "Reserved Memory (MB)":1497,
        "Used Memory (MB)":2971
    },
    {
        "Model":"team-lucid\/mptk-1b",
        "Arch":"mpt",
        "Params (B)":1.31,
        "Open LLM Score (%)":"20.84 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"None",
        "Prefill Latency (s)":0.0115,
        "Decode Throughput (tokens\/s)":88.59,
        "Allocated Memory (MB)":3135,
        "Energy (tokens\/kWh)":1127395.0,
        "E2E Latency (s)":11.3,
        "E2E Throughput (tokens\/s)":88.5,
        "Reserved Memory (MB)":3212,
        "Used Memory (MB)":4686
    },
    {
        "Model":"team-lucid\/mptk-1b",
        "Arch":"mpt",
        "Params (B)":1.31,
        "Open LLM Score (%)":"20.84 ",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"FlashAttentionV2",
        "Quantization":"None",
        "Prefill Latency (s)":0.0116,
        "Decode Throughput (tokens\/s)":87.04,
        "Allocated Memory (MB)":3135,
        "Energy (tokens\/kWh)":1140250.0,
        "E2E Latency (s)":11.5,
        "E2E Throughput (tokens\/s)":87.0,
        "Reserved Memory (MB)":3212,
        "Used Memory (MB)":4686
    },
    {
        "Model":"team-lucid\/mptk-1b",
        "Arch":"mpt",
        "Params (B)":1.31,
        "Open LLM Score (%)":"20.84*",
        "Backend":"pytorch",
        "Dtype":"float16",
        "Optimization":"None",
        "Quantization":"BnB.4bit",
        "Prefill Latency (s)":0.0201,
        "Decode Throughput (tokens\/s)":63.78,
        "Allocated Memory (MB)":1398,
        "Energy (tokens\/kWh)":892857.0,
        "E2E Latency (s)":15.7,
        "E2E Throughput (tokens\/s)":63.7,
        "Reserved Memory (MB)":1453,
        "Used Memory (MB)":2927
    }
]