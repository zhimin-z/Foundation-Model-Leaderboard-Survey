Leaderboard,N-shot,Metrics,Format
Chatbot Arena Leaderboad,5,EM,100.0
Flageval,0,EM,1.000
InstructEval,5,EM,100.0
LLM Benchmarker Suite,0,?,100.0
LLM-Leaderboard,"0,3,5,10","Accuracy,EM,ECE (10-bin),EM (Robustness),EM (Fairness),Denoised inference time (s),# eval,# train,truncated,# prompt tokens,# output tokens,# trials","1.000,100.00,100.0%,100.0"
Open Ko-LLM Leaderboard,5,Accuracy,100.00
Open LLM Leaderboard,5,Accuracy,100.00
Open Multilingual LLM Evaluation Leaderboard,5,Accuracy,100.0
OpenCompass,5,Accuracy,100.0
PromptBench,3,PDR,"1.00,+-"