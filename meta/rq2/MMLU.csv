Leaderboard,Metrics,Value Format,N-shot
Chatbot Arena Leaderboad,EM,1F,5
Flageval,EM,3F,0
HELM,"EM,ECE(10-bin),EM(Robustness),EM(Fairness),Denoised inference time(s),#eval,#train,truncated,#prompt tokens,#output tokens,#trials","0F,1F,3F",0
InstructEval,EM,1F,5
LLM Benchmarker Suite,?,1F,0
LLM-Leaderboard,"Accuracy,EM,ECE(10-bin),EM(Robustness),EM(Fairness),Denoised inference time(s),#eval,#train,truncated,#prompt tokens,#output tokens,#trials","0F,0F%,1F,2F,3F","0,3,5,10"
Open Ko-LLM Leaderboard,Accuracy,2F,5
Open LLM Leaderboard,Accuracy,2F,5
Open Multilingual LLM Evaluation Leaderboard,Accuracy,1F,5
OpenCompass,Accuracy,1F,5
PromptBench,PDR,"2F,+-",3