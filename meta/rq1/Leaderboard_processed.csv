Leaderboard,Sources,Sources (non-template) with model provenance links,Leaderboard splitting criteria for all sources (non-pwc),#Empty scenario-based leaderboards,Modality,Language
MTEB,"['GitHub, HuggingFace, PapersWithCode, Self-hosted website']","['GitHub, HuggingFace, Self-hosted website']","['language support', 'domain task']",0,['text'],"['Afrikaans', 'Albanian', 'Amharic', 'Arabic', 'Armenian', 'Assamese', 'Azerbaijani', 'Bangla', 'Basque', 'Belarusian', 'Bosnian', 'Breton', 'Bulgarian', 'Burmese', 'Catalan', 'Cebuano', 'Chichewa', 'Chinese (Simplified)', 'Chinese (Traditional)', 'Corsican', 'Croatian', 'Czech', 'Danish', 'Dhivehi', 'Dutch', 'English', 'Esperanto', 'Estonian', 'Ewe', 'Filipino', 'Finnish', 'French', 'Frisian', 'Galician', 'Georgian', 'German', 'Greek', 'Guarani', 'Gujarati', 'Haitian Creole', 'Hausa', 'Hawaiian', 'Hebrew', 'Hindi', 'Hmong', 'Hungarian', 'Icelandic', 'Igbo', 'Indonesian', 'Irish', 'Italian', 'Japanese', 'Javanese', 'Kannada', 'Kazakh', 'Khmer', 'Kinyarwanda', 'Korean', 'Kurdish (Kurmanji)', 'Kyrgyz', 'Lao', 'Latin', 'Latvian', 'Lithuanian', 'Luxembourgish', 'Macedonian', 'Malagasy', 'Malay', 'Malayalam', 'Maltese', 'Maori', 'Marathi', 'Mongolian', 'Nepali', 'Norwegian', 'Odia (Oriya)', 'Pashto', 'Persian', 'Polish', 'Portuguese', 'Punjabi', 'Quechua', 'Romanian', 'Russian', 'Samoan', 'Sanskrit', 'Scots Gaelic', 'Serbian', 'Sesotho', 'Shona', 'Sindhi', 'Sinhala', 'Slovak', 'Slovenian', 'Somali', 'Spanish', 'Sundanese', 'Swahili', 'Swedish', 'Tajik', 'Tamil', 'Tatar', 'Telugu', 'Thai', 'Tigrinya', 'Tsonga', 'Turkish', 'Turkmen', 'Ukrainian', 'Urdu', 'UyGitHubur', 'Uzbek']"
LLM-Leaderboard,"['GitHub, HuggingFace, Self-hosted website']","['GitHub, HuggingFace, Self-hosted website']",[],0,"['text', 'code']",['English']
InfiMM-Eval,"['GitHub, PapersWithCode']",[],[],0,"['text', 'image']",['English']
TheoremQA,"['GitHub, PapersWithCode']",[],[],0,['text'],['English']
AgentBench,"['GitHub, Self-hosted website']",[],[],0,['text'],['English']
AlignBench,"['GitHub, Self-hosted website']",[],['evaluation model'],0,['text'],['Chinese']
C-Eval,"['GitHub, Self-hosted website']","['GitHub, Self-hosted website']",['model accessibility'],0,['text'],['Chinese']
InstructEval,"['GitHub, Self-hosted website']","['GitHub, Self-hosted website']","['model capability', 'domain task']",0,['text'],['English']
LLM Benchmarker Suite,"['GitHub, Self-hosted website']",[],[],0,"['text', 'code']",['English']
LLMEval,"['GitHub, Self-hosted website']",[],"['evaluation model', 'leaderboard series']",0,['text'],['Chinese']
SafetyBench,"['GitHub, Self-hosted website']","['GitHub, Self-hosted website']","['evaluation data', 'language support']",0,['text'],"['English', 'Chinese']"
SuperCLUE,"['GitHub, Self-hosted website']",[],"['domain task', 'model capability', 'model accessibility', 'release date']",0,['text'],['Chinese']
SuperCLUE-Agent,"['GitHub, Self-hosted website']",[],"['domain task', 'model capability']",0,['text'],['Chinese']
SuperCLUE-Auto,"['GitHub, Self-hosted website']",[],['domain task'],0,['text'],['Chinese']
SuperCLUE-Safety,"['GitHub, Self-hosted website']",[],['domain task'],0,['text'],['Chinese']
CCBench,"['HuggingFace, Self-hosted website']","['HuggingFace, Self-hosted website']",['model accessibility'],1,"['text', 'image']",['Chinese']
Chatbot Arena Leaderboad,"['HuggingFace, Self-hosted website']","['HuggingFace, Self-hosted website']",[],0,['text'],['English']
Large Language Model Leaderboard,"['HuggingFace, Self-hosted website']","['HuggingFace, Self-hosted website']","['language support', 'model capability']",1,"['text', 'code']","['English', 'Chinese']"
MMBench,"['HuggingFace, Self-hosted website']","['HuggingFace, Self-hosted website']","['evaluation data', 'language support', 'model accessibility']",1,"['text', 'image']","['English', 'Chinese']"
Toloka LLM Leaderboard,"['HuggingFace, Self-hosted website']",[],[],0,['text'],['English']
a-NLI,['AI2'],[],[],0,['text'],['English']
CosmosQA,['AI2'],[],[],0,['text'],['English']
GENIE,['AI2'],[],['evaluation benchmark'],0,['text'],['English']
MOCHA,['AI2'],[],[],0,['text'],['English']
Natural Instructions,['AI2'],[],[],0,['text'],['English']
ProtoQA,['AI2'],[],[],0,['text'],['English']
QASC,['AI2'],[],[],0,['text'],['English']
Sherlock,['AI2'],[],[],0,"['text', 'image']",['English']
A-OKVQA,"['AI2', 'PapersWithCode']",[],[],0,"['text', 'image']",['English']
ARC,"['AI2', 'PapersWithCode']",[],[],0,['text'],"['English', 'Chinese']"
"CSQA (v1,v2)","['AI2', 'PapersWithCode']",[],[],0,['text'],['English']
MC-TACO,"['AI2', 'PapersWithCode']",[],[],0,['text'],['English']
OpenbookQA,"['AI2', 'PapersWithCode']",[],[],0,['text'],['English']
PIQA,"['AI2', 'PapersWithCode']",[],[],0,['text'],['English']
SIQA,"['AI2', 'PapersWithCode']",[],[],0,['text'],['English']
StrategyQA,"['AI2', 'PapersWithCode']",[],[],0,['text'],['English']
WinoGrande,"['AI2', 'PapersWithCode']",[],[],0,['text'],['English']
HellaSwag,"['AI2', 'PapersWithCode', 'Self-hosted website']",['Self-hosted website'],[],0,['text'],['English']
AlpacaEval,['GitHub'],['GitHub'],['evaluation model'],0,['text'],['English']
BIRD,['GitHub'],['GitHub'],['evaluation metrics'],0,"['text', 'code']",['English']
BotChat,['GitHub'],['GitHub'],[],0,['text'],['English']
ChEF,['GitHub'],[],"['model capability', 'model accessibility']",0,"['text', 'image']",['English']
ChineseFactEval,['GitHub'],[],[],0,['text'],['English']
CLiB,['GitHub'],[],"['model capability', 'model size']",0,['text'],['Chinese']
CMMLU,['GitHub'],['GitHub'],['#prompt example'],0,['text'],['Chinese']
Colossal-AI,['GitHub'],[],[],0,['text'],"['English', 'Chinese']"
DecodingTrust,['GitHub'],[],[],0,['text'],['English']
DS-1000,['GitHub'],['GitHub'],[],0,"['text', 'code']",['English']
EvalPlus,['GitHub'],['GitHub'],['evaluation benchmark'],0,"['text', 'code']",['English']
FacTool,['GitHub'],[],[],0,"['text', 'code']",['English']
FActScore,['GitHub'],['GitHub'],[],0,['text'],['English']
FELM,['GitHub'],[],[],0,['text'],['English']
FinanceIQ,['GitHub'],['GitHub'],['#prompt example'],0,['text'],['English']
GAOKAO-Bench,['GitHub'],[],[],0,['text'],"['English', 'Chinese']"
Hallucination Leaderboard,['GitHub'],[],[],0,['text'],['English']
HalluQA,['GitHub'],[],[],0,['text'],"['English', 'Chinese']"
InfiCoder-Eval,['GitHub'],['GitHub'],[],0,"['text', 'code']",['English']
InterCode,['GitHub'],[],['evaluation benchmark'],2,"['text', 'code']",['English']
JustEval,['GitHub'],[],[],0,['text'],['English']
KAgentBench,['GitHub'],[],['evaluation model'],0,['text'],['English']
L-Eval,['GitHub'],[],"['evaluation model', 'evaluation metrics']",0,['text'],['English']
LLMPerf Leaderboard,['GitHub'],[],"['evaluation metrics', 'model size']",0,['text'],['English']
LongBench,['GitHub'],[],"['language support', 'domain task']",0,"['text', 'code']","['English', 'Chinese']"
M3KE,['GitHub'],['GitHub'],['#prompt example'],0,['text'],['Chinese']
MATH401,['GitHub'],[],['evaluation metrics'],0,['text'],['English']
MathVista,['GitHub'],['GitHub'],['evaluation data'],0,['text'],['English']
MINT-Bench,['GitHub'],[],['evaluation metrics'],0,['text'],['English']
MMCU,['GitHub'],[],['domain task'],0,['text'],['Chinese']
MME,['GitHub'],['GitHub'],"['domain task', 'model capability']",0,"['text', 'image']",['English']
MMMU,['GitHub'],['GitHub'],"['domain task', 'evaluation data', 'evaluation metrics']",0,"['text', 'image']",['English']
MVBench,['GitHub'],[],['domain task'],0,"['text', 'video']",['English']
ODEX,['GitHub'],[],[],0,"['text', 'code']",['English']
OpenEval (code),['GitHub'],[],[],0,"['text', 'code']",['English']
PromptBench,['GitHub'],[],['model capability'],0,['text'],['English']
Q-Bench,['GitHub'],[],[],0,"['text', 'image']","['English', 'Chinese']"
QuALITY,['GitHub'],['GitHub'],[],0,['text'],['English']
ReForm-Eval,['GitHub'],[],[],0,"['text', 'image']",['English']
ScandEval,['GitHub'],[],[],0,['text'],"['English', 'Danish', 'Swedish', 'Norwegian', 'Icelandic', 'German', 'Dutch', 'Finnish', 'Russian', 'Arabic']"
SciGraphQA,['GitHub'],[],[],0,"['text', 'image']",['English']
SummEdits,['GitHub'],[],[],0,['text'],['English']
SuperCLUEgkzw,['GitHub'],[],[],0,['text'],['Chinese']
SuperCLUElyb,['GitHub'],[],[],0,['text'],['Chinese']
TabMWP,['GitHub'],['GitHub'],[],0,['text'],['English']
TouchStone,['GitHub'],[],[],0,"['text', 'image']",['English']
tStoryCloze,['GitHub'],[],[],0,['text'],['English']
UHGEval,['GitHub'],[],"['domain task', 'model capability']",0,['text'],['Chinese']
VisIT-Bench,['GitHub'],[],[],0,"['text', 'image']",['English']
VLM-Eval,['GitHub'],['GitHub'],[],0,"['text', 'video']",['English']
Xiezhi,['GitHub'],[],[],0,['text'],"['English', 'Chinese']"
HumanEval,"['GitHub', 'PapersWithCode']",['GitHub'],[],0,"['text', 'code']",['English']
LAiW Leaderboard,"['GitHub', 'HuggingFace']",[],['domain task'],2,['text'],['Chinese']
MMLU,"['GitHub', 'HuggingFace', 'PapersWithCode']","['GitHub', 'HuggingFace']",[],0,['text'],['English']
ANLI,"['GitHub', 'PapersWithCode']",['GitHub'],[],0,['text'],['English']
HallusionBench,"['GitHub', 'PapersWithCode']",[],[],0,"['text', 'image']",['English']
MBPP,"['GitHub', 'PapersWithCode']",['GitHub'],[],0,"['text', 'code']",['English']
PubMedQA,"['GitHub', 'PapersWithCode']",['GitHub'],[],0,['text'],['English']
ScienceQA,"['GitHub', 'PapersWithCode']",['GitHub'],[],0,"['text', 'image']",['English']
Spider,"['GitHub', 'PapersWithCode']",['GitHub'],[],0,"['text', 'code']",['English']
TruthfulQA,"['GitHub', 'PapersWithCode']",[],[],0,['text'],['English']
VideoInstruct,"['GitHub', 'PapersWithCode']",[],['domain task'],0,"['text', 'video']",['English']
ANGO,['HuggingFace'],[],['model capability'],0,['text'],['Chinese']
Big Code Models Leaderboard,['HuggingFace'],['HuggingFace'],[],0,"['text', 'code']",['English']
CanAiCode Leaderboard,['HuggingFace'],['HuggingFace'],['domain task'],0,"['text', 'code']",['English']
GAIA,['HuggingFace'],['HuggingFace'],[],0,['text'],['English']
LLM-Perf Leaderboard,['HuggingFace'],['HuggingFace'],[],0,['text'],['English']
Open Ko-LLM Leaderboard,['HuggingFace'],['HuggingFace'],[],0,['text'],['Korean']
Open LLM Leaderboard,['HuggingFace'],['HuggingFace'],[],0,['text'],['English']
Open Multilingual LLM Evaluation Leaderboard,['HuggingFace'],['HuggingFace'],[],0,['text'],"['Vietnamese', 'Ukrainian', 'Telugu', 'Tamil', 'Swedish', 'Spanish', 'Slovak', 'Serbian', 'Russian', 'Romanian', 'Portuguese', 'Nepali', 'Marathi', 'Malayalam', 'Kannada', 'Italian', 'Indonesian', 'Hungarian', 'Hindi', 'Gujarati', 'German', 'French', 'Dutch', 'Danish', 'Croatian', 'Chinese', 'Catalan', 'Bengali', 'Basque', 'Armenian', 'Arabic']"
SEED-Bench Leaderboard,['HuggingFace'],['HuggingFace'],['evaluation benchmark'],0,"['text', 'image', 'video']",['English']
Toolbench Leaderboard,['HuggingFace'],['HuggingFace'],[],0,['text'],['English']
Video-Bench Leaderboard,['HuggingFace'],[],[],0,"['text', 'video']",['English']
RAFT,"['HuggingFace', 'PapersWithCode']",[],[],0,['text'],['English']
ActivityNet,['PapersWithCode'],[],[],0,"['text', 'video']",['English']
ActivityNet-QA,['PapersWithCode'],[],[],0,"['text', 'video']",['English']
ADE20K,['PapersWithCode'],[],[],0,"['text', 'image']",['English']
AI2D,['PapersWithCode'],[],[],0,"['text', 'image']",['English']
AISHELL-1,['PapersWithCode'],[],[],0,"['text', 'audio']",['English']
APPS,['PapersWithCode'],[],[],0,"['text', 'code']",['English']
ASDiv,['PapersWithCode'],[],[],0,['text'],['English']
AVA,['PapersWithCode'],[],[],0,"['text', 'video']",['English']
BANKING77,['PapersWithCode'],[],[],0,['text'],['English']
BBH,['PapersWithCode'],[],[],0,"['text', 'image']",['English']
BEIR,['PapersWithCode'],[],[],0,['text'],['English']
BIG-Bench,['PapersWithCode'],[],[],0,"['text', 'code', 'image']",['English']
BioASQ,['PapersWithCode'],[],[],0,['text'],['English']
BoolQ,['PapersWithCode'],[],[],0,['text'],['English']
CB,['PapersWithCode'],[],[],0,['text'],['English']
Charades,['PapersWithCode'],[],[],0,"['text', 'video']",['English']
ChartQA,['PapersWithCode'],[],[],0,"['text', 'image']",['English']
CIFAR-10,['PapersWithCode'],[],[],0,"['text', 'image']",['English']
Civil Comments,['PapersWithCode'],[],[],0,['text'],['English']
CLUE,['PapersWithCode'],[],[],0,['text'],['Chinese']
CNN DM,['PapersWithCode'],[],[],0,['text'],['English']
CoLA,['PapersWithCode'],[],[],0,['text'],['English']
CoNaLa,['PapersWithCode'],[],[],0,"['text', 'code']",['English']
COPA,['PapersWithCode'],[],[],0,['text'],['English']
CoQA,['PapersWithCode'],[],[],0,['text'],['English']
CrowS-Pairs,['PapersWithCode'],[],[],0,['text'],['English']
DiDeMo,['PapersWithCode'],[],[],0,"['text', 'video']",['English']
DROP,['PapersWithCode'],[],[],0,['text'],['English']
FewCLUE,['PapersWithCode'],[],[],0,['text'],['Chinese']
FLEURS,['PapersWithCode'],[],['evaluation data'],0,"['text', 'audio']",['English']
Flickr30K,['PapersWithCode'],[],[],0,"['text', 'image']",['English']
Flores-101,['PapersWithCode'],[],[],0,['text'],['English']
Food-101,['PapersWithCode'],[],[],0,"['text', 'video']",['English']
GQA,['PapersWithCode'],[],[],0,"['text', 'image']",['English']
GSM8K,['PapersWithCode'],[],[],0,['text'],['English']
HMDB51,['PapersWithCode'],[],[],0,"['text', 'video']",['English']
ImageNet,['PapersWithCode'],[],[],0,"['text', 'image']",['English']
iNaturalist,['PapersWithCode'],[],[],0,"['text', 'image']",['English']
iVQA,['PapersWithCode'],[],[],0,"['text', 'video']",['English']
Kinetics,['PapersWithCode'],[],[],0,"['text', 'video']",['English']
KQA Pro,['PapersWithCode'],[],[],0,['text'],['English']
LAMBADA,['PapersWithCode'],[],[],0,['text'],['English']
LLaVA-Bench,['PapersWithCode'],[],[],0,"['text', 'image']",['English']
LogiQA,['PapersWithCode'],[],[],0,['text'],['English']
MATH,['PapersWithCode'],[],[],0,['text'],['English']
MathQA,['PapersWithCode'],[],[],0,['text'],['English']
MAWPS,['PapersWithCode'],[],[],0,['text'],['English']
MedQA,['PapersWithCode'],[],[],0,['text'],['English']
MiT,['PapersWithCode'],[],[],0,"['text', 'video']",['English']
MLS,['PapersWithCode'],[],[],0,"['text', 'audio']",['English']
MM-Vet,['PapersWithCode'],[],[],0,"['text', 'image']",['English']
MNLI,['PapersWithCode'],[],[],0,['text'],['English']
MRPC,['PapersWithCode'],[],[],0,['text'],['English']
MSCOCO,['PapersWithCode'],[],[],0,"['text', 'image']",['English']
MSRVTT,['PapersWithCode'],[],[],0,"['text', 'video']",['English']
MSRVTT-QA,['PapersWithCode'],[],[],0,"['text', 'video']",['English']
MSVD,['PapersWithCode'],[],[],0,"['text', 'video']",['English']
MSVD-QA,['PapersWithCode'],[],[],0,"['text', 'video']",['English']
MultiRC,['PapersWithCode'],[],[],0,['text'],['English']
NExT-QA,['PapersWithCode'],[],[],0,"['text', 'video']",['English']
NoCaps,['PapersWithCode'],[],[],0,"['text', 'image']",['English']
NQ,['PapersWithCode'],[],[],0,['text'],['English']
OK-VQA,['PapersWithCode'],[],[],0,"['text', 'image']",['English']
OmniBenchmark,['PapersWithCode'],[],[],0,"['text', 'image']",['English']
Pets37,['PapersWithCode'],[],[],0,"['text', 'image']",['English']
QNLI,['PapersWithCode'],[],[],0,['text'],['English']
QQP,['PapersWithCode'],[],[],0,['text'],['English']
RACE,['PapersWithCode'],[],[],0,['text'],['English']
ReCoRD,['PapersWithCode'],[],[],0,['text'],['English']
RefCOCO,['PapersWithCode'],[],[],0,"['text', 'image']",['English']
Robust04,['PapersWithCode'],[],[],0,['text'],['English']
RTE,['PapersWithCode'],[],[],0,['text'],['English']
SICK,['PapersWithCode'],[],[],0,['text'],['English']
"Something-Something (v1,v2)",['PapersWithCode'],[],[],0,"['text', 'video']",['English']
SQuAD,['PapersWithCode'],[],[],0,['text'],['English']
SST,['PapersWithCode'],[],[],0,['text'],['English']
STAR,['PapersWithCode'],[],[],0,"['text', 'video']",['English']
StereoSet,['PapersWithCode'],[],[],0,['text'],['English']
StoryCloze,['PapersWithCode'],[],[],0,['text'],['English']
STS-B,['PapersWithCode'],[],[],0,['text'],['English']
SVAMP,['PapersWithCode'],[],[],0,['text'],['English']
TGIF-QA,['PapersWithCode'],[],[],0,"['text', 'video']",['English']
The Pile,['PapersWithCode'],[],[],0,['text'],['English']
TREC-COVID,['PapersWithCode'],[],[],0,['text'],['English']
TriviaQA,['PapersWithCode'],[],[],0,['text'],['English']
TVQA,['PapersWithCode'],[],[],0,"['text', 'video']",['English']
TyDiQA,['PapersWithCode'],[],[],0,['text'],"['English', 'Arabic', 'Bengali', 'Finnish', 'Japanese', 'Indonesian', 'Kiswahili', 'Korean', 'Russian', 'Telugu', 'Thai']"
UCF101,['PapersWithCode'],[],[],0,"['text', 'video']",['English']
VCR,['PapersWithCode'],[],[],0,"['text', 'image']",['English']
VisDial,['PapersWithCode'],[],[],0,"['text', 'image']",['English']
VizWiz,['PapersWithCode'],[],[],0,"['text', 'image']",['English']
VNHSGE,['PapersWithCode'],[],[],0,['text'],"['English', 'Vietnamese']"
VQA (v2),['PapersWithCode'],[],[],0,"['text', 'image']",['English']
WebVid,['PapersWithCode'],[],[],0,"['text', 'video']",['English']
Whoops,['PapersWithCode'],[],[],0,"['text', 'image']",['English']
WiC,['PapersWithCode'],[],[],0,['text'],['English']
WikiEvents,['PapersWithCode'],[],[],0,['text'],['English']
WikiText-103,['PapersWithCode'],[],[],0,['text'],['English']
WikiText-2,['PapersWithCode'],[],[],0,['text'],['English']
Winoground,['PapersWithCode'],[],[],0,"['text', 'image']",['English']
WMT (2014),['PapersWithCode'],[],[],0,['text'],['English']
WNLI,['PapersWithCode'],[],[],0,['text'],['English']
WQSP,['PapersWithCode'],[],[],0,['text'],['English']
WSC,['PapersWithCode'],[],[],0,['text'],['English']
XSUM,['PapersWithCode'],[],[],0,['text'],['English']
YouCook2,['PapersWithCode'],[],[],0,"['text', 'video']",['English']
ActivityNet Captions,"['PapersWithCode', 'Self-hosted website']",['Self-hosted website'],[],0,"['text', 'video']",['English']
DocVQA,"['PapersWithCode', 'Self-hosted website']",['Self-hosted website'],[],0,"['text', 'image']",['English']
InfographicVQA,"['PapersWithCode', 'Self-hosted website']",['Self-hosted website'],[],0,"['text', 'image']",['English']
SWE-bench,"['PapersWithCode', 'Self-hosted website']",[],[],0,"['text', 'code']",['English']
CG-Eval,['Self-hosted website'],['Self-hosted website'],[],0,['text'],['Chinese']
CLEVA,['Self-hosted website'],[],['model capability'],0,"['text', 'code']",['English']
CMB,['Self-hosted website'],[],['domain task'],0,['text'],['Chinese']
Coding LLMs Leaderboard,['Self-hosted website'],[],[],0,"['text', 'code']",['English']
FlagEval,['Self-hosted website'],[],"['model capability', 'task modality', 'model size', 'model adaptation']",4,"['text', 'code', 'image', 'audio']","['English', 'Chinese']"
HEIM,['Self-hosted website'],[],"['evaluation benchmark', 'evaluation metrics', 'evaluation setup', 'language support', 'model capability', 'evaluation model', 'domain task']",0,"['text', 'image']","['English', 'Chinese', 'Hindi', 'Spanish']"
HELM Classic,['Self-hosted website'],[],"['evaluation benchmark', 'evaluation metrics', 'evaluation setup', 'language support', 'model capability', 'task modality', 'domain task', 'tokenizer']",?,"['text', 'code']","['English', 'Chinese']"
HELM Lite,['Self-hosted website'],[],"['evaluation benchmark', 'evaluation setup', 'domain task']",0,['text'],"['English', 'Czech', 'German', 'French', 'Hindi', 'Russian']"
KoLA,['Self-hosted website'],[],['release date'],0,['text'],['English']
LawBench,['Self-hosted website'],[],['#prompt example'],0,['text'],['English']
LLMonitor,['Self-hosted website'],[],[],0,['text'],['English']
LMExamQA,['Self-hosted website'],[],['domain task'],0,['text'],['English']
LVLM-eHub,['Self-hosted website'],['Self-hosted website'],"['model capability', 'evaluation metrics']",0,"['text', 'image']",['English']
OpenEval (text),['Self-hosted website'],[],['model capability'],0,['text'],['Chinese']
Program Synthesis Models Leaderboard,['Self-hosted website'],['Self-hosted website'],[],0,"['text', 'code']",['English']
Safety-Prompts,['Self-hosted website'],['Self-hosted website'],['evaluation data'],0,['text'],['Chinese']
SCROLLS,['Self-hosted website'],[],[],0,['text'],['English']
SuperGLUE,['Self-hosted website'],['Self-hosted website'],[],0,['text'],['English']
SuperLim (v2),['Self-hosted website'],[],[],0,['text'],['Swedish']
WikiHow,['Self-hosted website'],[],[],0,['text'],['English']
