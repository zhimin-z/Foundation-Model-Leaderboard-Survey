Leaderboard name,#Empty leaderboards (non-pwc),Display format (non-pwc),Feedback manners (iw),Host platforms,Host platforms with leaderboard downloading functionality (non-pwc),Host platforms with model linkage (non-pwc),Publishing organizations (non-pwc),Publishing venues,Structuring strategies (non-pwc),Submission artifacts (non-pwc),Submission manners (non-pwc),Supported languages,Supported modalities,Benchmarks,Evaluated models,Evaluation metrics (pwc),#Benchmark,#Display format,#Host platform,#Publishing organization,#Supported Language,#Supported Modality,#Structuring strategy,#Leaderboard split (non-pwc),#Evaluation record,#Evaluated model,Weight
A-OKVQA,,{},[],['PapersWithCode'],[],[],[],['ECCV'],[],[],[],['English'],"['Text', 'Image']",['A-OKVQA'],[],"['da vqa score', 'mc accuracy']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,10.0,0.0,1
A-OKVQA,,"{'independent website': ['Rankable Table', 'Scatter Plot']}",['Email'],['independent website'],['independent website'],['independent website'],['Allen Institute for AI'],['ECCV'],[],['Prediction Results'],['Submission Portal'],['English'],"['Text', 'Image']",['A-OKVQA'],[],[],1.0,2.0,1.0,1.0,1.0,2.0,0.0,1.0,305.0,0.0,1
ACE (2005),,{},[],['PapersWithCode'],[],[],[],['AAAI'],[],[],[],['English'],['Text'],['ACE'],[],"['relation f1', 'ner micro f1', 're micro f1', 'cross sentence', 're+ micro f1', 'relation classification f1', 'sentence encoder']",1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,29.0,0.0,1
ActivityNet,,{},[],['PapersWithCode'],[],[],[],['CVPR'],[],[],[],['English'],"['Text', 'Video']",['ActivityNet'],[],"['map iou@0.95', 'map', 'recall@10', 'map iou@0.5', 'mean rank', 'recall@5', 'median rank', 'recall@50', 'recall@1', 'map iou@0.75']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,59.0,0.0,1
ActivityNet Captions,,{},[],['PapersWithCode'],[],[],[],['ICCV'],[],[],[],['English'],"['Text', 'Video']",['ActivityNet Captions'],[],"['bleu-4', 'cider', 'rouge-l', 'bleu-3', 'meteor']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,5.0,0.0,1
ActivityNet-QA,,{},[],['PapersWithCode'],[],[],[],['AAAI'],[],[],[],['English'],"['Text', 'Video']",['ActivityNet-QA'],[],"['accuracy', 'confidence score']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,27.0,0.0,1
ADE20K,,{},[],['PapersWithCode'],[],[],[],['IJCV'],[],[],[],['English'],"['Text', 'Image']",['ADE20K'],[],"['#parameters', 'validation miou', 'test score', 'gflops']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,219.0,0.0,1
AgentBench,,"{'GitHub': ['Bar Chart', 'Table Screenshot'], 'independent website': ['Table']}",[],"['GitHub', 'independent website']",[],[],"['Tsinghua University', 'Ohio State University', 'University of California Berkeley']",['Preprint'],[],[],[],['English'],['Text'],"['ALFWorld', 'Mind2Web', 'WebShop']",[],[],3.0,3.0,2.0,3.0,1.0,1.0,0.0,1.0,25.0,0.0,1
AI2D,,{},[],['PapersWithCode'],[],[],[],['ECCV'],[],[],[],['English'],"['Text', 'Image']",['AI2D'],[],['exact match'],1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,4.0,0.0,1
AI2D,,{},[],['PapersWithCode'],[],[],[],['ECCV'],[],[],[],['English'],"['Text', 'Image']",['AI2D'],[],['exact match'],1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,4.0,0.0,1
AISHELL-1,,{},[],['PapersWithCode'],[],[],[],['O-COCOSDA'],[],[],[],['Chinese'],"['Text', 'Audio']",['AISHELL-1'],[],"['#parameters', 'word error rate']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,13.0,0.0,1
AlignBench,,"{'GitHub': ['Table'], 'independent website': ['Table']}",[],"['GitHub', 'independent website']",[],[],"['Tsinghua University', 'Zhipu AI', 'Renmin University of China', 'Sichuan University', 'Lehigh University']",['Preprint'],['Evaluator'],['Prediction Results'],['Submission Portal'],['Chinese'],['Text'],['AlignBench'],[],[],1.0,1.0,2.0,5.0,1.0,1.0,1.0,2.0,34.0,0.0,1
AlpacaEval (v2),,{'GitHub': ['Table']},[],['GitHub'],['GitHub'],['GitHub'],['Stanford University'],[],"['Aggregated Result', 'Evaluator', 'Leaderboard Version']",['Evaluation Results+Prediction Results+Model Configuration'],['Pull Request'],['English'],['Text'],"['OASST1', 'Koala', 'Vicuna', 'HH-RLHF', 'Self-Instruct']",[],[],5.0,1.0,1.0,1.0,1.0,1.0,3.0,3.0,126.0,0.0,1
Amazon Review,,{},[],['PapersWithCode'],[],[],[],[],[],[],[],['English'],['Text'],['Amazon Review'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,6.0,0.0,1
ANGO,,{'HuggingFace': ['Rankable Table']},[],['HuggingFace'],[],[],['Independent Contributor'],['Preprint'],['Supported Functionality'],['Evaluation Results+Prediction Results'],['Pull Request'],['Chinese'],['Text'],['ANGO'],[],[],1.0,1.0,1.0,1.0,1.0,1.0,1.0,3.0,62.0,0.0,1
ANLI,,{},[],['PapersWithCode'],[],[],[],['ACL'],[],[],[],['English'],['Text'],['ANLI'],[],"['a3', 'a2', 'a1']",1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,21.0,0.0,1
ANLI,,{'GitHub': ['Table']},[],['GitHub'],[],['GitHub'],"['University of North Carolina Chapel Hill', 'Meta']",['ACL'],[],['Prediction Results+Publication+Model Repository'],"['Email', 'Pull Request']",['English'],['Text'],['ANLI'],[],[],1.0,1.0,1.0,2.0,1.0,1.0,0.0,1.0,7.0,0.0,1
APPS,,{},[],['PapersWithCode'],[],[],[],['NeurIPS'],[],[],[],['English'],"['Text', 'Code']",['APPS'],[],"['pass@5', 'pass@any', 'pass@1000', 'pass@1']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,12.0,0.0,1
ARC,,{},[],['PapersWithCode'],[],[],[],['Preprint'],[],[],[],"['English', 'Chinese']",['Text'],['ARC'],[],['accuracy'],1.0,0.0,1.0,1.0,2.0,1.0,1.0,0.0,67.0,0.0,1
ARC,,"{'independent website': ['Rankable Table', 'Scatter Plot']}",['Email'],['independent website'],['independent website'],['independent website'],['Allen Institute for AI'],['Preprint'],[],['Prediction Results'],['Submission Portal'],"['English', 'Chinese']",['Text'],['ARC'],[],[],1.0,2.0,1.0,1.0,2.0,1.0,0.0,1.0,41.0,0.0,1
ASDiv,,{},[],['PapersWithCode'],[],[],[],['ACL'],[],[],[],['English'],['Text'],['ASDiv'],[],['execution accuracy'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,5.0,0.0,1
AudioCaps,,{},[],['PapersWithCode'],[],[],[],['NAAC'],[],[],[],['English'],"['Text', 'Audio']",['AudioCaps'],[],"['recall@10', 'recall@5', 'meteor', 'spice', 'bleu-4', 'cider', 'recall@1', 'spider', 'rouge-l']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,20.0,0.0,1
AVA,,{},[],['PapersWithCode'],[],[],[],['CVPR'],[],[],[],['English'],"['Text', 'Video']",['AVA'],[],"['val map', 'test map', 'map']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,44.0,0.0,1
BANKING77,,{},[],['PapersWithCode'],[],[],[],['NLP4ConvAI'],[],[],[],['English'],['Text'],['BANKING77'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,2.0,0.0,1
BBH,,{},[],['PapersWithCode'],[],[],[],['ACL'],[],[],[],['English'],"['Text', 'Image']","['Adjective Order', 'Boolean Expressions', 'Sorting Words', 'Dyck Languages', 'Salient Translation Error Detection', 'Sports Understanding', 'Logical Deduction', 'Formal Fallacies and Syllogisms with Negation', 'Web of Lies', 'Reasoning about Colored Objects', 'Date Understanding', 'Tables of Penguins', 'MovieLens', 'Causal Judgment', 'Disambiguation QA', 'SNARKS', 'Sequences', 'Ruin a Name with One Edit', 'Multistep Arithmetic', 'Tracking Shuffled Objects', 'Geometric Shapes', 'Object Counting', 'Navigation']",[],['average'],23.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,16.0,0.0,1
BEIR,,{},[],['PapersWithCode'],[],[],[],['NeurIPS'],[],[],[],['English'],['Text'],"['MSMARCO', 'SciDocs', 'TREC-COVID', 'QQP', 'Signal-1M', 'FiQA', 'SciFact', 'NFCorpus', 'Climate-FEVER', 'DBpedia', 'HotpotQA', 'Touche', 'TREC-News', 'Robust04', 'ArguAna', 'NQ', 'BioASQ', 'CQADupStack', 'FEVER']",[],"['average accuracy', 'ndcg@10', 'avg. ndcg@10']",19.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,107.0,0.0,1
BenchLMM,,{},[],['PapersWithCode'],[],[],[],['Preprint'],[],[],[],['English'],"['Text', 'Image']",['BenchLMM'],[],['gpt-3.5 score'],1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,10.0,0.0,1
BenchLMM,,{'GitHub': ['Table Screenshot']},[],['GitHub'],[],[],"['Nanyang Technological University', 'University of Technology Sydney', 'Northeastern University', 'Mohamed bin Zayed University of AI', 'Zhejiang University']",['Preprint'],['Task'],[],[],['English'],"['Text', 'Image']",['BenchLMM'],[],[],1.0,1.0,1.0,5.0,1.0,2.0,1.0,3.0,30.0,0.0,1
Big Code Models Leaderboard,,"{'HuggingFace': ['Rankable Table', 'Scatter Plot']}",[],['HuggingFace'],['HuggingFace'],['HuggingFace'],['BigCode'],[],['Aggregated Result'],['Prediction Results+Evaluation Results'],['Pull Request'],['English'],"['Text', 'Code']","['HumanEval', 'MultiPL-E']",[],[],2.0,2.0,1.0,1.0,1.0,2.0,1.0,1.0,45.0,0.0,1
BIG-Bench,,{},[],['PapersWithCode'],[],[],[],['TMLR'],[],[],[],['English'],"['Text', 'Code', 'Image']","['BBQ-Lite', 'Cause and Effect', 'Shakespeare Dialogue', 'Self-awareness', 'ParsiNLU', 'Physics Multiple Choice', 'Alignment of Simplicity Priors for Turing', 'ePiC', 'Gender Sensitivity Test', 'Identify Math Theorems', 'Factuality', 'Cornell Movie-Dialogs Corpus', 'Unit Conversion', 'MathQA', 'Logic Grid Puzzles', 'Sorting Words', 'SIQA', 'Discovery', 'Dyck Languages', 'Salient Translation Error Detection', 'Estimating Risk of Suicide', 'Arithmetic', 'Phrase Relatedness', 'ASCII Word Recognition', 'Forecasting Subquestions', 'MNLI', 'Entailed Polarity in Hindi', 'Linguistic Mappings', 'TellMeWhy', 'COM2SENSE', 'Reasoning about Colored Objects', 'Self Evaluation Courtroom', 'Emoji Movie', 'Root Finding, Optimization and Games', 'Human Organs and Senses', 'Medical Questions in Russian', 'CRT', 'Spelling Bee', 'Intersection Points', 'Topical-Chat', 'UnQover', 'RiddleSense', 'Word Problems on Sets and Graphs', 'CIFAR-10', 'characterRelations', 'Logical Arguments', 'Persian Idioms', 'CoQA', 'PARSINLU', 'Ruin a Name with One Edit', 'NQ', 'Rhyming', 'SIT', 'Multistep Arithmetic', 'Metaphor Understanding', 'Twenty Questions', 'Irony Identification', 'Geometric Shapes', 'SQuAD', 'Minute Mysteries QA', 'Transforming German Sentences to Gender', 'Taboo', 'Periodic Elements', 'Boolean Expressions', 'Common Morpheme', 'Conceptual Combinations', 'GRE Reading Comprehension', 'Metaphor Boolean', 'Simple arithmetic with subtasks', 'StrategyQA', 'Code Description', 'Figure of Speech Detection', 'Sequential Order', 'Sufficient Information', 'Implicatures', 'Language Games', 'Logical Deduction', 'Operators', 'Sentence Ambiguity', 'Data Wrangling', 'Reordering', 'What is the Tao', 'Web of Lies', 'CS Algorithms', 'State Tracking in Chess', 'CoDA', 'Navigation', 'Kannada Riddles', 'MovieLens', 'Simple arithmetic with multiple targets', 'Identify Odd Metaphor', 'Self Evaluation of Tutoring', 'Physics Questions', 'Simple multiple choice arithmetic', 'Diverse Metrics for Social Biases in Language Models', 'Presuppositions as NLI', 'Cycled Letters', 'Misconceptions', 'List Functions', 'TimeDial', 'ASCII MNIST', 'Strange Stories', 'English to Russian Proverbs', 'Fact-Checking', 'Wino-X', 'Automatic Debugging', 'Indic Cause and Effect', 'Natural Instructions', 'SQuADShifts', 'YesNoBlackWhite Game', 'KPWr', 'TruthfulQA', 'Cryobiology Spanish', 'Object Counting', 'RoFT', 'Text Navigation Game', 'High Low Guessing Game', 'Scientific Press Release', 'Simple arithmetic', 'Swedish to German proverbs', 'Disfl-QA', 'Conlang Translation Problems', 'Unnatural In-Context Learning', 'Novel Concepts', 'Analogical Similarity', 'Hinglish Toxicity Prediction', 'Understanding Fables', 'VitaminC', 'Judging Moral Permissibility', 'Hindu Mythology Trivia', 'Date Understanding', 'Key Value Maps', 'Tables of Penguins', 'Dynamic Counting', 'Swahili-English Paremiologic Competence', 'Word Unscrambling', 'Identifying Anachronisms', 'HHH', 'Disambiguation QA', 'Mathematical Induction', 'WinoWhy', 'Crash Blossoms', 'Kanji ASCII Art', 'Dark Humor Detection', 'Authorship Verification', 'MultiEmo', 'Autoclassification', 'Linguistic Puzzles', 'Cryptonite', 'Muslim-Violence Bias', 'Understanding Grammar of Unseen Words', 'Sudoku', 'Social Support', 'Wikimedia', 'Known Unknowns', 'EmoTag1200', 'Adjective Order', 'Hindi Question Answering', 'Empirical Judgments', 'Long Input Contexts', 'Verb Tense', 'Similarities Test for Abstraction', 'SNLI', 'Keyword Sentence Transformation', 'Truthful QA', 'Odd One Out', 'Intent Recognition', 'Sports Understanding', 'Matrix Shapes', 'LTI LangID Corpus', 'Formal Fallacies and Syllogisms with Negation', 'CRASS', 'Checkmate In One Move', 'General Knowledge', 'Modified Arithmetic', 'Entailed Polarity', 'Informal and Formal Fallacies', 'Simple Ethical Questions', 'Unit Interpretation', 'Causal Judgment', 'COPA', 'Analytic Entailment', 'Python Program Synthesis', 'Physical Intuition', 'Repeat Copy Logic', 'SNARKS', 'Training on the test set', 'TalkDown', 'The Essential, the Excessive, and the Extraneous', 'ARC [Abstraction and Reasoning Corpus]', 'SGD', 'Sequences', 'Goal-Step Inference', 'English Proverbs', 'SParC', 'Fantasy Reasoning', 'Subject-Verb Agreement', 'Codenames', 'GEM', 'Tracking Shuffled Objects', 'Simple Text Editing', 'Protein Interaction Sites', 'ISNotes', 'Social Bias from Sentence Probability', 'Wikidata', 'Which Wiki Edit', 'Spider', 'Python Programming', 'Color']",[],"['accuracy', 'exact string match', 'average']",209.0,0.0,1.0,1.0,1.0,3.0,1.0,0.0,312.0,0.0,1
BioASQ,,{},[],['PapersWithCode'],[],[],[],['AAAI'],[],[],[],['English'],['Text'],['BioASQ'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,6.0,0.0,1
BIRD,,{'GitHub': ['Table']},[],['GitHub'],[],['GitHub'],"['University of Hong Kong', 'Alibaba Group DAMO Academy', 'Tsinghua University', 'Shanghai AI Laboratory', 'Massachusetts Institute of Technology', 'Chinese University of Hong Kong', 'University of Illinois Urbana Champaign']",['NeurIPS'],['Evaluation Metric'],"['Inference API', 'Model Repository']",['Email'],['English'],"['Text', 'Code']",['BIRD'],[],[],1.0,1.0,1.0,7.0,1.0,2.0,1.0,2.0,44.0,0.0,1
BoolQ,,{},[],['PapersWithCode'],[],[],[],['NAACL'],[],[],[],['English'],['Text'],['BoolQ'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,44.0,0.0,1
BotChat,,{'GitHub': ['Table']},[],['GitHub'],[],['GitHub'],"['Shanghai AI Laboratory', 'Fudan University', 'Shanghai Jiao Tong University', 'Chinese University of Hong Kong']",['Preprint'],['Aggregated Result'],[],[],['English'],['Text'],['BotChat'],[],[],1.0,1.0,1.0,4.0,1.0,1.0,1.0,1.0,14.0,0.0,1
C-Eval,,"{'GitHub': ['Table'], 'independent website': ['Rankable Table']}",[],"['GitHub', 'independent website']",[],['independent website'],"['Shanghai Jiao Tong University', 'Tsinghua University', 'University of Edinburgh', 'Hong Kong University of Science and Technology']",['Preprint'],"['#Prompt Example', 'Model Accessibility', 'Evaluation Dataset']",['Prediction Results'],['Submission Portal+Questionaire'],['Chinese'],['Text'],['C-Eval'],[],[],1.0,2.0,2.0,4.0,1.0,1.0,3.0,3.0,119.0,0.0,1
C-Eval Hard,,{'GitHub': ['Table']},[],['GitHub'],[],[],"['Shanghai Jiao Tong University', 'Tsinghua University', 'University of Edinburgh', 'Hong Kong University of Science and Technology']",['Preprint'],[],[],[],['Chinese'],['Text'],['C-Eval Hard'],[],[],1.0,1.0,1.0,4.0,1.0,1.0,0.0,1.0,11.0,0.0,1
CanAiCode Leaderboard,,{'HuggingFace': ['Rankable Table']},[],['HuggingFace'],['GitHub'],['HuggingFace'],['Independent Contributor'],[],"['Aggregated Result', 'Task', 'Evaluation Dataset']",['?'],"['Pull Request', 'Issue']",['English'],"['Text', 'Code']",['CanAiCode Leaderboard'],[],[],1.0,1.0,1.0,1.0,1.0,2.0,3.0,6.0,1661.0,0.0,1
CB,,{},[],['PapersWithCode'],[],[],[],['Sinn und Bedeutung'],[],[],[],['English'],['Text'],['CB'],[],"['accuracy', 'f1']",1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,13.0,0.0,1
CCBench,2,"{'HuggingFace': ['Rankable Table'], 'independent website': ['Rankable Table']}",[],"['HuggingFace', 'independent website']",[],"['HuggingFace', 'independent website']","['Shanghai AI Laboratory', 'Nanyang Technological University', 'Chinese University of Hong Kong', 'National University of Singapore', 'Zhejiang University']",['Preprint'],['Model Accessibility'],['Prediction Results'],['Submission Portal'],['Chinese'],"['Text', 'Image']",['CCBench'],[],[],1.0,1.0,2.0,5.0,1.0,2.0,1.0,2.0,41.0,0.0,1
CCEval,,{'GitHub': ['Table Screenshot']},[],['GitHub'],[],[],"['Columbia University', 'Amazon AWS AI Lab']",['NeurIPS'],['Task'],[],[],['English'],"['Text', 'Code']",['CCEval'],[],[],1.0,1.0,1.0,2.0,1.0,2.0,1.0,1.0,9.0,0.0,1
CFQ,,{},[],['PapersWithCode'],[],[],[],['ICLR'],[],[],[],['English'],['Text'],['CFQ'],[],['exact match'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,5.0,0.0,1
CG-Eval,,{'independent website': ['Table']},"['Contact', 'Issue']",['independent website'],[],['independent website'],"['Besteasy', 'LanguageX AI Lab']",['Preprint'],[],['Prediction Results'],['Submission Portal'],['Chinese'],['Text'],['CG-Eval'],[],[],1.0,1.0,1.0,2.0,1.0,1.0,0.0,1.0,33.0,0.0,1
Charades,,{},[],['PapersWithCode'],[],[],[],['ECCV'],[],[],[],['English'],"['Text', 'Video']",['Charades'],[],['map'],1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,4.0,0.0,1
ChartQA,,{},[],['PapersWithCode'],[],[],[],['ACL'],[],[],[],['English'],"['Text', 'Image']",['ChartQA'],[],['1:1 accuracy'],1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,23.0,0.0,1
Chatbot Arena Leaderboard,,"{'HuggingFace': ['Rankable Table', 'Scatter Plot', 'Bar Chart'], 'independent website': ['Rankable Table']}",[],"['HuggingFace', 'independent website']",[],"['HuggingFace', 'independent website']","['University of California Berkeley', 'University of California San Diego', 'Carnegie Mellon University', 'Stanford University', 'Mohamed bin Zayed University of AI']",['Preprint'],['Evaluation Metric'],"['Inference API+Model Configuration', 'Model Repository+Model Configuration']",['Pull Request'],['English'],['Text'],"['Chatbot Arena Conversations', 'MT-Bench', 'MMLU']",[],[],3.0,3.0,2.0,4.0,1.0,1.0,1.0,2.0,142.0,0.0,1
ChEF,,{'GitHub': ['Table']},[],['GitHub'],[],[],"['Shanghai AI Laboratory', 'Beihang University', 'University of Sydney']",['Preprint'],"['Supported Functionality', 'Model Accessibility', 'Supported Modality']",[],[],['English'],"['Text', 'Image']","['Omnibenchmark', 'Flickr30K', 'MSCOCO', 'VOC', 'ScienceQA', 'MME', 'SEED-Bench', 'FSC147', 'CIFAR-10', 'MMBench']",[],[],10.0,1.0,1.0,3.0,1.0,2.0,3.0,7.0,41.0,0.0,1
ChineseFactEval,,{'GitHub': ['Table']},[],['GitHub'],[],[],"['Shanghai Jiao Tong University', 'Shanghai AI Laboratory']",['Preprint'],[],[],[],['English'],['Text'],['ChineseFactEval'],[],[],1.0,1.0,1.0,2.0,1.0,1.0,0.0,1.0,7.0,0.0,1
CIFAR-10,,{},[],['PapersWithCode'],[],[],[],['Preprint'],[],[],[],['English'],"['Text', 'Image']",['CIFAR-10'],[],"['#parameters', 'percentage correct', 'top-1 accuracy', 'accuracy']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,239.0,0.0,1
Civil Comments,,{},[],['PapersWithCode'],[],[],[],['WWW'],[],[],[],['English'],['Text'],['Civil Comments'],[],"['gmb subgroup', 'micro f1', 'recall', 'gmb bnsp', 'macro f1', 'gmb bpsn', 'auroc', 'precision']",1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,16.0,0.0,1
CLEVA,,"{'independent website': ['Rankable Table', 'Bar Chart']}","['Contact', 'Issue']",['independent website'],[],[],"['Chinese University of Hong Kong', 'Shanghai AI Laboratory']",['EMNLP'],"['Aggregated Result', 'Task']",['Inference API'],"['Questionaire', 'Email']",['English'],"['Text', 'Code']",['CLEVA'],[],[],1.0,2.0,1.0,2.0,1.0,2.0,2.0,9.0,190.0,0.0,1
CLiB,,{'GitHub': ['Table']},[],['GitHub'],[],[],['Independent Contributor'],[],"['Aggregated Result', 'Supported Functionality', 'Model Size']",[],[],['Chinese'],['Text'],['CLiB'],[],[],1.0,1.0,1.0,1.0,1.0,1.0,3.0,9.0,393.0,0.0,1
Clotho,,{},[],['PapersWithCode'],[],[],[],['ICASSP'],[],[],[],['English'],"['Text', 'Audio']",['Clotho'],[],"['recall@10', 'recall@5', 'meteor', 'spice', 'bleu-4', 'cider', 'recall@1', 'spider', 'rouge-l']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,25.0,0.0,1
CLUE,,{},[],['PapersWithCode'],[],[],[],['COLING'],[],[],[],['Chinese'],['Text'],"['DRCD', 'TNEWS', 'CLUE Diagnostics', 'AFQMC', 'CMRC', 'C3', 'iFLYTEK', 'WSC', 'CSL', 'ChID', 'CMNLI', 'OCNLI']",[],['accuracy'],12.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,10.0,0.0,1
CMB,,{'independent website': ['Table']},"['Contact', 'Issue']",['independent website'],[],[],"['Chinese University of Hong Kong', 'Shenzhen Research Institute of Big Data']",['Preprint'],['Task'],['Prediction Results'],['Email'],['Chinese'],['Text'],"['CMB-Clin', 'CMB-Exam']",[],[],2.0,1.0,1.0,2.0,1.0,1.0,1.0,2.0,56.0,0.0,1
CMMLU,,{'GitHub': ['Table']},[],['GitHub'],[],['GitHub'],"['Mohamed bin Zayed University of AI', 'Shanghai Jiao Tong University', 'Microsoft Research Asia', 'University of Melbourne']",['Preprint'],['#Prompt Example'],['Model Configuration+Evaluation Results'],"['Email', 'Pull Request']",['Chinese'],['Text'],['CMMLU'],[],[],1.0,1.0,1.0,4.0,1.0,1.0,1.0,2.0,56.0,0.0,1
CMMMU,,"{'GitHub': ['Table', 'Rankable Table', 'Table Screenshot']}",[],['GitHub'],[],[],"['Multimodal Art Projection Research Community', 'Hong Kong University of Science and Technology', 'University of Waterloo', 'Chinese Academy of Sciences', 'University of Chinese Academy of Sciences', 'Peking University', 'Hong Kong Polytechnic University', 'Waseda University', 'University of Manchester', '01.AI']",['Preprint'],"['Aggregated Result', 'Supported Functionality', 'Task']",[],[],['Chinese'],['Text'],['CMMMU'],[],[],1.0,3.0,1.0,10.0,1.0,1.0,3.0,4.0,58.0,0.0,1
CNN DM,,{},[],['PapersWithCode'],[],[],[],['CoNLL'],[],[],[],['English'],['Text'],['CNN DM'],[],"['rouge-2', 'rouge-1', 'rouge-l', 'perplexity']",1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,78.0,0.0,1
CodeContests,,{},[],['PapersWithCode'],[],[],[],['Science'],[],[],[],['English'],"['Text', 'Code']",['CodeContests'],[],"['test set pass@1', 'val set pass@1', 'val set pass@5', 'test set 10@100k', 'test set pass@5']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,4.0,0.0,1
Coding LLMs Leaderboard,,{'independent website': ['Bar Chart']},"['Contact', 'Issue']",['independent website'],[],[],['TabbyML'],['NeurIPS'],['Task'],[],[],['English'],"['Text', 'Code']",['CCEval'],[],[],1.0,1.0,1.0,1.0,1.0,2.0,1.0,3.0,22.0,0.0,1
CoLA,,{},[],['PapersWithCode'],[],[],[],['TACL'],[],[],[],['English'],['Text'],['CoLA'],[],"['accuracy', 'mcc']",1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,37.0,0.0,1
Common Voice,,{},[],['PapersWithCode'],[],[],[],['LREC'],[],[],[],"['Abkhaz', 'Arabic', 'Basque', 'Breton', 'Catalan', 'Chinese(China)', 'Chinese(Taiwan)', 'Chuvash', 'Dhivehi', 'Dutch', 'English', 'Esperanto', 'Estonian', 'French', 'German', 'Hakha Chin', 'Indonesian', 'Interlingua', 'Irish', 'Italian', 'Japanese', 'Kabyle', 'Kinyarwanda', 'Kyrgyz', 'Latvian', 'Mongolian', 'Persian', 'Portuguese', 'Russian', 'Sakha', 'Slovenian', 'Spanish', 'Swedish', 'Tamil', 'Tatar', 'Turkish', 'Votic', 'Welsh']","['Text', 'Audio']",['Common Voice'],[],"['test cer with lm', 'validation cer', 'test cer', 'validation wer', 'test wer', 'test wer with lm', 'test cer using lm', 'word error rate', 'wer unnormalized', 'cer lm', 'test wer using lm', 'cer', 'test wer on common voice 7', 'wer lm', 'mer']",1.0,0.0,1.0,1.0,38.0,2.0,1.0,0.0,350.0,0.0,1
ComplexWebQuestions,,{},[],['PapersWithCode'],[],[],[],['NAACL'],[],[],[],['English'],"['Text', 'Code']",['ComplexWebQuestions'],[],"['accuracy', 'f1', 'hits@1']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,5.0,0.0,1
CompMix,,{'independent website': ['Table']},['Email'],['independent website'],[],['independent website'],['Max Planck Institute for Informatics'],['Preprint'],[],[],[],['English'],['Text'],['CompMix'],[],[],1.0,1.0,1.0,1.0,1.0,1.0,0.0,1.0,4.0,0.0,1
CoNaLa,,{},[],['PapersWithCode'],[],[],[],['MSR'],[],[],[],['English'],"['Text', 'Code']",['CoNaLa'],[],"['bleu', 'exact match']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,10.0,0.0,1
CoNLL (2004),,{},[],['PapersWithCode'],[],[],[],['CoNLL'],[],[],[],['English'],['Text'],['CoNLL'],[],"['ner micro f1', 're+ macro f1', 'ner macro f1', 're+ micro f1']",1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,15.0,0.0,1
COPA,,{},[],['PapersWithCode'],[],[],[],['SemEval'],[],[],[],['English'],['Text'],['COPA'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,22.0,0.0,1
CoQA,,{},[],['PapersWithCode'],[],[],[],['TACL'],[],[],[],['English'],['Text'],"['Project Gutenberg', 'RACE', 'Wikipedia', 'MCTest', 'SciQ', 'WritingPrompts', 'CNN DM']",[],"['in-domain', 'overall', 'out-of-domain']",7.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,9.0,0.0,1
CORE-MM,,{'GitHub': ['Rankable Table']},[],"['GitHub', 'PapersWithCode']",[],[],"['ByteDance', 'Chinese Academy of Sciences', 'University of Texas Austin']",['Preprint'],[],['Prediction Results'],['Email'],['English'],"['Text', 'Image']",['CORE-MM'],[],[],1.0,1.0,2.0,4.0,1.0,2.0,1.0,1.0,16.0,0.0,1
CosmosQA,,"{'independent website': ['Rankable Table', 'Scatter Plot']}",['Email'],['independent website'],['independent website'],['independent website'],['Allen Institute for AI'],['EMNLP'],[],['Prediction Results'],['Submission Portal'],['English'],['Text'],['CosmosQA'],[],[],1.0,2.0,1.0,1.0,1.0,1.0,0.0,1.0,86.0,0.0,1
CrossNER,,{},[],['PapersWithCode'],[],[],[],['AAAI'],[],[],[],['English'],['Text'],['CrossNER'],[],"['science', 'politics', 'literature', 'ai', 'music']",1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,3.0,0.0,1
CrowS-Pairs,,{},[],['PapersWithCode'],[],[],[],['EMNLP'],[],[],[],['English'],['Text'],['CrowS-Pairs'],[],"['age', 'physical appearance', 'nationality', 'socioeconomic status', 'overall', 'religion', 'disability', 'sexual orientation', 'gender', 'race/color']",1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,4.0,0.0,1
CRUXEval,,{'GitHub': ['Table']},[],['GitHub'],[],['GitHub'],"['Massachusetts Institute of Technology', 'Meta']",['Preprint'],['Task'],[],[],['English'],"['Text', 'Code']",['CRUXEval'],[],[],1.0,1.0,1.0,2.0,1.0,2.0,1.0,2.0,62.0,0.0,1
CSQA (v2),,"{'independent website': ['Rankable Table', 'Scatter Plot']}",['Email'],['independent website'],['independent website'],['independent website'],['Allen Institute for AI'],['NAACL'],[],['Prediction Results'],['Submission Portal'],['English'],['Text'],['CSQA'],[],[],1.0,2.0,1.0,1.0,1.0,1.0,0.0,1.0,262.0,0.0,1
DecodingTrust,,{'GitHub': ['Rankable Table']},[],['GitHub'],[],['GitHub'],['University of Illinois Urbana Champaign'],['NeurIPS'],[],['Prediction Results+Evaluation Results'],['Pull Request'],['English'],['Text'],['DecodingTrust'],[],[],1.0,1.0,1.0,1.0,1.0,1.0,0.0,1.0,54.0,0.0,1
DiDeMo,,{},[],['PapersWithCode'],[],[],[],['ICCV'],[],[],[],['English'],"['Text', 'Video']",['DiDeMo'],[],"['recall@10', 'mean rank', 'recall@5', 'median rank', 'recall@50', 'recall@1']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,50.0,0.0,1
Do-Not-Answer,,"{'GitHub': ['Table', 'Bar Chart', 'Heatmap']}",[],['GitHub'],[],[],"['LibrAI', 'Mohamed bin Zayed University of AI', 'University of Melbourne']",['Preprint'],"['Evaluator', 'Supported Functionality']",[],[],['English'],['Text'],['Do-Not-Answer'],[],[],1.0,3.0,1.0,3.0,1.0,1.0,2.0,3.0,18.0,0.0,1
DocVQA,,{},[],['PapersWithCode'],[],[],[],['WACV'],[],[],[],['English'],"['Text', 'Image']",['DocVQA'],[],"['accuracy', 'anls']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,29.0,0.0,1
DocVQA,,"{'independent website': ['Rankable Table', 'Bar Chart']}",['Contact'],['independent website'],[],['independent website'],['Computer Vision Center '],['WACV'],[],['Prediction Results'],['Submission Portal'],['English'],"['Text', 'Image']",['DocVQA'],[],[],1.0,2.0,1.0,1.0,1.0,2.0,0.0,1.0,85.0,0.0,1
DROP,,{},[],['PapersWithCode'],[],[],[],['NAACL'],[],[],[],['English'],['Text'],['DROP'],[],"['accuracy', 'f1']",1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,22.0,0.0,1
DS-1000,,{'GitHub': ['Table']},[],['GitHub'],[],['GitHub'],"['University of Hong Kong', 'Peking University', 'Stanford University', 'University of California Berkeley', 'University of Washington', 'Meta', 'Carnegie Mellon University']",['PMLR'],[],[],[],['English'],"['Text', 'Code']",['DS-1000'],[],[],1.0,1.0,1.0,7.0,1.0,2.0,0.0,1.0,20.0,0.0,1
DyVal,,{'GitHub': ['Table']},[],['GitHub'],[],[],"['Microsoft', 'Georgia Institute of Technology', 'Duke University', 'Stanford University']",['Preprint'],"['Aggregated Result', 'Supported Functionality']",[],[],['English'],['Text'],['DyVal'],[],[],1.0,1.0,1.0,4.0,1.0,1.0,2.0,5.0,20.0,0.0,1
EQ-Bench Leaderboard,,{'GitHub': ['Rankable Table']},"['Contact', 'Issue']",['independent website'],[],['independent website'],['Independent Contributor'],['Preprint'],[],[],[],['English'],['Text'],"['EQ-Bench', 'AGIEval', 'MMLU']",[],[],3.0,1.0,1.0,1.0,1.0,1.0,0.0,1.0,102.0,0.0,1
EvalPlus,,"{'GitHub': ['Table', 'Scatter Plot']}",[],['GitHub'],[],['GitHub'],"['University of Illinois Urbana Champaign', 'Nanjing University']",['NeurIPS'],"['Aggregated Result', 'Benchmark']","['Inference API', 'Model Repository']",['Issue'],['English'],"['Text', 'Code']","['MBPP', 'HumanEval']",[],[],2.0,2.0,1.0,2.0,1.0,2.0,2.0,3.0,164.0,0.0,1
FActScore,,{'GitHub': ['Table']},[],['GitHub'],[],['GitHub'],"['University of Washington', 'University of Massachusetts Amherst', 'Allen Institute for AI', 'Meta']",['EMNLP'],[],[],[],['English'],['Text'],['FActScore'],[],[],1.0,1.0,1.0,4.0,1.0,1.0,0.0,1.0,12.0,0.0,1
Factuality Leaderboard,,{'GitHub': ['Table']},[],['GitHub'],[],[],"['Shanghai Jiao Tong University', 'Carnegie Mellon University', 'City University of Hong Kong', 'New York University', 'Meta', 'Hong Kong University of Science and Technology', 'Shanghai AI Laboratory']",['Preprint'],[],[],[],['English'],"['Text', 'Code']","['HumanEval', 'GSM8K', 'FactPrompts', 'Self-Instruct', 'RoSE']",[],[],5.0,1.0,1.0,7.0,1.0,2.0,0.0,1.0,5.0,0.0,1
FELM,,{'GitHub': ['Table']},[],['GitHub'],[],[],"['City University of Hong Kong', 'Hong Kong University of Science and Technology', 'National University of Singapore', 'Carnegie Mellon University', 'Shanghai Jiao Tong University']",['NeurIPS'],[],[],[],['English'],['Text'],['FELM'],[],[],1.0,1.0,1.0,5.0,1.0,1.0,0.0,1.0,3.0,0.0,1
FewCLUE,,{},[],['PapersWithCode'],[],[],[],['Preprint'],[],[],[],['Chinese'],['Text'],"['TNEWS', 'CSLDCP', 'BUSTM', 'EPRSTMT', 'iFLYTEK', 'WSC', 'CSL', 'ChID', 'OCNLI']",[],['accuracy'],9.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,16.0,0.0,1
FinanceIQ,,{'GitHub': ['Table']},[],['GitHub'],[],['GitHub'],['Duxiaoman'],[],['#Prompt Example'],[],[],['English'],['Text'],['FinanceIQ'],[],[],1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,34.0,0.0,1
FinQA,,{},[],['PapersWithCode'],[],[],[],['EMNLP'],[],[],[],['English'],['Text'],['FinQA'],[],"['execution accuracy', 'program accuracy']",1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,6.0,0.0,1
FlagEval,?,{'independent website': ['Rankable Table']},"['Contact', 'Issue']",['independent website'],[],[],"['Peking University', 'Nankai University', 'Beijing Normal University', 'Chinese Academy of Sciences', 'Beijing University of Posts and Telecommunications', 'Beihang University', 'China Electronics Standardization Institute', 'Minjiang University']",[],"['Supported Functionality', 'Supported Modality', 'Model Size', 'Model Type']",['Model Repository+Model Configuration'],['Submission Portal'],"['English', 'Chinese']","['Text', 'Code', 'Image', 'Audio']","['BoolQ', 'AISHELL-1', 'KeSpeech', 'BUSTM', 'C-SEM', 'EPRSTMT', 'GAOKAO-Bench', 'DTD', 'ChID', 'CLCC', 'VQA', 'Places', 'ADE20K', 'iNaturalist', 'KITTI Eigen split', 'UCF101', 'CelebA-HQ', 'Stanford Cars', 'Flowers102', 'MSRVTT', 'SOP', 'ImageNet-1K', 'IMDB', 'TNEWS', 'MSCOCO', 'RAFT', 'LibriSpeech', 'NYU-Depth', 'TDIUC', 'COCO-Stuff', 'Cityscapes', 'Flickr30K', 'HumanEval', 'CMMLU', 'FGVC-Aircraft', 'VQA-CP', 'TruthfulQA', 'IEMOCAP', 'WSC', 'MMLU', 'CSL', 'CUB', 'OCNLI', 'Food-101']",[],[],44.0,1.0,1.0,8.0,2.0,4.0,4.0,4.0,67.0,0.0,1
FLEURS,,{},[],['PapersWithCode'],[],[],[],['SLT'],[],[],[],"['Catalan', 'Croatian', 'Danish', 'Dutch', 'AmericanEnglish', 'Finnish', 'French', 'German', 'Greek', 'Hungarian', 'Irish', 'Italian', 'LatinAmericanSpanish', 'Maltese', 'Portuguese', 'Swedish', 'Welsh', 'Bulgarian', 'Czech', 'Estonian', 'Georgian', 'Latvian', 'Lithuanian', 'Polish', 'Romanian', 'Russian', 'Slovak', 'Slovenian', 'Ukrainian', 'Arabic', 'Kazakh', 'Kyrgyz', 'Mongolian', 'Pashto', 'Persian', 'Tajik', 'Turkish', 'Ganda', 'Swahili', 'Zulu', 'Assamese', 'Bengali', 'Hindi', 'Oriya', 'Punjabi', 'Tamil', 'Telugu', 'Cebuano', 'Indonesian', 'Lao', 'Thai', 'Vietnamese', 'Cantonese', 'Japanese', 'Mandarin', 'Asturian', 'Bosnian', 'Galician', 'Icelandic', 'Kabuverdianu', 'Luxembourgish', 'Norwegian', 'Occitan', 'Armenian', 'Belarusian', 'Macedonian', 'Serbian', 'Azerbaijani', 'Hebrew', 'Sorani-Kurdish', 'Uzbek', 'Afrikaans', 'Amharic', 'Fula', 'Hausa', 'Igbo', 'Kamba', 'Lingala', 'Luo', 'Northern-Sotho', 'Nyanja', 'Oromo', 'Shona', 'Somali', 'Umbundu', 'Wolof', 'Xhosa', 'Yoruba', 'Gujarati', 'Kannada', 'Malayalam', 'Marathi', 'Nepali', 'Sindhi', 'Urdu', 'Filipino', 'Javanese', 'Khmer', 'Malay', 'Maori', 'Burmese', 'Korean']","['Text', 'Audio']",['FLEURS'],[],"['test wer', 'test cer', 'accuracy', 'word error rate', 'wer unnormalized', 'cer', 'mer']",1.0,0.0,1.0,1.0,102.0,2.0,1.0,0.0,59.0,0.0,1
Flickr30K,,{},[],['PapersWithCode'],[],[],[],['TACL'],[],[],[],['English'],"['Text', 'Image']",['Flickr30K'],[],"['recall@sum', 'recall@1', 'recall@10', 'recall@5']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,23.0,0.0,1
Flores-101,,{},[],['PapersWithCode'],[],[],[],['TACL'],[],[],[],['English'],['Text'],['Flores-101'],[],['byte_perplexity'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,202.0,0.0,1
Food-101,,{},[],['PapersWithCode'],[],[],[],['ECCV'],[],[],[],['English'],"['Text', 'Video']",['Food-101'],[],['top-1 accuracy'],1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,3.0,0.0,1
FSD50K,,{},[],['PapersWithCode'],[],[],[],['TASLP'],[],[],[],['English'],"['Text', 'Audio']",['FSD50K'],[],['map'],1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,8.0,0.0,1
GAIA,,{'HuggingFace': ['Rankable Table']},[],['HuggingFace'],[],['HuggingFace'],"['Meta FAIR', 'Hugging Face', 'AutoGPT', 'Meta GenAI']",['Preprint'],['Evaluation Dataset'],['Prediction Results'],['Submission Portal'],['English'],['Text'],['GAIA'],[],[],1.0,1.0,1.0,3.0,1.0,1.0,1.0,2.0,10.0,0.0,1
GAOKAO-Bench,,"{'GitHub': ['Table', 'Bar Chart']}",[],['GitHub'],[],[],"['Fudan University', 'East China Normal University']",['Preprint'],[],[],[],"['English', 'Chinese']",['Text'],['GAOKAO-Bench'],[],[],1.0,2.0,1.0,2.0,2.0,1.0,0.0,1.0,19.0,0.0,1
GENIA,,{},[],['PapersWithCode'],[],[],[],['Bioinformatics'],[],[],[],['English'],['Text'],['GENIA'],[],['f1'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,13.0,0.0,1
GENIE,,"{'independent website': ['Rankable Table', 'Scatter Plot']}",['Email'],['independent website'],['independent website'],['independent website'],['Allen Institute for AI'],['EMNLP'],['Benchmark'],['Prediction Results'],['Submission Portal'],['English'],['Text'],"['a-NLG', 'XSUM', 'ARC-DA', 'WMT']",[],[],4.0,2.0,1.0,1.0,1.0,1.0,1.0,3.0,26.0,0.0,1
GQA,,{},[],['PapersWithCode'],[],[],[],['CVPR'],[],[],[],['English'],"['Text', 'Image']",['GQA'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,13.0,0.0,1
GSM8K,,{},[],['PapersWithCode'],[],[],[],['Preprint'],[],[],[],['English'],['Text'],['GSM8K'],[],"['accuracy', '#parameters']",1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,86.0,0.0,1
HalluQA,,{'GitHub': ['Table']},[],['GitHub'],[],[],"['Fudan University', 'Shanghai AI Laboratory']",['Preprint'],[],[],[],['Chinese'],['Text'],['HalluQA'],[],[],1.0,1.0,1.0,2.0,1.0,1.0,0.0,1.0,24.0,0.0,1
HallusionBench,,{},[],['PapersWithCode'],[],[],[],['Preprint'],[],[],[],['English'],"['Text', 'Image']",['HallusionBench'],[],['question pair acc'],1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,3.0,0.0,1
HallusionBench,,{'GitHub': ['Table']},[],['GitHub'],[],[],['University of Maryland College Park'],['Preprint'],[],[],[],['English'],"['Text', 'Image']",['HallusionBench'],[],[],1.0,1.0,1.0,1.0,1.0,2.0,0.0,1.0,16.0,0.0,1
HEIM,,{'independent website': ['Rankable Table']},"['Contact', 'Issue']",['independent website'],[],[],"['Stanford University', 'Microsoft', 'Aleph Alpha', 'Pohang University of Science and Technology', 'Adobe', 'Carnegie Mellon University']",['NeurIPS'],"['Benchmark', 'Supported Language', 'Supported Functionality', 'Task']",[],[],"['English', 'Chinese', 'Hindi', 'Spanish']","['Text', 'Image']","['Historical Figures', 'Landing Pages', 'I2P', 'MSCOCO', 'Mental Disorders', 'DrawBench', 'Logos', 'Magazine Cover Photos', 'Demographic Stereotypes', 'Dailydall.e', 'CSP', 'Relational Understanding', 'CUB', 'PartiPrompts', 'Winoground', 'PaintSkills']",[],[],16.0,1.0,1.0,6.0,4.0,2.0,4.0,84.0,2184.0,0.0,1
HellaSwag,,{},[],['PapersWithCode'],[],[],[],['ACL'],[],[],[],['English'],['Text'],['HellaSwag'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,40.0,0.0,1
HellaSwag Leaderboard,,{'independent website': ['Table']},"['Contact', 'Issue']",['independent website'],[],['independent website'],"['University of Washington', 'Allen Institute for AI']",['ACL'],[],['Prediction Results'],['Email'],['English'],['Text'],"['ActivityNet Captions', 'HellaSwag', 'WikiHow']",[],[],3.0,1.0,1.0,2.0,1.0,1.0,0.0,1.0,22.0,0.0,1
HELM Classic,?,{'independent website': ['Rankable Table']},"['Contact', 'Issue']",['independent website'],['independent website'],[],['Stanford University'],['Preprint'],"['Prompt Design', 'Task', 'Benchmark', 'Aggregated Result', 'Evaluation Dataset', 'Evaluation Metric', 'Supported Language', 'Supported Functionality', 'Supported Modality', 'Tokenizer']",[],[],"['English', 'Chinese']","['Text', 'Code']","['BoolQ', 'MSMARCO', 'BBQ', 'LegalSupport', 'Synthetic efficiency', 'GSM8K', 'Disinformation', 'bAbI', 'MultiLexSum', 'EntityMatching', 'CNN DM', 'Dyck Languages', 'WMT', 'LegalBench', 'The Pile', 'MedQA', 'OpenbookQA', 'NarrativeQA', 'APPS', 'IMDB', 'HellaSwag', 'LSAT', 'RAFT', 'Civil Comments', 'Billsum', 'XSUM', 'BLiMP', 'ICE', 'QuAC', 'Copyright', 'BOLD', 'WikiFact', 'NQ', 'HumanEval', 'DataImputation', 'EurLexSum', 'TruthfulQA', 'TwitterAAE', 'MMLU', 'RealToxicityPrompts', 'MATH', 'Synthetic Reasoning', 'Numerical reasoning']",[],[],43.0,1.0,1.0,1.0,2.0,2.0,10.0,301.0,16005.0,0.0,1
HELM Lite,,{'independent website': ['Rankable Table']},"['Contact', 'Issue']",['independent website'],[],[],['Stanford University'],[],"['Benchmark', 'Task', 'Supported Functionality']",[],[],"['English', 'Czech', 'German', 'French', 'Hindi', 'Russian']",['Text'],"['NQ', 'GSM8K', 'LegalBench', 'WMT', 'MedQA', 'MMLU', 'MATH', 'NarrativeQA', 'OpenbookQA']",[],[],9.0,1.0,1.0,1.0,6.0,1.0,3.0,34.0,1020.0,0.0,1
HHEM Leaderboard,,"{'GitHub': ['Table'], 'HuggingFace': ['Rankable Table']}",[],"['GitHub', 'HuggingFace']",[],[],['Vectara'],[],[],['Model Repository'],['Submission Portal'],['English'],['Text'],['CNN DM'],[],[],1.0,2.0,2.0,1.0,1.0,1.0,0.0,1.0,19.0,0.0,1
HMDB51,,{},[],['PapersWithCode'],[],[],[],['ICCV'],[],[],[],['English'],"['Text', 'Video']",['HMDB51'],[],"['accuracy', 'top-1 accuracy', 'top-5 accuracy', 'average accuracy of 3 splits']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,103.0,0.0,1
HumanEval,,{},[],['PapersWithCode'],[],[],[],['Preprint'],[],[],[],['English'],"['Text', 'Code']",['HumanEval'],[],"['pass@10', 'pass@1', 'pass@100']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,55.0,0.0,1
HumanEval,,{'GitHub': ['Table']},[],['GitHub'],[],['GitHub'],"['OpenAI', 'Anthropic', 'Zipline']",['Preprint'],[],[],[],['English'],"['Text', 'Code']",['HumanEval'],[],[],1.0,1.0,1.0,3.0,1.0,2.0,0.0,1.0,13.0,0.0,1
ImageNet,,{},[],['PapersWithCode'],[],[],[],['CVPR'],[],[],[],['English'],"['Text', 'Image']",['ImageNet'],[],"['#parameters', 'top-1 accuracy', 'accuracy', 'energy consumption', 'top-5 accuracy', 'operations per network pass', 'gflops', 'hardware burden']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,1185.0,0.0,1
iNaturalist,,{},[],['PapersWithCode'],[],[],[],['CVPR'],[],[],[],['English'],"['Text', 'Image']",['iNaturalist'],[],['top-1 accuracy'],1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,55.0,0.0,1
InfiCoder-Eval,,{'GitHub': ['Rankable Table']},[],['GitHub'],[],['GitHub'],"['ByteDance', 'Peking University']",['Preprint'],[],[],[],['English'],"['Text', 'Code']",['InfiCoder-Eval'],[],[],1.0,1.0,1.0,2.0,1.0,2.0,0.0,1.0,33.0,0.0,1
InfiMM-Eval,,{'GitHub': ['Rankable Table']},[],"['GitHub', 'PapersWithCode']",[],['GitHub'],"['ByteDance', 'Chinese Academy of Sciences', 'University of Texas Austin']",['Preprint'],[],['Prediction Results'],['Email'],['English'],"['Text', 'Image']",['InfiMM-Eval'],[],[],1.0,1.0,2.0,4.0,1.0,2.0,1.0,1.0,17.0,0.0,1
InfographicVQA,,{},[],['PapersWithCode'],[],[],[],['WACV'],[],[],[],['English'],"['Text', 'Image']",['InfographicVQA'],[],['anls'],1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,19.0,0.0,1
InfographicVQA,,"{'independent website': ['Rankable Table', 'Bar Chart']}",['Contact'],['independent website'],[],['independent website'],['Computer Vision Center '],['WACV'],[],['Prediction Results'],['Submission Portal'],['English'],"['Text', 'Image']",['InfographicVQA'],[],[],1.0,2.0,1.0,1.0,1.0,2.0,0.0,1.0,19.0,0.0,1
InstructEval,,"{'GitHub': ['Rankable Table', 'Table']}",[],['GitHub'],[],['GitHub'],"['Singapore University of Technology and Design', 'Alibaba Group DAMO Academy']",['Preprint'],"['Task', 'Supported Functionality']",[],[],['English'],['Text'],"['BBH', 'DROP', 'HumanEval', 'HHH', 'IMPACT', 'CRASS', 'MMLU']",[],[],7.0,2.0,1.0,2.0,1.0,1.0,2.0,0.0,0.0,0.0,1
InterCode,2,{'GitHub': ['Table']},[],['GitHub'],[],[],['Princeton University'],['Preprint'],['Benchmark'],[],[],['English'],"['Text', 'Code']","['MBPP', 'InterCode-CTF', 'SWE-bench', 'NL2Bash', 'Spider']",[],[],5.0,1.0,1.0,1.0,1.0,2.0,1.0,3.0,35.0,0.0,1
iVQA,,{},[],['PapersWithCode'],[],[],[],['ICCV'],[],[],[],['English'],"['Text', 'Video']",['iVQA'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,4.0,0.0,1
JFT-300M,,{},[],['PapersWithCode'],[],[],[],['ICCV'],[],[],[],['English'],"['Text', 'Image']",['JFT-300M'],[],['prec@1'],1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,4.0,0.0,1
JustEval,,{'GitHub': ['Rankable Table']},[],['GitHub'],[],[],"['Allen Institute for AI', 'University of Washington']",['Preprint'],"['Evaluation Dataset', 'Supported Functionality', 'Task']",[],[],['English'],['Text'],['JustEval'],[],[],1.0,1.0,1.0,2.0,1.0,1.0,3.0,3.0,48.0,0.0,1
KAgentBench,,{'GitHub': ['Table']},[],['GitHub'],[],[],"['Kuaishou', 'Harbin Institute of Technology']",['Preprint'],['Evaluator'],[],[],['English'],['Text'],['KAgentBench'],[],[],1.0,1.0,1.0,2.0,1.0,1.0,1.0,2.0,15.0,0.0,1
Kinetics,,{},[],['PapersWithCode'],[],[],[],['Preprint'],[],[],[],['English'],"['Text', 'Video']",['Kinetics'],[],"['#parameters', 'top-1 accuracy', 'flops', 'test map', 'top-5 accuracy', 'gflops', 'acc@1', 'val map', 'acc@5', 'fvd']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,320.0,0.0,1
KoLA,,{'independent website': ['Table']},"['Contact', 'Issue']",['independent website'],[],[],['Tsinghua University'],['Preprint'],['Leaderboard Launch Date'],"['Inference API+Model Configuration', 'Model Repository+Model Configuration']",['Submission Portal'],['English'],['Text'],"['2WikiMQA', 'Encyclopedic', 'MAVEN-ERE', 'HotpotQA', 'COPEN', 'ETM', 'MAVEN', 'ETU', 'High-Frequency Knowledge', 'KQA Pro', 'DocRED', 'ETC', 'Low-Frequency Knowledge', 'KoRC', 'ETA', 'FewNERD', 'MuSiQue']",[],[],17.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,10.0,0.0,1
KQA Pro,,{},[],['PapersWithCode'],[],[],[],['ACL'],[],[],[],['English'],['Text'],['KQA Pro'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,1.0,0.0,1
L-Eval,,"{'GitHub': ['Rankable Table', 'Bar Chart']}",[],['GitHub'],[],[],"['Fudan University', 'University of Hong Kong', 'University of Illinois Urbana Champaign', 'Shanghai AI Laboratory']",['Preprint'],"['Aggregated Result', 'Evaluator', 'Evaluation Metric']",['Prediction Results+Evaluation Results'],['Email'],['English'],['Text'],"['SFiction', 'Qasper', 'GSM8K', 'SummScreen', 'BigPatent', 'Multi-News', 'QuALITY', 'OPENREVIEW', 'MultiDoc2Dial', 'CUAD', 'NarrativeQA', 'SPACE', 'Coursera', 'QMSum', 'LONGFQA', 'NQ', 'TOEFL-QA', 'TopicRet', 'CodeU', 'GovReport']",[],[],20.0,2.0,1.0,4.0,1.0,1.0,3.0,6.0,68.0,0.0,1
LAiW Leaderboard,,"{'HuggingFace': ['Rankable Table', 'Radar Chart']}",[],"['GitHub', 'HuggingFace']",['HuggingFace'],[],"['Sichuan University', 'ChanceFocus', 'Wuhan University', 'Southwest Petroleum University']",['Preprint'],"['Task', 'Aggregated Result']",[],[],['Chinese'],['Text'],"['CAIL', 'CrimeKgAssitant', 'CJRC', 'Criminal-S', 'JEC-QA', 'CFM', 'MSJudge', 'MLMN', 'AC-NLG']",[],[],9.0,2.0,2.0,4.0,1.0,1.0,2.0,3.0,54.0,0.0,1
LAMBADA,,{},[],['PapersWithCode'],[],[],[],['ACL'],[],[],[],['English'],['Text'],['LAMBADA'],[],"['accuracy', 'perplexity']",1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,34.0,0.0,1
LawBench,,"{'independent website': ['Rankable Table', 'Bar Chart'], 'GitHub': ['Table']}","['Contact', 'Issue']","['GitHub', 'independent website']",[],[],"['Nanjing University', 'Amazon Alexa AI Lab', 'Saarland University', 'Shanghai AI Laboratory']",['Preprint'],['#Prompt Example'],[],[],['English'],['Text'],['LawBench'],[],[],1.0,3.0,2.0,4.0,1.0,1.0,1.0,2.0,102.0,0.0,1
LibriSpeech,,{},[],['PapersWithCode'],[],[],[],['ICASSP'],[],[],[],['English'],"['Text', 'Audio']",['LibriSpeech'],[],['word error rate'],1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,100.0,0.0,1
LLaVA-Bench,,{},[],['PapersWithCode'],[],[],[],['NeurIPS'],[],[],[],['English'],"['Text', 'Image']",['LLaVA-Bench'],[],['avg score'],1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,7.0,0.0,1
LLM API Hosts Leaderboard,,{'independent website': ['Rankable Table']},['Email'],['independent website'],[],['independent website'],['Artificial Analysis'],[],"['Service Load', 'Prompt Length', 'Evaluation Metric']",[],[],['English'],['Text'],['LLM API Hosts Leaderboard'],[],[],1.0,1.0,1.0,1.0,1.0,1.0,3.0,4.0,248.0,0.0,1
LLM Benchmarker Suite,,"{'GitHub': ['Table'], 'independent website': ['Rankable Table']}",[],"['GitHub', 'independent website']",[],[],['TheoremOne'],[],[],[],[],['English'],"['Text', 'Code']","['BoolQ', 'HellaSwag', 'HumanEval', 'NQ', 'WinoGrande', 'GSM8K', 'OpenbookQA', 'MMLU', 'TriviaQA', 'AGIEval', 'QuAC']",[],[],11.0,2.0,2.0,1.0,1.0,2.0,0.0,1.0,8.0,0.0,1
LLM Safety Leaderboard,,{'HuggingFace': ['Rankable Table']},[],['HuggingFace'],[],['HuggingFace'],"['University of Illinois Urbana Champaign', 'Stanford University', 'University of California Berkeley', 'Center for AI Safety', 'Microsoft', 'Chinese University of Hong Kong']",['NeurIPS'],[],['Model Repository'],['Submission Portal'],['English'],['Text'],['DecodingTrust'],[],[],1.0,1.0,1.0,6.0,1.0,1.0,0.0,1.0,29.0,0.0,1
LLM-Leaderboard,,"{'GitHub': ['Table'], 'independent website': ['Rankable Table'], 'HuggingFace': ['Rankable Table']}",[],"['GitHub', 'HuggingFace', 'independent website']","['HuggingFace', 'independent website']","['GitHub', 'HuggingFace', 'independent website']",['Independent Contributor'],[],[],['Evaluation Results'],['Pull Request'],['English'],"['Text', 'Code']","['Chatbot Arena Conversations', 'HellaSwag', 'HumanEval', 'WinoGrande', 'MMLU', 'TriviaQA', 'LAMBADA']",[],[],7.0,2.0,3.0,1.0,1.0,2.0,0.0,1.0,52.0,0.0,1
LLM-Perf Leaderboard,,"{'HuggingFace': ['Rankable Table', 'Scatter Plot']}",[],['HuggingFace'],[],['HuggingFace'],['Hugging Face'],[],[],[],[],['English'],['Text'],['LLM-Perf Leaderboard'],[],[],1.0,2.0,1.0,1.0,1.0,1.0,0.0,2.0,1819.0,0.0,1
LLMEval,,"{'independent website': ['Table'], 'GitHub': ['Table', 'Bar Chart']}",[],"['GitHub', 'independent website']",[],[],"['Fudan University', 'Shanghai Jiaotong University']",['AAAI'],"['Aggregated Result', 'Leaderboard Version']",['Prediction Results'],['Submission Portal'],['Chinese'],['Text'],['LLMEval'],[],[],1.0,2.0,2.0,2.0,1.0,1.0,2.0,2.0,46.0,0.0,1
LLMonitor,,{'independent website': ['Table']},"['Contact', 'Issue']",['independent website'],[],[],['Lunary'],[],[],[],[],['English'],['Text'],['LLMonitor'],[],[],1.0,1.0,1.0,1.0,1.0,1.0,0.0,1.0,54.0,0.0,1
LLMPerf,,"{'GitHub': ['Table', 'Bar Chart']}",[],['GitHub'],[],[],['Anyscale'],[],"['Evaluation Metric', 'Model Size']",['Inference API'],"['Email', 'Issue']",['English'],['Text'],['LLMPerf'],[],[],1.0,2.0,1.0,1.0,1.0,1.0,2.0,6.0,38.0,0.0,1
LMExamQA,,{'independent website': ['Bar Chart']},['Contact'],['independent website'],['independent website'],[],"['Tsinghua University', 'Singapore Management University', 'University of California Los Angeles', 'Beijing University of Posts and Telecommunications']",['Preprint'],"['Aggregated Result', 'Task', 'Evaluation Dataset']",[],[],['English'],['Text'],['LMExamQA'],[],[],1.0,1.0,1.0,4.0,1.0,1.0,3.0,887.0,7096.0,0.0,1
LogiQA,,{},[],['PapersWithCode'],[],[],[],['IJCAI'],[],[],[],['English'],['Text'],['LogiQA'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,2.0,0.0,1
LongBench,,{'GitHub': ['Table']},[],['GitHub'],[],[],"['Tsinghua University', 'Chinese Academy of Sciences']",['Preprint'],"['Supported Language', 'Task']",[],[],"['English', 'Chinese']","['Text', 'Code']","['Qasper', 'VCSUM', 'MuSiQue', 'SAMSum', 'Multi-News', 'MultiFieldQA', 'PassageRetrieval', 'NarrativeQA', '2WikiMQA', 'HotpotQA', 'LSHTC', 'PassageCount', 'LCC', 'QMSum', 'DuReader', 'RepoBench-P', 'GovReport', 'TriviaQA', 'TREC']",[],[],19.0,1.0,1.0,2.0,2.0,2.0,2.0,8.0,64.0,0.0,1
LVLM-eHub,,"{'independent website': ['Rankable Table', 'Table']}",['Contact'],['independent website'],[],['independent website'],"['Shanghai AI Laboratory', 'University of Hong Kong', 'Peking University']",['Preprint'],"['Aggregated Result', 'Supported Functionality', 'Evaluation Metric']","['Evaluation Results', 'Inference API+Model Configuration']",['Email'],['English'],"['Text', 'Image']","['SVTP', 'Whoops', 'VizWiz', 'SNLI-VE', 'FUNSD', 'IIIT5K', 'Minecraft', 'IconQA', 'VSR', 'HOST', 'SROIE', 'Virtual Home', 'NoCaps', 'Flowers102', 'OK-VQA', 'Franka Kitchen', 'ImageNet-1K', 'COCO-Text', 'OCR-VQA', 'MSCOCO', 'VCR-OC', 'CUTE80', 'SVT', 'WOST', 'ScienceQA IMG', 'CIFAR-10', 'DocVQA', 'Meta-World', 'STVQA', 'Flickr30K', 'VCR', 'CTW', 'Total-Text', 'VisDial', 'IC', 'ImageNetVC', 'Pets37', 'GQA', 'TextVQA', 'VCR-MCI', 'WordArt']",[],[],41.0,2.0,1.0,3.0,1.0,2.0,3.0,8.0,65.0,0.0,1
M3DBench,,{'GitHub': ['Rankable Table']},[],['GitHub'],[],[],"['Fudan University', 'Tencent', 'Institute for Infocomm Research', 'A*STAR']",['Preprint'],[],[],[],['English'],"['Text', 'Model']",['M3DBench'],[],[],1.0,1.0,1.0,4.0,1.0,2.0,0.0,1.0,4.0,0.0,1
M3KE,,{'GitHub': ['Table']},[],['GitHub'],[],['GitHub'],"['Tianjin University', ""Huawei Noah's Ark Lab""]",['Preprint'],['#Prompt Example'],['?'],"['Email', 'Pull Request']",['Chinese'],['Text'],['M3KE'],[],[],1.0,1.0,1.0,2.0,1.0,1.0,1.0,2.0,26.0,0.0,1
MATH,,{},[],['PapersWithCode'],[],[],[],['NeurIPS'],[],[],[],['English'],['Text'],['MATH'],[],"['accuracy', '#parameters']",1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,59.0,0.0,1
MATH401,,{'GitHub': ['Table Screenshot']},[],['GitHub'],[],[],"['Alibaba Group', 'Tsinghua University']",['Preprint'],['Evaluation Metric'],[],[],['English'],['Text'],['MATH401'],[],[],1.0,1.0,1.0,2.0,1.0,1.0,1.0,2.0,50.0,0.0,1
MathBench,,{'GitHub': ['Table']},[],['GitHub'],[],['GitHub'],['?'],['?'],['Aggregated Result'],['?'],['Issue'],"['English', 'Chinese']",['Text'],['MathBench'],[],[],1.0,1.0,1.0,1.0,2.0,1.0,1.0,2.0,26.0,0.0,1
MathQA,,{},[],['PapersWithCode'],[],[],[],['NAACL'],[],[],[],['English'],['Text'],['MathQA'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,2.0,0.0,1
MathVista,,"{'GitHub': ['Bar Chart', 'Table', 'Rankable Table']}",[],['GitHub'],[],['GitHub'],"['University of California Los Angeles', 'University of Washington', 'Microsoft']",['ICLR'],['Evaluation Dataset'],['Prediction Results'],['Email'],['English'],['Text'],['MathVista'],[],[],1.0,3.0,1.0,3.0,1.0,1.0,1.0,2.0,28.0,0.0,1
MAWPS,,{},[],['PapersWithCode'],[],[],[],['NAACL'],[],[],[],['English'],['Text'],['MAWPS'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,14.0,0.0,1
MBPP,,{},[],['PapersWithCode'],[],[],[],['Preprint'],[],[],[],['English'],"['Text', 'Code']",['MBPP'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,6.0,0.0,1
MC-TACO,,{},[],['PapersWithCode'],[],[],[],['EMNLP'],[],[],[],['English'],['Text'],['MC-TACO'],[],['exact match'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,2.0,0.0,1
MC-TACO,,"{'independent website': ['Rankable Table', 'Scatter Plot']}",['Email'],['independent website'],['independent website'],['independent website'],['Allen Institute for AI'],['EMNLP'],[],['Prediction Results'],['Submission Portal'],['English'],['Text'],['MC-TACO'],[],[],1.0,2.0,1.0,1.0,1.0,1.0,0.0,1.0,21.0,0.0,1
MedBench,,{'independent website': ['Rankable Table']},"['Contact', 'Issue']",['independent website'],[],[],"['East China Normal University', 'Shanghai AI Laboratory', 'Hasso Plattner Institute', 'University of Potsdam', 'Shanghai Jiao Tong University']",['Preprint'],"['Task', 'Aggregated Result']",['Prediction Results'],['Submission Portal'],['Chinese'],['Text'],"['SafetyBench', 'DDx-advanced', 'MedMC', 'Med-Exam', 'CHIP-CTC', 'CHIP-CDN', 'DBMHG', 'MedDG', 'CMeIE', 'SMDoc', 'MedHC', 'CMB-Clin', 'IMCS-MRG', 'CMeEE', 'MedTreat', 'DrugCA', 'MedSpeQA', 'DDx-basic', 'CHIP-CDEE', 'MedHG']",[],[],20.0,1.0,1.0,5.0,1.0,1.0,2.0,6.0,30.0,0.0,1
MedQA,,{},[],['PapersWithCode'],[],[],[],['Applied Sciences'],[],[],[],['English'],['Text'],['MedQA'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,19.0,0.0,1
Mementos,,"{'GitHub': ['Fgure', 'Table']}",[],['GitHub'],[],['GitHub'],"['University of Maryland College Park', 'University of North Carolina Chapel Hill']",['Preprint'],['Aggregated Result'],['Prediction Results'],['Email'],['English'],"['Text', 'Image']",['Mementos'],[],[],1.0,2.0,1.0,2.0,1.0,2.0,1.0,2.0,48.0,0.0,1
MGSM,,{},[],['PapersWithCode'],[],[],[],['ICLR'],[],[],[],"['Bengali', 'Chinese', 'French', 'German', 'Japanese', 'Russian', 'Spanish', 'Swahili', 'Telugu', 'Thai.']",['Text'],['MGSM'],[],['average'],1.0,0.0,1.0,1.0,10.0,1.0,1.0,0.0,8.0,0.0,1
MINT-Bench,,"{'independent website': ['Rankable Bar Chart', 'Line Chart', 'Rankable Table']}",[],['independent website'],[],[],"['University of Illinois Urbana Champaign', 'Renmin University of China']",['Preprint'],"['Aggregated Result', 'Supported Functionality']",['Prediction Results'],['Pull Request'],['English'],['Text'],['MINT-Bench'],[],[],1.0,3.0,1.0,2.0,1.0,1.0,2.0,6.0,119.0,0.0,1
MiT,,{},[],['PapersWithCode'],[],[],[],['PAMI'],[],[],[],['English'],"['Text', 'Video']",['MiT'],[],"['top-1 accuracy', 'top-5 accuracy']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,30.0,0.0,1
MLLM-Bench,,"{'GitHub': ['Table'], 'independent website': ['Table']}",[],"['GitHub', 'independent website']",[],[],"['Shenzhen Research Institute of Big Data', 'Chinese University of Hong Kong']",['Preprint'],[],[],[],['English'],"['Text', 'Image']",['MLLM-Bench'],[],[],1.0,1.0,2.0,2.0,1.0,2.0,0.0,1.0,12.0,0.0,1
MLS,,{},[],['PapersWithCode'],[],[],[],['Interspeech'],[],[],[],"['English', 'German', 'Dutch', 'Spanish', 'French', 'Italian', 'Portuguese', 'Polish']","['Text', 'Audio']",['MLS'],[],['word error rate'],1.0,0.0,1.0,1.0,8.0,2.0,1.0,0.0,6.0,0.0,1
MM-Vet,,{},[],['PapersWithCode'],[],[],[],['Preprint'],[],[],[],['English'],"['Text', 'Image']",['MM-Vet'],[],"['#parameters', 'gpt-4 score']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,36.0,0.0,1
MMBench,,"{'HuggingFace': ['Rankable Table'], 'independent website': ['Rankable Table']}",[],"['HuggingFace', 'independent website']",[],"['HuggingFace', 'independent website']","['Shanghai AI Laboratory', 'Nanyang Technological University', 'Chinese University of Hong Kong', 'National University of Singapore', 'Zhejiang University']",['Preprint'],"['Evaluation Dataset', 'Supported Language', 'Model Accessibility']",['Prediction Results'],['Submission Portal'],"['English', 'Chinese']","['Text', 'Image']","['PISC', 'CLEVR', 'KonIQ-10k', 'VSR', 'W3C School', 'LLaVA-Bench', 'COCO Captions', 'ScienceQA', 'Internet', 'ARAS', 'TextVQA', 'Places']",[],[],12.0,1.0,2.0,5.0,2.0,2.0,3.0,8.0,234.0,0.0,1
MMCU,,{'GitHub': ['Table']},[],['GitHub'],[],[],['Besteasy'],['Preprint'],"['Task', 'Aggregated Result']",[],[],['Chinese'],['Text'],['MMCU'],[],[],1.0,1.0,1.0,1.0,1.0,1.0,2.0,3.0,21.0,0.0,1
MME,,{'GitHub': ['Table']},[],['GitHub'],[],['GitHub'],"['Tencent Youtu Lab', 'Xiamen University']",['Preprint'],"['Task', 'Supported Functionality', 'Model Type']",['?'],['Email'],['English'],"['Text', 'Image']",['MME'],[],[],1.0,1.0,1.0,2.0,1.0,2.0,3.0,32.0,816.0,0.0,1
MMLU,,{},[],['PapersWithCode'],[],[],[],['ICLR'],[],[],[],['English'],['Text'],['MMLU'],[],"['accuracy', 'proprietary', 'average']",1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,105.0,0.0,1
MMLU,,{'GitHub': ['Table']},[],['GitHub'],[],['GitHub'],"['University of California Berkeley', 'Columbia University', 'University of Chicago', 'University of Illinois Urbana Champaign']",['ICLR'],[],['?'],"['Email', 'Pull Request']",['English'],['Text'],['MMLU'],[],[],1.0,1.0,1.0,4.0,1.0,1.0,0.0,1.0,12.0,0.0,1
MMLU-by-task Leaderboard,,"{'HuggingFace': ['Rankable Table', 'Scatter Plot']}",[],['HuggingFace'],['HuggingFace'],['HuggingFace'],"['Hugging Face', 'Independent Contributor']",[],[],[],[],['English'],['Text'],"['HellaSwag', 'ARC', 'MMLU']",[],[],3.0,2.0,1.0,2.0,1.0,1.0,0.0,1.0,1121.0,0.0,1
MMMU,,"{'GitHub': ['Rankable Table', 'Table', 'Bar Chart']}",[],['GitHub'],[],['GitHub'],"['in.ai', 'University of Waterloo', 'Ohio State University', 'Carnegie Mellon University', 'University of Victoria', 'Princeton University', 'Independent Contributor']",['Preprint'],"['Task', 'Evaluation Dataset', 'Supported Functionality', 'Aggregated Result']",['Prediction Results'],['Submission Portal'],['English'],"['Text', 'Image']",['MMMU'],[],[],1.0,3.0,1.0,7.0,1.0,2.0,4.0,37.0,292.0,0.0,1
MMVP,,{'GitHub': ['Bar Chart']},[],['GitHub'],[],[],"['New York University', 'University of California Berkeley']",['ICCV'],[],[],[],['English'],"['Text', 'Image']",['MMVP'],[],[],1.0,1.0,1.0,2.0,1.0,2.0,0.0,1.0,10.0,0.0,1
MMVP-VLM,,{'GitHub': ['Table Screenshot']},[],['GitHub'],[],[],"['New York University', 'University of California Berkeley']",['ICCV'],[],[],[],['English'],"['Text', 'Image']",['MMVP-VLM'],[],[],1.0,1.0,1.0,2.0,1.0,2.0,0.0,1.0,10.0,0.0,1
MNLI,,{},[],['PapersWithCode'],[],[],[],['NAACL'],[],[],[],['English'],['Text'],['MNLI'],[],"['matched', 'mismatched', 'accuracy', 'dev mismatched', 'dev matched']",1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,49.0,0.0,1
MOCHA,,"{'independent website': ['Rankable Table', 'Scatter Plot']}",['Email'],['independent website'],['independent website'],['independent website'],['Allen Institute for AI'],['EMNLP'],[],['Prediction Results'],['Submission Portal'],['English'],['Text'],"['SIQA', 'DROP', 'CosmosQA', 'Quoref', 'NarrativeQA', 'MCScript']",[],[],6.0,2.0,1.0,1.0,1.0,1.0,0.0,1.0,4.0,0.0,1
Models Leaderboard,,"{'independent website': ['Rankable Table', 'Scatter Plot', 'Box Plot', 'Bar Chart', 'Line Chart']}",['Email'],['independent website'],[],['independent website'],['Artificial Analysis'],[],"['Service Load', 'Prompt Length', 'Benchmark', 'Evaluation Metric']",[],[],['English'],['Text'],['Models Leaderboard'],[],[],1.0,5.0,1.0,1.0,1.0,1.0,4.0,4.0,84.0,0.0,1
MP-DocVQA,,"{'independent website': ['Rankable Table', 'Bar Chart']}",[],['independent website'],[],['independent website'],['Universitat Autnoma de Barcelona'],['Pattern Recognition'],[],['Prediction Results'],['Submission Portal'],['English'],"['Text', 'Image']",['MP-DocVQA'],[],[],1.0,2.0,1.0,1.0,1.0,2.0,0.0,1.0,9.0,0.0,1
MRPC,,{},[],['PapersWithCode'],[],[],[],['IJCNLP'],[],[],[],['English'],['Text'],['MRPC'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,2.0,0.0,1
MSCOCO,,{},[],['PapersWithCode'],[],[],[],['ECCV'],[],[],[],['English'],"['Text', 'Image']",['MSCOCO'],[],"['bleu-1', 'recall@10', 'fid-8', 'cider', 'rouge', 'recall@1', 'rouge-l', 'soa-c', 'inception score', 'qps', 'fid', 'fid-2', 'bleu-3', 'recall@5', 'meteor', 'bleu-4', 'fid-4', 'fid-1', 'bleu-2']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,117.0,0.0,1
MSRVTT,,{},[],['PapersWithCode'],[],[],[],['CVPR'],[],[],[],['English'],"['Text', 'Video']",['MSRVTT'],[],"['fid', 'recall@10', 'mean rank', 'clipsim', 'recall@5', 'median rank', 'meteor', 'cider', 'bleu-4', 'recall@1', 'rouge-l', 'fvd']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,149.0,0.0,1
MSRVTT-QA,,{},[],['PapersWithCode'],[],[],[],['ACM-MM'],[],[],[],['English'],"['Text', 'Video']",['MSRVTT-QA'],[],"['accuracy', 'confidence score']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,47.0,0.0,1
MSVD,,{},[],['PapersWithCode'],[],[],[],['ACL'],[],[],[],['English'],"['Text', 'Video']",['MSVD'],[],"['recall@10', 'mean rank', 'recall@5', 'median rank', 'recall@50', 'meteor', 'cider', 'bleu-4', 'recall@1', 'rouge-l']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,37.0,0.0,1
MSVD-QA,,{},[],['PapersWithCode'],[],[],[],['ACM-MM'],[],[],[],['English'],"['Text', 'Video']",['MSVD-QA'],[],"['accuracy', 'confidence score']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,46.0,0.0,1
MTEB,,"{'HuggingFace': ['Rankable Table'], 'GitHub': ['Table'], 'independent website': ['Rankable Table']}",[],"['GitHub', 'HuggingFace', 'PapersWithCode', 'independent website']",['independent website'],"['GitHub', 'HuggingFace', 'independent website']","['Hugging Face', 'Cohere']",['EACL'],"['Supported Language', 'Task']",['Evaluation Results'],['Metadata Upload'],"['Afrikaans', 'Albanian', 'Amharic', 'Arabic', 'Armenian', 'Assamese', 'Azerbaijani', 'Bangla', 'Basque', 'Belarusian', 'Bosnian', 'Breton', 'Bulgarian', 'Burmese', 'Catalan', 'Cebuano', 'Chichewa', 'Chinese (Simplified)', 'Chinese (Traditional)', 'Corsican', 'Croatian', 'Czech', 'Danish', 'Dhivehi', 'Dutch', 'English', 'Esperanto', 'Estonian', 'Ewe', 'Filipino', 'Finnish', 'French', 'Frisian', 'Galician', 'Georgian', 'German', 'Greek', 'Guarani', 'Gujarati', 'Haitian Creole', 'Hausa', 'Hawaiian', 'Hebrew', 'Hindi', 'Hmong', 'Hungarian', 'Icelandic', 'Igbo', 'Indonesian', 'Irish', 'Italian', 'Japanese', 'Javanese', 'Kannada', 'Kazakh', 'Khmer', 'Kinyarwanda', 'Korean', 'Kurdish (Kurmanji)', 'Kyrgyz', 'Lao', 'Latin', 'Latvian', 'Lithuanian', 'Luxembourgish', 'Macedonian', 'Malagasy', 'Malay', 'Malayalam', 'Maltese', 'Maori', 'Marathi', 'Mongolian', 'Nepali', 'Norwegian', 'Odia (Oriya)', 'Pashto', 'Persian', 'Polish', 'Portuguese', 'Punjabi', 'Quechua', 'Romanian', 'Russian', 'Samoan', 'Sanskrit', 'Scots Gaelic', 'Serbian', 'Sesotho', 'Shona', 'Sindhi', 'Sinhala', 'Slovak', 'Slovenian', 'Somali', 'Spanish', 'Sundanese', 'Swahili', 'Swedish', 'Tajik', 'Tamil', 'Tatar', 'Telugu', 'Thai', 'Tigrinya', 'Tsonga', 'Turkish', 'Turkmen', 'Ukrainian', 'Urdu', 'Uyghur', 'Uzbek']",['Text'],"['PPC', 'Angry Tweets', 'FEVER', 'MSMARCO', 'DanishPoliticalComments', 'PolEmo', 'SciDocs', 'TREC-COVID', 'STS', '20 Newsgroups', '10kGNAD', 'SweFAQ', 'PAC', 'LinkSO', 'SummEval', 'DKhate', 'CBD', 'LanguageNet', 'PSC', 'QQP', 'Blurbs', 'Reddit', 'SICK', 'Polish CDSCorpus', 'Allegro Reviews', 'Bornholmsk', 'MASSIVE', 'Nordic Language Identification', 'CARER', 'FiQA', 'SciFact', 'Tweet Sentiment Extraction', 'ScaLA', 'B77', 'BUCC', 'TwitterSemEval', 'MARC', 'IMDB', 'Climate-FEVER', 'medRxiv', 'DaLAJ', 'DBpedia', 'HotpotQA', 'NFCorpus', 'Touche', 'Civil Comments', 'NoReC', 'Tatoeba', 'MIND', 'MTOP', 'LCC', 'arXiv', 'SprintDuplicateQuestions', 'AMCD', 'Amazon Polarity', 'ArguAna', 'NQ', 'BIOSSES', 'CQADupStack', 'SweRec', 'NPSC', 'STS-B', 'bioRxiv', '8TAGS', 'AskUbuntu', 'Stack Exchange', 'ATEC', 'OnlineShopping', 'Waimai', 'T2Ranking', 'cCOVID-News', 'mMARCO', 'CMNLI', 'OCNLI', 'THUCNews', 'TNEWS', 'AFQMC', 'PAWS-X', 'QBQTC', 'JDReview', 'LCQMC', 'DuReader', 'STS-B', 'cMedQA', 'Multi-CPR', 'iFLYTEK', 'CSL', 'BQ']",[],[],88.0,2.0,4.0,3.0,112.0,1.0,2.0,28.0,1786.0,0.0,1
Multi-modal Model Leaderboard,,"{'independent website': ['Rankable Table'], 'HuggingFace': ['Rankable Table']}",[],"['HuggingFace', 'independent website']",[],"['HuggingFace', 'independent website']","['Aliyun', 'East Money', 'Duxiaoman', 'Fudan University', 'Nanjing University', 'Nanyang Technological University', 'OPPO', 'Shanghai AI Laboratory', 'Tencent', 'TigerResearch', 'Chinese University of Hong Kong', 'Zhejiang University', 'Zhipu AI']",[],[],"['Inference API+Model Configuration', 'Model Repository+Model Configuration']",['Submission Portal'],"['English', 'Chinese']","['Text', 'Image']","['CCBench', 'MathVista', 'LLaVA-Bench', 'MME', 'SEED-Bench', 'MMMU', 'AI2D', 'MM-Vet', 'HallusionBench', 'MMBench']",[],[],10.0,1.0,2.0,13.0,2.0,2.0,0.0,1.0,38.0,0.0,1
MultiRC,,{},[],['PapersWithCode'],[],[],[],['NAACL'],[],[],[],['English'],['Text'],['MultiRC'],[],"['accuracy', 'f1', 'exact match']",1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,21.0,0.0,1
MusicCaps,,{},[],['PapersWithCode'],[],[],[],['Preprint'],[],[],[],['English'],"['Text', 'Audio']",['MusicCaps'],[],['fad vgg'],1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,12.0,0.0,1
MusicCaps,,{},[],['PapersWithCode'],[],[],[],['Preprint'],[],[],[],['English'],"['Text', 'Audio']",['MusicCaps'],[],['fad vgg'],1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,12.0,0.0,1
MusicQA,,{},[],['PapersWithCode'],[],[],[],['Preprint'],[],[],[],['English'],"['Text', 'Audio']",['MusicQA'],[],"['bertscore', 'rouge', 'bleu', 'meteor']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,3.0,0.0,1
MVBench,,"{'HuggingFace': ['Rankable Table'], 'GitHub': ['Table Screenshot']}",[],"['GitHub', 'HuggingFace']",['HuggingFace'],[],"['Chinese Academy of Sciences', 'University of Chinese Academy of Sciences', 'Shanghai AI Laboratory', 'University of Hong Kong', 'Fudan University', 'Nanjing University']",['Preprint'],"['Task', 'Aggregated Result']",['Evaluation Results'],['Submission Portal'],['English'],"['Text', 'Video']","['CLEVRER', 'FunQA', 'TVQA', 'Perception Test', 'NTU RGB+D', 'MiT', 'STAR', 'Charades-STA', 'MovieNet', 'PAXION', 'VLN-CE']",[],[],11.0,2.0,2.0,6.0,1.0,2.0,2.0,1.0,20.0,0.0,1
Natural Instructions (v2),,"{'independent website': ['Rankable Table', 'Scatter Plot']}",['Email'],['independent website'],['independent website'],['independent website'],['Allen Institute for AI'],['ACL'],[],['Prediction Results'],['Submission Portal'],['English'],['Text'],['Natural Instructions'],[],[],1.0,2.0,1.0,1.0,1.0,1.0,0.0,1.0,11.0,0.0,1
NExT-QA,,{},[],['PapersWithCode'],[],[],[],['CVPR'],[],[],[],['English'],"['Text', 'Video']",['NExT-QA'],[],"['accuracy', 'wups']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,30.0,0.0,1
NLVR,,{},[],['PapersWithCode'],[],[],[],['ACL'],[],[],[],['English'],"['Text', 'Image']",['NLVR'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,27.0,0.0,1
NoCaps,,{},[],['PapersWithCode'],[],[],[],['ICCV'],[],[],[],['English'],"['Text', 'Image']",['NoCaps'],[],"['b4', 'b2', 'b1', 'b3', 'meteor', 'spice', 'cider', 'rouge-l']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,26.0,0.0,1
NQ,,{},[],['PapersWithCode'],[],[],[],['TACL'],[],[],[],['English'],['Text'],['NQ'],[],"['precision@100', 'precision@20', 'exact match']",1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,47.0,0.0,1
OCRBench,,{'HuggingFace': ['Rankable Table']},[],['HuggingFace'],['HuggingFace'],['HuggingFace'],"['Huazhong University of Science and Technology', 'Microsoft', 'University of Science and Technology Beijing', 'Chinese Academy of Sciences', 'South China University of Technology']",['Preprint'],[],['Evaluation Results'],['Email'],['English'],"['Text', 'Image']","['SVTP', 'Semantic Text', 'FUNSD', 'ReCTS', 'IIIT5K', 'ChartQA', 'POIE', 'HOST', 'ORAND-CAR-2014', 'SROIE', 'CT80', 'InfographicVQA', 'ESTVQA', 'IC15', 'COCO-Text', 'OCR-VQA', 'SVT', 'WOST', 'SCUT-CTW1500', 'DocVQA', 'STVQA', 'IAM', 'Total-Text', 'IC13', 'Non-Semantic Text', 'HME100K', 'TextVQA', 'WordArt']",[],[],28.0,1.0,1.0,5.0,1.0,2.0,0.0,1.0,12.0,0.0,1
ODEX,,{'GitHub': ['Table Screenshot']},[],['GitHub'],[],[],"['Carnegie Mellon University', 'Inspired Cognition']",['Preprint'],[],[],[],"['English', ' Spanish', 'Japanese', 'Russian']","['Text', 'Code']",['ODEX'],[],[],1.0,1.0,1.0,2.0,4.0,2.0,0.0,1.0,24.0,0.0,1
OK-VQA,,{},[],['PapersWithCode'],[],[],[],['CVPR'],[],[],[],['English'],"['Text', 'Image']",['OK-VQA'],[],"['accuracy', 'recall@5', 'exact match']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,33.0,0.0,1
OmniBenchmark,,{},[],['PapersWithCode'],[],[],[],['ECCV'],[],[],[],['English'],"['Text', 'Image']",['OmniBenchmark'],[],['average top-1 accuracy'],1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,23.0,0.0,1
Open Ko-LLM Leaderboard,,{'HuggingFace': ['Rankable Table']},[],['HuggingFace'],[],['HuggingFace'],['Upstage'],[],[],['Model Repository'],['Submission Portal'],['Korean'],['Text'],"['HellaSwag', 'ARC', 'CommonGen', 'TruthfulQA', 'MMLU']",[],[],5.0,1.0,1.0,1.0,1.0,1.0,0.0,1.0,986.0,0.0,1
Open LLM Leaderboard,,{'HuggingFace': ['Rankable Table']},[],['HuggingFace'],[],['HuggingFace'],['Hugging Face'],[],[],['Model Repository'],['Submission Portal'],['English'],['Text'],"['HellaSwag', 'ARC', 'WinoGrande', 'GSM8K', 'TruthfulQA', 'MMLU']",[],[],6.0,1.0,1.0,1.0,1.0,1.0,0.0,1.0,4339.0,0.0,1
Open Multilingual LLM Evaluation Leaderboard,,{'HuggingFace': ['Rankable Table']},[],['HuggingFace'],[],['HuggingFace'],['University of Oregon'],[],[],['Prediction Results'],['Pull Request'],"['Russian', 'German', 'Chinese', 'French', 'Spanish', 'Italian', 'Dutch', 'Vietnamese', 'Indonesian', 'Arabic', 'Hungarian', 'Romanian', 'Danish', 'Slovak', 'Ukrainian', 'Catalan', 'Serbian', 'Croatian', 'Hindi', 'Bengali', 'Tamil', 'Nepali', 'Malayalam', 'Marathi', 'Telugu', 'Kannada']",['Text'],"['HellaSwag', 'TruthfulQA', 'ARC', 'MMLU']",[],[],4.0,1.0,1.0,1.0,26.0,1.0,0.0,1.0,62.0,0.0,1
OpenbookQA,,{},[],['PapersWithCode'],[],[],[],['EMNLP'],[],[],[],['English'],['Text'],['OpenbookQA'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,21.0,0.0,1
OpenbookQA,,"{'independent website': ['Rankable Table', 'Scatter Plot']}",['Email'],['independent website'],['independent website'],['independent website'],['Allen Institute for AI'],['EMNLP'],[],['Prediction Results'],['Submission Portal'],['English'],['Text'],['OpenbookQA'],[],[],1.0,2.0,1.0,1.0,1.0,1.0,0.0,1.0,62.0,0.0,1
OpenCompass LLM Leaderboard (v2),,"{'independent website': ['Rankable Table'], 'HuggingFace': ['Rankable Table']}",[],"['HuggingFace', 'independent website']",[],"['HuggingFace', 'independent website']","['Aliyun', 'East Money', 'Duxiaoman', 'Fudan University', 'Nanjing University', 'Nanyang Technological University', 'OPPO', 'Shanghai AI Laboratory', 'Tencent', 'TigerResearch', 'Chinese University of Hong Kong', 'Zhejiang University', 'Zhipu AI']",[],"['Aggregated Result', 'Supported Functionality']","['Inference API+Model Configuration', 'Model Repository+Model Configuration']",['Submission Portal'],"['English', 'Chinese']","['Text', 'Code']","['BoolQ', 'DROP', 'EPRSTMT', 'CSQA', 'C3', 'GSM8K', 'GAOKAO-Bench', 'DS-1000', 'ChID', 'HumanEval-X', 'SIQA', 'L-Eval', 'C-Eval', 'TyDiQA', 'ReCoRD', 'Broad-Coverage Diagnostic', 'CMNLI', 'LAMBADA', 'OpenbookQA', 'CIBench', 'OCNLI', 'HellaSwag', 'RACE', 'AFQMC', 'LCSTS', 'CreationBench', 'COPA', 'CSL', 'Flores-101', 'XSUM', 'MathBench', 'LongBench', 'BBH', 'MBPP', 'PIQA', 'HumanEval', 'ARC', 'OCRBench', 'NQ', 'Winogender Diagnostic', 'CMMLU', 'WiC', 'WSC', 'MMLU', 'TriviaQA', 'MATH', 'RTE', 'T-Eval', 'AGIEval']",[],[],49.0,1.0,2.0,13.0,2.0,2.0,2.0,8.0,248.0,0.0,1
OpenEval (code),,{'GitHub': ['Table']},[],['GitHub'],[],[],"['Nanjing University of Aeronautics and Astronautics', 'Nantong University', 'Monash University', 'Commonwealth Scientific and Industrial Research Organisation', 'University of London']",['Preprint'],[],[],[],['English'],"['Text', 'Code']",['OpenEval'],[],[],1.0,1.0,1.0,5.0,1.0,2.0,0.0,1.0,10.0,0.0,1
OpenEval (text),,{'independent website': ['Rankable Table']},[],['independent website'],[],[],"['Tianjin University', 'Zhengzhou University', 'China Academy of Information and Communications Technology', 'China Software Test Center', 'University of Macau', 'Macau University of Science and Technology', 'Chinese University of Hong Kong', 'Shanghai Jiao Tong University']",[],['Supported Functionality'],"['Prediction Results', 'Inference API']",['Submission Portal'],['Chinese'],['Text'],"['Power-seeking', 'C3', 'Self-awareness', 'SWSR', 'GAOKAO-Bench', 'SNLI', 'COLD', 'CBBQ', 'ChID', 'OL-CC', 'M3KE', 'CMNLI', 'CAIL', 'TOCP', 'Guilt Law', 'CommonMT', 'TUMCC', 'One-box Tendency', 'Corrigible', 'WGlaw', 'CORGI-PM', 'WPLC', 'CooridinateAI', 'BiPaR', 'CDIAL-BIAS', 'CMMLU', 'WSC', 'Myopia Reward', 'TGEA', 'SQuAD']",[],[],30.0,1.0,1.0,8.0,1.0,1.0,1.0,4.0,36.0,0.0,1
Pets37,,{},[],['PapersWithCode'],[],[],[],['CVPR'],[],[],[],['English'],"['Text', 'Image']",['Pets37'],[],"['accuracy', '#parameters', 'top-1 error rate', 'flops']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,16.0,0.0,1
PIQA,,{},[],['PapersWithCode'],[],[],[],['AAAI'],[],[],[],['English'],['Text'],['PIQA'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,36.0,0.0,1
PIQA,,"{'independent website': ['Rankable Table', 'Scatter Plot']}",['Email'],['independent website'],['independent website'],['independent website'],['Allen Institute for AI'],['AAAI'],[],['Prediction Results'],['Submission Portal'],['English'],['Text'],['PIQA'],[],[],1.0,2.0,1.0,1.0,1.0,1.0,0.0,1.0,38.0,0.0,1
PMC-VQA,,{},[],['PapersWithCode'],[],[],[],['Preprint'],[],[],[],['English'],"['Text', 'Image']",['PMC-VQA'],[],"['accuracy', 'bleu-1']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,11.0,0.0,1
Program Synthesis Models Leaderboard,,{'independent website': ['Table']},"['Contact', 'Issue']",['independent website'],[],['independent website'],['Accubits'],[],[],[],[],['English'],"['Text', 'Code']",['Program Synthesis Models Leaderboard'],[],[],1.0,1.0,1.0,1.0,1.0,2.0,0.0,1.0,8.0,0.0,1
PromptBench,,{'GitHub': ['Table']},[],['GitHub'],[],[],"['Microsoft Research Asia', 'Chinese Academy of Sciences', 'University of Science and Technology of China', 'Carnegie Mellon University']",['Preprint'],"['Task', 'Benchmark']",[],[],['English'],['Text'],"['Boolean Expressions', 'CSQA', 'CoLA', 'GSM8K', 'MultiUN', 'QQP', 'Valid Parantheses', 'MNLI', 'WNLI', 'IWSLT', 'Date Understanding', 'NumerSense', 'QNLI', 'SST-2', 'LastLetterConcat', 'Tracking Shuffled Objects', 'MMLU', 'QASC', 'MATH', 'RTE', 'SQuAD', 'MRPC']",[],[],22.0,1.0,1.0,4.0,1.0,1.0,2.0,3.0,23.0,0.0,1
ProtoQA,,"{'independent website': ['Rankable Table', 'Scatter Plot']}",['Email'],['independent website'],['independent website'],['independent website'],['Allen Institute for AI'],['EMNLP'],[],['Prediction Results'],['Submission Portal'],['English'],['Text'],['ProtoQA'],[],[],1.0,2.0,1.0,1.0,1.0,1.0,0.0,1.0,189.0,0.0,1
Provider Leaderboard,,{'independent website': ['Rankable Table']},['Contact'],['independent website'],[],[],['Martian'],[],"['Output Length', 'Service Load']",[],[],['English'],['Text'],['Provider Leaderboard'],[],[],1.0,1.0,1.0,1.0,1.0,1.0,2.0,6.0,112.0,0.0,1
PubMedQA,,{},[],['PapersWithCode'],[],[],[],['EMNLP'],[],[],[],['English'],['Text'],['PubMedQA'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,26.0,0.0,1
PubMedQA,,{'GitHub': ['Table']},[],['GitHub'],[],['GitHub'],"['University of Pittsburgh', 'Carnegie Mellon University', 'Google']",['EMNLP'],[],['Prediction Results'],['Email'],['English'],['Text'],['PubMedQA'],[],[],1.0,1.0,1.0,3.0,1.0,1.0,0.0,1.0,21.0,0.0,1
Q-Bench,,"{'GitHub': ['Rankable Table', 'Table'], 'HuggingFace': ['Rankable Table']}",[],"['GitHub', 'HuggingFace']",['HuggingFace'],[],"['Nanyang Technological University', 'Shanghai Jiao Tong University', 'SenseTime']",['ICLR'],[],[],[],"['English', 'Chinese']","['Text', 'Image']","['LLDescribe', 'CGIQA-6K', 'SPAQ', 'KonIQ-10k', 'AGIQA-3K', 'LIVE-FB LSVQ', 'LLVisionQA', 'KADID-10K', 'LIVE-itw']",[],[],9.0,2.0,2.0,3.0,2.0,2.0,0.0,10.0,142.0,0.0,1
QASC,,"{'independent website': ['Rankable Table', 'Scatter Plot']}",['Email'],['independent website'],['independent website'],['independent website'],['Allen Institute for AI'],['AAAI'],[],['Prediction Results'],['Submission Portal'],['English'],['Text'],['QASC'],[],[],1.0,2.0,1.0,1.0,1.0,1.0,0.0,1.0,17.0,0.0,1
QNLI,,{},[],['PapersWithCode'],[],[],[],['EMNLP'],[],[],[],['English'],['Text'],['QNLI'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,2.0,0.0,1
QQP,,{},[],['PapersWithCode'],[],[],[],[],[],[],[],['English'],['Text'],['QQP'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,21.0,0.0,1
QuALITY,,{'GitHub': ['Table']},[],['GitHub'],[],['GitHub'],['New York University'],['NAACL'],[],['Prediction Results'],"['Email', 'Questionaire']",['English'],['Text'],['QuALITY'],[],[],1.0,1.0,1.0,1.0,1.0,1.0,0.0,1.0,14.0,0.0,1
RACE,,{},[],['PapersWithCode'],[],[],[],['EMNLP'],[],[],[],['English'],['Text'],['RACE'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,25.0,0.0,1
RAFT,,{},[],['PapersWithCode'],[],[],[],['NeurIPS'],[],[],[],['English'],['Text'],"['ToS', 'Over', 'SRI', 'TweetEval', 'OSE', 'SOT', 'ADE Corpus', 'TC', 'B77', 'TAI', 'NIS']",[],"['sot', 'tc', 'b77', 'sri', 'average', 'tai', 'over', 'tos', 'nis', 'ose', 'ade', 'teh']",11.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,9.0,0.0,1
RAFT,,{'HuggingFace': ['Table']},[],['HuggingFace'],[],[],"['Ought', 'Hugging Face', 'Stiftung Neue Verantwortung', 'Nippon Telegraph and Telephone', 'University of Oxford', 'Alan Turing Institute', 'Harvard University', 'Australian Catholic University']",['NeurIPS'],[],['Evaluation Results'],['Metadata Upload'],['English'],['Text'],"['ToS', 'Over', 'SRI', 'TweetEval', 'OSE', 'SOT', 'ADE Corpus', 'TC', 'B77', 'TAI', 'NIS']",[],[],11.0,1.0,1.0,8.0,1.0,1.0,0.0,1.0,81.0,0.0,1
ReCoRD,,{},[],['PapersWithCode'],[],[],[],['Preprint'],[],[],[],['English'],['Text'],"['CNN DM', 'Internet Archive']",[],"['f1', 'exact match']",2.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,30.0,0.0,1
Red-Eval,,{'GitHub': ['Table']},[],['GitHub'],[],[],['Singapore University of Technology and Design'],['Preprint'],[],[],[],['English'],['Text'],"['HarmfulQA', 'DangerousQA']",[],[],2.0,1.0,1.0,1.0,1.0,1.0,0.0,1.0,11.0,0.0,1
RefCOCO,,{},[],['PapersWithCode'],[],[],[],['EMNLP'],[],[],[],['English'],"['Text', 'Image']",['RefCOCO'],[],"['test a', 'test b', 'accuracy', 'val']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,27.0,0.0,1
ReForm-Eval,,{'GitHub': ['Table']},[],['GitHub'],[],[],"['Fudan University', 'Northeastern University', 'Alibaba Group', 'Hong Kong University of Science and Technology']",['Preprint'],[],['Evaluation Results'],['Email'],['English'],"['Text', 'Image']","['Whoops', 'VizWiz', 'SNLI-VE', 'ScienceQA', 'FUNSD', 'VQA', 'IIIT5K', 'POIE', 'VSR', 'CLEVR', 'SROIE', 'A-OKVQA', 'NoCaps', 'Flowers102', 'OK-VQA', 'MEDIC', 'WikiHow', 'ViQuAE', 'ImageNet-1K', 'COCO-Text', 'OCR-VQA', 'TextCaps', 'MSCOCO', 'MOCHEG', 'CUTE80', 'RefCOCO', 'MP3D', 'CIFAR-10', 'DocVQA', 'TDIUC', 'Winoground', 'Flickr30K', 'TextOCR', 'VisDial', 'IC', 'ImageNetVC', 'Pets37', 'GQA', 'TextVQA', 'WordArt']",[],[],40.0,1.0,1.0,4.0,1.0,2.0,0.0,1.0,16.0,0.0,1
Robust (2004),,{},[],['PapersWithCode'],[],[],[],['TREC'],[],[],[],['English'],['Text'],['Robust'],[],"['ndcg@20', 'map', 'precision@20']",1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,21.0,0.0,1
RoleEval,,{'GitHub': ['Table']},[],['GitHub'],[],[],"['Tianjin University', 'China Academy of Information and Communications Technology']",['Preprint'],"['Evaluation Dataset', 'Supported Language']",['Prediction Results'],['Email'],"['English', 'Chinese']",['Text'],['RoleEval'],[],[],1.0,1.0,1.0,2.0,2.0,1.0,2.0,4.0,138.0,0.0,1
RTE,,{},[],['PapersWithCode'],[],[],[],['TAC'],[],[],[],['English'],['Text'],['RTE'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,56.0,0.0,1
Safety-Prompts,,{'independent website': ['Table']},"['Contact', 'Issue']",['independent website'],[],['independent website'],['Tsinghua University'],['Preprint'],['Evaluation Dataset'],['Prediction Results'],['Submission Portal'],['Chinese'],['Text'],['Safety-Prompts'],[],[],1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,20.0,0.0,1
SafetyBench,,"{'independent website': ['Table'], 'GitHub': ['Bar Chart']}",[],"['GitHub', 'independent website']",[],"['GitHub', 'independent website']","['Tsinghua University', 'Northwest Minzu University', 'Peking University', 'China Mobile']",['Preprint'],"['Evaluation Dataset', 'Supported Language']",['Prediction Results'],['Submission Portal'],"['English', 'Chinese']",['Text'],['SafetyBench'],[],[],1.0,2.0,2.0,4.0,2.0,1.0,2.0,3.0,49.0,0.0,1
ScandEval,,{'independent website': ['Rankable Table']},[],['independent website'],['independent website'],[],['Alexandra Institute'],['NoDaLiDa'],['Supported Language'],[],[],"['English', 'Danish', 'Swedish', 'Norwegian', 'Icelandic', 'German', 'Dutch', 'Finnish', 'Russian', 'Arabic']",['Text'],"['Angry Tweets', 'DaNE', 'NorNE', 'SUC', 'ScandiQA', 'SweRec', 'NoReC', 'ScaLA']",[],[],8.0,1.0,1.0,1.0,10.0,1.0,1.0,10.0,440.0,0.0,1
ScienceQA,,{},[],['PapersWithCode'],[],[],[],['NeurIPS'],[],[],[],['English'],"['Text', 'Image']",['ScienceQA'],[],"['text context', 'average accuracy', 'natural science', 'language science', 'no context', 'grades 7-12', 'image context', 'grades 1-6', 'social science']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,8.0,0.0,1
ScienceQA,,{'GitHub': ['Rankable Table']},[],['GitHub'],[],['GitHub'],"['University of California Los Angeles', 'Arizona State University', 'Allen Institute for AI']",['NeurIPS'],[],['Evaluation Results'],"['Email', 'Issue']",['English'],"['Text', 'Image']",['ScienceQA'],[],[],1.0,1.0,1.0,3.0,1.0,2.0,0.0,1.0,109.0,0.0,1
SciGraphQA,,{'GitHub': ['Table']},[],['GitHub'],[],[],['Independent Contributor'],['Preprint'],[],[],[],['English'],"['Text', 'Image']",['SciGraphQA'],[],[],1.0,1.0,1.0,1.0,1.0,2.0,0.0,1.0,9.0,0.0,1
SciQ,,{},[],['PapersWithCode'],[],[],[],['WNUT'],[],[],[],['English'],['Text'],['SciQ'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,5.0,0.0,1
SCROLLS,,{'independent website': ['Table']},['Contact'],['independent website'],[],[],"['Tel Aviv University', 'International Business Machines', 'Meta']",['Preprint'],[],['Prediction Results'],['Submission Portal'],['English'],['Text'],"['Qasper', 'QuALITY', 'SummScreen', 'GovReport', 'ContractNLI', 'QMSum', 'NarrativeQA']",[],[],7.0,1.0,1.0,3.0,1.0,1.0,0.0,1.0,12.0,0.0,1
SEED-Bench Leaderboard,,{'HuggingFace': ['Rankable Table']},[],['HuggingFace'],[],['HuggingFace'],"['Tencent AI Lab', 'Tencent PCG ARC Lab', 'Chinese University of Hong Kong']",['Preprint'],['Benchmark'],['Prediction Results'],['Submission Portal'],['English'],"['Text', 'Image', 'Video']",['SEED-Bench Leaderboard'],[],[],1.0,1.0,1.0,3.0,1.0,3.0,1.0,2.0,72.0,0.0,1
Sherlock,,"{'independent website': ['Rankable Table', 'Scatter Plot']}",['Email'],['independent website'],['independent website'],['independent website'],['Allen Institute for AI'],['ECCV'],[],['Prediction Results'],['Submission Portal'],['English'],"['Text', 'Image']",['Sherlock'],[],[],1.0,2.0,1.0,1.0,1.0,2.0,0.0,1.0,96.0,0.0,1
SICK,,{},[],['PapersWithCode'],[],[],[],['LREC'],[],[],[],['English'],['Text'],['SICK'],[],['spearman correlation'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,23.0,0.0,1
SIQA,,{},[],['PapersWithCode'],[],[],[],"['EMNLP', 'IJCNLP']",[],[],[],['English'],['Text'],['SIQA'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,8.0,0.0,1
SIQA,,"{'independent website': ['Rankable Table', 'Scatter Plot']}",['Email'],['independent website'],['independent website'],['independent website'],['Allen Institute for AI'],"['EMNLP', 'IJCNLP']",[],['Prediction Results'],['Submission Portal'],['English'],['Text'],['SIQA'],[],[],1.0,2.0,1.0,1.0,1.0,1.0,0.0,1.0,119.0,0.0,1
Something-Something (v2),,{},[],['PapersWithCode'],[],[],[],['ICCV'],[],[],[],['English'],"['Text', 'Video']",['Something-Something'],[],"['#parameters', 'top-1 accuracy', 'top-5 accuracy', 'gflops']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,116.0,0.0,1
Spider,,{},[],['PapersWithCode'],[],[],[],['EMNLP'],[],[],[],['English'],"['Text', 'Code']",['Spider'],[],"['accuracy', 'execution accuracy', 'exact match']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,17.0,0.0,1
Spider,,{'GitHub': ['Table']},[],['GitHub'],[],['GitHub'],['Yale University'],['EMNLP'],['Evaluation Metric'],['Prediction Results'],['Email'],['English'],"['Text', 'Code']",['Spider'],[],[],1.0,1.0,1.0,1.0,1.0,2.0,1.0,2.0,118.0,0.0,1
SQuAD,,{},[],['PapersWithCode'],[],[],[],['EMNLP'],[],[],[],['English'],['Text'],['SQuAD'],[],"['f1', 'exact match']",1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,53.0,0.0,1
SST,,{},[],['PapersWithCode'],[],[],[],['EMNLP'],[],[],[],['English'],['Text'],"['SST-2', 'SST-5']",[],"['accuracy', 'dev accuracy']",2.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,85.0,0.0,1
STAR,,{},[],['PapersWithCode'],[],[],[],['NeurIPS'],[],[],[],['English'],"['Text', 'Video']",['STAR'],[],"['accuracy', 'average accuracy']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,19.0,0.0,1
StereoSet,,{},[],['PapersWithCode'],[],[],[],"['ACL', 'IJCNLP']",[],[],[],['English'],['Text'],['StereoSet'],[],"['lms', 'ss', 'icat score']",1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,11.0,0.0,1
StoryCloze,,{},[],['PapersWithCode'],[],[],[],['NAACL'],[],[],[],['English'],['Text'],['StoryCloze'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,18.0,0.0,1
StrategyQA,,{},[],['PapersWithCode'],[],[],[],['TACL'],[],[],[],['English'],['Text'],['StrategyQA'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,6.0,0.0,1
StrategyQA,,"{'independent website': ['Rankable Table', 'Scatter Plot']}",['Email'],['independent website'],['independent website'],['independent website'],['Allen Institute for AI'],['TACL'],[],['Prediction Results'],['Submission Portal'],['English'],['Text'],['StrategyQA'],[],[],1.0,2.0,1.0,1.0,1.0,1.0,0.0,1.0,196.0,0.0,1
STS-B,,{},[],['PapersWithCode'],[],[],[],['EMNLP'],[],[],[],['English'],['Text'],['STS-B'],[],"['dev pearson correlation', 'spearman correlation', 'pearson correlation', 'accuracy', 'dev spearman correlation']",1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,226.0,0.0,1
SummEdits,,{'GitHub': ['Table']},[],['GitHub'],[],[],['Salesforce'],['Preprint'],[],[],[],['English'],['Text'],"['Google News', 'ECTSum', 'Sales Call', 'Sales Email', 'Spotify Podcast', 'Billsum', 'TinyShakespeare', 'QMSum', 'SciTLDR', 'SAMSum']",[],[],10.0,1.0,1.0,1.0,1.0,1.0,0.0,1.0,20.0,0.0,1
SuperCLUE,,"{'independent website': ['Rankable Table'], 'GitHub': ['Table']}",[],"['GitHub', 'independent website']",[],[],"['CLUE', 'Westlake University']",['Preprint'],"['Task', 'Aggregated Result', 'Supported Functionality', 'Model Accessibility', 'Leaderboard Launch Date']",['?'],"['Email', 'WeChat']",['Chinese'],['Text'],"['OPEN Set', 'CLOSE Set', 'CArena']",[],[],3.0,2.0,2.0,2.0,1.0,1.0,5.0,7.0,170.0,0.0,1
SuperCLUE-Agent,,"{'independent website': ['Rankable Table', 'Table Screenshot'], 'GitHub': ['Table']}",[],"['GitHub', 'independent website']",[],[],['CLUE'],[],"['Task', 'Aggregated Result', 'Supported Functionality']",['?'],"['Email', 'WeChat']",['Chinese'],['Text'],['SuperCLUE-Agent'],[],[],1.0,3.0,2.0,1.0,1.0,1.0,3.0,5.0,85.0,0.0,1
SuperCLUE-Auto,,"{'independent website': ['Rankable Table'], 'GitHub': ['Table']}",[],"['GitHub', 'independent website']",[],[],['CLUE'],[],"['Task', 'Aggregated Result']",['?'],"['Email', 'WeChat']",['Chinese'],['Text'],['SuperCLUE-Auto'],[],[],1.0,2.0,2.0,1.0,1.0,1.0,2.0,5.0,60.0,0.0,1
SuperCLUE-Math6,,{'GitHub': ['Table']},[],['GitHub'],[],[],['CLUE'],['Preprint'],"['Benchmark', 'Evaluation Metric']",['?'],"['Email', 'WeChat']",['Chinese'],['Text'],['SuperCLUE-Math6'],[],[],1.0,1.0,1.0,1.0,1.0,1.0,2.0,5.0,55.0,0.0,1
SuperCLUE-Safety,,"{'independent website': ['Rankable Table', 'Table'], 'GitHub': ['Table']}",[],"['GitHub', 'independent website']",[],[],['CLUE'],['Preprint'],"['Task', 'Aggregated Result']",['?'],"['Email', 'WeChat']",['Chinese'],['Text'],['SuperCLUE-Safety'],[],[],1.0,2.0,2.0,1.0,1.0,1.0,2.0,4.0,68.0,0.0,1
SuperCLUEgkzw,,{'GitHub': ['Table']},[],['GitHub'],[],[],['CLUE'],[],[],['?'],"['Email', 'WeChat']",['Chinese'],['Text'],['SuperCLUEgkzw'],[],[],1.0,1.0,1.0,1.0,1.0,1.0,0.0,1.0,9.0,0.0,1
SuperCLUElyb,,{'GitHub': ['Table Screenshot']},[],['GitHub'],[],[],['CLUE'],[],[],"['Inference API', 'Model Repository']",['Questionaire'],['Chinese'],['Text'],['SuperCLUElyb'],[],[],1.0,1.0,1.0,1.0,1.0,1.0,0.0,1.0,16.0,0.0,1
SuperGLUE,,{'independent website': ['Table']},"['Contact', 'Issue']",['independent website'],[],['independent website'],"['New York University', 'Meta', 'University of Washington', 'Google DeepMind']",['NeurIPS'],[],['Prediction Results'],['Submission Portal'],['English'],['Text'],"['BoolQ', 'CB', 'COPA', 'Winogender Diagnostic', 'Broad-Coverage Diagnostic', 'WiC', 'WSC', 'ReCoRD', 'MultiRC', 'RTE']",[],[],10.0,1.0,1.0,4.0,1.0,1.0,0.0,1.0,59.0,0.0,1
SuperLim (v2),,{'independent website': ['Rankable Table']},"['Contact', 'Issue']",['independent website'],[],[],"['University of Gothenburg', 'National Library of Sweden', 'Embark Studios', 'AI Sweden', 'iguanodon.ai']",['EMNLP'],['Evaluation Dataset'],['Prediction Results+Evaluation Results+Model Repository'],['Pull Request'],['Swedish'],['Text'],"['SuperSim', 'SweDN', 'Winograd', 'Swedish ABSAbank-Imm', 'MNLI', 'Winogender Diagnostic', 'DaLAJ-GED-SuperLim', 'STS-B', 'SweFAQ', 'GLUE Diagnostic', 'SweWiC', 'SweSAT Synonyms', 'Swedish analogy', 'Argumentation sentences']",[],[],14.0,1.0,1.0,5.0,1.0,1.0,1.0,2.0,36.0,0.0,1
SVAMP,,{},[],['PapersWithCode'],[],[],[],['NAACL'],[],[],[],['English'],['Text'],['SVAMP'],[],"['execution accuracy', 'accuracy']",1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,32.0,0.0,1
SWE-bench,,{},[],['PapersWithCode'],[],[],[],['Preprint'],[],[],[],['English'],"['Text', 'Code']",['SWE-bench'],[],['resolved'],1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,4.0,0.0,1
SWE-bench,,{'independent website': ['Table']},"['Contact', 'Issue']",['independent website'],[],[],"['Princeton University', 'University of Chicago']",['Preprint'],['Task'],['?'],['Email'],['English'],"['Text', 'Code']",['SWE-bench'],[],[],1.0,1.0,1.0,2.0,1.0,2.0,1.0,2.0,10.0,0.0,1
T-Eval,,"{'GitHub': ['Table', 'Table Screenshot', 'Scatter Plot']}",[],['GitHub'],[],['GitHub'],"['University of Science and Technology of China', 'Shanghai AI Laboratory', 'Tsinghua University', 'Jilin University']",['Preprint'],['Supported Language'],['Prediction Results'],"['Issue', 'Email']","['English', 'Chinese']",['Text'],['T-Eval'],[],[],1.0,3.0,1.0,4.0,2.0,1.0,1.0,2.0,41.0,0.0,1
TabMWP,,"{'GitHub': ['Rankable Table', 'Table']}",[],['GitHub'],[],['GitHub'],"['University of California Los Angeles', 'Georgia Institute of Technology', 'Allen Institute for AI']",['ICLR'],[],['Evaluation Results'],"['Email', 'Issue']",['English'],['Text'],['TabMWP'],[],[],1.0,2.0,1.0,3.0,1.0,1.0,0.0,1.0,50.0,0.0,1
TACRED,,{},[],['PapersWithCode'],[],[],[],['EMNLP'],[],[],[],['English'],['Text'],['TACRED'],[],['f1'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,46.0,0.0,1
TAT-DQA,,{'GitHub': ['Table']},[],['GitHub'],[],[],"['National University of Singapore', '6Estates', 'Sichuan University', 'University of Science and Technology of China']",['ACM-MM'],[],['Prediction Results'],['Email'],['English'],['Text'],['TAT-DQA'],[],[],1.0,1.0,1.0,4.0,1.0,1.0,0.0,1.0,6.0,0.0,1
TAT-QA,,{'GitHub': ['Table']},[],['GitHub'],[],[],"['National University of Singapore', '6Estates', 'Sichuan University', 'Bloomberg']",['ACL'],[],['Prediction Results'],['Email'],['English'],['Text'],['TAT-QA'],[],[],1.0,1.0,1.0,4.0,1.0,1.0,0.0,1.0,26.0,0.0,1
TextSynth Server,,{'independent website': ['Table']},['Email'],['independent website'],[],['independent website'],['Independent Contributor'],[],"['Service Load', 'Task', 'Benchmark']",[],[],['English'],"['Text', 'Image']","['PIQA', 'HellaSwag', 'CoQA', 'WinoGrande', 'LAMBADA']",[],[],5.0,1.0,1.0,1.0,1.0,2.0,3.0,4.0,97.0,0.0,1
TGIF-QA,,{},[],['PapersWithCode'],[],[],[],['IJCV'],[],[],[],['English'],"['Text', 'Video']",['TGIF-QA'],[],"['accuracy', 'confidence score']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,20.0,0.0,1
The Pile,,{},[],['PapersWithCode'],[],[],[],['Preprint'],[],[],[],['English'],['Text'],['The Pile'],[],['bits per byte'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,5.0,0.0,1
The Pile,,{'independent website': ['Table']},"['Contact', 'Issue']",['independent website'],[],[],['EleutherAI'],['Preprint'],[],['?'],['Email'],['English'],['Text'],['The Pile'],[],[],1.0,1.0,1.0,1.0,1.0,1.0,0.0,1.0,2.0,0.0,1
TheoremQA,,{'GitHub': ['Table']},[],"['GitHub', 'PapersWithCode']",[],[],"['University of Waterloo', 'UC Santa Barbara', 'University of California Los Angeles']",['Preprint'],[],[],[],['English'],['Text'],['TheoremQA'],[],[],1.0,1.0,2.0,4.0,1.0,1.0,1.0,1.0,21.0,0.0,1
Toloka LLM Leaderboard,,"{'HuggingFace': ['Rankable Table'], 'independent website': ['Rankable Table']}",[],"['HuggingFace', 'independent website']",[],[],['Toloka'],[],[],[],[],['English'],['Text'],['Toloka LLM Leaderboard'],[],[],1.0,1.0,2.0,1.0,1.0,1.0,0.0,1.0,6.0,0.0,1
Toolbench Leaderboard,,{'HuggingFace': ['Rankable Table']},[],['HuggingFace'],[],['HuggingFace'],['SambaNova Systems'],['Preprint'],[],[],[],['English'],['Text'],['Toolbench Leaderboard'],[],[],1.0,1.0,1.0,1.0,1.0,1.0,0.0,1.0,44.0,0.0,1
TouchStone,,{'GitHub': ['Table Screenshot']},[],['GitHub'],[],[],"['Alibaba Group', 'Huazhong University of Science and Technology', 'Tsinghua University']",['Preprint'],[],[],[],['English'],"['Text', 'Image']",['TouchStone'],[],[],1.0,1.0,1.0,3.0,1.0,2.0,0.0,1.0,7.0,0.0,1
TravelPlanner,,"{'HuggingFace': ['Rankable Table'], 'GitHub': ['Table Screenshot', 'Pie Chart']}",[],"['GitHub', 'HuggingFace']",[],[],"['Fudan University', 'Ohio State University', 'Pennsylvania State University', 'Meta']",['Preprint'],"['Task', 'Evaluation Dataset']",['Prediction Results'],['Submission Portal'],['English'],['Text'],['TravelPlanner'],[],[],1.0,3.0,2.0,4.0,1.0,1.0,2.0,5.0,33.0,0.0,1
TREC-COVID,,{},[],['PapersWithCode'],[],[],[],['ACM SIGIR Forum'],[],[],[],['English'],['Text'],['TREC-COVID'],[],['ndcg@10'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,6.0,0.0,1
TriviaQA,,{},[],['PapersWithCode'],[],[],[],['ACL'],[],[],[],['English'],['Text'],['TriviaQA'],[],"['accuracy', 'f1', 'exact match']",1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,41.0,0.0,1
TrustLLM,,{'GitHub': ['Rankable Table']},[],['GitHub'],[],[],"['Lehigh University', 'Illinois Institute of Technology', 'Institut Polytechnique de Paris', 'College of William & Mary', 'Texas A&M University', 'University of Georgia', 'Samsung Research America', 'Stanford University', 'Lawrence Livermore National Laboratory', 'Salesforce', 'University of Wisconsin Madison', 'Microsoft', 'Carnegie Mellon University', 'University of Maryland', 'University of California Berkeley', 'University of Illinois Urbana Champaign', 'University of North Carolina Chapel Hill', 'Massachusetts Institute of Technology', 'Harvard University', 'University of Notre Dame', 'Duke University', 'University of Tennessee Knoxville', 'University of Southern California', 'Michigan State University', 'Microsoft Research Asia', 'Drexel University', 'University of California Los Angeles', 'Virginia Polytechnic Institute and State University', 'Cyber Intelligence Sharing and Protection Act', 'University of Illinois Chicago', 'International Business Machines', 'Yale University', 'Columbia University', 'University of California Santa Barbara', 'Massachusetts General Hospital', 'Northwestern University', 'Florida International University', 'Johns Hopkins University', 'University of Pennsylvania', 'Mohamed bin Zayed University of AI']",['Preprint'],['Supported Functionality'],['Prediction Results'],['Questionaire'],['English'],['Text'],"['CODAH', 'Privacy Awareness', 'AdvInstruction', 'AdvGLUE', 'ConfAIde', 'Do-Not-Answer', 'COVID-Fact', 'ToolE', 'XSTest', 'ETHICS', 'SciFact', 'StereoSet', 'HealthVer', 'Adult', 'Climate-FEVER', 'HotpotQA', 'DDXPlus', 'Social Chemistry 101', 'MoralChoice', 'AdversarialQA', 'WinoBias', 'Opinion pairs', 'LM-exp-sycophancy', 'Enron Email', 'TruthfulQA', 'Misuse', 'Flipkart', 'Jailbraek Trigger', 'SQuAD']",[],[],29.0,1.0,1.0,36.0,1.0,1.0,1.0,6.0,96.0,0.0,1
TruthfulQA,,{},[],['PapersWithCode'],[],[],[],['ACL'],[],[],[],['English'],['Text'],['TruthfulQA'],[],"['mc2', '% true', 'bleurt', 'rouge', 'mc1', '% info', 'bleu']",1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,26.0,0.0,1
TruthfulQA,,{'GitHub': ['Table']},[],['GitHub'],[],[],"['University of Oxford', 'OpenAI']",['ACL'],['Leaderboard Version'],[],[],['English'],['Text'],['TruthfulQA'],[],[],1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,4.0,0.0,1
tStoryCloze,,{'GitHub': ['Table']},[],['GitHub'],[],[],"['Meta FAIR', 'OpenAI', 'Hebrew University of Jerusalem']",['NeurIPS'],[],[],[],['English'],['Text'],['tStoryCloze'],[],[],1.0,1.0,1.0,3.0,1.0,1.0,0.0,1.0,3.0,0.0,1
TVQA,,{},[],['PapersWithCode'],[],[],[],['EMNLP'],[],[],[],['English'],"['Text', 'Video']",['TVQA'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,9.0,0.0,1
TyDiQA,,{},[],['PapersWithCode'],[],[],[],['TACL'],[],[],[],"['English', 'Arabic', 'Bengali', 'Finnish', 'Japanese', 'Indonesian', 'Kiswahili', 'Korean', 'Russian', 'Telugu', 'Thai']",['Text'],['TyDiQA'],[],['accuracy'],1.0,0.0,1.0,1.0,11.0,1.0,1.0,0.0,2.0,0.0,1
UCF101,,{},[],['PapersWithCode'],[],[],[],['Preprint'],[],[],[],['English'],"['Text', 'Video']",['UCF101'],[],"['3-fold accuracy', 'inception score', 'fvd128', 'top-1 accuracy', 'fvd16', 'accuracy', 'split-1  top-1 accuracy', 'top-5 accuracy', 'kvd16', 'frozen', 'pre-training dataset']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,213.0,0.0,1
UHGEval,,{'GitHub': ['Table Screenshot']},[],"['GitHub', 'HuggingFace']",[],[],"['Renmin University of China', 'Institute for Advanced Algorithms Research', 'Xinhua']",['Preprint'],"['Task', 'Supported Functionality']",[],[],['Chinese'],['Text'],['XinhuaHallucinations'],[],[],1.0,1.0,2.0,3.0,1.0,1.0,2.0,3.0,33.0,0.0,1
VBench,,"{'HuggingFace': ['Rankable Table'], 'GitHub': ['Rankable Table']}",[],"['GitHub', 'HuggingFace']",[],"['GitHub', 'HuggingFace']","['Nanyang Technological University', 'Shanghai AI Laboratory', 'Chinese University of Hong Kong', 'Nanjing University']",['Preprint'],['Aggregated Result'],['Prediction Results'],['Submission Portal'],['English'],"['Text', 'Video']",['VBench'],[],[],1.0,1.0,2.0,4.0,1.0,2.0,1.0,2.0,19.0,0.0,1
VCR,,{},[],['PapersWithCode'],[],[],[],['CVPR'],[],[],[],['English'],"['Text', 'Image']",['VCR'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,26.0,0.0,1
VGGSound,,{},[],['PapersWithCode'],[],[],[],['ICASSP'],[],[],[],['English'],"['Text', 'Audio']",['VGGSound'],[],"['mean ap', 'top-1 accuracy', 'auc', 'top-5 accuracy', 'd-prime']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,19.0,0.0,1
Video-Bench,,{'HuggingFace': ['Rankable Table']},[],['HuggingFace'],[],[],"['Peking University', 'Peng Cheng Laboratory', 'Microsoft', 'FarReel AI Lab']",['Preprint'],[],['Prediction Results+Model Repository'],['Submission Portal'],['English'],"['Text', 'Video']","['ActivityNet-QA', 'DLE', 'TVQA', 'UCF-Crime', 'MVQA', 'MOT', 'TGIF-QA', 'NBAQA', 'DDM', 'YouCook2', 'SQA3D', 'MSRVTT-QA', 'MSVD-QA']",[],[],13.0,1.0,1.0,4.0,1.0,2.0,0.0,1.0,40.0,0.0,1
VideoInstruct,,{},[],['PapersWithCode'],[],[],[],['Preprint'],[],[],[],['English'],"['Text', 'Video']",['VideoInstruct'],[],"['consistency', 'detail orientation', 'correctness of information', 'temporal understanding', 'mean', 'gpt-score', 'contextual understanding']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,61.0,0.0,1
ViP-Bench,,{},[],['PapersWithCode'],[],[],[],['Preprint'],[],[],[],['English'],"['Text', 'Image']","['PointQA', 'Flickr30K', 'VCR', 'RefCOCOg', 'Visual Genome', 'Visual7W']",[],['gpt-4 score'],6.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,11.0,0.0,1
ViP-Bench,,{'GitHub': ['Table Screenshot']},[],['GitHub'],[],[],"['University of Wisconsin Madison', ' Cruise']",['Preprint'],[],[],[],['English'],"['Text', 'Image']","['PointQA', 'Flickr30K', 'VCR', 'RefCOCOg', 'Visual Genome', 'Visual7W']",[],[],6.0,1.0,1.0,2.0,1.0,2.0,0.0,1.0,17.0,0.0,1
VisDial,,{},[],['PapersWithCode'],[],[],[],['CVPR'],[],[],[],['English'],"['Text', 'Image']",['VisDial'],[],"['recall@1', 'mrr', 'recall@10', 'mean rank', 'recall@5']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,19.0,0.0,1
VisIT-Bench,,"{'HuggingFace': ['Rankable Table'], 'GitHub': ['Rankable Table']}",[],"['GitHub', 'HuggingFace']",['HuggingFace'],[],"['Hebrew University of Jerusalem', 'Google', 'University of California Los Angeles', 'Allen Institute for AI', 'University of Washington', 'UC Santa Barbara', 'Stanford University', 'Large-scale AI Open Network']",['NeurIPS'],[],['Prediction Results'],['Email'],['English'],"['Text', 'Image']",['VisIT-Bench'],[],[],1.0,1.0,2.0,8.0,1.0,2.0,0.0,1.0,16.0,0.0,1
VisualWebArena,,{'independent website': ['Table']},"['Contact', 'Issue']",['independent website'],[],[],['Carnegie Mellon University'],['Preprint'],[],[],[],['English'],"['Text', 'Image']",['VisualWebArena'],[],[],1.0,1.0,1.0,1.0,1.0,2.0,0.0,1.0,20.0,0.0,1
VizWiz,,{},[],['PapersWithCode'],[],[],[],['CVPR'],[],[],[],['English'],"['Text', 'Image']",['VizWiz'],[],"['unanswerable', 'overall', 'other', 'number', 'yes/no']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,15.0,0.0,1
VLM-Eval,,{'GitHub': ['Table']},[],['GitHub'],[],['GitHub'],"['Megvii', 'Shanghai Jiao Tong University']",['Preprint'],[],['Prediction Results'],['Pull Request'],['English'],"['Text', 'Video']","['ActivityNet', 'Kinetics-400', 'UCF101', 'TGIF', 'MSVD', 'MSRVTT', 'HMDB51']",[],[],7.0,1.0,1.0,2.0,1.0,2.0,0.0,1.0,7.0,0.0,1
VNHSGE,,{},[],['PapersWithCode'],[],[],[],['Preprint'],[],[],[],"['English', 'Vietnamese']",['Text'],['VNHSGE'],[],['accuracy'],1.0,0.0,1.0,1.0,2.0,1.0,1.0,0.0,19.0,0.0,1
VoxPopuli,,{},[],['PapersWithCode'],[],[],[],['ACL'],[],[],[],"['Bulgarian', 'Czech', 'Croatian', 'Danish', 'Dutch', 'English', 'Estonian', 'Finnish', 'French', 'German', 'Greek', 'Hungarian', 'Italian', 'Latvian', 'Lithuanian', 'Maltese', 'Polish', 'Portuguese', 'Romanian', 'Slovak', 'Slovene', 'Spanish', 'Swedish']","['Text', 'Audio']",['VoxPopuli'],[],"['word error rate', 'cer', 'wer unnormalized', 'mer']",1.0,0.0,1.0,1.0,23.0,2.0,1.0,0.0,6.0,0.0,1
VQA (v2),,{},[],['PapersWithCode'],[],[],[],['CVPR'],[],[],[],['English'],"['Text', 'Image']",['VQA'],[],"['overall', 'accuracy', 'other', 'number', 'yes/no']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,115.0,0.0,1
WebQuestions,,{},[],['PapersWithCode'],[],[],[],['EMNLP'],[],[],[],['English'],['Text'],['WebQuestions'],[],"['f1', 'exact match']",1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,21.0,0.0,1
WebQuestionsSP,,{},[],['PapersWithCode'],[],[],[],['ACL'],[],[],[],['English'],"['Text', 'Code']",['WebQuestionsSP'],[],"['hits@1', 'accuracy', 'f1']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,12.0,0.0,1
WebVid,,{},[],['PapersWithCode'],[],[],[],['ICCV'],[],[],[],['English'],"['Text', 'Video']",['WebVid'],[],['fvd'],1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,1.0,0.0,1
WenetSpeech,,{},[],['PapersWithCode'],[],[],[],['ICASSP'],[],[],[],['Chinese'],"['Text', 'Audio']",['WenetSpeech'],[],['character error rate'],1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,7.0,0.0,1
Whoops,,{},[],['PapersWithCode'],[],[],[],['ICCV'],[],[],[],['English'],"['Text', 'Image']",['Whoops'],[],"['specificity', 'bleu-4', 'cider', 'bem', 'human', 'exact match']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,23.0,0.0,1
WiC,,{},[],['PapersWithCode'],[],[],[],['NAACL'],[],[],[],['English'],['Text'],['WiC'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,2.0,0.0,1
WikiEvents,,{},[],['PapersWithCode'],[],[],[],['AAAI'],[],[],[],['English'],['Text'],['WikiEvents'],[],"['f1', 'head f1', 'auc']",1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,4.0,0.0,1
WikiText-103,,{},[],['PapersWithCode'],[],[],[],['ICLR'],[],[],[],['English'],['Text'],['WikiText-103'],[],"['#parameters', 'validation perplexity', 'test perplexity']",1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,83.0,0.0,1
WikiText-2,,{},[],['PapersWithCode'],[],[],[],['ICLR'],[],[],[],['English'],['Text'],['WikiText-2'],[],"['#parameters', 'validation perplexity', 'test perplexity']",1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,38.0,0.0,1
WinoGrande,,{},[],['PapersWithCode'],[],[],[],['AAAI'],[],[],[],['English'],['Text'],['WinoGrande'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,23.0,0.0,1
WinoGrande,,"{'independent website': ['Rankable Table', 'Scatter Plot']}",['Email'],['independent website'],['independent website'],['independent website'],['Allen Institute for AI'],['AAAI'],[],['Prediction Results'],['Submission Portal'],['English'],['Text'],['WinoGrande'],[],[],1.0,2.0,1.0,1.0,1.0,1.0,0.0,1.0,73.0,0.0,1
Winoground,,{},[],['PapersWithCode'],[],[],[],['CVPR'],[],[],[],['English'],"['Text', 'Image']",['Winoground'],[],"['group score', 'image score', 'text score']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,97.0,0.0,1
WMT (2014),,{},[],['PapersWithCode'],[],[],[],['WMT'],[],[],[],['English'],['Text'],['WMT'],[],"['#parameters', 'sacrebleu', 'hardware burden', 'operations per network pass', 'bleu']",1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,105.0,0.0,1
WNLI,,{},[],['PapersWithCode'],[],[],[],['EMNLP'],[],[],[],['English'],['Text'],['WNLI'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,16.0,0.0,1
WQSP,,{},[],['PapersWithCode'],[],[],[],['ACL'],[],[],[],['English'],['Text'],['WQSP'],[],"['hits@1', 'accuracy', 'f1']",1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,12.0,0.0,1
WSC,,{},[],['PapersWithCode'],[],[],[],['AI Magazine'],[],[],[],['English'],['Text'],['WSC'],[],['accuracy'],1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,18.0,0.0,1
Xiezhi,,{'GitHub': ['Table Screenshot']},[],['GitHub'],[],[],['Fudan University'],['Preprint'],[],[],[],"['English', 'Chinese']",['Text'],['Xiezhi'],[],[],1.0,1.0,1.0,1.0,2.0,1.0,0.0,1.0,32.0,0.0,1
XSUM,,{},[],['PapersWithCode'],[],[],[],['EMNLP'],[],[],[],['English'],['Text'],['XSUM'],[],"['rouge-3', 'rouge-2', 'rouge-l', 'rouge-1']",1.0,0.0,1.0,1.0,1.0,1.0,1.0,0.0,18.0,0.0,1
YALL,,"{'HuggingFace': ['Rankable Table', 'Bar Chart']}",[],"['GitHub', 'HuggingFace']",['HuggingFace'],['GitHub'],['Independent Contributor'],[],['Benchmark'],[],[],['English'],['Text'],"['GPT4All', 'TruthfulQA', 'AGIEval', 'BIG-Bench']",[],[],4.0,2.0,2.0,1.0,1.0,1.0,1.0,1.0,87.0,0.0,1
YouCook2,,{},[],['PapersWithCode'],[],[],[],['AAAI'],[],[],[],['English'],"['Text', 'Video']",['YouCook2'],[],"['bleu-3', 'recall@10', 'mean rank', 'recall@5', 'median rank', 'meteor', 'bleu-4', 'cider', 'recall@1', 'rouge-l']",1.0,0.0,1.0,1.0,1.0,2.0,1.0,0.0,27.0,0.0,1
NLI,,"{'independent website': ['Rankable Table', 'Scatter Plot']}",['Email'],['independent website'],['independent website'],['independent website'],['Allen Institute for AI'],['ICLR'],[],['Prediction Results'],['Submission Portal'],['English'],['Text'],['NLI'],[],[],1.0,2.0,1.0,1.0,1.0,1.0,0.0,1.0,120.0,0.0,1
