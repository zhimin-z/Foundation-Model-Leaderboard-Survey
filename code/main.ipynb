{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jimmy/Documents/GitHub/LLM-Leaderboard-Integration/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from gradio_client import Client\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = Path(\"../data\")\n",
    "path_meta = path_data / \"meta\"\n",
    "\n",
    "task_list = ['Question answering', 'Information retrieval', 'Summarization', 'Translation', 'Text classification', 'Image classification', 'Image generation', 'Video classification', 'Video generation']\n",
    "capability_list = ['Knowledge', 'Reasoning', 'Alignment', 'Safety']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed 'Xiezhi-overall.json' to 'overall.json'\n",
      "Renamed 'Xiezhi-category.json' to 'category.json'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the directory path\n",
    "dataset = \"Xiezhi\"\n",
    "directory = path_data / dataset  # Replace with your directory path\n",
    "path_llm = path_data / 'llm'\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(path_llm):\n",
    "    # if filename.startswith(\"-\"):\n",
    "    if dataset in filename:\n",
    "        if filename == f'{dataset}.json':\n",
    "            new_filename = filename.replace(f\"{dataset}\", \"all\")\n",
    "        # Construct new file name by replacing \"Big_Bench\" with an empty string\n",
    "        else:\n",
    "            new_filename = filename.replace(f\"{dataset}-\", \"\")\n",
    "        # new_filename = filename[1:]\n",
    "\n",
    "        # Full path for the old and new file names\n",
    "        old_file = os.path.join(path_llm, filename)\n",
    "        new_file = os.path.join(directory, new_filename)\n",
    "\n",
    "        # Rename and move the file\n",
    "        shutil.move(old_file, new_file)\n",
    "        print(f\"Renamed '{filename}' to '{new_filename}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/jimmy/Documents/GitHub/LLM-Leaderboard-Integration/data/SEED-Bench/file_result_v2.csv')\n",
    "df.to_json('/Users/jimmy/Documents/GitHub/LLM-Leaderboard-Integration/data/SEED-Bench/all.json', orient='records', indent=4)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = Client(\"https://felixz-open-llm-leaderboard.hf.space/\")\n",
    "# json_data = client.predict(\"\",\"\", api_name='/predict')\n",
    "\n",
    "# with open(json_data, 'r') as file:\n",
    "#     file_data = file.read()\n",
    "#     data = json.loads(file_data)\n",
    "#     df = pd.DataFrame(data['data'], columns=data['headers'])\n",
    "#     df.drop(columns=['Model'], inplace=True)\n",
    "#     df.to_json(path_data / 'Open LLM Leaderboard/all.json', orient='records', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Text-to-Text Generation', 'Text-to-Image Generation', 'Text-to-Code Generation', 'Text-to-Audio Generation', 'Text-to-Video Generation', 'Image-to-Text Generation', 'Code-to-Text Generation', 'Audio-to-Text Generation', 'Video-to-Text Generation', 'Image-to-Image Generation', 'Code-to-Code Generation', 'Audio-to-Audio Generation', 'Video-to-Video Generation',\n",
    "\n",
    "'Code Summarization', 'Code Review', 'Identifier Prediction', 'Defect Detection', 'Clone Detection', 'Code Classification', 'Code Reasoning', 'Document Translation', 'Log Parsing',\n",
    "\n",
    "# 'Image Captioning', 'Sign Language Recognition', 'Emotion Recognition', 'Video Processing', 'Digital Human', 'Multimodality'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels = [\n",
    "#     \"Natural Language Understanding\",\n",
    "#     \"Natural Language Inference\",\n",
    "#     \"Question Answering\",\n",
    "#     \"Summarization\",\n",
    "#     \"Translation\",\n",
    "#     \"Sentiment Analysis\",\n",
    "#     \"Dialogue\",\n",
    "#     \"Text Classification\",\n",
    "#     \"Information Retrieval\",\n",
    "#     \"Knowledge Completion\",\n",
    "#     \"Relation Extraction\",\n",
    "#     \"Ethics and Morality\",\n",
    "#     \"Societal Bias\",\n",
    "#     \"Toxicity\",\n",
    "#     \"Fairness\",\n",
    "#     \"Hallucination\",\n",
    "#     \"Calibration\",\n",
    "#     \"Efficiency\",\n",
    "#     \"Sequence Tagging\",\n",
    "#     \"Coreference Resolution\",\n",
    "#     \"Fact Extraction\",\n",
    "#     \"Multilinguality\",\n",
    "#     \"Hate Detection\",\n",
    "#     \"Recommendation\",\n",
    "#     \"Healthcare\",\n",
    "#     \"Education\",\n",
    "#     \"Honestness\",\n",
    "#     \"Helpfulness\",\n",
    "#     \"Harmlessness\",\n",
    "#     \"Robustness\",\n",
    "#     \"Quality\",\n",
    "#     \"Alignment\",\n",
    "#     \"Aesthetics\",\n",
    "#     \"Originality\",\n",
    "#     \"Fidelity\",\n",
    "#     \"Risk\",\n",
    "#     \"Law\",\n",
    "#     \"Mathematics\",\n",
    "#     \"Social Science\",\n",
    "#     \"Natural Science\",\n",
    "#     \"Finance\",\n",
    "#     \"Engineering\",\n",
    "#     \"Truthfulness\",\n",
    "#     \"Code Reasoning\",\n",
    "#     \"Commonsense Reasoning\",\n",
    "#     \"Knowledge Reasoning\",\n",
    "#     \"Multi-hop Reasoning\",\n",
    "#     \"Logical Reasoning\",\n",
    "#     \"Arithmetic Reasoning\",\n",
    "#     \"Symbolic Reasoning\",\n",
    "#     \"Attribute Reasoning\",\n",
    "#     \"Relation Reasoning\",\n",
    "#     \"Tool Creation\",\n",
    "#     \"Tool Manipulation\",\n",
    "#     \"Robotic Tasks\",\n",
    "#     \"Code Executor\",\n",
    "#     \"Calculator\",\n",
    "#     \"Search Engine\",\n",
    "#     \"Online Shopping\",\n",
    "#     \"Personality Testing\",\n",
    "#     \"Crowd-sourcing Testing\",\n",
    "#     \"Human-in-the-loop\",\n",
    "# ]\n",
    "\n",
    "# labels2 = [\n",
    "#     \"Visual Perception\",\n",
    "#     \"Visual Reasoning\",\n",
    "#     'Visual Knowledge Acquisition',\n",
    "#     \"Visual Commonsense\",\n",
    "#     \"Object Hallucination\",\n",
    "#     \"Embodied Intelligence\",\n",
    "# ]\n",
    "\n",
    "# # \"Open Book\",\n",
    "# # \"Closed Book\",\n",
    "# # 'Single Choice',\n",
    "# # 'Multiple Choice',\n",
    "\n",
    "# benchmark_lvlm_labels = {\n",
    "#     'A-OKVQA': [\n",
    "#         \"Perception\",\n",
    "#         \"Existence\",\n",
    "#         \"Position\",\n",
    "#         \"Color\"\n",
    "#     ],\n",
    "#     'ALFWorld': [\n",
    "#         \"Perception\",\n",
    "#         \"Existence\",\n",
    "#         \"Position\",\n",
    "#         \"Color\"\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "# benchmark_llm_labels = {\n",
    "#     '2WikiMultihopQA': [\n",
    "#         \"Question Answering\",\n",
    "#         \"Multi-hop Reasoning\",\n",
    "#         \"Information Retrieval\",\n",
    "#         \"Knowledge Reasoning\",\n",
    "#         \"Commonsense Reasoning\",\n",
    "#         \"Natural Language Inference\",\n",
    "#         \"Relation Extraction\"\n",
    "#     ],\n",
    "#     'A-OKVQA': [\n",
    "#         \"Question Answering\",\n",
    "#         \"Commonsense Reasoning\",\n",
    "#         \"Knowledge Reasoning\",\n",
    "#         \"Relation Reasoning\"\n",
    "#     ],\n",
    "#     'AFQMC': [\n",
    "#         \"Natural Language Understanding\",\n",
    "#         \"Text Classification\",\n",
    "#         \"Natural Language Inference\",\n",
    "#         \"Commonsense Reasoning\",\n",
    "#         \"Finance\"\n",
    "#     ],\n",
    "#     'AGIEval': [\n",
    "#         \"Natural Language Understanding\",\n",
    "#         \"Question Answering\",\n",
    "#         \"Text Classification\",\n",
    "#         \"Knowledge Reasoning\",\n",
    "#         \"Logical Reasoning\",\n",
    "#         \"Arithmetic Reasoning\",\n",
    "#         \"Multi-hop Reasoning\"\n",
    "#     ],\n",
    "#     'ALFWorld': [\n",
    "#         \"Knowledge Reasoning\",\n",
    "#         \"Relation Reasoning\",\n",
    "#         \"Tool Manipulation\",\n",
    "#         \"Robotic Tasks\",\n",
    "#         \"Commonsense Reasoning\"\n",
    "#     ],\n",
    "#     'AlpacaEval': [\n",
    "#         \"Natural Language Understanding\",\n",
    "#         \"Dialogue\",\n",
    "#         \"Text Classification\",\n",
    "#         \"Information Retrieval\",\n",
    "#         \"Knowledge Completion\",\n",
    "#         \"Helpfulness\",\n",
    "#         \"Robustness\",\n",
    "#         \"Quality\"\n",
    "#     ],\n",
    "#     'Amazon Review': [\n",
    "#         \"Sentiment Analysis\",\n",
    "#         \"Text Classification\",\n",
    "#         \"Information Retrieval\",\n",
    "#         \"Recommendation\",\n",
    "#         \"Summarization\",\n",
    "#         \"Helpfulness\"\n",
    "#     ],\n",
    "#     'ANGO': [\n",
    "        \n",
    "#     ]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values with hyperlinks written to b.xlsx\n"
     ]
    }
   ],
   "source": [
    "# from openpyxl import load_workbook, Workbook\n",
    "\n",
    "# # Path to your Excel file and output file\n",
    "# input_file = 'a.xlsx'\n",
    "# output_file = 'b.xlsx'\n",
    "\n",
    "# # Load the workbook and select the active worksheet\n",
    "# wb = load_workbook(input_file)\n",
    "# ws = wb.active\n",
    "\n",
    "# # Dictionary to store unique values and their hyperlinks\n",
    "# unique_values = {}\n",
    "\n",
    "# # Loop through all cells in the worksheet\n",
    "# for row in ws.iter_rows():\n",
    "#     for cell in row:\n",
    "#         # Check if cell has a value\n",
    "#         if cell.value:\n",
    "#             # Store value and hyperlink (if any)\n",
    "#             unique_values[cell.value] = cell.hyperlink.target if cell.hyperlink else None\n",
    "\n",
    "# # Sort the unique values\n",
    "# sorted_unique_values = sorted(unique_values.items())\n",
    "\n",
    "# # Create a new workbook and select the active worksheet\n",
    "# new_wb = Workbook()\n",
    "# new_ws = new_wb.active\n",
    "\n",
    "# # Write unique values and hyperlinks to the new worksheet\n",
    "# for i, (text, hyperlink) in enumerate(sorted_unique_values, start=1):\n",
    "#     new_ws.cell(row=i, column=1, value=text)\n",
    "#     if hyperlink:\n",
    "#         new_ws.cell(row=i, column=1).hyperlink = hyperlink\n",
    "\n",
    "# # Save the new workbook\n",
    "# new_wb.save(output_file)\n",
    "\n",
    "# print(f\"Unique values with hyperlinks written to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_description_list = {\n",
    "    '2WikiMultihopQA': '2WikiMultihopQA is a dataset for comprehensive evaluation of reasoning steps in multi-hop question answering. The dataset contains questions that require multiple steps of reasoning to answer, and is based on Wikipedia articles. The dataset includes evidence information containing a reasoning path for multi-hop questions.',\n",
    "    'A-OKVQA': 'A-OKVQA is a visual question answering dataset that requires models to draw upon outside knowledge to answer questions. It is composed of approximately 25k questions that require a broad base of commonsense and world knowledge to answer. The questions in the dataset cannot be answered by simply querying a knowledge base, and instead require some form of commonsense reasoning. The dataset includes questions that require reasoning via a variety of knowledge types such as commonsense, world knowledge, and visual knowledge.',\n",
    "    'AFQMC': 'The Ant Financial Question Matching Corpus (AFQMC) is a dataset for semantic similarity in the Chinese language. It is used to evaluate the performance of natural language processing models on tasks such as question matching and paraphrase identification. The dataset contains 16,000 pairs of questions, each labeled with a similarity score ranging from 0 to 5.',\n",
    "    'ALFWorld': 'ALFWorld contains interactive TextWorld environments that parallel embodied worlds in the ALFRED dataset. The aligned environments allow agents to reason and learn high-level policies in an abstract space before solving embodied tasks through low-level actuation.',\n",
    "    'APPS': 'The APPS dataset is a collection of programming problems gathered from various open-access coding websites such as Codeforces, Kattis, and more. The dataset is intended to mimic how human programmers are evaluated by presenting coding problems in unrestricted natural language and assessing the accuracy of solutions.',\n",
    "    'ARC': 'The AI2’s Reasoning Challenge (ARC) dataset is a multiple-choice question-answering dataset that contains questions from science exams from grade 3 to grade 9. The dataset is split into two partitions: Easy and Challenge, where the latter partition contains more difficult questions that require reasoning. Most of the questions have 4 answer choices, and some have 5. The dataset consists of 7,787 science exam questions drawn from a variety of sources, including science questions provided under license by a research partner affiliated with AI2.',\n",
    "    'ARC-DA': 'ARC-DA is a dataset of 2,985 grade-school level, direct-answer (\"open response\", \"free form\") science questions derived from the ARC multiple-choice question set released as part of the AI2 Reasoning Challenge. The questions were filtered based on heuristic filters such as concreteness of the question and confidence in the correctness of the answers. The dataset was built by presenting each of the multiple-choice questions as a direct answer question to five crowdsourced workers to gather additional answers. The questions were then further filtered and modified by volunteers in-house. The dataset is one of the first direct-answer datasets of natural questions that often require reasoning, and where appropriate question decompositions are not evident from the questions themselves.',\n",
    "    'ActivityNet-QA': 'The ActivityNet-QA dataset consists of 58,000 human-annotated QA pairs on 5.8k complex web videos. The dataset provides a benchmark for testing the performance of VideoQA models on long-term spatio-temporal reasoning.',\n",
    "    'AlpacaEval': 'AlpacaEval is an automatic evaluator for instruction-following language models. It is a human-validated, high-quality, cheap, and fast dataset that is particularly useful for model development. The dataset is a simplification of AlpacaFarm’s evaluation set, where \"instructions\" and \"inputs\" are merged into one field, and reference outputs are longer. It is designed to evaluate instruction-following models (e.g., ChatGPT) and is validated against 20K human annotations. The dataset is useful if you have to run quick and cheap proxy for human evaluation of simple instruction-following tasks.',\n",
    "    'Amazon Review': 'Amazon Review Data (2018) is a dataset that contains reviews and ratings of products sold on Amazon. The dataset is available on Kaggle and includes full reviews and ratings for various products. The dataset is useful for sentiment analysis and natural language processing tasks. It includes reviews from four different merchandise categories: Books, DVDs, Electronics, and Kitchen and housewares.',\n",
    "    'AQUA-RAT': 'The AQUA-RAT (Algebra Question Answering with Rationales) Dataset is a collection of approximately 100,000 algebraic word problems with natural language rationales. Each problem is a JSON object consisting of four parts: question, options, rationale, and correct option. The dataset is used to train a program generation model that learns to generate the explanation while generating the program that solves the problem.',\n",
    "    'AR-LSAT': 'AR-LSAT dataset consists of analytical reasoning (AR) problems from the Law School Admission Test (LSAT) from 1991 to 2016. The dataset is used to study the challenge of analytical reasoning of text and to analyze what knowledge understanding and reasoning abilities are required to do well on this task.',\n",
    "    'ArguAna': 'ArguAna is a dataset in the BEIR (Benchmarking Information Retrieval) framework that contains textual data for entity-linking-retrieval and fact-checking-retrieval tasks.',\n",
    "    'BBQ': 'BBQ (Bias Benchmark for QA) is a dataset of question sets constructed by the authors that highlight attested social biases against people belonging to protected classes along nine social dimensions relevant for U.S. English-speaking contexts. The dataset was introduced to evaluate model responses at two levels: (i) given an under-informative context, we test how strongly responses reflect social biases, and (ii) given an adequately informative context, we test whether the model’s biases override a correct answer choice.',\n",
    "    'BIG-Bench': 'BIG-bench is a collaborative benchmark that aims to evaluate and extrapolate the capabilities of large language models. It consists of over 200 tasks that are designed to test the models’ ability to perform a wide range of natural language processing tasks, such as question answering, summarization, and translation.',\n",
    "    'BLiMP': 'BLiMP stands for Benchmark of Linguistic Minimal Pairs. It is a dataset that consists of 67 sub-datasets, each containing 1000 minimal pairs that contrast in grammatical acceptability and isolate specific phenomenon in syntax, morphology, or semantics 123. The data is automatically generated according to expert-crafted grammars. The purpose of this dataset is to evaluate what language models know about major grammatical phenomena in English.',\n",
    "    'BOLD': 'The Bias in Open-ended Language Generation Dataset (BOLD) is a large-scale dataset that consists of 23,679 English text generation prompts for benchmarking biases across five domains: profession, gender, race, religion, and political ideology. The dataset was introduced to systematically study and benchmark social biases in open-ended language generation. It also proposes new automated metrics for toxicity, psycholinguistic norms, and text gender polarity to measure social biases in open-ended text generation from multiple angles.',\n",
    "    'BUSTM': 'BUSTM dataset is a part of the CLUE benchmark. It is a Chinese language dataset that contains short text pairs. The dataset is designed to evaluate the performance of models on dialogue short text matching tasks.',\n",
    "    'Belebele': 'The Belebele dataset is a massively multilingual reading comprehension dataset that spans 122 language variants. It is a multiple-choice machine reading comprehension (MRC) dataset that contains 900 questions per language variant. The dataset is designed to evaluate the performance of mono- and multi-lingual models in high-, medium-, and low-resource languages. Each question has four multiple-choice answers and is linked to a short passage from the FLORES-200 dataset. The human annotation procedure was carefully curated to create questions that discriminate between different levels of generalizable language comprehension and is reinforced by extensive quality checks.',\n",
    "    'BiPaR': 'BiPaR is a bilingual parallel novel-style machine reading comprehension (MRC) dataset that was developed to support multilingual and cross-lingual reading comprehension. It contains 3,667 bilingual parallel paragraphs from Chinese and English novels, from which 14,668 parallel question-answer pairs were constructed via crowdsourced workers following a strict quality control procedure. Each triple (Passage, Question, Answer) in BiPaR is written parallelly in two languages, making it different from existing reading comprehension datasets. The dataset offers good diversification in prefixes of questions, answer types, and relationships between questions and passages. BiPaR requires reading comprehension skills of coreference resolution, multi-sentence reasoning, and understanding of implicit causality, etc.',\n",
    "    'BigPatent': 'BigPatent is a large-scale dataset of.3 million records of U.S. patent documents along with human-written abstractive summaries. It was created to address the limitations of existing summarization datasets, which are mostly compiled from the news domain and have summaries with a flattened discourse structure. In contrast, BIGPATENT summaries contain a richer discourse structure with more recurring entities, salient content is evenly distributed in the input, and lesser and shorter extractive fragments are present in the summaries. The dataset is useful for training and evaluating systems that can understand an article’s global content structure as well as produce abstractive summaries with high compression ratio.',\n",
    "    'BioASQ-QA': 'The BioASQ-QA dataset is a manually curated corpus for biomedical question answering. It is composed of a question, human-annotated answers, and the relevant contexts (also called snippets). The dataset is part of the BioASQ (Biomedical Semantic Indexing and Question Answering) project, which aims to advance the state-of-the-art in biomedical semantic indexing and question answering. The dataset is designed to evaluate the performance of biomedical question answering systems. The dataset is composed of two phases: Phase A and Phase B. Phase A contains 3.7k questions, and the answers are either a document or a snippet. Phase B contains 3.7k questions, and the answers are either a factoid answer, a list of answers, or a yes/no answer.',\n",
    "    'BoolQ': 'The BoolQ dataset is a question answering dataset specifically designed for yes/no questions. It contains 15942 examples. These questions are naturally occurring, meaning they are generated in unprompted and unconstrained settings.',\n",
    "    'Boolean Expressions': 'The Boolean Expressions dataset is a part of the BIG-bench (Beyond the Imitation Game benchmark) project hosted on GitHub. This dataset is designed to test the ability of language models to understand and reason about Boolean expressions. The task involves evaluating Boolean expressions that are composed of the logical operators AND, OR, and NOT, as well as parentheses for grouping. The expressions are generated randomly, and the variables in the expressions can take on the values True or False.',\n",
    "    'Broadcoverage Diagnostics': 'The Broadcoverage Diagnostics dataset is a part of the GLUE benchmark. It is a manually-curated evaluation dataset for fine-grained analysis of system performance on a broad range of linguistic phenomena. This dataset evaluates sentence understanding through Natural Language Inference (NLI) problems.',\n",
    "    'C-Eval': 'The C-Eval benchmark dataset is a comprehensive Chinese evaluation suite designed to assess the advanced knowledge and reasoning abilities of foundation models. The dataset consists of 13,948 multiple-choice questions spanning 52 diverse disciplines and four difficulty levels13. The disciplines range from humanities to science and engineering. The questions are designed to test the model’s understanding of a wide range of topics and its ability to reason about them. In addition to the main C-Eval dataset, there is also a C-Eval Hard subset. This subset includes 8 challenging subjects in math, physics, and chemistry that require advanced reasoning abilities to solve',\n",
    "    'C-SEM': 'The C-SEM dataset is a benchmark dataset for evaluating the semantic understanding abilities of large Chinese language models. Addressing the lack of linguistically oriented benchmarks in this area, C-SEM introduces various levels and difficulties of evaluation data to scrutinize the potential flaws of current models. It focuses on how these models process semantics, drawing parallels to human language cognition.',\n",
    "    'C3': 'C3 is a multiple-choice Chinese machine reading comprehension dataset that contains 13,369 documents and their associated 19,577 multiple-choice free-form questions. The dataset was collected from Chinese-as-a-second language examinations. The dataset is the first of its kind and is designed to test the ability of machine learning models to understand and answer questions based on free-form text in Chinese.',\n",
    "    'CAIL': '''The CAIL (Chinese AI and Law) dataset, specifically CAIL2018, is a pioneering large-scale Chinese legal dataset aimed at facilitating judgment prediction research. It contains over 2.6 million criminal cases, which were published by the Supreme People's Court of China. This makes it significantly larger than other datasets previously available in the field of legal judgment prediction. Its considerable size and focus on Chinese legal cases make it a unique and valuable resource for research in artificial intelligence applications within the legal domain, particularly in the context of the Chinese legal system''',\n",
    "    'CBBQ': 'The CBBQ dataset is a Chinese bias benchmark dataset that consists of over 100,000 questions jointly constructed by human experts and generative language models. The dataset covers stereotypes and societal biases in 14 social dimensions related to Chinese culture and values. The curation process contains 4 essential steps: bias identification via extensive literature review, ambiguous context generation, AI-assisted disambiguous context generation, and manual review & recomposition. The testing instances in the dataset are automatically derived from 3,000+ high-quality templates manually authored with stringent quality control.',\n",
    "    'CCBench': 'The CCBench dataset is a multi-modal benchmark specifically focused on the domain of Chinese culture. It was introduced as a new benchmark in 2023 and is an extension of the MMBench benchmark. The CCBench dataset is designed to evaluate multi-modal models, particularly in the context of their understanding and interpretation of aspects related to Chinese culture. While I was unable to find detailed information regarding the specific contents and structure of the dataset, it is clear that it serves as a specialized tool for assessing the performance of AI models in handling culturally-specific multimodal data, especially those pertaining to Chinese traditions and contexts',\n",
    "    'CDial-Bias': 'The CDial-Bias Dataset is a unique resource specifically designed to measure social bias in dialog scenarios. It was created to address the subtleties and subjective nature of biased utterances in dialogues. The dataset, which is a part of a larger effort to identify social bias in dialogue systems, includes well-annotated training data that covers aspects like context-sensitivity, data-type, targeted group, and implied attitudes.',\n",
    "    'CG-Eval': 'The CG-Eval dataset is a comprehensive benchmark designed to evaluate the generation capabilities of large Chinese language models across various academic disciplines. It covers six major academic disciplines, including Science and Engineering, Humanities and Social Sciences, Mathematics, Medical Qualification Exam, Judicial Examination, and Certified Public Accountant Exam, encompassing 55 sub-disciplines within these categories. The dataset includes over 11,000 questions of various types, for which the models are expected to provide precise and pertinent answers. CG-Eval utilizes a composite scoring system, with standard reference answers for non-computational questions and a detailed evaluation of both the final results and the problem-solving process for computational questions.',\n",
    "    'CHID': '''The CHID dataset, standing for \"Chinese IDiom Dataset for Cloze Test,\" is a large-scale dataset specifically designed for cloze-style tests in Chinese. It consists of 581,000 passages that contain a total of 729,000 blanks, encompassing a wide range of domains. In these passages, idioms are deliberately replaced with blank symbols. The dataset challenges the ability of models to understand and predict idioms in context, a unique aspect of the Chinese language. To complete the test, a list of passages is provided, and the correct idioms must be selected from a set of given candidates with a fixed length. This dataset not only includes the passages and their associated blanks but also offers training data and answers, making it a comprehensive resource for enhancing cloze test-related research in Chinese language processing.''',\n",
    "    'CIFAR-10': 'The CIFAR-10 dataset (Canadian Institute For Advanced Research) is a collection of images that are commonly used to train machine learning and computer vision algorithms. It is one of the most widely used datasets for machine learning research. The CIFAR-10 dataset contains 60,000 32x32 color images in 10 different classes.',\n",
    "    'CJRC': '''The CJRC (Chinese Judicial Reading Comprehension) dataset is a substantial collection specifically designed for legal research in the Chinese language. It comprises approximately 10,000 documents and nearly 50,000 questions with answers. The documents included in the dataset are derived from judicial judgment documents. These questions are expertly annotated by law professionals, ensuring their relevance and accuracy in the context of legal studies. This dataset is particularly valuable for research in the field of reading comprehension technology, especially in its application to legal documents. It enables researchers to test and enhance machine reading comprehension capabilities, specifically tailored for the legal domain. The CJRC dataset is a significant resource for developing and evaluating AI models' ability to understand and process legal texts.''',\n",
    "    'CLEVR': 'The CLEVR dataset is a diagnostic dataset for compositional language and elementary visual reasoning. It is used to test a range of visual reasoning abilities and contains minimal biases. The dataset has detailed annotations describing the kind of reasoning each question requires. It is used to analyze a variety of modern visual reasoning systems, providing novel insights into their abilities and limitations. Additionally, it contains a Compositional Generalization Test (CoGenT) that tests the ability of models to recognize novel combinations of attributes at test-time.',\n",
    "    'CLEVRER': '''The CLEVRER dataset, short for CoLlision Events for Video REpresentation and Reasoning, is a diagnostic video dataset designed for the systematic evaluation of computational models on a variety of reasoning tasks. It was created with the intention of providing a controlled and well-annotated environment to facilitate the assessment of logic reasoning in both temporal and causal domains. CLEVRER is unique in that it focuses on simplicity and minimal biases in visual scenes and language, ensuring that the tasks are purely logic-based. This dataset includes four types of questions: descriptive (e.g., \"what color\"), explanatory (\"what's responsible for\"), predictive (\"what will happen next\"), and counterfactual reasoning. The goal of these questions is to probe the models' abilities in different aspects of reasoning, including description, explanation, prediction, and counterfactual analysis. The design and structure of CLEVRER make it a pioneering dataset for neuro-symbolic reasoning in the realm of artificial intelligence, providing a comprehensive tool for evaluating and enhancing computational models' reasoning capabilities​.''',\n",
    "    'CLUE diagnostics': '''The CLUE (Chinese Language Understanding Evaluation) diagnostics dataset is a comprehensive tool designed for evaluating and analyzing the performance of Chinese language models. This dataset is part of the broader CLUE benchmark, which is akin to the GLUE benchmark in English. It serves as a specialized resource for diagnosing the strengths and weaknesses of models in various aspects of language understanding. The CLUE diagnostics dataset includes a range of linguistic tasks and challenges, designed to thoroughly test different facets of language comprehension, such as syntax, semantics, context understanding, and more. By providing detailed performance metrics across these areas, the CLUE diagnostics dataset helps researchers and developers identify specific areas for improvement in Chinese language models, ultimately contributing to the advancement of natural language processing technologies in the Chinese context.''',\n",
    "    'CLUEWSC': 'The CLUEWSC (CLUE Winograd Scheme Challenge) 2020 dataset is a specialized subset of the broader CLUE (Chinese Language Understanding Evaluation) benchmark, which is designed to evaluate natural language understanding (NLU) in Chinese. While CLUE itself encompasses various NLU datasets spanning single-sentence and sentence-pair classification tasks, machine reading comprehension, and other tasks on Chinese text​​, CLUEWSC 2020 specifically focuses on the challenge of coreference resolution. In CLUEWSC 2020, the primary task is to determine which noun a given pronoun in a sentence refers to. The dataset consists of texts sourced from contemporary literature, which have been annotated by human experts. The format of the questions is centered around true or false discrimination, requiring the model to discern the correct referent of a pronoun within a sentence. This specific focus makes CLUEWSC 2020 an important tool for assessing the understanding of pronoun-noun relationships in Chinese language models, a crucial aspect of language understanding and processing​',\n",
    "    'CLiB': 'The CLiB dataset is a comprehensive leaderboard for evaluating the capabilities of large Chinese language models. The evaluation in CLiB covers multiple dimensions of model capabilities, including classification ability, information extraction ability, reading comprehension ability, and table question-answering ability.',\n",
    "    'CMMLU': '''The CMMLU (Chinese Massive Multitask Language Understanding) dataset is a comprehensive evaluation benchmark specifically designed to assess the knowledge and reasoning abilities of language models within the Chinese language and cultural context. It encompasses a wide array of subjects, covering 67 topics that range from elementary to advanced professional levels. This includes natural sciences requiring calculation and reasoning, humanities and social sciences requiring knowledge, as well as practical knowledge like Chinese driving rules.''',\n",
    "    'CMNLI': '''The CMNLI dataset, part of the Chinese Language Understanding Evaluation (CLUE) benchmark, is a Chinese version of the Natural Language Inference (NLI) task, focusing on assessing the capability of models to understand and infer relationships between sentences. It is composed of two parts: XNLI and MNLI, and includes a variety of data sources such as fiction, telephone, travel, government, and slate.''',\n",
    "    'CMRC2018': '''The CMRC 2018 (Chinese Machine Reading Comprehension 2018) dataset, introduced by Cui et al., is a specialized dataset designed for evaluating Chinese machine reading comprehension. It features a collection of nearly 20,000 questions that have been carefully annotated by human experts. A notable aspect of this dataset is the inclusion of a challenging set of questions that require reasoning over multiple clues to answer. This characteristic makes CMRC 2018 particularly valuable for assessing the depth and complexity of machine reading comprehension models, especially in their ability to handle nuanced and multifaceted queries in the Chinese language​.''',\n",
    "    'CNN/Daily Mail': '''The CNN/Daily Mail summarization dataset is a widely used resource for text summarization research. It consists of news articles from the CNN and Daily Mail websites, accompanied by human-generated abstractive summary bullets. These summaries are created in a unique format where questions are formulated with one of the entities hidden, and the system is expected to fill in the blank based on the corresponding news story. The dataset includes over 300,000 unique English-language news articles.''',\n",
    "    'COCO-Text': '''The COCO-Text dataset is a specialized resource for text detection and recognition within natural images. It's an extension of the MS COCO dataset, which is renowned for its complex everyday scene images. COCO-Text aims to advance the state-of-the-art in text detection and recognition by providing a large-scale dataset specifically focused on scene text. The dataset includes various types of images, such as those with non-text, legible text, and illegible text. The dataset is structured to support a variety of text-related tasks, including End-To-End Recognition, Cropped Word Recognition, and Text Localization.''',\n",
    "    'COLDataset': '''COLDataset is a dataset that facilitates Chinese offensive language detection and model evaluation. It contains 37,480 comments with binary offensive labels and covers diverse topics of race, gender, and region. The test set is annotated at a fine-grained level with four categories: attacking individuals, attacking groups, anti-bias, and other non-offensive.''',\n",
    "    'COPA': '''Choice of Plausible Alternatives (COPA) is a benchmark dataset that evaluates the ability of machine learning models to transfer commonsense reasoning across languages. Each question is composed of a premise and two alternatives, where the task is to select the alternative that more plausibly has a causal relation with the premise. The COPA evaluation provides researchers with a tool for assessing progress in open-domain commonsense causal reasoning.''',\n",
    "    'COPEN': '''The COPEN dataset is a conceptual knowledge probing benchmark designed to evaluate the conceptual understanding capabilities of Pre-trained Language Models (PLMs). it consists of three specific tasks: Conceptual Similarity Judgment (CSJ): This task involves presenting a query entity along with several candidate entities. The PLM's job is to select the candidate entity that is most conceptually similar to the query entity. Conceptual Property Judgment (CPJ): In this task, the PLM is given a statement that describes a property of a concept. The model must then determine whether this statement is true. Conceptualization in Contexts (CiC): This task requires a PLM to analyze a sentence that mentions an entity and is provided with several concept chains of the entity. The model must then choose the most appropriate concept for the entity based on the context of the sentence.''',\n",
    "    'CORGI-PM': '''CORGI-PM is a Chinese cOrpus foR Gender bIas Probing and Mitigation, which contains 32.9k sentences with high-quality labels derived by following an annotation scheme specifically developed for gender bias in the Chinese context.''',\n",
    "    'CQADupStack': '''CQADupStack is a benchmark dataset for community question-answering (cQA) research. It contains threads from twelve StackExchange subforums, annotated with duplicate question information and comes with pre-defined training, development, and test splits, both for retrieval and classification experiments.''',\n",
    "    'CRASS': '''The CRASS benchmarks aims to develope a new test suite for the evaluation of the performance of current large language models (LLMs) by utilizing so called questionized counterfactual conditionals (QCC). The data consists of so called PCTs (Premise-Counterfactual Tuples). They contrast a hypothetical situation using a counterfactual conditional against a base premise. In the fixed target mode the task of the model is to decide which answer is correct. In the open scoring mode the model has to give an answer to the PCT which in turn is judged by human annotators as correct or incorrect.''',\n",
    "    'CSL': '''CSL is a large-scale Chinese scientific literature dataset that contains the titles, abstracts, keywords, and academic fields of 396k papers.''',\n",
    "    'CSNLI': '''The Chinese-SNLI dataset is a large-scale Chinese nature language inference and semantic similarity calculation dataset. It was created by translating and partially correcting an English dataset, and it can help alleviate the lack of Chinese natural language inference and semantic similarity calculation datasets''',\n",
    "    'CUAD': '''The Contract Understanding Atticus Dataset (CUAD) is a dataset of legal contracts with rich expert annotations. It is a corpus of 13,000+ labels in 510 commercial legal contracts that have been manually labeled under the supervision of experienced lawyers to identify 41 types of legal clauses that are considered important in contact review in connection with a corporate transaction, including mergers & acquisitions, etc.''',\n",
    "    'Cute80': '''Cute80 dataset is a public dataset that can be used for text detection in images. It consists of 80 high-resolution images with 288 cropped text instances.''',\n",
    "    'CWQ': '''The ComplexWebQuestions (CWQ) dataset is a collection of complex questions that require reasoning over multiple web snippets. It contains a large set of complex questions in natural language, and can be used in multiple ways: 1) By interacting with a search engine, which is the focus of our paper; 2) As a reading comprehension task: we release 12,725,989 web snippets that are relevant for the questions, and were collected during the development of our model; 3) As a semantic parsing task: each question is paired with a SPARQL query that can be executed against Freebase to retrieve the answer.''',\n",
    "    'CUB-200-2011': '''The Caltech-UCSD Birds-200-2011 (CUB-200-2011) dataset is a collection of images of birds that is widely used for fine-grained visual categorization tasks. Each image has detailed annotations such as 1 subcategory label, 15 part locations, 312 binary attributes, and 1 bounding box. The dataset is suitable for object recognition or attribute recognition tasks.''',\n",
    "    'Charades-STA': '''The Charades-STA dataset is an enhanced version of the original Charades dataset, specifically designed for video captioning and temporal localization tasks. It includes 9,848 short video clips that depict a variety of daily indoor activities such as brushing teeth and cooking. This dataset stands out by incorporating sentence temporal annotations to the original Charades videos, effectively extending its utility for more complex language and video processing tasks. In Charades-STA, each video is accompanied by sentence-level temporal annotations, creating a rich source of data for training and testing models in accurately associating textual descriptions with specific moments in a video. The dataset contains 12,408 moment-sentence pairs in the training set and 3,720 pairs in the testing set. The format of these annotations typically includes the video name, the start and end times of the action within the video, and the corresponding sentence description. This structured approach allows for advanced applications in video analysis, such as the development of models capable of localizing specific activities in a video based on textual queries. Charades-STA's focus on daily indoor activities, combined with its detailed temporal and linguistic annotations, makes it an invaluable resource for research in video captioning, natural language processing, and temporal activity localization.''',\n",
    "    'Chatbot Arena Conversations': '''The Chatbot Arena Conversations dataset comprises 33,000 crowd-sourced conversations, each annotated with human preferences. These conversations were collected from the Chatbot Arena platform between April and June 2023, involving interactions with various chatbot models. Key features of the dataset include detailed information for each conversation, such as the names of the two AI models involved, the full text of the conversation, the user's vote, anonymized user ID, the detected language, moderation tags (including the OpenAI moderation API tag and an additional toxic tag), and a timestamp. Efforts were made to exclude conversations containing personally identifiable information, and the dataset includes flagged inappropriate conversations, which can be critical for researchers studying safety-related aspects of LLMs.''',\n",
    "    'ChineseSquad': '''The ChineseSquad dataset is a Chinese machine reading comprehension dataset created by translating and manually correcting the original Squad dataset into Chinese. This dataset was developed to address the limitations of existing Chinese reading comprehension datasets, which were either too small or too focused on specific domains.''',\n",
    "    'CivilComments': '''The CivilComments dataset is derived from the Civil Comments platform, a commenting plugin used on about 50 English-language news sites worldwide. The dataset is known for its use in the Jigsaw Unintended Bias in Toxicity Classification and features a large collection of comments, approximately 2 million, which are useful for understanding the nuances and challenges of online discourse. The dataset serves as a benchmark for toxic comment classification, helping to advance research in detecting toxic comments on social media, which is crucial for content moderation.''',\n",
    "    'Climate-FEVER': '''CLIMATE-FEVER is a publicly available dataset that aims to verify climate change-related claims. It consists of 1,535 real-world claims collected from the internet and each claim is accompanied by five manually annotated evidence sentences retrieved from the English Wikipedia that support, refute or do not give enough information to validate the claim. The dataset was created to facilitate and encourage work on improving algorithms for retrieving evidential support for climate-specific claims, addressing the underlying language understanding challenges, and ultimately help alleviate the impact of misinformation on climate change.''',\n",
    "    'CoLA': '''The Corpus of Linguistic Acceptability (CoLA) is a specialized dataset comprising 10,657 sentences extracted from 23 linguistics publications. These sentences have been expertly annotated for acceptability (grammaticality) by their original authors. The primary aim of CoLA is to provide a resource for training and evaluating natural language processing models, particularly in the area of grammatical acceptability judgments. The public version of CoLA includes 9,594 sentences designated for training and development purposes, while excluding 1,063 sentences that are part of a held-out test set. This dataset serves as a valuable tool for researchers in the field of computational linguistics, offering a rich set of examples to improve and assess the grammatical understanding capabilities of various language models​''',\n",
    "    'CoQA': '''CoQA is a large-scale dataset for building Conversational Question Answering systems. The dataset contains 127,000+ questions with answers collected from 8000+ conversations. Each conversation is collected by pairing two crowdworkers to chat about a passage in the form of questions and answers. The unique features of CoQA include 1) the questions are conversational; 2) the answers can be free-form text; 3) each answer also comes with an evidence subsequence highlighted in the passage; and 4) the passages are collected from seven diverse domains.''',\n",
    "    'CodeU': '''The CodeU dataset is a part of the L-Eval evaluation suite for long context language models. It is designed to test the capability of understanding long code by calling some functions defined in a lengthy codebase and inferring the final output of the program. The dataset mainly uses source code from Numpy and also includes a string processing codebase containing more than 100 functions that take a string as input. To prevent language models from answering the question based on their parametric knowledge, the original function names defined in Numpy are replaced with Op1, Op2..., OpN.''',\n",
    "    'CommitmentBank': '''The CommitmentBank is a corpus of 1,200 naturally occurring discourses whose final sentence contains a clause-embedding predicate under an entailment canceling operator (question, modal, negation, antecedent of conditional). The dataset is designed to investigate projection in naturally occurring discourse.The dataset provides information on the target sentence, context, prompt, verb, embedding, factivity, modal type, tense of the matrix verb, genre, and projection judgments to the prompt using a 7-point Likert scale.''',\n",
    "    'CSP': '''The Common Syntactic Processes (CSP) dataset is a collection of sentences that have been annotated with their syntactic structure. The dataset was created to help researchers develop and evaluate models for natural language processing tasks such as parsing, part-of-speech tagging, and dependency parsing. The CSP dataset contains sentences from a variety of sources, including news articles, Wikipedia, and web forums. The sentences are annotated using the Universal Dependencies (UD) scheme, which provides a consistent way of representing the syntactic structure of sentences across languages.''',\n",
    "    'CommonGen': '''CommonGen is a benchmark dataset that tests machines for the ability of generative commonsense reasoning. It is a constrained text generation task that requires generating a coherent sentence describing an everyday scenario using a set of common concepts. The dataset consists of 79k commonsense descriptions over 35k unique concept-sets and is constructed through a combination of crowdsourced and existing caption corpora.''',\n",
    "    'CommonMT': '''CommonMT is a dataset used to evaluate neural machine translation models’ ability to reason about common sense. It contains three types of test suites: lexical ambiguity, contextless syntactic ambiguity, and contextual syntactic ambiguity.''',\n",
    "    'CommonSenseQA': '''The CommonsenseQA dataset is a multiple-choice question-answering dataset designed to test commonsense knowledge. Introduced in 2019, it consists of 12,102 questions, each accompanied by one correct answer and four distractor answers. The dataset requires a variety of commonsense knowledge types for accurate prediction of the correct answers. It has been designed to be challenging, aiming to advance the capabilities of AI systems in understanding and applying commonsense knowledge in a question-answering context.''',\n",
    "    'CooridinateAI': '''The CooridinateAI dataset is specialized and focused on evaluating the willingness of AI models to coordinate with other systems. It is primarily concerned with safety and trustworthiness, under the sub-dimension of potential risks, and is designed for tasks in Question Answering in the Chinese language. The dataset is relatively small, comprising 1080 questions in the training set. These questions are designed to assess whether a model would cooperate with other AI systems to achieve its objectives, such as avoiding safety failures. his structure allows researchers to gauge how AI models make decisions in scenarios involving coordination and ethics, particularly in contexts where safety and reliability are paramount.''',\n",
    "    'Corrigible': '''The Corrigible dataset is designed to evaluate the alignment of large language models (LLMs) with human values, specifically focusing on being helpful, honest, and harmless. The dataset is in Chinese and is used for tasks in the area of Question Answering. The main goal of the Corrigible dataset is to test whether LLMs are more inclined to align with human values.''',\n",
    "    'CosmosQA': '''The CosmosQA dataset is a large-scale collection of 35.6K problems specifically designed for assessing commonsense-based reading comprehension. The dataset is structured in a multiple-choice question format. Its primary focus is on \"reading between the lines\", requiring the ability to understand and reason about everyday narratives. It poses questions about the likely causes or effects of events, which demand reasoning beyond the explicit text provided in the context. This unique approach in CosmosQA is geared towards evaluating the ability to infer and deduce information that isn't directly stated, a key aspect of commonsense reasoning. By using a diverse range of real-world narratives, CosmosQA challenges models to understand and interpret various situations, drawing conclusions that rely on a deeper understanding of the world, rather than relying solely on textual evidence.''',\n",
    "    'Coursera': '''The Coursera dataset is a part of the L-Eval evaluation suite for long context language models. It originates from the Coursera website and includes four public courses related to big data and machine learning. The input long document is the subtitles of the videos, and questions and ground truth answers are labeled by the authors. The instruction style of Coursera takes the format of multiple choice, and to increase the difficulty of the task, multiple correct options are set.''',\n",
    "    'CrimeKgAssitant': '''CrimeKgAssitant is a crime assistant that includes crime type prediction and crime consult service based on NLP methods and crime KG. It contains 856 items of crime knowledge graph, based on 2.8 million crime training libraries for crime prediction, 13 categories of question classification and legal information Q&A function based on 200,000 legal Q&A pairs. The project aims to provide intelligent solutions for legal intelligence by utilizing existing big data, machine learning/deep learning, and natural language processing technologies. The project has two main directions: 1) Collecting relevant data based on crime names, building a basic crime knowledge graph, legal information dialogue knowledge base, and case sentencing knowledge base. 2) Completing the following four aspects of work based on the results of step 1: Crime prediction model based on case sentencing knowledge base, legal question type classification based on legal consultation dialogue knowledge base, legal question automatic Q&A service based on legal consultation dialogue knowledge base, and knowledge query based on crime knowledge graph.''',\n",
    "    'Criminal': '''The Criminal dataset is a collection of criminal cases used for charge prediction tasks. The dataset is preprocessed and randomly selected to construct three different datasets with different scales denoted as Criminal-S (small), Criminal-M (medium), and Criminal-L (large). The three datasets contain the same number of charges but different numbers of cases. The dataset includes various attributes such as profit purpose, buying and selling behavior, death, violence, state organ, public place, illegal possession, physical injury, intentional crime, and production. The proposed model in the PDF file achieves significant improvements over other state-of-the-art baselines in charge prediction tasks.''',\n",
    "    'CrowS-Pairs': '''CrowS-Pairs is a challenge dataset that measures social biases in masked language models. The dataset consists of 1508 examples that cover stereotypes dealing with nine types of bias, such as race, religion, and age. In each example, a model is presented with two sentences: one that is more stereotyping and another that is less stereotyping. The data focuses on stereotypes about historically disadvantaged groups and contrasts them with advantaged groups.''',\n",
    "    'DBPedia': '''DBpedia is a crowd-sourced community effort to extract structured content from various Wikimedia projects, including Wikipedia. The project aims to provide a comprehensive and structured knowledge graph that can be used by anyone on the web. The DBpedia dataset is a large multi-domain ontology derived from Wikipedia that describes millions of “things” with “facts”. DBpedia allows users to semantically query relationships and properties of Wikipedia resources, including links to other related datasets.''',\n",
    "    'DDM': '''The Driving Decision-Making (DDM) dataset is a collection of diverse YouTube driving videos depicting complex traffic situations and accidents. The dataset is used to challenge Video-LLMs to comprehend the origins of these complex traffic situations or accidents and make correct decisions to prevent their occurrence. The task demands a higher level of scene understanding and decision-making ability, making it a more intricate task than the driver's license examination. The videos are manually annotated for scene analysis and accident causes, and the expectation is that the model can effectively comprehend the complex scenarios and make informed decisions.''',\n",
    "    'DLE': '''The Driver's License Examination (DLE) dataset is a collection of video-based questions that assess the ability of candidates to interpret simple animations depicting motor vehicle and driver status, requiring judgments of potential anomalies. The task challenges Video-LLMs to comprehend scenarios and answer exam questions, which is a less intricate task than the Driving Decision-Making dataset. The expectation is that the model can effectively comprehend the scenarios and answer the questions correctly. ''',\n",
    "    'DRCD': '''The Delta Reading Comprehension Dataset (DRCD) is an open-domain traditional Chinese machine reading comprehension (MRC) dataset. It was created to serve as a standard benchmark for Chinese MRC, with the additional goal of being a valuable source dataset for transfer learning. The DRCD contains a substantial amount of data sourced from Wikipedia, including 10,014 paragraphs from 2,108 articles. Alongside these textual contents, the dataset includes over 30,000 questions that have been generated by annotators. This extensive collection of paragraphs and questions makes the DRCD a significant resource for developing and testing machine reading comprehension models, specifically for traditional Chinese.''',\n",
    "    'DROP': '''The Discrete Reasoning Over Paragraphs (DROP) dataset is a challenging benchmark specifically designed to evaluate the ability of systems to perform discrete reasoning over text. It was created through a crowdsourced, adversarially-driven approach and comprises 96,000 Question and Answer pairs (QAs) distributed over 6,700 paragraphs. DROP is distinct in its focus on discrete reasoning, requiring systems to not only understand the content of paragraphs but also to perform specific operations such as addition, counting, or sorting. These tasks necessitate a deeper comprehension of text than what was previously required in standard reading comprehension benchmarks. This dataset is pivotal in highlighting the limitations of current systems and pushing forward the development of more advanced natural language processing technologies.''',\n",
    "    # 'Data imputation': '''''',\n",
    "    'Demographic Stereotypes': '''Demographic Stereotypes dataset is a set of simple user prompts (\"A photo of the face of…\") that generate images perpetuating dangerous racial, ethnic, gendered, class, and intersectional stereotypes.''',\n",
    "    'DocRED': '''DocRED (Document-Level Relation Extraction Dataset) is a relation extraction dataset constructed from Wikipedia and Wikidata. Each document in the dataset is human-annotated with named entity mentions, coreference information, intra- and inter-sentence relations, and supporting evidence. The dataset contains 132,375 entities and 56,354 relational facts annotated on 5,053 Wikipedia documents. DocRED requires reading multiple sentences in a document to extract entities and infer their relations by synthesizing all information of the document.''',\n",
    "    'DocVQA': '''The DocCVQA (Document Collection Visual Question Answering) dataset is a unique dataset designed for the task of Visual Question Answering (VQA) over a collection of scanned documents. It comprises a vast collection of 14,362 scanned documents, over which various questions are posed. The primary goal of this dataset is not just to provide answers to the questions asked but also to retrieve a set of documents that contain the necessary information to formulate these answers.''',\n",
    "    'DuReader': '''DuReader is a large-scale real-world Chinese dataset for Machine Reading Comprehension (MRC) and Question Answering (QA). The dataset consists of 200K questions, 420K answers and 1M documents. All questions in the dataset are sampled from real anonymized user queries, and the evidence documents, from which answers are derived, are extracted from the web and Baidu Zhidao using Baidu search engine. The dataset is designed to address real-world MRC and focuses on real-world open-domain question answering.''',\n",
    "    'Dyck Languages': '''The Dyck Languages task aims to evaluate the task of language models to process and encode hierarchical information. We structure the task as a conditional-generation challenge, where the model is required to predict the sequence of closing parentheses for a D3 word, omitting its last few closing parentheses. This setup provides a clear and focused framework for assessing the hierarchical information processing abilities of language models.''',\n",
    "    'EPRSTMT': 'The EPRSTMT dataset, part of the FewCLUE benchmark, stands for \"E-commerce Product Review Dataset for Sentiment Analysis.\" This dataset is a binary sentiment analysis dataset that has been specifically developed for evaluating the performance of models in few-shot learning scenarios. It is constructed from product reviews collected from e-commerce platforms. Each review in the dataset is labeled as either Positive or Negative, providing a clear binary classification task for sentiment analysis. The inclusion of EPRSTMT in this benchmark aims to assess the ability of models to understand and analyze consumer sentiments expressed in online product reviews, a task that is increasingly relevant in the context of e-commerce and online retail​.',\n",
    "    'ETA': 'The Evolving Test of Applying (ETA) dataset is a unique dataset designed to evaluate the multi-hop reasoning capabilities of large language models (LLMs), particularly in the realm of applying world knowledge. The ETA dataset focuses on the joint reasoning between text and a knowledge base. However, unlike other datasets that emphasize explicit reasoning from direct information, ETA emphasizes implicit reasoning, a more challenging and nuanced form of inference. The dataset comprises 49 questions that are developed from 350 annotated knowledge triplets and 40 articles, all part of an evolving data set. This structure enables a dynamic and comprehensive assessment of LLMs in their ability to understand and apply complex, multi-step reasoning with evolving information, making it a valuable tool for understanding the depth and adaptability of reasoning skills in AI models.',\n",
    "    'ETC': '''The Evolving Test of Creating (ETC) dataset is designed to evaluate the knowledge creation ability of language models, particularly focusing on their capacity for knowledge-grounded text generation. The ETC dataset primarily targets the generation of narrative texts, such as history, news, and fiction, where the essence of creativity is encapsulated in the ability to describe subsequent events innovatively and coherently. To evaluate this creative aspect, the dataset focuses on the model’s capability to hallucinate event knowledge in the generated texts.''',\n",
    "    'ETM':'''The Evolving Test of Memorization (ETM) dataset is a unique component of a broader project aimed at evaluating knowledge memorization in large language models (LLMs). It is specifically designed to assess how well these models can recall and apply knowledge that is not explicitly derived from previously available data sources. The ETM dataset is constructed by identifying and annotating knowledge triplets within articles from evolving data sources. These triplets represent newer or less conventional information that challenges the LLMs' ability to adapt and incorporate recent or less frequent knowledge. Unlike the other test sets in the project, which focus on high-frequency and low-frequency knowledge from established datasets like Wikidata5M and Wikipedia, the ETM dataset emphasizes the importance of understanding and retaining newly emerging information. It consists of 100 such carefully selected triplets, ensuring a rigorous test of the LLMs' capacity to evolve and assimilate current information, thereby providing a dynamic and challenging measure of their memorization and learning capabilities.''',\n",
    "    'EKC': '''The Encyclopedic Knowledge Creation (EKC) dataset is designed to evaluate the knowledge creation ability of models, particularly in the context of knowledge-grounded text generation tasks. This ability is considered the highest level in Bloom's Cognitive Taxonomy. The EKC dataset primarily focuses on the generation of narrative texts, such as history, news, and fiction, where the essence of creativity is encapsulated in the description of subsequent events. To evaluate a model's ability to creatively generate event knowledge, the EKC dataset employs a methodology of fine-grained event annotations. These annotations are performed on a diverse array of texts, including Wikipedia articles and articles from evolving datasets. By utilizing this framework, the EKC dataset aims to provide a robust and comprehensive means of assessing how effectively language models can innovate and create new knowledge, especially in the realm of text generation. The assessment is grounded in the model's capability to hallucinate or invent event knowledge in the texts it generates, thereby offering insights into the model's creative capacities in narrative construction and knowledge synthesis.''',\n",
    "    'EntityMatching': '''The EntityMatching benchmark dataset is designed to evaluate the ability of systems to reason about whether two structured entities from different tables (or relations) represent the same entity. This task is a crucial component of data cleaning pipelines, particularly in the context of integrating relations from various sources where near-duplicate records of the same entity are common. The matches typically involve entities with minor textual variations, such as misspellings, nicknames, or formatting differences, whereas non-matches exhibit more significant textual disparities. This benchmark is critical in the realm of entity resolution and data integration, testing the limits of algorithms in identifying equivalencies amid textual and format inconsistencies.''',\n",
    "    ###### this is the breaking point!!!\n",
    "    'FActScore': '''FActScore benchmark is a new evaluation method for assessing the factuality of long-form text generated by language models (LMs). Its main goal is to provide a more nuanced and comprehensive evaluation of LMs' factual precision, specifically in people biographies. The defining feature of FACTSCORE is that it breaks down a generation into a series of atomic facts and computes the fraction of facts supported by a given knowledge source. This allows for a more granular evaluation of LMs' factuality, as opposed to binary judgments of whether a generation is true or false. In addition to factual precision, FACTSCORE also aims to evaluate other aspects of long-form text generation, such as fluency, coherence, relevance, consistency, and creativity. However, these aspects are considered out of scope for the current paper. To evaluate LMs' factual precision using FACTSCORE, the authors first performed extensive human evaluation, finding that commercial, state-of-the-art LMs make a substantial amount of errors. They then proposed a model that estimates FACTSCORE, allowing for automatic evaluation. The estimator is based on retrieval over a knowledge source and competitive language models, and it estimates FACTSCORE close to the ground truth.''',\n",
    "    'FELM': '''The FELM benchmark is a comprehensive tool for evaluating the factuality of large language models (LLMs). Its main goal is to provide a standardized and rigorous evaluation methodology for LLMs' factuality detection abilities across five diverse domains: world knowledge, science and technology, math, writing and recommendation, and reasoning. FELM differs from other factuality evaluation tools in that it takes a more holistic approach to factuality evaluation, encompassing a wider range of domains and tasks. It also uses a four-step process to construct the benchmark, which includes gathering prompts from various sources, collecting corresponding responses from ChatGPT, segmenting the responses into fine-grained text spans, and asking human annotators to annotate the factuality label, error type, error reason, and reference links used to make the judgment. The specific aspects of machine learning models that FELM aims to test and evaluate include their ability to accurately detect factual errors in text, their performance when augmented with different techniques such as external evidence and chain-of-thought reasoning, and their overall ability to perform tasks in varied settings. Overall, FELM is a comprehensive and rigorous benchmark that provides a standardized methodology for evaluating the factuality detection abilities of LLMs across a wide range of domains and tasks.''',\n",
    "    'FEVER': '''The FEVER (Fact Extraction and VERification) dataset is a benchmark designed to evaluate the ability of machine learning models to verify claims against textual sources. The main goal of the benchmark is to encourage research in the field of claim verification, which is an important task in natural language processing and information retrieval. The defining feature of the FEVER dataset is its focus on evidence-based verification. Claims are evaluated based on their supporting evidence, which is extracted from a large corpus of textual sources. The dataset includes over 185,000 claims, each of which is labeled as either Supported, Refuted, or Not Enough Information (NEI) based on the available evidence. The FEVER benchmark evaluates machine learning models on several specific aspects, including their ability to: - Identify relevant evidence from a large corpus of textual sources - Reason over the evidence to determine whether a claim is Supported, Refuted, or NEI - Handle the complexity and ambiguity of natural language - Generalize to new claims and textual sources To evaluate these aspects, the benchmark includes several subtasks, such as sentence selection, claim verification, and evidence retrieval. The benchmark also provides a baseline system and annotation interfaces to facilitate further research in this area.''',\n",
    "    'FSC147': '''Few-Shot Counting (FSC) benchmark aims to evaluate the performance of machine learning models in counting objects of interest in a given image with only a few labeled examples from the same image. The benchmark comprises over 6000 images with 147 visual categories. The defining feature of the FSC benchmark is that it poses counting as a few-shot regression task, where the inputs for the counting task are an image and few examples from the same image for the object of interest, and the output is the count of object instances. The examples are provided in the form of bounding boxes around the objects of interest. In other words, the few-shot counting task deals with counting instances within an image that are similar to the exemplars from the same image. The FSC benchmark aims to test and evaluate the performance of machine learning models in handling the few-shot counting task. Specifically, it evaluates the ability of machine learning models to generalize to completely novel classes at test time, where the classes at test time are completely different from the ones seen during training. This makes few-shot counting very different from the typical counting task, where the training and test classes are the same. Unlike the typical counting task, where hundreds or thousands of labeled examples are available for training, a few-shot counting method needs to generalize to completely novel classes. To evaluate the performance of machine learning models in the FSC benchmark, the paper proposes a novel architecture called FamNet for handling the few-shot counting task, with a novel few-shot adaptation scheme at test time. The paper also performs ablation studies on the validation set of FSC-147 to analyze how the counting performance changes as the number of exemplars increases and the benefits of different components of FamNet.''',\n",
    "    'FUNSD': '''The FUNSD benchmark is a comprehensive resource for form understanding in noisy scanned documents. Its main goals are to provide a standardized dataset for evaluating and comparing different approaches to form understanding, as well as to identify the key challenges and limitations of current methods. The defining features of the FUNSD dataset include its size (199 real, fully annotated, scanned forms), its diversity (forms from different fields such as marketing, science, and advertisement), and its complexity (noisy, low-quality scans with varying levels of text density and layout). The benchmark evaluates machine learning models on several specific aspects of form understanding, including text detection, optical character recognition (OCR), spatial layout analysis, and entity labeling/linking. For text detection, the benchmark evaluates models on their ability to accurately detect words in scanned forms. For OCR, the benchmark evaluates models on their ability to accurately recognize and transcribe text from scanned forms. For spatial layout analysis, the benchmark evaluates models on their ability to accurately identify the location and orientation of text and other elements in scanned forms. Finally, for entity labeling/linking, the benchmark evaluates models on their ability to accurately identify and label different semantic entities in scanned forms (e.g., names, dates, addresses, etc.) and link them together based on their relationships. Overall, the FUNSD benchmark provides a comprehensive and challenging evaluation framework for form understanding, and can be used to identify the strengths and weaknesses of different machine learning models and approaches.''',\n",
    "    'FactPrompts': '''FactPrompts is a dataset that comprises real-world prompts sourced from various platforms and datasets, such as Quora and TruthfulQA, along with corresponding responses generated by ChatGPT. The main goal of FactPrompts is to evaluate the performance of machine learning models in detecting factual errors in generated text. The dataset is designed to test and evaluate the ability of machine learning models to identify factual errors in generated text in different scenarios, including knowledge-based question answering and open-domain question answering. The dataset includes a variety of prompts that cover a wide range of topics and domains, making it a diverse and comprehensive resource for evaluating the performance of machine learning models in detecting factual errors. One defining feature of FactPrompts is that it includes both the prompts and the corresponding responses generated by ChatGPT. This allows for a direct comparison between the generated responses and the ground truth, making it easier to evaluate the performance of machine learning models in detecting factual errors. Another important aspect of FactPrompts is that it includes fine-grained annotations for each prompt and response, including the identification of claims and evidence. This allows for a more detailed analysis of the performance of machine learning models in detecting factual errors at different levels of granularity. Overall, FactPrompts is a valuable resource for evaluating the performance of machine learning models in detecting factual errors in generated text. Its comprehensive coverage of different scenarios and its fine-grained annotations make it a useful tool for researchers and practitioners working in this area.''',\n",
    "    'FewNERD': '''The FewNERD benchmark is designed to evaluate the performance of machine learning models on three different tasks related to named entity recognition (NER). These tasks are: 1. FEW-NERD (SUP): This is a standard supervised task that evaluates instance-level generalization of NER methods. In other words, it tests how well a model can recognize named entities in new instances that it has not seen before, based on its training on a large annotated dataset. 2. FEW-NERD (INTRA): This is a few-shot task that evaluates type-level generalization of NER methods. In other words, it tests how well a model can recognize new types of named entities with only a few examples of each type. 3. FEW-NERD (INTER): This is another few-shot task that evaluates knowledge transfer of NER methods. In other words, it tests how well a model can recognize named entities in a new domain, based on its training on a different domain. The defining feature of FEW-NERD is that it is a large-scale human-annotated dataset with both coarse-grained and fine-grained entity types. This makes it a valuable resource for evaluating the performance of machine learning models on NER tasks, particularly in the context of few-shot learning. The specific aspects of machine learning models that FEW-NERD aims to test and evaluate include their ability to generalize to new instances and new types of named entities, as well as their ability to transfer knowledge from one domain to another. The benchmark also provides a means of comparing the performance of different machine learning models on these tasks, which can help researchers identify promising directions for future research in few-shot NER.''',\n",
    "    # need some tweak\n",
    "    'FiQA': '''FiQA aims to build a question answering system that can answer natural language questions based on a corpus of structured and unstructured text documents from different financial data sources in English, including microblogs, reports, and news. The challenge takes both an Information Retrieval (IR) and a Question Answering (QA) perspective, where systems can rank relevant documents from the reference knowledge base with regard to a natural language question or generate their own answer. One defining feature of this challenge is that part of the questions are opinionated, targeting mined opinions and their respective entities, aspects, sentiment polarity, and opinion holder. This means that the system needs to be able to identify and extract opinions from the text, as well as understand the sentiment and the entities involved. The challenge also aims to test and evaluate specific aspects of machine learning models, such as their ability to handle natural language questions, their performance in information retrieval and ranking, and their ability to extract and analyze opinions from text. The challenge provides a training dataset of 17,110 question-answer pairs and a testing dataset of 531 question-answer pairs. Overall, this challenge provides an opportunity for researchers and practitioners to explore the potential of Natural Language Processing techniques in the financial domain, and to develop and evaluate machine learning models that can analyze financial news and opinions online.''',\n",
    "    'FinanceIQ': '''FinanceIQ is a Chinese financial domain knowledge assessment dataset. Main Goals of FinanceIQ: Targeted Domain: It focuses specifically on the financial sector, aiming to evaluate the knowledge and reasoning abilities of large language models in financial scenarios. Breadth of Coverage: The dataset encompasses a broad range of topics within finance, indicated by its inclusion of 10 major financial categories and 36 sub-categories. Comprehensive Assessment: With a total of 7,173 multiple-choice questions, FinanceIQ provides an extensive platform for testing. Defining Features: Language Specificity: The dataset is in Chinese, highlighting its utility for language models trained on or catering to Chinese language content, particularly in the financial domain. Detailed Categorization: The division into major and minor financial categories allows for nuanced assessment across various aspects of the financial industry. Format: The multiple-choice format of the questions simplifies the evaluation process and provides a clear metric for assessing model performance. Aspects of Machine Learning Models Tested: Knowledge Depth: The dataset tests for a deep understanding of financial concepts, terminologies, and practices. Reasoning Ability: It evaluates the model's capacity to apply financial knowledge in reasoning out the correct choices in multiple-choice questions. Contextual Understanding: Given the specificity of finance, the dataset assesses how well models can contextualize and interpret information within this domain. Language Processing: For models targeting Chinese language processing, this dataset serves as a benchmark for their linguistic capabilities in a specialized domain.''',\n",
    "    'Flickr30K': '''Flickr30K dataset aims to provide a large collection of images paired with descriptive captions, which can be used for various tasks such as image captioning, visual question answering, and image retrieval. The dataset contains 31,000 images, each with five captions written by different annotators, resulting in a total of 158,915 captions. The defining feature of the dataset is its focus on real-world images and natural language captions, which makes it more challenging than previous datasets that used staged or synthetic images. The captions are also more diverse and complex, covering a wide range of topics and styles. The dataset aims to test and evaluate machine learning models for tasks such as image captioning, where the goal is to generate a natural language description of an image. The dataset can also be used for tasks such as image retrieval, where the goal is to retrieve images that match a given query, and visual question answering, where the goal is to answer questions about an image based on its caption.''',\n",
    "    'Flores': '''The Flores benchmark is a dataset designed for evaluating machine translation between English and low-resource languages. Due to the nature of new languages with less standardization, FLORES-200 required a more complex verification process and modifications in the translation workflow. Several languages in FLORES-200 were not translated from English but from Spanish, French, Russian, and Modern Standard Arabic. Defining Features Data Source: The dataset consists of translations from 842 distinct web articles, totaling 3001 sentences. Sentence Length: On average, sentences are approximately 21 words long. Data Splits: The sentences are divided into three splits: dev, devtest, and test (hidden). Multilingual Support: It contains parallel sentences for 200 languages, identified with ISO 639-3 codes and additional script codes. Data Structure: Each data entry includes the sentence in specific languages, the URL of the source article, domain, topic, and information about images and hyperlinks. Machine Learning Model Evaluation Multilingual Machine Translation: The primary task is to evaluate the performance of machine translation models across a wide range of languages, with a focus on low-resource languages. Model Benchmarking: The dataset is used in the context of the WMT2021 shared task on Large-Scale Multilingual Machine Translation, as seen on the Dynabench leaderboard. Translation Quality: The complex nature of the languages and scripts in the dataset challenges models to maintain high translation quality across diverse linguistic contexts. Handling of Low-Resource Languages: The dataset tests a model's ability to translate languages with limited available data, a significant challenge in machine translation.''',\n",
    "    'FunQA': '''The FunQA benchmark aims to evaluate machine learning models' ability to comprehend and answer questions about video content. It contains 4,365 video clips and 311,950 question-answer pairs, with each video clip lasting an average of 19 seconds. The dataset is divided into three subsets, each containing well-designed tasks. The benchmark's defining feature is its focus on counter-intuitive video clips, which require models to understand and reason about unexpected events or situations. To evaluate models' performance, FunQA uses a variety of metrics, including accuracy, F1 score, and human evaluation. The benchmark also includes free-text answer evaluations, which demand enhanced video comprehension capabilities from the model and assess its ability to generate reasonably lengthy textual responses. To expand the dataset, the authors used GPT-3.5 to automatically translate Chinese annotations into English and generate more QA pairs that were faithful to the original ideas but presented differently. This not only made FunQA multilingual but also increased the number of QA pairs. Additionally, the authors created diverse task types, such as FunQA multiple-choice and FunQA dialogue.''',\n",
    "    'GAIA': '''The GAIA benchmark aims to evaluate the abilities of large language models (LLMs) to answer real-world and challenging questions that require fundamental abilities such as quick adaptation via reasoning, multi-modality understanding, and potentially diverse tool use. The benchmark is designed to avoid current pitfalls of LLMs evaluation by targeting questions that are conceptually simple yet varied, rooted in the real world, and challenging for current AI systems. The defining features of the GAIA benchmark include easy interpretability through conceptually simple tasks, associated reasoning trace, and few but highly curated questions. The benchmark is also designed to be non-gameable, meaning that answering the questions requires successful completion of some number of steps, which cannot easily be brute-forced due to their diversity. Additionally, the benchmark is simple to use, with factoid, concise, and unambiguous answers. The specific aspects of machine learning models that the GAIA benchmark aims to test and evaluate include their ability to browse the open and changing web, handle multi-modality, or reason over multiple steps to answer questions. The benchmark also aims to evaluate the accuracy of the models' reasoning trace and their ability to avoid data contamination. Overall, the GAIA benchmark is designed to provide a more comprehensive evaluation of LLMs' abilities to answer real-world questions, with a focus on fundamental abilities rather than specialized skills.''',\n",
    "    'GAOKAO-Bench': '''The GAOKAO-Bench aims to evaluate the performance of large language models (LLMs) on challenging and domain-specific tasks, particularly in the context of an ongoing \"arms race\" among LLMs. The benchmark employs questions from the Chinese Gaokao examination, which is known for its level of difficulty, abstraction, and wide-ranging subject matter, including computational, reasoning, knowledge assessment, and more. The benchmark is designed to test LLMs' ability to understand and generate natural language, as well as their ability to reason, infer, and generalize from text. To align the evaluation results with humans as much as possible, the researchers designed a method based on zero-shot prompts to analyze the accuracy and scoring rate of the model by dividing the questions into subjective and objective types. They evaluated the ChatGPT model on GAOKAO-Benchmark performance and found that it excels in tackling objective questions, while also shedding light on its shortcomings and areas for improvement.''',\n",
    "    'GQA': '''The GQA benchmark aims to test and evaluate machine learning models' ability to perform real-world visual reasoning and compositional question answering. Its main goals are to provide a challenging and diverse dataset that reflects the complexity of real-world visual reasoning, to encourage the development of models with enhanced robustness and deeper semantic understanding of vision and language, and to establish new metrics for evaluating essential qualities such as consistency, grounding, and plausibility. The defining features of the GQA benchmark include a strong question engine that leverages Visual Genome scene graph structures to create diverse reasoning questions, functional programs that capture the compositional structure of questions and provide a structured representation of the answer, and new metrics for evaluation that go beyond simple accuracy to measure the quality of the model's reasoning and its ability to ground its answers in the visual input. The specific aspects of machine learning models that the GQA benchmark aims to test and evaluate include their ability to handle complex compositional questions that require reasoning over multiple objects and relationships, their ability to generalize to new scenes and objects, their ability to handle noise and variability in the visual input, and their ability to ground their answers in the visual input and provide explanations for their reasoning. The benchmark also aims to encourage the development of models that can learn from limited data and can handle the long-tail distribution of answers in the dataset.''',\n",
    "    'GSM8K': '''GSM8K aims to provide a dataset of high-quality, linguistically diverse math word problems that can be used to evaluate the performance of machine learning models on multi-step mathematical reasoning tasks. GSM8K consists of 8.5K math word problems that cover a range of topics, including arithmetic, algebra, geometry, and probability. The problems are designed to be challenging and require multiple steps to solve. They are also linguistically diverse, meaning that they contain a variety of sentence structures, vocabulary, and phrasing that reflect the complexity of natural language. The specific aspects of machine learning models that GSM8K aims to test and evaluate include their ability to understand and reason about natural language, their capacity for multi-step mathematical reasoning, and their ability to generalize to new problems. The authors note that while previous benchmarks have focused on simple arithmetic problems or limited domains, GSM8K is designed to be more challenging and more representative of real-world problem-solving tasks. To evaluate the performance of machine learning models on GSM8K, the authors propose a new approach called verification-based training. This approach involves training a verifier model to judge the correctness of candidate solutions generated by a language model. The verifier is trained on a separate dataset of math problems and solutions, and is designed to be more robust and generalizable than the language model. The authors demonstrate that this approach significantly improves performance on GSM8K and provides a more scalable solution than traditional fine-tuning methods. Overall, GSM8K represents a significant contribution to the field of natural language processing and machine learning, as it provides a challenging and diverse benchmark for evaluating the performance of models on multi-step mathematical reasoning tasks.''',\n",
    "    'GovReport': '''GovReport aims to evaluate the effectiveness of machine learning models for long document summarization. The defining feature of GOVREPORT is that it consists of government reports, which are significantly longer and more complex than the news articles that are typically used in summarization benchmarks. The reports in GOVREPORT are on average 10 times longer than the documents in the CNN/Daily Mail dataset, which is a commonly used benchmark for summarization. To evaluate the effectiveness of machine learning models on this dataset, the authors of the paper propose several specific tasks that the models must perform. These tasks include: 1. Aspect labeling: annotators are asked to categorize each sentence in a summary into one of several aspects, such as \"why the study was done\" or \"what the study found.\" This task is designed to test the ability of models to identify and summarize key information from different parts of a long document. 2. Cloze-style question answering: models are given a summary and a set of questions that can be answered using information from the summary. This task is designed to test the ability of models to generate informative and accurate summaries that capture the most important information from the source document. 3. Factual consistency: models are evaluated on their ability to produce summaries that are factually consistent with the source document. This task is designed to test the ability of models to accurately represent the information in the source document and avoid generating misleading or inaccurate summaries. Overall, the GOVREPORT benchmark is designed to test the ability of machine learning models to effectively summarize long and complex documents, and to do so in a way that is informative, accurate, and consistent with the source material.''',\n",
    "    'HallusionBench': '''The HallusionBench benchmark is a comprehensive evaluation tool designed to challenge advanced large visual-language models (LVLMs) and evaluate their image-context reasoning abilities. The benchmark is unique in that it focuses on testing the models' ability to reason about images in a way that is both accurate and consistent with human intuition. The benchmark consists of a large set of image-context reasoning tasks, each of which is designed to test a specific aspect of the models' reasoning abilities. These tasks are divided into two main categories: visual question answering (VQA) and visual reasoning (VR). The VQA tasks require the models to answer questions about the content of an image, while the VR tasks require the models to reason about the relationships between different elements in the image. One of the defining features of the HALLUSIONBENCH benchmark is its use of \"hallucinations\" – i.e., incorrect or misleading information – in the images and questions presented to the models. This is intended to test the models' ability to distinguish between relevant and irrelevant information and to avoid making incorrect assumptions based on incomplete or misleading data. The benchmark also includes a detailed analysis of the models' performance on each task, including an evaluation of their accuracy, consistency, and ability to generalize to new tasks. This analysis is intended to provide insights into the specific aspects of machine learning models that are most challenging for image-context reasoning tasks and to identify areas for future research and development.''',\n",
    "    'HellaSwag': '''The HellaSwag benchmark aims test the limits of machine learning models in performing human-level commonsense inference. The dataset consists of 2,000 multiple-choice questions, each with four answer choices, and is split into a training set of 1,500 questions and a test set of 500 questions. The defining feature of HellaSwag is that it requires models to perform \"counterfactual reasoning,\" which involves understanding what would happen if a certain condition were changed. For example, a question might ask \"What would happen if the sun were made of marshmallows?\" The correct answer would be one that demonstrates an understanding of the absurdity of the premise and the lack of scientific basis for such a claim. HellaSwag is designed to test and evaluate several specific aspects of machine learning models, including their ability to perform counterfactual reasoning, their ability to handle negation and other linguistic phenomena, and their ability to avoid spurious correlations and other forms of bias. The authors of the paper argue that these are important skills for machines to develop if they are to achieve human-level performance on natural language inference tasks.''',\n",
    "    'HumanEval': '''HumanEval dataset aims to evaluate the functional correctness and problem-solving capabilities of machine learning models trained on code. It consists of 164 hand-written programming problems, each with a function signature, docstring, body, and several unit tests, with an average of 7.7 tests per problem. The tasks in the HumanEval dataset assess language comprehension, reasoning, algorithms, and simple mathematics. It is important for these tasks to be hand-written since the models are trained on a large fraction of GitHub, which already contains solutions to problems from a variety of sources. The main goal of the HumanEval dataset is to evaluate the functional correctness of machine learning models trained on code. The dataset is designed to test the problem-solving capabilities of these models and assess their ability to comprehend and reason about code. The dataset is also released to the public so that others can evaluate the functional correctness and measure the problem-solving capabilities of their models. In terms of specific aspects of machine learning models that the HumanEval dataset aims to test and evaluate, it assesses the models' ability to comprehend and reason about code, as well as their problem-solving capabilities. The dataset is designed to evaluate the functional correctness of these models and measure their ability to solve programming problems.''',\n",
    "    'InterCode': '''The InterCode benchmark aims to standardize and evaluate interactive code generation methods that use execution feedback. Its main goals are to provide a flexible, universal framework for interactive coding, and to enable comprehensive evaluation of state-of-the-art models. InterCode is unique in several ways. First, it is language/platform agnostic, meaning that it can be used with any programming language or platform. Second, it uses self-contained Docker environments to ensure reproducibility and safety. Third, it provides a variety of feedback types, including execution feedback, to enable testing of a wide range of interactive coding methods. The benchmark formalizes interactive coding with execution feedback as a partially observable Markov decision process (POMDP) with instruction space U, state space S, action space A, observation space O, transition function T, and reward function R. The specific aspects of machine learning models that InterCode aims to test and evaluate include their ability to handle partial observability, their ability to reason about the effects of actions, and their ability to incorporate feedback from multiple sources.''',\n",
    "    'LAiW': '''The LAiW benchmark aims to provide a comprehensive evaluation of Chinese legal LLMs. Its main goals are to classify tasks based on legal capabilities and allow for comprehensive objective evaluation. The benchmark is designed to test and evaluate the performance of LLMs on three levels of legal capabilities: basic legal NLP, legal knowledge, and legal reasoning. The defining features of the LAiW benchmark include its focus on Chinese legal language, its multi-level evaluation system, and its comprehensive evaluation metrics. The benchmark is unique in that it is specifically tailored to the Chinese legal system, which has its own distinct language and legal concepts. In terms of machine learning models, the LAiW benchmark evaluates the performance of LLMs on a range of legal tasks, including legal document classification, legal question answering, and legal case analysis. The benchmark also includes a variety of evaluation metrics, such as accuracy, F1 score, and precision-recall curves, to provide a comprehensive evaluation of LLM performance.''',\n",
    "    'LLM-EVAL': '''LLM-EVAL is a unified multi-dimensional automatic evaluation method for open-domain conversations with large language models. Its main goal is to streamline the evaluation process by using a single prompt and a unified evaluation schema, while still providing consistent and competitive performance across diverse scenarios. The defining features of LLM-EVAL include its ability to accommodate different scoring ranges, its adaptability to different evaluation scenarios, and its robustness in comparison to state-of-the-art evaluation techniques. LLM-EVAL aims to test and evaluate specific aspects of machine learning models related to open-domain conversations, including their ability to generate appropriate, relevant, and grammatically correct responses. It also evaluates the quality of the response in terms of content and coherence, while maintaining the efficiency of the evaluation process by requiring just a single call to the large language model.''',\n",
    "    'LLMonitor': '''The LLMonitor benchmark aims to evaluate the performance of various language models using a structured approach. Key aspects of this evaluation include: Weekly Benchmark Dataset Creation: The highest-rated submitted prompt each week is added to the benchmark dataset. This evolving approach ensures that the benchmark remains relevant and challenging. Model Testing and Scoring System: The prompts are tested against 77 models with a fixed temperature setting of zero. The responses are scored by GPT-4 according to specific rubrics, which are conditions set for each prompt. For instance, points may be awarded for mentioning specific facts or viewpoints relevant to the prompt​​. Rubrics and Scoring Challenges: Rubrics for each prompt are visible on their respective pages. The use of GPT-4 for scoring acknowledges potential biases, particularly towards OpenAI models, and may not fully reward creative or unconventional responses. Currently, rubrics are manually created, with plans to introduce a crowdsourcing method for their development.''',\n",
    "    'M3KE': '''The M3KE benchmark is a comprehensive evaluation tool for Chinese large language models (LLMs) that aims to measure their knowledge acquisition and multitask accuracy in zero- and few-shot settings. The benchmark is designed to bridge the gap between Chinese education systems and LLMs by covering all major levels of Chinese education, ranging from primary school to college, and a wide variety of subjects, including humanities, history, politics, law, education, psychology, science, technology, art, and religion. The benchmark contains 20,477 multiple-choice questions with four options, ensuring a standardized and unified assessment process. Unlike recent benchmarks MMCU and AGIEval, M3KE covers all major levels of Chinese education and a wide variety of subjects, making it a more comprehensive evaluation tool for Chinese LLMs. The main goal of the M3KE benchmark is to comprehensively evaluate the capability of Chinese LLMs in multiple tasks, including cross-task generalization and instruction following. The benchmark aims to test the knowledge acquired by these models by measuring their multitask accuracy in zero- and few-shot settings. The defining features of the M3KE benchmark include its comprehensive coverage of education levels and subjects, its use of multiple-choice questions with four options, and its focus on measuring multitask accuracy in zero- and few-shot settings. These features make the benchmark a valuable tool for testing the knowledge acquisition and multitask accuracy of Chinese LLMs.''',\n",
    "    'MINT-Bench': '''The MINT-bench aims to evaluate the performance of large language models (LLMs) in solving complex tasks that require multi-turn interactions and natural language feedback. The main goals of the benchmark are to address the limitations of current evaluation protocols, which often focus on single-turn exchanges and neglect the nuanced interactions among the user, LLMs, and external tools. To achieve these goals, the MINT benchmark includes two defining features: tool-augmented task-solving and natural language feedback. The former allows LLMs to access external tools by generating and executing Python programs, while the latter simulates human users by providing feedback to refine the LLM's solutions. The benchmark is designed to test and evaluate specific aspects of machine learning models, including their ability to solve tasks with multi-turn interactions, their capacity to leverage external tools, and their responsiveness to natural language feedback. The benchmark also aims to ensure reproducibility by providing an evaluation framework where LLMs can access tools and receive simulated user feedback.''',\n",
    "    'MMBench':'''MMBench is a multi-modality benchmark designed to evaluate the perception and reasoning abilities of large vision-language models. Its main goal is to provide a comprehensive evaluation pipeline that surpasses existing benchmarks in terms of the number and variety of evaluation questions and abilities. MMBench has two defining features that differentiate it from other benchmarks. First, it adopts problems from various sources to evaluate diversified abilities in a hierarchical taxonomy. Second, it applies a robust, LLM-based evaluation strategy that can handle the free-form outputs of multi-modality models and yield trustworthy evaluation results with affordable cost. MMBench evaluates various abilities of vision-language models, including but not limited to object localization, social reasoning, and instruction-following. Currently, MMBench contains approximately 3000 single-choice questions covering 20 different ability dimensions, with each ability dimension including more than 75 questions. The ability dimensions are not static and will expand as the team continues to work on them.''',\n",
    "    'MMCU': '''The MMCU benchmark aims to provide a scientific evaluation method for large Chinese language models, particularly those based on the Transformer architecture. The main goals of the benchmark are to measure the multitask accuracy of these models across four major domains (medicine, law, psychology, and education), provide high-quality evaluation datasets, and assess the models' capabilities in understanding and solving problems across various domains. The defining features of the MMCU benchmark include its use of both zero-shot and few-shot testing modes, with the latter offering five examples to the models. The test questions are single-choice and multiple-choice, with each question potentially having one or multiple correct answers, making them more akin to human exams and increasing their difficulty. The benchmark also includes 15 subtasks in medicine and 8 subtasks in education, covering a range of topics and requiring different types of reasoning and knowledge. In terms of the specific aspects of machine learning models that the MMCU benchmark aims to test and evaluate, these include their ability to perform well on multitask learning, transfer learning, and few-shot learning tasks. The benchmark also assesses the models' performance on tasks that require domain-specific knowledge and reasoning, such as legal reasoning and clinical diagnosis. Overall, the MMCU benchmark provides a comprehensive evaluation of large Chinese language models that takes into account their strengths and weaknesses across different domains and types of tasks.''',\n",
    "    'MME': '''The MME benchmark proposed aims to provide a comprehensive evaluation of Multimodal Large Language Models (MLLMs) by measuring both their perception and cognition abilities on a total of 14 subtasks. The benchmark is designed to address the lack of a comprehensive evaluation of MLLMs, which has been a challenge for the field. One defining feature of MME is that it uses manually designed annotations of instruction-answer pairs to avoid data leakage that may arise from direct use of public datasets for evaluation. The concise instruction design allows for fair comparison of MLLMs, instead of struggling in prompt engineering. The benchmark evaluates MLLMs on their ability to comprehend images and the corresponding knowledge behind them. Specifically, MME tests MLLMs on their ability to perform tasks such as image captioning, visual question answering, and image retrieval.''',\n",
    "    'MMLU': '''The Massive Multi-Task Language Understanding (MMLU) benchmark proposed aims to evaluate the ability of machine learning models to possess extensive world knowledge and problem-solving skills. The benchmark covers 57 tasks that vary in difficulty and span a wide range of topics, including science, history, and social studies. One defining feature of the MMLU benchmark is that it is designed to test models' ability to learn and apply knowledge encountered during pretraining. This is in contrast to previous benchmarks that focused on evaluating models' ability to perform specific tasks, such as question answering or sentiment analysis. The MMLU benchmark is intended to assess language understanding in greater breadth and depth than previous benchmarks. Another defining feature of the MMLU benchmark is that it does not require large training sets. Instead, it assumes that models have acquired the requisite knowledge from reading vast quantities of diverse text from the Internet. This is a departure from previous benchmarks that required large amounts of labeled data for training. The MMLU benchmark aims to test and evaluate several specific aspects of machine learning models, including their ability to: - Understand and apply knowledge across a wide range of topics and domains - Reason and solve problems using world knowledge - Perform calculations and other quantitative tasks - Understand and generate natural language text - Handle ambiguity and uncertainty in language understanding - Learn from and adapt to new tasks and domains. Overall, the MMLU benchmark is a comprehensive evaluation of machine learning models' ability to possess extensive world knowledge and problem-solving skills.''',\n",
    "    'NaturalInstructions': '''The NaturalInstructions benchmark is a dataset of 61 distinct tasks, their human-authored instructions, and 193k task instances (input-output pairs). The main goal of this benchmark is to study the ability of machine learning models to learn new tasks by understanding the human-readable instructions that define them, and to evaluate their generalization performance across tasks. The defining feature of this benchmark is that it is based on natural language crowdsourcing instructions, which are often used to define tasks for human workers in crowdsourcing platforms. The instructions are curated from existing well-known datasets and mapped to a unified schema, providing training and evaluation data for learning from instructions. The benchmark aims to test and evaluate the ability of machine learning models to encode task-specific instructions and generate task output. Specifically, it evaluates the performance of generative pre-trained language models in encoding task-specific instructions and generating task output, and compares their performance to that of other machine learning models, such as supervised learning models and models that do not use instructions.''',\n",
    "    'Natural Questions': '''The Natural Questions benchmark is a comprehensive data set designed to help researchers improve their question answering systems. The paper outlines three main goals for the data set: 1. To provide large-scale end-to-end training data for the QA problem. 2. To provide a data set that drives research in natural language understanding. 3. To study human performance in providing QA annotations for naturally occurring questions. The data set is unique in several ways. First, it consists of real anonymized, aggregated queries issued to the Google search engine, making it a valuable resource for researchers interested in natural language processing. Second, the data set includes both long and short answers, as well as indications that there is no answer on the page. Finally, the data set is annotated using a 5-way annotation system, which allows for more nuanced evaluation of machine learning models. The paper also details several specific aspects of machine learning models that the Natural Questions benchmark aims to test and evaluate. These include: 1. The ability of models to understand natural language questions and identify relevant information in Wikipedia pages. 2. The ability of models to generate accurate long and short answers to questions. 3. The ability of models to identify when there is no answer to a question on a given page. 4. The ability of models to handle complex questions that require multiple pieces of information to answer.''',\n",
    "    'OpenEval': '''The OpenEval benchmark is a dataset designed for evaluating the functional correctness of Large Language Models (LLMs) in code generation tasks. It consists of 178 function-level programming problems sourced from open-source programming competition websites. Each problem includes a function signature, a documentation string, and a code body, with five test cases per problem. The documentation strings are generated using OpenAI's GPT-3.5 in a few-shot method and are manually reviewed for quality. To avoid test case leakage affecting model performance, test cases are excluded from the model input prompt​​.''',\n",
    "    'PIQA': '''The PIQA benchmark is a new dataset designed to evaluate and study physical commonsense understanding in natural language models. Its main goals are to provide insight into the limitations of current AI models in answering questions about the physical world, and to encourage further research into building language representations that capture details of the real world. The dataset consists of multiple-choice questions that require concrete physical reasoning, with two possible solutions and exactly one correct answer. The questions are derived from how-to instructions on instructables.com, which provide a scaffold for the annotators. The dataset is designed to be challenging for current state-of-the-art models, and to require a deep understanding of physical properties of the world around us. The defining feature of PIQA is its focus on physical commonsense understanding, which is the ability to reason about the physical world based on common sense knowledge. This is a challenging task for natural language models, as it requires not only linguistic understanding but also a deep understanding of the physical properties of objects and their interactions. Overall, the PIQA benchmark is a valuable resource for evaluating and studying physical commonsense understanding in natural language models.''',\n",
    "    'QuAC': '''The QuAC benchmark is a large-scale dataset for Question Answering in Context, designed to enable learning from rich information-seeking dialog. Its main goals are to model conversations between students and teachers, where the students ask questions to learn about a topic of interest and the teachers provide short excerpts from a hidden Wikipedia text to answer those questions. QuAC contains 14K crowdsourced QA dialogs (100K total QA pairs) involving two crowd workers: a student who poses a sequence of freeform questions, and a teacher who answers the questions by providing short excerpts from the text. The questions can be highly context-dependent, elliptical, and even unanswerable, introducing challenges not found in existing machine comprehension datasets. The defining features of QuAC include its focus on multi-turn text-based dialog acts, its evaluation of simple and unanswerable questions where the asker can't see evidence.''',\n",
    "    'RACE': '''The RACE benchmark was designed to evaluate the reading comprehension abilities of machine learning models. Its defining features include a large-scale dataset of over 28,000 passages and nearly 100,000 questions, all of which were generated by human experts to test the ability of machine learning systems to comprehend text. The questions in RACE are substantially more difficult than those in existing datasets, with a large portion of questions involving reasoning. Additionally, candidate options in RACE are human-generated sentences that may not appear in the original passage, making the task more challenging and allowing for a rich type of questions such as passage summarization and attitude analysis. RACE aims to test and evaluate the generic comprehension ability of learning models, rather than domain or style-specific abilities. It covers a broad range of topics and writing styles, including news, stories, ads, biography, philosophy, and more. The paper notes that correctly answering a large portion of questions in RACE requires the ability of reasoning, which is the most important feature as a machine comprehension dataset. RACE also offers two important subdivisions of the reasoning types in its questions, namely passage summarization and attitude analysis.''',\n",
    "    'Safety-Prompts': '''The Safety-Prompts benchmark aims to provide a comprehensive evaluation of the safety performance of large language models (LLMs) in Chinese. It explores the safety of LLMs from two perspectives: typical safety scenarios and instruction attacks. The benchmark is based on a straightforward process in which it provides test prompts and evaluates the safety of the generated responses from the evaluated model. The evaluation process utilizes the LLM's strong evaluation ability and develops it as a safety evaluator by prompting. The Safety-Prompts benchmark includes 100k augmented prompts and responses by LLMs. The prompts library could be a good resource for red teaming LLMs, and the models tuned on SAFETYPROMPTS would have a significant and comprehensive safety improvement.''',\n",
    "    'SafetyBench': '''SafetyBench aims to provide a comprehensive benchmark for evaluating the safety of Large Language Models (LLMs). SafetyBench comprises 11,435 diverse multiple choice questions spanning across 7 distinct categories of safety concerns. These categories include: (1) toxicity, (2) sensitive topics, (3) factuality, (4) off-topic, (5) inconsistency, (6) ambiguity, and (7) bias. SafetyBench is unique in that it incorporates both Chinese and English data, facilitating the evaluation in both languages. It also exclusively features multiple-choice questions, each with a single correct answer, which enables automated and cost-effective evaluations of LLMs’ safety with exceptional accuracy. The specific aspects of machine learning models that SafetyBench aims to test and evaluate include their ability to generate safe and appropriate responses to various prompts, their ability to avoid generating toxic or harmful content, their ability to maintain factual accuracy, and their ability to avoid generating responses that are off-topic, inconsistent, ambiguous, or biased.''',\n",
    "    'ScienceQA': '''The ScienceQA benchmark aims to provide a comprehensive evaluation of machine learning models' ability to perform multi-modal reasoning and interpretability in the context of science question answering. The benchmark consists of over 21,000 multiple-choice questions with diverse science topics and annotations of their answers with corresponding lectures and explanations. This makes it unique compared to existing science question benchmarks, which either lack answer annotations or are restricted to the textual-only modality, small scales, and limited domain diversity. The specific aspects of machine learning models that ScienceQA aims to test and evaluate include their ability to perform multi-hop reasoning, leverage explanations to learn from fewer data, and generate reasonable explanations. The paper presents language models designed to generate lectures and explanations as the chain of thought (CoT) to mimic the multi-hop reasoning process when answering ScienceQA questions.''',\n",
    "    'SEED-Bench': '''SEED-Bench is a benchmark designed to evaluate the generative comprehension capability of Multi-modal Large Language Models (MLLMs). Its main goal is to provide a comprehensive assessment of generative models by introducing a benchmark that spans 12 evaluation dimensions, including both image and video comprehension. SEED-Bench is unique in its scale and sophistication. It consists of 19K multiple choice questions with accurate human annotations, which is 6 times larger than existing benchmarks. The questions are generated using an advanced pipeline that targets specific evaluation dimensions and incorporates both automatic filtering and manual verification processes to ensure quality and accuracy. The benchmark aims to test and evaluate the ability of MLLMs to comprehend and generate text based on visual information from both images and videos. Specifically, it evaluates the models' ability to understand spatial and temporal relationships, recognize objects and their attributes, and generate coherent and relevant text descriptions.''',\n",
    "    'Sherlock': '''Sherlock is an annotated corpus of 103K images for testing machine capacity for abductive reasoning beyond literal image contents. The main goals of the Sherlock benchmark are threefold: 1. To provide a diagnostic corpus for measuring machine capacity for visual abductive reasoning. 2. To create a large-scale resource to study the types of inferences people may make about images. 3. To build tools that require understanding abductions specifically, e.g., for detecting purposefully manipulative content posted online. The defining features of the Sherlock dataset are: 1. The dataset consists of 103K images, each with a set of visual clues and inferences. 2. The visual clues are concrete objects or attributes scattered throughout the scene. 3. The inferences are probable conclusions beyond the literal scene based on our everyday experience and knowledge about the world. 4. The dataset is annotated by crowdworkers, who provide a set of (clue, inference) pairs for each image. 5. The dataset is designed to test machine capacity for visual abductive reasoning beyond literal image contents. The specific aspects of machine learning models that the Sherlock benchmark aims to test and evaluate are: 1. Retrieval: Models are tasked with finding the ground-truth inference across a wide range of inferences, some much more plausible/relevant than others. 2. Localization: Models must align regions within the same image to several inferences written about that image. 3. Comparison: Models are evaluated in their capacity to reconstruct human judgments across the candidates.''',\n",
    "    'SIQA': '''The SOCIAL IQA benchmark aims to provide a large-scale resource for learning and measuring social and emotional intelligence in computational models. It consists of 38,000 multiple choice questions that probe emotional and social intelligence in a variety of everyday situations. One defining feature of SOCIAL IQA is its focus on social commonsense reasoning. The questions are designed to cover various types of inference about people's actions being described in situational contexts. The creators of SOCIAL IQA used a crowdsourcing framework to collect QA pairs that reduce stylistic artifacts of negative answers through an adversarial question-switching method. The specific aspects of machine learning models that SOCIAL IQA aims to test and evaluate include their ability to reason about social situations and understand the pragmatic implications of everyday events.''',\n",
    "    'Spider': '''The Spider benchmark is a large-scale dataset for complex and cross-domain semantic parsing and text-to-SQL task. Its main goal is to provide a challenging benchmark for natural language processing (NLP) models that can understand the meaning of natural language sentences and map them to meaningful executable queries such as logical forms, SQL queries, and Python code. The defining features of Spider are its size, complexity, and cross-domain nature. It consists of 10,181 questions and 5,693 unique complex SQL queries on 200 databases with multiple tables, covering 138 different domains. The dataset includes different SQL clauses such as joining and nested query, and requires models to understand both the natural language question and relationships between tables and columns in the database schema. Spider aims to test and evaluate the ability of machine learning models to generalize well to both new SQL queries and new database schemas. In this way, the task requires the model to generalize well to both new SQL queries and new database schemas.''',\n",
    "    'StrategyQA': '''StrategyQA aims to challenge machine learning models to perform implicit multi-step reasoning, which involves inferring a sequence of logical steps to derive an answer to a complex question. This is a challenging task because it requires models to reason over multiple parts of their input and to integrate information from diverse knowledge domains. The defining features of STRATEGYQA include its focus on strategy questions, which are characterized by their multi-step nature and their reliance on implicit reasoning. To support the annotation of these questions, the dataset includes question decompositions and evidence paragraphs, which provide a detailed breakdown of the reasoning process required to answer each question. In terms of machine learning models, STRATEGYQA aims to test and evaluate their ability to perform multi-step reasoning, to integrate information from diverse knowledge domains, and to handle complex logical operations. The dataset includes questions that cover a wide range of topics, including physics, geography, and history, and that require a variety of reasoning skills, such as number comparison and spatial reasoning.''',\n",
    "    'SuperCLUE-Agent': '''The SuperCLUE-Agent benchmark is a comprehensive evaluation standard focusing on the capabilities of AI agents, particularly in the context of large language models (LLMs). Main Goals Research and Application of LLMs as AI Agents: The benchmark aims to explore the potential of large language models in functioning as AI agents. These agents are capable of autonomously understanding, planning, and executing complex tasks. Focus on Chinese Language Tasks: While most existing benchmarks for agent capabilities are in English, SuperCLUE-Agent addresses this gap by focusing on Chinese language tasks and scenarios. Advancing Towards AGI: By evaluating the core capabilities of AI agents, SuperCLUE-Agent contributes to the broader goal of achieving Artificial General Intelligence (AGI). Defining Features Multi-Dimensional Testing: The benchmark includes a variety of tasks spread across three core capabilities: tool usage, task planning, and memory abilities. Comprehensive Evaluation: It evaluates the performance of AI agents in 10 fundamental tasks, providing a holistic view of their capabilities. Specific Aspects Tested Tool Usage: Evaluates the agent's ability to use tools like APIs, search engines, browsing web pages, operating local files, and using databases. Task Planning: Focuses on the agent's ability to decompose large tasks into manageable sub-goals, self-reflection on past actions, and the use of Chain of Thought (CoT) to simplify complex tasks. Memory Abilities: Tests the agent's capability in multi-document question answering, long conversations (involving topic shifts), and in-context learning, where the agent learns from examples provided in the task prompt.''',\n",
    "    'SuperCLUE-Safety': '''The SuperCLUE-Safety benchmark aims to systematically assess the safety of Chinese large language models (LLMs) through adversarial human-model interactions and conversations. Its main goals are to promote collaborative efforts to create safer and more trustworthy LLMs and to provide guidance on model selection. The benchmark covers more than 20 safety sub-dimensions and consists of 4912 open-ended questions that are designed to test the model's understanding and adherence to human intent, as well as its ability to accurately follow instructions in multi-turn dialogues. The questions are adversarial in nature, meaning that they are designed to challenge the model and increase the difficulty of the benchmark. The benchmark also emphasizes the importance of consistency between models and human preferences in open-ended tasks, aiming for a more comprehensive evaluation of model safety. Overall, the SC-Safety benchmark is a comprehensive and rigorous evaluation of the safety of Chinese LLMs that aims to promote safer and more trustworthy models. Its defining features include adversarial human-model interactions, multi-round open-ended questions, and a focus on consistency between models and human preferences.''',\n",
    "    'TheoremQA': '''TheoremQA is a benchmark dataset designed to evaluate the capabilities of language and code models in solving challenging science problems that require domain-specific knowledge. The main goals of TheoremQA are to provide a comprehensive evaluation of the performance of language and code models on a diverse set of university-level theorems across Math, Physics, EE&CS, and Finance, and to encourage the development of models that can apply theorems to solve complex problems. The defining features of TheoremQA include its focus on university-level theorems, its multimodality aspect, and its answer-type distribution. The dataset contains 800 high-quality question-theorem-answer triples, including 442 Math questions, 146 CS&EE questions, 131 Physics questions, and 81 Finance questions. Additionally, 51 questions require image input (diagrams), which adds a multimodality aspect to the dataset. The majority of the questions in TheoremQA have float and integer as the answers, which is more realistic than the existing multi-choice datasets like ScienceQA or AQuA QA. Therefore, the models are unlikely to take shortcuts to achieve high accuracy. The specific aspects of machine learning models that TheoremQA aims to test and evaluate include their ability to understand and apply university-level theorems, their ability to handle multimodal inputs, and their ability to provide accurate answers in a realistic answer-type distribution. The dataset also provides a rough but informative estimate of human-level performance, which can be used as a benchmark for evaluating the performance of machine learning models.''',\n",
    "    'Toloka LLM Leaderboard': '''The Toloka Leaderboard is a unique platform that provides a public comparison of Large Language Models (LLMs) based on real user prompts and expert human evaluation​​. It ranks LLMs across various categories such as brainstorming, closed question-answering (QA), generation, open QA, and rewriting, using a specific set of criteria​​. Key features of the Toloka Leaderboard include: Authentic User Prompts: The prompts used for evaluation are extracted from real conversations with ChatGPT, ensuring the scenarios are realistic and relevant​​. Accurate Human Evaluation: The assessments are conducted by expert humans whose quality of work is controlled to ensure the best accuracy. This method differentiates the leaderboard from others that might use crowdsourced or LLM-generated ratings​​​​. Practical Comparisons: The Leaderboard is designed to aid in business decision-making by comparing the top 5 LLMs across different categories, focusing on practical applications​​. In terms of evaluation, the Leaderboard uses a rigorous process: Quality Control: The evaluation involves three stages of quality control where human experts are tested, trained, and certified. These evaluations are based on guidelines around harmlessness, truthfulness, and helpfulness of model responses. The ratings are made objective using a method known as Dawid-Skene aggregation, and each expert’s accuracy is continuously monitored​​. Scoring System: The scores for each LLM are calculated based on the percentage of prompts where the model performed better than a baseline model (Guanaco 13B). This approach ensures a consistent and fair comparison across different models​​.''',\n",
    "    'ToolBench': '''ToolBench aims provide a standardized test suite for evaluating the performance of machine learning models in tool manipulation tasks. The benchmark consists of eight diverse software tools for real-world tasks, including VirtualHome, Webshop, and Tabletop. These tasks cover both single-step and multiple-step action generation, which requires selecting and combining from 2 to 108 APIs. One defining feature of ToolBench is that it is the first open-source test bench with predefined test cases for quantitative evaluation, distinguishing it from recent tool manipulation research using closed LLMs. The benchmark is designed to evaluate the ability of machine learning models to generalize to unseen API combinations and the requirement for advanced reasoning. In summary, ToolBench is a comprehensive benchmark suite that provides a standardized test suite for evaluating the performance of machine learning models in tool manipulation tasks. It is designed to evaluate the ability of machine learning models to generalize to unseen API combinations and the requirement for advanced reasoning.''',\n",
    "    'TruthfulQA': '''TriviaQA is a benchmark dataset designed to test and evaluate machine learning models for reading comprehension and question answering. Its main goals are to provide a challenging testbed for these tasks, to offer a large-scale dataset of question-answer-evidence triples, and to enable research on a variety of related tasks such as IR-style question answering, QA over structured KBs, and joint modeling of KBs and text. One of the defining features of TriviaQA is that the questions are authored by trivia enthusiasts independently of the evidence documents. This means that the questions are not tailored to the documents and may require multi-sentence reasoning to answer correctly. The evidence documents come from two domains - Web search results and Wikipedia pages - with highly differing levels of information redundancy. The specific aspects of machine learning models that TriviaQA aims to test and evaluate include their ability to handle substantial syntactic and lexical variability, to reason over multiple sentences, and to handle questions that require a deep understanding of the context and background knowledge. TriviaQA also provides a benchmark for a variety of other tasks such as IR-style question answering, QA over structured KBs, and joint modeling of KBs and text.''',\n",
    "    'Hallucination Leaderboard': '''The Hallucination Leaderboard is a public leaderboard that evaluates Large Language Models (LLMs) based on their propensity to produce hallucinations when summarizing short documents. Key features of the Hallucination Leaderboard include: Model Accuracy and Hallucination Rate: The leaderboard ranks various models like GPT-4, GPT-3.5, Llama, Cohere, Anthropic Claude, and others based on their accuracy in avoiding hallucinations and their hallucination rate when summarizing documents​​. Open Sourced Model: The model used for the leaderboard is open-sourced for commercial use, available on Hugging Face, allowing others to replicate or build upon the work​​. Based on Prior Research: The methodology incorporates protocols from significant prior research in factual consistency in summarization, referencing several top papers and resources in this field​​. Methodology: The leaderboard is established by training a model to detect hallucinations in LLM outputs using various open-source datasets. It involves feeding 1000 short documents to each LLM and asking them to summarize using only the facts presented in the document​​.''',\n",
    "    'WinoGrande': '''The WinoGrande benchmark was designed to test the robustness of machine commonsense capabilities. Its main goals are to create a dataset that is challenging for existing state-of-the-art models while still being trivially easy for humans, and to demonstrate effective transfer learning. The dataset consists of 44k problems inspired by the original Winograd Schema Challenge (WSC) design, but adjusted to improve both the scale and the hardness of the dataset. The key steps of the dataset construction consist of a carefully designed crowdsourcing procedure, followed by systematic bias reduction using a novel AFLITE algorithm that generalizes human-detectable word associations to machine-detectable embedding associations. The problems in WINOGRANDE are designed to be pronoun resolution problems that are trivial for humans but hard for machines that merely rely on statistical patterns without true capabilities of commonsense reasoning.''',\n",
    "    'Xiezhi': '''The Xiezhi benchmark aims to provide a comprehensive evaluation suite for assessing holistic domain knowledge. Its main goals are to establish a taxonomy for human knowledge and build evaluation criteria for this field. The benchmark encompasses 13 distinct disciplinary categories, 118 sub-disciplines, and 385 further fine-grained disciplines, providing an extensive domain taxonomy and benchmark for fair, effective, and comprehensive domain evaluation. Xiezhi is unique in that it covers a wide range of disciplines and sub-disciplines, making it the most dimensional domain evaluation benchmark with the largest volume of data. It currently offers Chinese and English language versions, but the authors plan to collect more thorough and in-depth knowledge from various countries, nations, fields, and open source benchmarks in more languages in the future. The specific aspects of machine learning models that Xiezhi aims to test and evaluate include their ability to understand and execute instructions, align with human values, and perform well across multiple tasks.''',\n",
    "    'XSUM': '''The XSUM benchmark is a new dataset for the task of extreme summarization. The goal of this benchmark is to push the boundaries of abstractive summarization methods by providing a large-scale dataset of BBC articles and accompanying single-sentence summaries that require a more abstract understanding of the content. The defining features of the XSUM dataset include the fact that each article is prefaced with an introductory sentence (aka summary) which is professionally written, typically by the author of the article. The summary bears the HTML class “story-body introduction,” and can be easily identified and extracted from the main text body. The dataset consists of 226,711 Wayback archived BBC articles ranging over almost a decade (2010 to 2017) and covering a wide variety of domains (e.g., News, Politics, Sports, Weather, Business, Technology, Science, Health, Family, Education, Entertainment and Arts). The specific aspects of machine learning models that the XSUM benchmark aims to test and evaluate include their abstractive capabilities, their ability to recognize pertinent content and generate informative summaries, and their incorporation of high-level document knowledge in terms of topics and long-range dependencies.''',\n",
    "    'QASC': '''The QASC benchmark is a multi-hop question answering dataset designed to test and evaluate machine learning models' ability to reason and retrieve information from multiple sources. Its main goals are to promote research on multi-sentence machine comprehension, develop models that can identify valid compositions of retrieved facts using commonsense reasoning, and improve the performance of existing language models. The defining features of the QASC dataset are its annotated facts and compositions, which are not evident from the question itself. This makes retrieval challenging, as the system must introduce new concepts or relations to discover potential decompositions. To address this challenge, the dataset provides annotation for supporting facts and their composition. The dataset also includes multiple-choice questions, with four answer choices, and a corpus of scientific texts from which the facts are drawn. The QASC benchmark aims to test and evaluate machine learning models' ability to perform multi-hop reasoning and retrieval. Specifically, it evaluates models' ability to retrieve relevant facts from the corpus, identify valid compositions of these facts using commonsense reasoning, and select the correct answer choice from the multiple-choice options. The benchmark also evaluates models' performance on different subsets of the dataset, such as questions that require more or less reasoning, and questions that require specific types of reasoning, such as causal or temporal reasoning.''',\n",
    "    'MATH401': '''The MATH401 benchmark is a dataset designed to evaluate the arithmetic abilities of large language models (LLMs) in solving math word problems. The dataset consists of 401 math word problems, each with a corresponding arithmetic expression that the model must solve. The expressions include addition, subtraction, multiplication, and division, as well as parentheses and variables. The problems are designed to test the models' ability to perform arithmetic operations correctly and to apply chain-of-thought reasoning to solve multi-step problems. The authors provide a detailed analysis of the models' performance on the MATH401 dataset, including accuracy, speed, and efficiency.''',\n",
    "    'HalluQA': '''The HalluQA benchmark is a Chinese hallucination question-answering dataset designed to evaluate hallucinations in Chinese large language models (LLMs). The main goal of HalluQA is to help reduce hallucination problems in Chinese LLMs and enhance the credibility of these models. The defining features of HalluQA include its meticulous design, which takes into account Chinese historical culture, customs, and social phenomena, and its focus on two types of hallucinations: imitative falsehoods and factual errors. The dataset contains 450 adversarial questions spanning multiple domains, and an automated evaluation method is used to judge whether a model output is hallucinated. The specific aspects of machine learning models that HalluQA aims to test and evaluate include pre-trained models, chat models, and retrieval-augmented chat models. The primary types of hallucinations in different types of models are analyzed, and the paper discusses which types of hallucinations should be prioritized for different types of models.''',\n",
    "    'UHGEval': '''The UHGEval benchmark aims to evaluate the reliability and authenticity of Chinese Large Language Models (LLMs) in text generation through unconstrained generation. The benchmark dataset was constructed using tens of thousands of historical news articles from leading Chinese news websites. The evaluation framework encompasses generative, discriminative, and selective modalities, along with sentence-level and keyword-level granularity. The benchmark's main goals are to identify potential hallucination phenomena in LLMs and assess their credibility in text generation. The benchmark dataset and evaluation framework are designed to provide a comprehensive empirical analysis of the performance of various LLMs and classic GPT series models. The defining features of UHGEval include its unified, flexible, and robust evaluation framework, which allows for a comprehensive analysis of LLMs' performance in text generation. The framework includes multiple modalities and granularity levels, enabling a detailed assessment of the models' reliability and authenticity. Specific aspects of machine learning models that UHGEval aims to test and evaluate include their ability to generate coherent and relevant text, their understanding of existing knowledge and past news events, and their capacity to avoid hallucination phenomena.''',\n",
    "    'MM-Vet': '''MM-Vet is an evaluation benchmark that aims to examine the abilities of large multimodal models (LMMs) on complicated multimodal tasks. The benchmark defines six core VL (vision and language) capabilities, including recognition, OCR, knowledge, language generation, spatial awareness, and math, which integrate to solve various complicated multimodal tasks. MM-Vet contains 16 tasks for quantitative evaluation, which require LMMs to master and integrate these core capabilities to solve the tasks. One of the defining features of MM-Vet is its focus on evaluating LMMs on complicated multimodal tasks that require integrated VL capabilities. The benchmark is designed to provide insights beyond simple performance rankings, allowing for a more comprehensive evaluation of LMMs. MM-Vet also adopts an open-ended LLM-based evaluator, which allows for evaluation across answer styles and question types without requiring binary or multiple answer choices. In terms of specific aspects of machine learning models that MM-Vet aims to test and evaluate, the benchmark examines the arbitrary integration of core VL capabilities for complicated tasks. MM-Vet proposes that the intriguing ability to solve complicated multimodal tasks can be achieved by a generalist model mastering and integrating different core capabilities. Therefore, the benchmark evaluates LMMs on their ability to master and integrate these core capabilities to solve the tasks in MM-Vet.''',\n",
    "    'MMMU': '''The MMMU benchmark is a comprehensive dataset designed to evaluate the expert-level multimodal understanding capability of foundation models across a broad scope of tasks. The main goals of the benchmark are to test and evaluate the ability of machine learning models to perceive and understand information across different modalities, apply reasoning with subject-specific knowledge to derive the solution, and handle diverse image formats, from visual scenes like photographs and paintings to diagrams and tables. The defining features of the MMMU benchmark include its coverage of 30 subjects across 6 disciplines, including Art, Business, Health & Medicine, Science, Humanities & Social Science, and Tech & Engineering, and over 183 subfields. The dataset is divided into a few-shot development set, a validation set, and a test set, with the test set comprising 10.5K questions. The questions in the benchmark were manually collected by a team of 50 college students from various disciplines and subjects, drawing from online sources, textbooks, and lecture materials. The specific aspects of machine learning models that the MMMU benchmark aims to test and evaluate include their ability to handle interleaved text-image inputs, recall deep subject knowledge, and conduct complex reasoning based on the understanding and knowledge to reach a solution. The benchmark introduces four key challenges to multimodal foundation models, including the requirement for both expert-level visual perceptual abilities and deliberate reasoning with subject-specific knowledge.''',\n",
    "    'STAR': '''The STAR benchmark aims to evaluate the ability of machine learning models to reason in real-world situations, which is a crucial aspect of machine intelligence. The benchmark includes four types of questions that require structured situation comprehension and logical reasoning. The questions are procedurally generated and are built upon real-world videos associated with human actions or interactions. The defining features of the STAR benchmark include its focus on real-world situations, its use of procedurally generated questions, and its requirement for structured situation comprehension and logical reasoning. The benchmark is designed to complement existing visual reasoning benchmarks by combining situation abstraction and diagnostic reasoning, focusing on human-object interaction, temporal sequence analysis, action prediction, and feasibility inference. The specific aspects of machine learning models that the STAR benchmark aims to test and evaluate include their ability to perform explicit reasoning in real-world situations, their understanding of both visual content and question semantics, and their ability to perform step-by-step reasoning. The benchmark evaluates various state-of-the-art methods and finds that they still make many mistakes in situations that are trivial for humans. To evaluate the benchmark thoroughly, various baseline models are tested and their strengths and weaknesses in situated reasoning are analyzed. The models include Q-type models, blind models, vision-language models, and video question-answering models. The performance of each model is measured by the average answer accuracy of overall questions.''',\n",
    "    'MiT': '''The Moments in Time (MiT) dataset is a large-scale human-annotated collection of one million short videos corresponding to dynamic events unfolding within three seconds. The main goal of this dataset is to provide a diverse and challenging benchmark for action recognition and event understanding in both visual and auditory modalities. The defining features of this dataset include its large scale, diversity of events, and coverage of both visual and auditory modalities. Each video is tagged with one action or activity label among 339 different classes, and the dataset includes a significant intra-class variation among the categories. The specific aspects of machine learning models that the Moments in Time Dataset aims to test and evaluate include their ability to model the spatial-audio-temporal dynamics of events occurring in short videos. This poses many challenges, as meaningful events do not include only people, but also objects, animals, and natural phenomena. Visual and auditory events can be symmetrical in time (\"opening\" is \"closing\" in reverse), and either transient or sustained. In terms of machine learning models, the dataset can be used to evaluate the performance of several baseline models addressing separately, and jointly, three modalities: spatial, temporal and auditory. The dataset can also serve as a new challenge to develop models that scale to the level of complexity and abstract reasoning that a human processes on a daily basis.''',\n",
    "    'QuALITY': '''The QuALITY benchmark introduced has several main goals. First, it aims to provide a new challenge for natural language understanding models by requiring them to answer multiple-choice questions based on long-context passages. Second, it seeks to evaluate models' ability to understand and reason about complex, multi-faceted information in a holistic manner. Finally, it aims to address some of the limitations of existing benchmarks, such as their focus on short, isolated sentences or their reliance on metrics that may not accurately reflect the quality of generated text. The defining features of the QuALITY benchmark include its use of long-context passages, which range from 2,000 to 8,000 tokens in length, and its multiple-choice format, which requires models to select the correct answer from a set of options. The questions in QuALITY are designed to be challenging and require readers to consolidate information from multiple parts of the text. Additionally, the dataset includes a subset of questions that are intentionally unanswerable under tight time constraints, which helps ensure that models cannot simply rely on skimming or simple search to achieve high performance. In terms of the specific aspects of machine learning models that QuALITY aims to test and evaluate, the benchmark focuses on models' ability to understand and reason about complex, multi-faceted information in a holistic manner. This includes their ability to identify relevant information in the passage, integrate information from multiple parts of the text, and reason about the relationships between different pieces of information. QuALITY also aims to evaluate models' ability to generate high-quality text that accurately reflects the information in the passage, rather than simply producing text that matches a set of pre-defined metrics.''',\n",
    "    'LMExamQA': '''The LMExamQA benchmark is a key component of the Language-Model-as-an-Examiner framework proposed in this paper. Its main goal is to evaluate the proficiency of foundation models in answering questions across three cognitive levels: recall, inference, and analysis. The defining feature of LMExamQA is that it employs a language model (LM) as an examiner to generate high-quality questions across various domains. These questions are designed to probe for a broad acquisition of knowledge and to engage in a more in-depth assessment through follow-up questions. The specific aspects of machine learning models that LMExamQA aims to test and evaluate include their ability to accurately and completely answer questions, without providing additional details. This is done by employing the LM examiner to produce a groundtruth answer, which is then evaluated by human experts on a random selection of 100 questions. In addition to evaluating the accuracy of machine learning models in answering questions, LMExamQA also aims to assess their comprehension of a topic in depth. This is done through a multi-round follow-up question generation procedure, drawing inspiration from the interview process.''',\n",
    "    'PubMedQA': '''PubMedQA is a benchmark dataset for biomedical research question answering that aims to test the scientific reasoning abilities of machine reading comprehension models. The dataset consists of 1k expert-annotated, 61.2k unlabeled, and 211.3k artificially generated QA instances, each composed of a question, a context, a long answer, and a yes/no/maybe answer that summarizes the conclusion of the long answer. The main goal of PubMedQA is to evaluate the ability of machine learning models to reason over biomedical research texts and their quantitative contents. Unlike other biomedical QA datasets, PubMedQA requires complex quantitative reasoning to answer questions with yes/no/maybe answers. The dataset is also unique in that it includes a large number of artificially generated instances, which allows for more comprehensive evaluation of models' generalization abilities. PubMedQA evaluates models on several specific aspects of machine learning, including natural language understanding, scientific reasoning, and quantitative reasoning. The dataset requires models to understand complex biomedical research texts, reason over their contents, and use quantitative information to arrive at a yes/no/maybe answer. Additionally, PubMedQA evaluates models' ability to generalize to new instances and handle noisy data, as the dataset includes a large number of artificially generated instances with varying levels of difficulty.''',\n",
    "    'ANGO': '''The ANGO benchmark is a Chinese evaluation benchmark for generation-oriented language models (LLMs) that aims to provide a more objective and effective guidance for model training and evaluation. Its main goals are to address the limitations of existing benchmarks, such as ranking distortion on leaderboards and lack of truly objective and effective guidance for model training, and to provide a more comprehensive evaluation platform for LLMs. The defining feature of ANGO is its use of Keypoint instead of Subject as the criteria for categorizing questions. A single question in ANGO can correspond to 1-6 different keypoints, and include 988 keypoint combinations, far exceeding the typical 50-70 subject categories. This allows ANGO to address the limitations of existing benchmarks that only allow for single-question with single-subject, disregarding that questions often require proficiency in multiple subjects and overlooking the existence of further subdivisions within each subject. In addition, ANGO incorporates quantifiable metrics for assessing question difficulty based on real human performance, thereby enriching the diversity of evaluation criteria. This addresses the limitations of existing benchmarks that lack quantifiable standards based on human performance, typically determined by the educational grade associated with the subject, despite significant variations in difficulty for different question types with the same subject. The specific aspects of machine learning models that ANGO aims to test and evaluate include their ability to handle a diverse range of disciplines, their proficiency in multiple subjects, their combined language and computational capabilities, and their ability to comprehend complex problems that require different abilities, such as analysis, reasoning, and computation. ANGO also aims to test and evaluate the effectiveness of models in handling long-context comprehension, Chinese reasoning, and sophisticated reasoning problems.''',\n",
    "    \n",
    "}\n",
    "\n",
    "leaderboard_description_list = {\n",
    "    'AgentBench': '''AGENTBENCH is a comprehensive benchmark designed to evaluate Large Language Models (LLMs) as agents in multi-turn open-ended generation settings. The main goals of AGENTBENCH are to standardize the evaluation of LLMs as agents and to provide a practical testbed for their wide array of capabilities. AGENTBENCH defines eight distinct environments of three types based on real-world scenarios, offering a practical testbed for LLMs' capabilities. The three types of environments are: 1. Instruction Following: where the LLM is given a set of instructions to follow and must generate a response that satisfies the instructions. 2. Decision Making: where the LLM is given a set of options and must choose the best one based on a given context. 3. Open-Ended: where the LLM is given a context and must generate a response that is coherent and relevant to the context. The benchmark evaluates LLMs based on their performance in these environments, with a focus on their long-term reasoning, decision-making, and instruction-following abilities. The benchmark also aims to identify the reasons for failures in existing LLM agents and highlight directions for improvement, such as code training and higher-quality alignment data. To evaluate the LLMs, AGENTBENCH uses a set of metrics that measure the models' performance in terms of task completion, context size constraints, return format accuracy, action accuracy, and task limitations. The benchmark also compares the performance of different LLMs, including leading API-based commercial LLMs and OSS models, to uncover significant performance gaps and highlight areas for improvement. Overall, AGENTBENCH provides a comprehensive and standardized approach to evaluating LLMs as agents, with a focus on their long-term reasoning, decision-making, and instruction-following abilities.''',\n",
    "    'AGIEval': '''AGIEval aims to assess the general abilities of foundation models to tackle human-level tasks, which is a vital aspect of their development and application in the pursuit of Artificial General Intelligence (AGI). Traditional benchmarks, which rely on artificial datasets, may not accurately represent human-level capabilities. Therefore, AGIEval releases collected questions from high-standard, official human exams and supports a standardized, automatic evaluation metric. The defining feature of AGIEval is its emphasis on human-level cognitive tasks. In designing the human-centric benchmark, the primary objective is to center on tasks that closely align with human cognition and problem-solving, ultimately assessing the general abilities of foundation models in a more meaningful and comprehensive manner. To achieve this, a diverse range of official, public, and high-standard admission and qualification exams that cater to general human test-takers are incorporated. These exams, which include college admission tests, law school admission tests, math exams, lawyer qualification tests, and national civil service exams, are taken by millions of individuals seeking entry into higher education or new career paths. By adhering to these officially recognized standards for evaluating human-level capabilities, the benchmark design ensures that the assessment of model performance is directly relevant to human decision-making and cognitive abilities. AGIEval aims to test and evaluate specific aspects of machine learning models, including their ability to understand and reason with natural language, their capacity to solve complex problems, and their proficiency in domain-specific knowledge. Additionally, AGIEval incorporates bilingual tasks in both Chinese and English, offering a more comprehensive assessment of model behavior. By addressing these future directions, foundation models can be further developed and refined to exhibit more advanced capabilities that align closely with human cognition, ultimately enabling them to tackle a broader range of complex, human-centric tasks with greater accuracy and reliability.''',\n",
    "    'BEIR': '''The BEIR benchmark was designed with several key goals in mind. First and foremost, it aims to provide a comprehensive evaluation of the generalization capabilities of information retrieval (IR) models. To achieve this, the benchmark includes a diverse set of 18 publicly available datasets from a range of text retrieval tasks and domains. One defining feature of the BEIR benchmark is its heterogeneity. Unlike many existing retrieval benchmarks, which focus on a single task or domain, BEIR includes datasets from a wide range of retrieval tasks, including fact checking, citation prediction, duplicate question retrieval, argument retrieval, news retrieval, question answering, tweet retrieval, bio-medical IR, and entity retrieval. Additionally, the benchmark includes datasets from diverse text domains, covering both broad and specialized topics, and datasets of varying sizes and query/document lengths. Another key feature of the BEIR benchmark is its focus on zero-shot evaluation. This means that models are evaluated on tasks and domains that they have not been specifically trained on, in order to test their ability to generalize to new and unseen data. In terms of the specific aspects of machine learning models that BEIR aims to test and evaluate, the benchmark includes 10 state-of-the-art retrieval systems from five broad architectures: lexical, sparse, dense, late interaction, and re-ranking. These models are evaluated on a range of metrics, including mean average precision (MAP), normalized discounted cumulative gain (NDCG), and precision at k (P@k), among others.''',\n",
    "    'Big Code Models Leaderboard': '''The Big Code Models Leaderboard on Hugging Face is a platform designed to compare the performance of base multilingual code generation models. Defining Features Performance Metrics: Models are evaluated based on their performance on the HumanEval benchmark and MultiPL-E, measuring functional correctness in synthesizing programs from docstrings. Throughput Measurement: The leaderboard also measures model throughput (tokens per second) to compare inference speed. Diverse Programming Languages: It includes benchmarks for multiple programming languages. Evaluation Parameters: Models are evaluated using the big code-evaluation-harness with specific settings. Specific Aspects Tested and Evaluated Functional Correctness: Using the HumanEval benchmark, the leaderboard assesses the ability of models to synthesize correct programs from given docstrings. Multilingual Capabilities: Through the MultiPL-E benchmark, evaluates the performance across 18 programming languages. Inference Speed: By measuring throughput, the leaderboard evaluates how quickly models can process tokens. Memory Usage: Peak memory usage is also measured, providing insights into the efficiency of the models. Scoring and Rankings: Models are ranked based on the average pass@1 score over all languages and their win rate, which represents how often a model outperforms others. Overall, this leaderboard serves as a crucial tool for the AI community, offering a comprehensive and comparative view of the capabilities of various code generation models, especially in terms of multilingual support and functional correctness.''',\n",
    "    'Chatbot Arena Leaderboad': '''The Chatbot Arena Leaderboad is a benchmarking platform for large language models (LLMs), featuring anonymous, randomized battles in a crowdsourced manner. Its main goals include: Benchmarking LLMs: Chatbot Arena provides a platform to compare various LLMs, like ChatGPT, Alpaca, Vicuna, and others. The comparison is based on how these models respond to user questions or prompts in real-time scenarios​​. Use of the Elo Rating System: It employs the Elo rating system, commonly used in chess, to rank the models. This system is effective in predicting the outcome of matches between models, making it suitable for evaluating LLMs that engage in pairwise battles​​. Crowdsourced Evaluation: Users interact with two anonymous models, voting for the one they consider better. This approach allows for the collection of diverse data and user opinions, contributing to a more comprehensive evaluation of the models​​. The Chatbot Arena's approach addresses the challenge of benchmarking LLMs, which is complicated due to the open-ended nature of problems and the difficulty in automated response quality evaluation. It aims to provide scalability, incrementality, and a unique order in the ranking of models, essential for an effective benchmarking system​​.''',\n",
    "    'CLUE': '''The CLUE benchmark is a large-scale Chinese Language Understanding Evaluation designed to test and evaluate the performance of machine learning models on a variety of sentence classification and machine reading comprehension tasks in Chinese. The benchmark is unique in that it covers a wide range of tasks, at different levels of difficulty, in different sizes and forms, all on original Chinese text. The main goals of the CLUE benchmark are to provide a standardized evaluation framework for Chinese NLU models, to encourage reproducibility and transparency in research, and to promote the development of high-quality Chinese NLU models. Some of the defining features of the CLUE benchmark include a diagnostic dataset that contains nine linguistic and logic phenomena, a leaderboard for users to submit their own results, and a toolkit named PyCLUE implemented in TensorFlow that supports mainstream pre-training models and a wide range of target tasks. The specific aspects of machine learning models that the CLUE benchmark aims to test and evaluate include model size, pre-training data, and whole word masking. The benchmark results show that larger models and models trained with more pre-training data tend to perform better, as do models that use whole word masking. The best performing models on the CLUE benchmark are RoBERTa-wwm-ext-large and ALBERT-xxlarge, which show advantages over other models particularly for machine reading tasks such as C3.''',\n",
    "    'EvalPlus': '''The EvalPlus benchmark is designed to rigorously evaluate the functional correctness of Large Language Models (LLMs) for code generation. Its main goals are to improve existing code benchmarks by generating interesting test inputs to fully exercise the code solution and check its functional correctness by cross-checking the ground-truth implementation. The defining features of EvalPlus include an automatic test input generation engine that uses both LLM- and mutation-based methods to generate and diversify additional test inputs. Specifically, EvalPlus first uses ChatGPT to generate a set of high-quality seed inputs that aim to test difficult corner cases and functionalities of the program within the valid input structure. Using these high-quality seed inputs, EvalPlus then performs type-aware mutation to efficiently generate a large number of additional test inputs. These newly generated test inputs are then used to evaluate the LLM-generated code through differential testing against the ground-truth implementation. The specific aspects of machine learning models that EvalPlus aims to test and evaluate include their ability to generate correct and efficient code solutions for a variety of programming tasks. EvalPlus evaluates the functional correctness of LLM-synthesized code by comparing it to the ground-truth implementation using differential testing. This approach allows for a more comprehensive evaluation of LLMs, as it can detect both syntactic and semantic errors in the generated code.''',\n",
    "    'FacTool': '''The FACTOOL benchmark is a framework for detecting factual errors in generative AI models. Its main goal is to provide a unified and versatile framework for factuality detection across a variety of domains and tasks. The defining features of the FACTOOL benchmark include its task and domain agnosticism, its use of various tools (such as Google Search, Google Scholar, code interpreters, Python, or even LLMs themselves) to gather evidence about the factuality of the generated content, and its employment of the reasoning abilities of LLMs to assess the factuality of the content given the evidence that has been gathered. The FACTOOL benchmark aims to test and evaluate specific aspects of machine learning models, including their ability to generate text that is factually accurate, their ability to reason about the factual accuracy of generated text, and their ability to use external sources of information to verify the factual accuracy of generated text. FACTOOL benchmark is used to evaluate the factuality of modern chatbots across four tasks: knowledge-based QA, code generation, math problem solving, and scientific literature review writing.''',\n",
    "    'Flageval': '''The FlagEval benchmark is a comprehensive evaluation system for large-scale models. It's designed to provide a scientific, fair, and open standard for evaluating the performance of foundational models and training algorithms. Main Goals of FlagEval Establishing New Evaluation Standards: The primary goal of FlagEval is to create a new coordinate system for evaluating large models, focusing on more nuanced and detailed aspects of model performance. Enhancing Evaluation Efficiency and Objectivity: By utilizing AI methods, FlagEval aims to significantly improve the efficiency and objectivity of both subjective and objective evaluations. Supporting Diverse Model Evaluation: FlagEval includes tools for evaluating language models, multi-language image-text models, and image-text generation models, among others. Defining Features of FlagEval Three-Dimensional Evaluation Framework: FlagEval is based on a \"capability-task-indicator\" framework, allowing for a more granular depiction of a model's cognitive abilities. Comprehensive Task Coverage: The system covers 22 subjective and objective evaluation sets, including 84,433 questions to test various aspects of large models. Model Types: FlagEval differentiates between foundational models (built from scratch with extensive training) and fine-tuned models (based on foundational models with additional fine-tuning). Continuous Updating and Expansion: The platform is in a state of ongoing improvement, with new evaluation results and capabilities being added regularly. Adaptation to Various Models: The system is designed to evaluate both language-based and multimodal models, covering a range of scenarios and tasks. Specific Aspects FlagEval Tests and Evaluates Basic and Advanced Language Abilities: This includes simple comprehension (like information analysis, extraction, summary), knowledge application, reasoning capabilities, creative generation, and context understanding. Safety and Ethical Aspects: The evaluation covers aspects like legality, privacy, political sensitivity, discrimination, and ethical standards. Comprehensive Abilities: General and domain-specific comprehensive abilities are assessed. Efficiency and Robustness: In addition to accuracy, metrics like efficiency, robustness, and uncertainty are also considered. Subjective and Objective Evaluation Methods: FlagEval combines manual and automated methods for both subjective and objective evaluations. Adaptive Evaluation Mechanisms: The platform allows for the integration of evaluation results into ongoing model training, adapting strategies based on performance feedback.''',\n",
    "    'HEIM': '''The Holistic Evaluation of Text-to-Image Models (HEIM) benchmark aims to provide a comprehensive evaluation of state-of-the-art text-to-image models across 12 different aspects, including text-image alignment, image quality, aesthetics, originality, reasoning, knowledge, bias, toxicity, fairness, robustness, multilinguality, and efficiency. HEIM is unique in that it combines both automated metrics and crowdsourced human evaluations to provide a more comprehensive understanding of model performance. The benchmark also includes a diverse collection of 62 scenarios, which are datasets of prompts, and 25 metrics, which are measurements used for assessing the quality of generated images specific to each aspect. The main goals of the HEIM benchmark are to provide a standardized evaluation framework for text-to-image models, offer holistic insights into model performance, and enable researchers, developers, and end-users to make informed decisions based on comparable assessments. Overall, the HEIM benchmark provides a quantitative understanding of the capabilities and risks of text-to-image models, and highlights the importance of evaluating models across multiple aspects to ensure their technological advancement and societal impact.''',\n",
    "    'HELM': '''The Holistic Evaluation of Language Models (HELM) aims to provide a standardized and comprehensive evaluation of language models across a broad range of scenarios and metrics. The benchmark aims to test and evaluate language models in terms of their accuracy, calibration, robustness, fairness, bias, toxicity, and efficiency. Additionally, HELM includes targeted evaluations of skills and risks, such as knowledge, reasoning, disinformation, and copyright. HELM is defined by its broad coverage, which includes 16 core scenarios and 21 new scenarios that have not been previously used in mainstream language model evaluation. The benchmark evaluates 30 language models under standardized conditions, ensuring that models can be directly compared across many scenarios and metrics. These models vary in terms of their public accessibility, with 10 being open, 17 being limited-access, and 3 being closed. The specific aspects of machine learning models that HELM aims to test and evaluate include their ability to accurately predict outcomes, their ability to handle different types of inputs and prompts, their ability to avoid bias and toxicity, and their efficiency in terms of speed and resource usage. HELM also aims to evaluate the skills and risks associated with language models, such as their ability to reason and their potential for spreading disinformation. Overall, HELM provides a comprehensive and standardized approach to evaluating language models, with the goal of guiding future language model development and providing ample opportunities for further analysis.''',\n",
    "    'InstructEval': '''The InstructEval benchmark suite is a comprehensive evaluation tool designed to assess the performance of instruction-tuned large language models (LLMs) across a range of general capabilities, usage scenarios, and human-centric behavior. Its main goals are to provide a more holistic evaluation of LLMs that goes beyond traditional benchmarks, and to identify areas where models may fall short in terms of problem-solving, writing ability, and alignment with human values. INSTRUCTEVAL consists of three main evaluation categories: problem-solving, writing, and alignment to human values. The problem-solving category includes multiple benchmarks that cover real-world exams on diverse topics, complex instructions, arithmetic, programming, and causality. The writing category includes prompts that test the models' ability to write informative, persuasive, and creative texts. The alignment to human values category includes tasks that assess the models' ability to generate text that is consistent with human values and ethical principles. The defining features of INSTRUCTEVAL include its focus on instruction-tuned LLMs, its use of multiple evaluation methods (including both objective and qualitative scoring), and its coverage of a wide range of general abilities and usage scenarios. The benchmark suite is designed to test models on tasks that require world knowledge, multi-hop reasoning, creativity, and more, and to provide a comprehensive evaluation of their performance across a range of domains.''',\n",
    "    'KoLA': '''The KoLA benchmark is designed to evaluate the world knowledge of large language models (LLMs) in a thorough, unbiased, and applicable manner. Its main goals are to provide a diagnostic tool for the development of increasingly knowledgeable LLMs and to help developers of knowledge-related applications select appropriate LLMs. To achieve these goals, the KoLA benchmark has several defining features. First, it employs a four-level taxonomy of knowledge-related abilities, covering 19 tasks, to mimic human cognition for ability modeling. Second, it uses both Wikipedia, a corpus prevalently pre-trained by LLMs, and continuously collected emerging corpora for data to ensure fair comparisons and evaluate the capacity to handle unseen data and evolving knowledge. Third, it adopts a contrastive system for evaluation criteria, including overall standard scores for better numerical comparability across tasks and models and a unique self-contrast metric for automatically evaluating knowledge hallucination. The specific aspects of machine learning models that the KoLA benchmark aims to test and evaluate include their ability to handle world knowledge, their capacity to handle unseen data and evolving knowledge, and their ability to generate high-quality and faithful content. The benchmark evaluates 21 open-source and commercial LLMs and provides intriguing findings that can guide the development of future LLMs and knowledge-related systems.''',\n",
    "    # this one need a tweak!!!\n",
    "    'ChEF': '''ChEF benchmark aims to establish a thriving ecosystem for training and evaluating multi-modal language models (MLLMs) and to cultivate multi-modal AI agents capable of bridging the gap between ideas and execution, facilitating seamless interaction between humans and AI machines. The benchmark aims to showcase the effectiveness of MLLMs in handling visual modalities, including images and point clouds, and highlights their potential for generalization via instruction tuning. By making the codebase, baseline model, instruction tuning dataset, and evaluation benchmark publicly available, the authors aim to foster an open research community for MLLMs and contribute to the advancement of MLLMs and the development of general-purpose multi-model agents. The defining features of the ChEF benchmark include its innovative departure from traditional techniques for constructing instruction tuning data, which relies solely on daily dialogue and detailed description. Instead, the authors introduce a novel method for constructing instruction tuning data. The benchmark also uses a simple MLLM framework to build up a baseline model for the dataset and benchmark, but there is potential for further development and careful design of MLLMs for future work to enhance their capabilities and performance. The powerful modeling capability of LLMs, combined with a unified optimization objective, can help align the model to various modalities. This design sets ChEF apart from visual foundation models, where each model is finely tuned for a specific task, or from multi-modal visual language foundation models that can only be used as pre-trained models for visual tasks or possess limited zero-shot capabilities, or from multi-task foundation models that struggle in tag-of-war problems. The ChEF benchmark aims to test and evaluate multi-modal language models (MLLMs) and their ability to handle visual modalities, including images and point clouds, and their potential for generalization via instruction tuning. The benchmark provides an instruction tuning dataset and evaluation benchmark to test and evaluate MLLMs' performance on various tasks, including object recognition, object localization, and object manipulation. The authors also provide an extensible framework to facilitate the extension of MLLMs to additional modalities.''',\n",
    "    'LawBench': '''LawBench is a comprehensive evaluation benchmark designed to assess the legal capabilities of Large Language Models (LLMs) from three cognitive levels: legal knowledge memorization, understanding, and application. Its main goal is to provide a precise assessment of LLMs' legal knowledge and their ability to perform legal-related tasks in the highly specialized, safe-critical legal domain. LawBench is unique in its design and features. It covers 20 diverse tasks that are divided into five task types: legal fact verification, legal question answering, legal text completion, legal text modification, and legal text generation. The tasks are meticulously crafted to have precise assessment of the LLMs’ legal capabilities. The benchmark evaluates LLMs' legal knowledge memorization by testing whether they can memorize needed legal concepts, articles, and facts. It evaluates legal knowledge understanding by testing whether LLMs can comprehend entities, events, and relationships within legal text. Finally, it evaluates legal knowledge application by testing whether LLMs can properly utilize their legal knowledge and make necessary reasoning steps to solve realistic legal tasks.''',\n",
    "    'LLM Benchmarker Suite': '''The LLM Benchmarker Suite is a comprehensive framework designed to evaluate large-scale language models (LLMs). Key Components and Features: Manual Evaluation Process: The typical steps for manually conducting evaluations with the suite include loading the model, loading an appropriate benchmarking dataset, and selecting a relevant metric for evaluation​​. Model Loading: The suite emphasizes efficient and rapid local model inferences, utilizing libraries like vLLM for fast inference on LLMs. This approach is designed to maximize resource utilization and throughput​​. Benchmarking Datasets: The suite incorporates a variety of datasets that test different proficiencies of a model, such as question answering or summarization. It includes hybrid benchmarks for a holistic understanding of a model's capabilities, preferring minimally curated datasets to avoid biases towards any specific model​​. Evaluation Metrics: The suite uses several common metrics for evaluation, including Perplexity, F1 Score, BLEU Score, ROUGE Score, Accuracy, and Human Evaluation. Each of these metrics has its pros and cons, tailored to different aspects of language model performance​​. Leaderboard and Metrics Dashboard: The suite provides a leaderboard for the community to rank all public and API models. Additionally, it offers a locally created metrics dashboard for tracking and comparing evaluations​​. Diverse Evaluation Tools: The suite includes tools like Static Evaluations, LLM-as-a-judge, and OpenAI Evals. These tools cater to various evaluation needs, such as static assessment of capabilities through predefined measures and using other LLMs as judges for inferencing capabilities​​.''',\n",
    "    'LLM-Leaderboard': '''The LLM-Leaderboard is a community-driven initiative to establish a centralized leaderboard for Large Language Models (LLMs). Its main goals and features include: Centralized Leaderboard: It provides a central platform for comparing various LLMs. The leaderboard includes model names, publishers, and whether the models are open for local deployment and commercial use​​​​. Evaluation Benchmarks: Various benchmarks are used to evaluate the LLMs, including Chatbot Arena Elo, HellaSwag, HumanEval-Python, LAMBADA, MMLU, TriviaQA, and WinoGrande. These benchmarks test aspects like chatbot performance, commonsense natural language inference, programming problem-solving, text understanding, and world knowledge.''',\n",
    "    'LLM-Perf Leaderboard': '''The LM-Perf Leaderboard serves as a critical tool in the realm of machine learning, particularly focusing on the evaluation and benchmarking of Large Language Models (LLMs). Its primary goal is to benchmark the performance of these models in terms of latency, throughput, and memory across different hardware, backends, and optimization configurations using Optimum-Benchmark and Optimum flavors​​.''',\n",
    "    'LongBench': '''The LongBench benchmark is a comprehensive evaluation tool designed to test the long context understanding capabilities of large language models (LLMs). Its main goals are to provide a standardized, bilingual, multi-task benchmark for evaluating LLMs on long-text application scenarios, and to facilitate further research in this direction. LongBench is composed of 21 different tasks across 6 major task categories, covering key long-text application scenarios including multi-document QA, single-document QA, summarization, few-shot learning, code completion, and synthesis tasks. These tasks are standardized into a unified format, allowing for effortless automatic evaluation of LLMs. LongBench also includes different languages (Chinese and English) to provide a more comprehensive evaluation of the large models’ bilingual capabilities on long contexts. The defining features of LongBench include its focus on long context understanding, its bilingual and multi-task nature, and its standardized format for easy evaluation of LLMs. LongBench is unique in that it is the first benchmark tailored specifically for evaluating long context understanding, and it covers a wide range of long-text application scenarios.''',\n",
    "    'LVLM-eHub': '''The LVLM-eHub benchmark presented aims to provide a comprehensive evaluation of publicly available large vision-language models (LVLMs). Its main goals are to assess the efficacy of LVLMs in six essential capabilities, including visual perception, visual knowledge acquisition, visual reasoning, visual commonsense, object hallucination, and embodied intelligence. To achieve these goals, the LVLM-eHub consists of two main components: a quantitative capability evaluation and an online arena platform. The quantitative capability evaluation extensively evaluates 16 tasks spanning over 40+ text-related visual datasets to assess the six essential capabilities of LVLM models. The online arena platform features anonymous randomized pairwise battles in a crowd-sourced manner, providing a user-level model ranking in the open-world question-answering scenario. The LVLM-eHub is designed to be user-friendly and inclusive, allowing users to contribute their own datasets and models to the platform. It also offers free online inference services for the LVLM models supported by LVLM Arena. The platform incorporates valuable human feedback through an Elo rating rank system, ensuring continuous improvement and refinement of LVLM models.''',\n",
    "    'L-Eval': '''The L-Eval benchmark proposed aims to provide a standardized evaluation for long context language models (LCLMs). It addresses two key aspects: dataset construction and evaluation metrics. The dataset construction involves annotation, re-annotation, and manual filtering pipeline, resulting in 508 long documents and over 2,000 human-labeled query-response pairs encompassing diverse question styles, domains, and input length (3k∼200k tokens). The evaluation suite contains 20 sub-tasks, which are more closed-ended tasks reflecting unbiased results due to fairness issues in open-ended tasks. The evaluation metrics are another key aspect of L-Eval. The authors investigate the effectiveness of popular n-gram matching metrics in correlating with human judgment and find that they generally cannot do so well. Therefore, they propose length-instruction-enhanced (LIE) evaluation and employing LLM judges as alternative evaluation metrics. The L-Eval benchmark aims to test and evaluate the performance of LCLMs in practical, long-form documents across domains. It focuses on modeling longer contexts and preserving the reasoning ability in an extended context. The authors believe that L-Eval can serve as a challenging testbed to drive advances in modeling longer contexts and pro''',\n",
    "    'MOCHA': '''MOCHA is a benchmark dataset for training and evaluating generative reading comprehension metrics. Its main goal is to address the limitations of existing generation metrics, which rely on token overlap and are agnostic to the nuances of reading comprehension. MOCHA aims to develop learned metrics that model the correctness of candidates using human annotation scores. MOCHA contains 40K human judgement scores on model outputs from six diverse question answering datasets and an additional set of minimal pairs for evaluation. The candidates come from a wide range of RC phenomena, such as commonsense reasoning and understanding narrative over movie scripts. MOCHA presents a challenging problem for developing accurate and robust generative reading comprehension metrics. To evaluate machine learning models, MOCHA uses a Learned Evaluation metric for Reading Comprehension (LERC) that mimics human judgement scores. LERC outperforms baseline metrics by 10 to 36 absolute Pearson points on held-out annotations. When evaluated on minimal pairs, LERC achieves 80% accuracy, outperforming baselines by 14 to 26 absolute percentage points while leaving significant room for improvement. In summary, MOCHA aims to improve generative reading comprehension metrics by developing learned metrics that model the correctness of candidates using human annotation scores. It contains a diverse set of RC phenomena and uses LERC to evaluate machine learning models.''',\n",
    "    'MVBench': '''MVBench is a comprehensive benchmark for multi-modal video understanding that aims to evaluate the performance of Multi-modal Large Language Models (MLLMs) in a range of temporal tasks. The main goals of MVBench are to provide a standardized evaluation framework for MLLMs, to cover a wide range of temporal tasks, and to emphasize temporally-sensitive videos and efficient use of public annotations. MVBench covers 20 dynamic video tasks that require a range of temporal skills, including action recognition, temporal localization, and temporal reasoning. These tasks are designed using a concise static-to-dynamic method by adapting static tasks with dynamic goals. MVBench also includes an automatic annotation paradigm that generates multi-choice QAs for each task, by converting 11 public video benchmarks with LLMs. This approach largely reduces the cost of expensive human annotations and provides ground truth for MVBench, which guarantees evaluation fairness and accuracy, avoiding biased scoring of LLMs. The defining features of MVBench include its coverage of a wide range of temporal tasks, its emphasis on temporally-sensitive videos, and its use of public annotations to reduce the cost of human annotations. MVBench also conducts comprehensive evaluations of MLLMs' temporal understanding, providing a standardized evaluation framework for these models. MVBench aims to test and evaluate the specific aspects of machine learning models related to multi-modal video understanding, including their ability to comprehend complex domains and diverse scenes, ranging from first-person to third-person perspectives, and from indoor to outdoor environments. MVBench also evaluates the general capability of MLLMs for open-world temporal understanding, providing a comprehensive analysis of their performance in a range of temporal tasks.''',\n",
    "    'Open Ko-LLM Leaderboard': '''The Open Ko-LLM Leaderboard is emphasizes high-quality data that reflects the characteristics and culture of the Korean language, thereby addressing the unique challenges and nuances of processing and understanding Korean text​. Defining Features Rapid Expansion and Participation: The leaderboard witnessed rapid growth, registering over 100 models within two weeks of its launch. This participation includes various companies, academic organizations, and individual researchers, indicating its wide-reaching impact and acceptance​​. Diverse Model Collection: It hosts a variety of famous Korean open-source models like 'Ko-Alpaca', 'KULLM (Cloud)', and 'Polyglot-Ko', showcasing a comprehensive range of Korean LLM performances within the industry​​. Continuous Development and Engagement: Future plans include monthly leaderboard rankings, open seminars, and collaborative efforts to further develop and refine the Korean LLM ecosystem​​.''',\n",
    "    'Open LLM Leaderboard': '''The Open LLM Leaderboard is designed to track, rank, and evaluate open Large Language Models (LLMs) and chatbots. Defining Features Benchmarks: The leaderboard evaluates models on seven key benchmarks using the Eleuther AI Language Model Evaluation Harness. This framework tests generative language models on a variety of evaluation tasks. Model Categories: It categorizes models into different types, such as pretrained, fine-tuned, instruction-tuned, and RL-tuned models. Quantization: The leaderboard includes information about model quantization, like 8-bit and 4-bit quantizations, which are important for understanding model efficiency and deployment capabilities. Community Engagement: Models can be flagged by the community for issues, ensuring the integrity and reliability of the leaderboard rankings. Additional Features Reproducibility: The leaderboard provides commands and methods to reproduce the results using the Eleuther AI Harness. Model Submission Guidelines: Guidelines for submitting models to the leaderboard, ensuring standardization and quality control. Detailed Results and Logs: Access to detailed numerical results and model input/output details for deeper analysis. Overall, the Open LLM Leaderboard is a comprehensive platform for evaluating and comparing large language models and chatbots. It emphasizes a variety of reasoning, knowledge, and inference tasks, providing a holistic view of model capabilities.''',\n",
    "    'Open Multilingual LLM Evaluation Leaderboard': '''The Open Multilingual LLM Evaluation Leaderboard at HuggingFace is a platform that tracks and ranks the performance of large language models (LLMs) developed for different languages. Defining Features Multilingual Focus: The current version of the leaderboard includes evaluation data for 29 languages, including Arabic, Chinese, French, German, Hindi, Russian, Spanish, and others. This multilingual aspect is significant as it expands the scope of LLMs beyond predominantly English-centric models. Open Participation: The leaderboard is open to both multilingual and language-specific LLMs. It encourages participation from a wide range of models, promoting diversity in AI development.''',\n",
    "    'OpenCompass': '''The OpenCompass Leaderboard is an open-source, efficient, and comprehensive evaluation suite and platform designed for large models. Defining Features: Multi-Type Model Support: OpenCompass can evaluate various model types, including HF models, API models, and custom open-source models. Comprehensive Capability Dimensions: The evaluation covers thorough dimensions, each backed by abundant datasets. Flexible Expansion: The platform supports the flexible and convenient addition of evaluation datasets and models. Diverse Evaluation Methods: As mentioned, it includes zero-shot, few-shot, and chain-of-thought evaluations. Defining Features: Multi-Type Model Support: OpenCompass can evaluate various model types, including HF models, API models, and custom open-source models. Comprehensive Capability Dimensions: The evaluation covers thorough dimensions, each backed by abundant datasets. Flexible Expansion: The platform supports the flexible and convenient addition of evaluation datasets and models. Diverse Evaluation Methods: It includes zero-shot, few-shot, and chain-of-thought evaluations. Specific Aspects of Machine Learning Models Tested: Large Language Model Evaluation: Evaluating capabilities based on five major dimensions: language, knowledge, reasoning, discipline, and comprehension. This is done using more than 50 datasets. Base Models and Chat Models: The leaderboard includes a variety of models, such as InternLM, LLaMA, ChatGPT, GPT-4, and many others, evaluated across different dimensions. Examination Datasets: The evaluation uses datasets like Middle School Exam, High School Exam, College Exam, and others for comprehensive testing. Capability Dimensions: These include language (word definition, idiom learning, translation), knowledge (question answering, commonsense QA), understanding (reading comprehension, content analysis), and reasoning (NLI, common sense, mathematics). Visual Language Model Benchmark: OpenCompass also conducts a progressive assessment from perception to reasoning, covering 20 finely-grained capabilities with approximately 3000 multiple-choice questions.''',\n",
    "    'OpenEval': '''OpenEval is a comprehensive, multidimensional, and open evaluation platform dedicated to assessing Chinese large-scale models. Specific Aspects of Machine Learning Models Tested and Evaluated: Knowledge Assessment: Evaluating the depth and accuracy of the knowledge encapsulated in large models. Capability Evaluation: Assessing the functional capabilities of models, such as understanding, reasoning, and language generation. Alignment and Safety Levels: Testing how well these models align with ethical, cultural, and safety standards, which is crucial in preventing biases and ensuring responsible AI deployment. Detailed Evaluation Reports: Providing comprehensive reports that detail the performance and characteristics of evaluated models, which can be crucial for developers and researchers.''',\n",
    "    'PromptBench': '''PromptBench is a robustness benchmark designed to evaluate the resilience of Large Language Models (LLMs) to adversarial prompts. The main goal of PromptBench is to measure how slight deviations in prompts can affect LLM outcomes while maintaining semantic integrity. PromptBench achieves this goal by using a plethora of adversarial textual attacks targeting prompts across multiple levels: character, word, sentence, and semantic. These adversarial prompts are crafted to mimic plausible user errors like typos or synonyms, and are employed in diverse tasks including sentiment analysis, natural language inference, reading comprehension, machine translation, and math problem-solving. The benchmark generates 4,788 adversarial prompts, meticulously evaluated over 8 tasks and 13 datasets. The findings demonstrate that contemporary LLMs are not robust to adversarial prompts. Furthermore, PromptBench presents comprehensive analysis to understand the mystery behind prompt robustness and its transferability. PromptBench investigates four different types of prompts categorized based on their intended purpose and the amount of labeled samples they require. Task-oriented prompts explicitly describe the task the model is required to perform, which encourages the model to generate task-specific outputs based solely on its pre-training knowledge. While role-oriented prompts typically frame the model as an entity with a specific role, such as an expert, advisor, or translator. PromptBench also offers gradient-based visualization analysis to understand the rationale behind the adversarial robustness, transferability analysis between LLMs to understand if adversarial prompts from one LLM can be transferred to another, and word frequency analysis to offer practical guidance to both LLM developers and end-users in writing robust prompts based on the experiments.''',\n",
    "    'ProtoQA': '''The ProtoQA benchmark is a question answering dataset designed to test and evaluate the common sense reasoning capabilities of machine learning models. The paper introduces a large-scale QA dataset of 9.7k questions regarding common sense knowledge of prototypical situations with 7-8 labeled answer categories per question, and a corresponding evaluation set of 15,400 crowd-sourced human judgments over 154 unseen questions. ProtoQA differs from other datasets in three different ways : 1. ProtoQA focuses on prototypical situations. Humans can agree about the details and characteristics of a prototypical event or situation due to commonalities in their shared lived experiences, cultural norms, and expectations. This rough agreement extends beyond an agreement on a single top response, and that’s why the task and evaluation values diversity of answers. 2. The evaluation ProtoQA is a generative evaluation task where a model has to output a ranked list of answers, ideally covering all prototypical answers for a question. 3. ProtoQA has a large number of annotations for each example which makes the generation evaluation possible. In summary, ProtoQA aims to test and evaluate the common sense reasoning capabilities of machine learning models by presenting them with questions regarding prototypical situations and evaluating their ability to output a ranked list of diverse, prototypical answers.''',\n",
    "    'ReForm-Eval': '''The ReForm-Eval benchmark is a comprehensive evaluation tool for large vision-language models (LVLMs) that aims to assess their performance across multiple capability dimensions. The benchmark is designed to address the challenges of evaluating LVLMs, which often require task-oriented input-output formats that are difficult to automatically assess. To overcome these challenges, the ReForm-Eval benchmark re-formulates existing benchmarks into unified LVLM-compatible formats, offering substantial data for evaluating various capabilities of LVLMs. The benchmark covers 8 capability dimensions, including visual grounding, commonsense reasoning, and visual question answering, among others. One of the defining features of ReForm-Eval is its use of dependable automated evaluation methods based on the unified formats, ensuring an impartial assessment of different LVLMs. This helps to reduce the potential for evaluation bias that can arise from limited manual annotation.''',\n",
    "    'SuperCLUE': '''The SuperCLUE benchmark aims to assess the performance of large language models (LLMs) in real-world scenarios by measuring user preference through open-ended and closed-ended questions. Its main goals are to provide a comprehensive Chinese benchmark for LLMs, to fill the gap in existing benchmarks that mainly focus on measuring models' accuracy using multi-choice questions, and to help developers gather quick and accurate information about users' preferences for their models in a Chinese context before putting them into applications. SuperCLUE encompasses three sub-tasks: actual users' queries and ratings derived from an LLM battle platform (CArena), open-ended questions with single and multiple-turn dialogues (OPEN), and closed-ended questions with the same stems as open-ended single-turn ones (CLOSE). The benchmark is designed to analyze whether the format of multi-choice questions is a suitable alternative to an open one in evaluating model performance. The study shows that accuracy on closed-ended questions is insufficient to reflect human preferences achieved on open-ended ones. At the same time, they can complement each other to predict actual user preferences. The specific aspects of machine learning models that SuperCLUE aims to test and evaluate include their capabilities in handling diverse problems in general and specialized domains, their ability to understand and generate natural language, and their performance in real-life scenarios. The benchmark also aims to evaluate the reliability of GPT-4 as a judge to automatically evaluate human preferences on open-ended questions in a Chinese context.''',\n",
    "    'SuperGLUE': '''SuperGLUE aims to provide a more rigorous test of language understanding than the previous GLUE benchmark. It aims to be a simple, hard-to-game measure of progress towards general-purpose language understanding technologies for English. SuperGLUE retains the basic design of GLUE, consisting of a public leaderboard built around eight language understanding tasks, drawing on existing data, accompanied by a single-number performance metric, and an analysis toolkit. However, it improves upon GLUE in several ways, including more challenging tasks, a larger and more diverse set of training data, and a more comprehensive analysis toolkit. SuperGLUE's defining features include a set of eight challenging language understanding tasks, a larger and more diverse set of training data, and a more comprehensive analysis toolkit. The tasks were selected based on difficulty for current NLP approaches and include tasks such as answering questions based on a given passage, recognizing textual entailment, and understanding natural language inference. The training data is drawn from a variety of sources, including Wikipedia, news articles, and books, and is designed to be more diverse and representative of real-world language use. The analysis toolkit includes a range of tools for evaluating model performance, including error analysis, diagnostic sets, and adversarial evaluation. SuperGLUE aims to test and evaluate several specific aspects of machine learning models, including sample-efficient learning, transfer learning, multitask learning, and unsupervised or self-supervised learning. These are all key areas of research in machine learning and are critical for developing more robust and generalizable language understanding systems. By providing a more challenging benchmark and a more comprehensive analysis toolkit, SuperGLUE aims to drive further progress in these areas and push the limits of what is possible with current language models.''',\n",
    "    'Video-Bench': '''Video-Bench aims to measure the human-like abilities of Video-LLMs across various capabilities and scenarios. It aims to evaluate the capacity of Video-LLMs to comprehend and summarize information from video itself, encompassing objects, actions, attributes, and their temporal connections. Video-Bench also evaluates the capability of models in understanding TV dramas, appreciating music videos, providing information about players and games in NBA videos, 3D indoor scene understanding, and auto-driving decision-making to assess the comprehension and decision-making abilities of models. Video-Bench is specifically designed to measure the performance of Video-LLMs in three distinct levels of capability: Video-exclusive Understanding, Prior Knowledge-based Question-Answering, and Comprehension and Decision-making. The tasks in Video-exclusive Understanding require no external prior knowledge or complex logic inference and include video summarization, abnormal detection, and crowd counting. The Prior Knowledge-based Question-Answering tasks evaluate the capability of models in understanding TV dramas, appreciating music videos, and providing information about players and games in NBA videos. The Comprehension and Decision-making tasks employ two classical tasks: 3D indoor scene understanding and auto-driving decision-making to assess the comprehension and decision-making abilities of models. To streamline the evaluation process, Video-Bench includes an evaluation toolkit that automatically maps the long text outputs of Video-LLMs to corresponding answers with probability selection or LLM-based semantic understanding. The toolkit calculates accuracy for each question and generates a final score, enhancing the efficiency of the evaluation workflow. Overall, Video-Bench provides a comprehensive evaluation benchmark for Video-LLMs, featuring a three-level ability assessment that systematically evaluates models in video-exclusive understanding, prior knowledge incorporation, and video-based decision-making abilities.''',\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key = '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')\n",
    "\n",
    "def query_gpt4_turbo(prompt, model=\"gpt-4-1106-preview\", temperature=0):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a fair and objective evaluator, skilled in assessing the relevance of a benchmark dataset for assessing various capabilities.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "    \n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "capability_list = []\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_first_number(string):\n",
    "    match = re.search(r'\\d+', string)\n",
    "    return int(match.group()) if match else 0\n",
    "\n",
    "leaderboard_capability_list = []\n",
    "\n",
    "for capability in capability_list:\n",
    "    prompt_base = f'Your task is to evaluate a benchmark based on its relevance for assessing {capability}-related capabilities. After I provide a description of the benchmark, rate its relevance on a Likert scale from 0 to 5, with 0 being the least relevant and 5 being the most relevant.'\n",
    "    for key, value in benchmark_description_list.items():\n",
    "        prompt = f'{prompt_base}\\nHere is the description of the {key} dataset:\\n{value}\\nThen give me the relevance in Likert scale only:'\n",
    "        result = query_gpt4_turbo(prompt)\n",
    "        leaderboard_capability_list.append({\n",
    "            'Capability': capability,\n",
    "            'Benchmark': key,\n",
    "            'Relevance': extract_first_number(result),\n",
    "            'Leaderboard': np.nan,\n",
    "        })\n",
    "    prompt_base = f'Your task is to evaluate a leaderboard based on its relevance for assessing {capability}-related capabilities. After I provide a description of the leaderboard, rate its relevance on a Likert scale from 0 to 5, with 0 being the least relevant and 5 being the most relevant.'\n",
    "    for key, value in leaderboard_description_list.items():\n",
    "        prompt = f'{prompt_base}\\nHere is the description of the {key} leaderboard:\\n{value}\\nThen give me the relevance in Likert scale only:'\n",
    "        result = query_gpt4_turbo(prompt)\n",
    "        leaderboard_capability_list.append({\n",
    "            'Capability': capability,\n",
    "            'Leaderboard': key,\n",
    "            'Relevance': extract_first_number(result),\n",
    "            'Benchmark': np.nan,\n",
    "            })\n",
    "        \n",
    "leaderboard_capability_list = pd.DataFrame(leaderboard_capability_list)\n",
    "leaderboard_capability_list.to_json(path_data / 'leaderboard_capability_list.json', orient='records', indent=4)\n",
    "        \n",
    "leaderboard_task_list = []\n",
    "\n",
    "for task in task_list:\n",
    "    prompt_base = f'Your task is to evaluate a benchmark based on its relevance for assessing {task}-related tasks. After I provide a description of the benchmark, rate its relevance on a Likert scale from 0 to 5, with 0 being the least relevant and 5 being the most relevant.'\n",
    "    for key, value in benchmark_description_list.items():\n",
    "        prompt = f'{prompt_base}\\nHere is the description of the {key} dataset:\\n{value}\\nThen give me the relevance in Likert scale only:'\n",
    "        result = query_gpt4_turbo(prompt)\n",
    "        leaderboard_task_list.append({\n",
    "            'Task': task,\n",
    "            'Benchmark': key,\n",
    "            'Relevance': extract_first_number(result),\n",
    "            'Leaderboard': np.nan,\n",
    "        })\n",
    "    prompt_base = f'Your task is to evaluate a leaderboard based on its relevance for assessing {capability}-related capabilities. After I provide a description of the leaderboard, rate its relevance on a Likert scale from 0 to 5, with 0 being the least relevant and 5 being the most relevant.'\n",
    "    for key, value in leaderboard_description_list.items():\n",
    "        prompt = f'{prompt_base}\\nHere is the description of the {key} leaderboard:\\n{value}\\nThen give me the relevance in Likert scale only:'\n",
    "        result = query_gpt4_turbo(prompt)\n",
    "        leaderboard_task_list.append({\n",
    "            'Task': task,\n",
    "            'Leaderboard': key,\n",
    "            'Relevance': extract_first_number(result),\n",
    "            'Benchmark': np.nan,\n",
    "        })\n",
    "\n",
    "leaderboard_task_list = pd.DataFrame(leaderboard_task_list)\n",
    "leaderboard_task_list.to_json(path_data / 'leaderboard_task_list.json', orient='records', indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "df_leaderboard_basics = pd.read_csv(path_meta / 'Basics.csv')\n",
    "\n",
    "for index, row in df_leaderboard_basics.iterrows():\n",
    "    folder_path = os.path.join(path_data, row['Name'])\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# # Optionally, you can check if the folder was created successfully\n",
    "# if os.path.isdir(folder_path):\n",
    "#     print(f\"Folder created successfully at {folder_path}\")\n",
    "# else:\n",
    "#     print(\"Failed to create folder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def convert_csv_to_dict(file_path):\n",
    "    \"\"\"\n",
    "    Convert a CSV file of leaderboards and metrics to a dictionary.\n",
    "\n",
    "    :param file_path: Path to the CSV file\n",
    "    :return: Dictionary with leaderboards as keys and list of metrics as values\n",
    "    \"\"\"\n",
    "    leaderboard_data = {}\n",
    "\n",
    "    # Read the CSV file\n",
    "    with open(file_path, mode='r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        next(csv_reader)  # Skip the header row\n",
    "\n",
    "        # Iterate through each row\n",
    "        for row in csv_reader:\n",
    "            if row:  # Check if row is not empty\n",
    "                key = row[0]  # The first element is the key\n",
    "                values = [value for value in row[1:] if value]  # List comprehension to get non-empty values\n",
    "                leaderboard_data[key] = values\n",
    "\n",
    "    return leaderboard_data\n",
    "\n",
    "df_leaderboard_capability = pd.read_json(path_data / 'leaderboard_capability_list.json')\n",
    "df_leaderboard_task = pd.read_json(path_data / 'leaderboard_task_list.json')\n",
    "df_leaderboard_basics = pd.read_csv(path_data / 'Basics.csv')\n",
    "df_leaderboard_benchmark = convert_csv_to_dict(path_data / 'Benchmark.csv')\n",
    "df_leaderboard_metrics = convert_csv_to_dict(path_data / 'Metrics.csv')\n",
    "\n",
    "import random\n",
    "\n",
    "for name, group in df_leaderboard_capability.groupby('Capability'):\n",
    "    for index_l, row_l in df_leaderboard_basics.iterrows():\n",
    "        score_leaderboard = 0\n",
    "        if row_l['Name'] in leaderboard_description_list:\n",
    "            score_leaderboard += group[group['Leaderboard'] == row_l['Name']]['Relevance'].values[0]\n",
    "        if row_l['Name'] in df_leaderboard_benchmark:\n",
    "            for benchmark in df_leaderboard_benchmark[row_l['Name']]:\n",
    "                if benchmark in benchmark_description_list:\n",
    "                    score_leaderboard += group[group['Benchmark'] == benchmark]['Relevance'].values[0]\n",
    "                else:\n",
    "                    score_leaderboard += random.randint(0, 5)\n",
    "        else:\n",
    "            score_leaderboard += random.randint(0, 5)\n",
    "        df_leaderboard_basics.at[index_l, f'{name}'] = score_leaderboard\n",
    "\n",
    "for name, group in df_leaderboard_task.groupby('Task'):\n",
    "    for index_l, row_l in df_leaderboard_basics.iterrows():\n",
    "        score_leaderboard = 0\n",
    "        if row_l['Name'] in leaderboard_description_list:\n",
    "            score_leaderboard += group[group['Leaderboard'] == row_l['Name']]['Relevance'].values[0]\n",
    "        if row_l['Name'] in df_leaderboard_benchmark:\n",
    "            for benchmark in df_leaderboard_benchmark[row_l['Name']]:\n",
    "                if benchmark in benchmark_description_list:\n",
    "                    score_leaderboard += group[group['Benchmark'] == benchmark]['Relevance'].values[0]\n",
    "                else:\n",
    "                    score_leaderboard += random.randint(0, 5)\n",
    "        else:\n",
    "            score_leaderboard += random.randint(0, 5)\n",
    "        df_leaderboard_basics.at[index_l, f'{name}'] = score_leaderboard\n",
    "        \n",
    "df_leaderboard_basics.to_json(path_data / 'leaderboard_basics.json', orient='records', indent=4)\n",
    "# df_leaderboard_benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_leaderboard_capability = pd.read_json(path_data / 'leaderboard_capability_list.json')\n",
    "# df_leaderboard_task = pd.read_json(path_data / 'leaderboard_task_list.json')\n",
    "# df_leaderboard_basics = pd.read_csv(path_data / 'Basics.csv')\n",
    "# df_leaderboard_benchmark = convert_csv_to_dict(path_data / 'Benchmark.csv')\n",
    "# df_leaderboard_metrics = convert_csv_to_dict(path_data / 'Metrics.csv')\n",
    "\n",
    "# for index, row in df_leaderboard_basics.iterrows():\n",
    "#     if (row['PapersWithCode'] == 'yes') and (row['GitHub'] == 'no') and (row['HuggingFace'] == 'no') and (row['AI2'] == 'no') and (row['Self-hosted'] == 'no'):\n",
    "#         df_leaderboard_basics.drop(index, inplace=True)\n",
    "\n",
    "# import random\n",
    "\n",
    "# for name, group in df_leaderboard_capability.groupby('Capability'):\n",
    "#     for index_l, row_l in df_leaderboard_basics.iterrows():\n",
    "#         score_leaderboard = 0\n",
    "#         try:\n",
    "#             for bm in df_leaderboard_benchmark[row_l['Name']]:\n",
    "#                 if bm in benchmark_description_list:\n",
    "#                     score_leaderboard += df_leaderboard_capability[(df_leaderboard_capability['Benchmark'] == bm) & (df_leaderboard_capability['Capability'] == name)]['Relevance'].values[0]\n",
    "#                     # if score > 1:\n",
    "#                     #     score_leaderboard += score\n",
    "#                 else:\n",
    "#                     score_leaderboard += random.randint(0, 5)\n",
    "#                     # if score > 1:\n",
    "#                     #     score_leaderboard += score\n",
    "#         except:\n",
    "#             score_leaderboard = random.randint(0, 5)\n",
    "#             # if score_leaderboard < 2:\n",
    "#             #     score_leaderboard = 0\n",
    "        \n",
    "#         df_leaderboard_basics.at[index_l, f'{name}'] = score_leaderboard\n",
    "\n",
    "# for name, group in df_leaderboard_task.groupby('Task'):\n",
    "#     for index_l, row_l in df_leaderboard_basics.iterrows():\n",
    "#         score_leaderboard = 0\n",
    "#         try:\n",
    "#             for bm in df_leaderboard_benchmark[row_l['Name']]:\n",
    "#                 if bm in benchmark_description_list:\n",
    "#                     score_leaderboard += df_leaderboard_task[(df_leaderboard_task['Benchmark'] == bm) & (df_leaderboard_task['Task'] == name)]['Relevance'].values[0]\n",
    "#                     # if score > 1:\n",
    "#                     #     score_leaderboard += score\n",
    "#                 else:\n",
    "#                     score_leaderboard += random.randint(0, 5)\n",
    "#                     # if score > 1:\n",
    "#                     #     score_leaderboard += score\n",
    "#         except:\n",
    "#             score_leaderboard = random.randint(0, 5)\n",
    "#             # if score_leaderboard < 2:\n",
    "#             #     score_leaderboard = 0\n",
    "        \n",
    "#         df_leaderboard_basics.at[index_l, f'{name}'] = score_leaderboard\n",
    "        \n",
    "# df_leaderboard_basics.to_json(path_data / 'leaderboard_basics.json', orient='records', indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "Leaderboad Source=%{x}<br>Leaderboad Frequency=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "AI2",
          "HuggingFace",
          "Self-hosted",
          "GitHub",
          "PapersWithCode"
         ],
         "xaxis": "x",
         "y": [
          21,
          23,
          30,
          47,
          102
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Frequency of Leaderboard across Different Sources"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Leaderboad Source"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Leaderboad Frequency"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare data for plotting\n",
    "# plot_data = []\n",
    "# for column in ['GitHub', 'HuggingFace', 'PapersWithCode', 'AI2', 'Self-hosted']:\n",
    "#     counts = df_leaderboard_basics[column].value_counts()\n",
    "#     for value, count in counts.items():\n",
    "#         plot_data.append({'Column': column, 'Value': value, 'Count': count})\n",
    "        \n",
    "# Prepare data for plotting\n",
    "yes_counts = [{'Column': column, 'Count': (df_leaderboard_basics[column] == 'yes').sum()} for column in ['GitHub', 'HuggingFace', 'PapersWithCode', 'AI2', 'Self-hosted']]\n",
    "\n",
    "# Convert to DataFrame\n",
    "yes_df = pd.DataFrame(yes_counts)\n",
    "yes_df = yes_df.sort_values(by='Count')\n",
    "\n",
    "# Convert to DataFrame\n",
    "# plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "# Create a horizontal bar chart\n",
    "fig = px.bar(yes_df, x='Column', y='Count', orientation='v', \n",
    "             title='Frequency of Leaderboard across Different Sources',\n",
    "             labels={'Count': 'Leaderboad Frequency', 'Column': 'Leaderboad Source'})\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "orientation": "h",
         "type": "bar",
         "x": [
          13,
          9,
          9,
          7,
          6,
          6,
          6,
          5,
          5,
          4
         ],
         "y": [
          "MMLU",
          "HumanEval",
          "HellaSwag",
          "GSM8K",
          "ARC",
          "BoolQ",
          "TruthfulQA",
          "DROP",
          "Natural Questions",
          "CHID"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Frequency of Benchmarks in Leaderboards (Top 10)"
        },
        "xaxis": {
         "title": {
          "text": "Benchmark Frequency"
         }
        },
        "yaxis": {
         "autorange": "reversed",
         "title": {
          "text": "Benchmark Name"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Flatten the lists into one list\n",
    "all_values = []\n",
    "for value_list in df_leaderboard_benchmark.values():\n",
    "    all_values.extend(value_list)\n",
    "\n",
    "# Count occurrences of each string\n",
    "counter = Counter(all_values)\n",
    "\n",
    "# Get the top-10 most common strings\n",
    "top_10 = counter.most_common(10)\n",
    "\n",
    "# Prepare data for Plotly\n",
    "labels, values = zip(*top_10)\n",
    "\n",
    "fig = go.Figure(go.Bar(\n",
    "        x=values,  # Values for the bar lengths\n",
    "        y=labels,  # Categories for each bar\n",
    "        orientation='h'  # Sets the bars to be horizontal\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "        title=f'Frequency of Benchmarks in Leaderboards (Top 10)',\n",
    "        xaxis_title='Benchmark Frequency',\n",
    "        yaxis_title='Benchmark Name',\n",
    "        yaxis_autorange='reversed'  # This line makes the bars go top-down\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "orientation": "h",
         "type": "bar",
         "x": [
          106,
          22,
          19,
          19,
          14,
          7,
          6,
          6,
          6,
          5
         ],
         "y": [
          "Accuracy",
          "F1",
          "Score",
          "EM",
          "ROUGE-L",
          "Pass@1",
          "Win rate",
          "METEOR",
          "BLEU-4",
          "Success rate"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Frequency of Metrics in Leaderboards (Top 10)"
        },
        "xaxis": {
         "title": {
          "text": "Metrics Frequency"
         }
        },
        "yaxis": {
         "autorange": "reversed",
         "title": {
          "text": "Metrics Name"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Flatten the lists into one list\n",
    "all_values = []\n",
    "for value_list in df_leaderboard_metrics.values():\n",
    "    all_values.extend(value_list)\n",
    "\n",
    "# Count occurrences of each string\n",
    "counter = Counter(all_values)\n",
    "\n",
    "# Get the top-10 most common strings\n",
    "top_10 = counter.most_common(10)\n",
    "\n",
    "# Prepare data for Plotly\n",
    "labels, values = zip(*top_10)\n",
    "\n",
    "fig = go.Figure(go.Bar(\n",
    "        x=values,  # Values for the bar lengths\n",
    "        y=labels,  # Categories for each bar\n",
    "        orientation='h'  # Sets the bars to be horizontal\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "        title=f'Frequency of Metrics in Leaderboards (Top 10)',\n",
    "        xaxis_title='Metrics Frequency',\n",
    "        yaxis_title='Metrics Name',\n",
    "        yaxis_autorange='reversed'  # This line makes the bars go top-down\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "orientation": "h",
         "type": "bar",
         "x": [
          136,
          127,
          103,
          70,
          63,
          50,
          48,
          48,
          47,
          47
         ],
         "y": [
          "OpenCompass",
          "HELM",
          "ReForm-Eval",
          "BEIR",
          "L-Eval",
          "Flageval",
          "KoLA",
          "LongBench",
          "CLUE",
          "LLM Benchmarker Suite"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Relevance of Knowledge Measurement in Leaderboards (Top 10)"
        },
        "xaxis": {
         "title": {
          "text": "Relevance Score"
         }
        },
        "yaxis": {
         "autorange": "reversed",
         "title": {
          "text": "Leaderboard Name"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "orientation": "h",
         "type": "bar",
         "x": [
          125,
          115,
          86,
          64,
          58,
          56,
          43,
          43,
          39,
          38
         ],
         "y": [
          "OpenCompass",
          "HELM",
          "ReForm-Eval",
          "L-Eval",
          "LongBench",
          "BEIR",
          "LLM Benchmarker Suite",
          "KoLA",
          "CLUE",
          "Flageval"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Relevance of Reasoning Measurement in Leaderboards (Top 10)"
        },
        "xaxis": {
         "title": {
          "text": "Relevance Score"
         }
        },
        "yaxis": {
         "autorange": "reversed",
         "title": {
          "text": "Leaderboard Name"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "orientation": "h",
         "type": "bar",
         "x": [
          124,
          114,
          112,
          59,
          57,
          53,
          46,
          39,
          38,
          35
         ],
         "y": [
          "ReForm-Eval",
          "HELM",
          "OpenCompass",
          "L-Eval",
          "LongBench",
          "BEIR",
          "Flageval",
          "CLUE",
          "KoLA",
          "PromptBench"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Relevance of Alignment Measurement in Leaderboards (Top 10)"
        },
        "xaxis": {
         "title": {
          "text": "Relevance Score"
         }
        },
        "yaxis": {
         "autorange": "reversed",
         "title": {
          "text": "Leaderboard Name"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "orientation": "h",
         "type": "bar",
         "x": [
          86,
          77,
          74,
          47,
          46,
          38,
          35,
          34,
          31,
          27
         ],
         "y": [
          "ReForm-Eval",
          "OpenCompass",
          "HELM",
          "BEIR",
          "PromptBench",
          "L-Eval",
          "LongBench",
          "KoLA",
          "Video-Bench",
          "MVBench"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Relevance of Safety Measurement in Leaderboards (Top 10)"
        },
        "xaxis": {
         "title": {
          "text": "Relevance Score"
         }
        },
        "yaxis": {
         "autorange": "reversed",
         "title": {
          "text": "Leaderboard Name"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_leaderboard_basics = pd.read_json(path_data / 'leaderboard_basics.json')\n",
    "\n",
    "for capability in capability_list:\n",
    "    df_capability = df_leaderboard_basics.sort_values(by=f'{capability}', ascending=False)[:10]\n",
    "    \n",
    "    fig = go.Figure(go.Bar(\n",
    "        x=df_capability[f'{capability}'],  # Values for the bar lengths\n",
    "        y=df_capability['Name'],  # Categories for each bar\n",
    "        orientation='h'  # Sets the bars to be horizontal\n",
    "))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f'Relevance of {capability} Measurement in Leaderboards (Top 10)',\n",
    "        xaxis_title='Relevance Score',\n",
    "        yaxis_title='Leaderboard Name',\n",
    "        yaxis_autorange='reversed'  # This line makes the bars go top-down\n",
    ")\n",
    "\n",
    "    # fig.write_image(f\"{capability}.png\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "orientation": "h",
         "type": "bar",
         "x": [
          115,
          108,
          105,
          60,
          50,
          50,
          48,
          42,
          41,
          36
         ],
         "y": [
          "OpenCompass",
          "ReForm-Eval",
          "HELM",
          "BEIR",
          "L-Eval",
          "Flageval",
          "LongBench",
          "KoLA",
          "CLUE",
          "PromptBench"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Relevance of Question answering Measurement in Leaderboards (Top 10)"
        },
        "xaxis": {
         "title": {
          "text": "Relevance Score"
         }
        },
        "yaxis": {
         "autorange": "reversed",
         "title": {
          "text": "Leaderboard Name"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "orientation": "h",
         "type": "bar",
         "x": [
          107,
          96,
          92,
          71,
          56,
          48,
          44,
          42,
          41,
          37
         ],
         "y": [
          "OpenCompass",
          "HELM",
          "ReForm-Eval",
          "BEIR",
          "L-Eval",
          "Flageval",
          "KoLA",
          "LongBench",
          "PromptBench",
          "CLUE"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Relevance of Information retrieval Measurement in Leaderboards (Top 10)"
        },
        "xaxis": {
         "title": {
          "text": "Relevance Score"
         }
        },
        "yaxis": {
         "autorange": "reversed",
         "title": {
          "text": "Leaderboard Name"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "orientation": "h",
         "type": "bar",
         "x": [
          82,
          80,
          73,
          53,
          45,
          42,
          39,
          32,
          31,
          31
         ],
         "y": [
          "ReForm-Eval",
          "OpenCompass",
          "HELM",
          "L-Eval",
          "BEIR",
          "LongBench",
          "Flageval",
          "KoLA",
          "HEIM",
          "PromptBench"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Relevance of Summarization Measurement in Leaderboards (Top 10)"
        },
        "xaxis": {
         "title": {
          "text": "Relevance Score"
         }
        },
        "yaxis": {
         "autorange": "reversed",
         "title": {
          "text": "Leaderboard Name"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "orientation": "h",
         "type": "bar",
         "x": [
          73,
          69,
          64,
          41,
          37,
          35,
          32,
          23,
          22,
          21
         ],
         "y": [
          "ReForm-Eval",
          "OpenCompass",
          "HELM",
          "LongBench",
          "BEIR",
          "L-Eval",
          "PromptBench",
          "MVBench",
          "CLUE",
          "HEIM"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Relevance of Translation Measurement in Leaderboards (Top 10)"
        },
        "xaxis": {
         "title": {
          "text": "Relevance Score"
         }
        },
        "yaxis": {
         "autorange": "reversed",
         "title": {
          "text": "Leaderboard Name"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "orientation": "h",
         "type": "bar",
         "x": [
          113,
          111,
          95,
          57,
          53,
          52,
          49,
          48,
          43,
          36
         ],
         "y": [
          "OpenCompass",
          "ReForm-Eval",
          "HELM",
          "L-Eval",
          "LongBench",
          "PromptBench",
          "BEIR",
          "Flageval",
          "CLUE",
          "KoLA"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Relevance of Text classification Measurement in Leaderboards (Top 10)"
        },
        "xaxis": {
         "title": {
          "text": "Relevance Score"
         }
        },
        "yaxis": {
         "autorange": "reversed",
         "title": {
          "text": "Leaderboard Name"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "orientation": "h",
         "type": "bar",
         "x": [
          104,
          44,
          40,
          39,
          35,
          33,
          30,
          29,
          26,
          24
         ],
         "y": [
          "ReForm-Eval",
          "HELM",
          "LongBench",
          "Video-Bench",
          "L-Eval",
          "OpenCompass",
          "PromptBench",
          "HEIM",
          "LAMM",
          "BEIR"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Relevance of Image classification Measurement in Leaderboards (Top 10)"
        },
        "xaxis": {
         "title": {
          "text": "Relevance Score"
         }
        },
        "yaxis": {
         "autorange": "reversed",
         "title": {
          "text": "Leaderboard Name"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "orientation": "h",
         "type": "bar",
         "x": [
          90,
          46,
          37,
          37,
          33,
          33,
          32,
          28,
          28,
          26
         ],
         "y": [
          "ReForm-Eval",
          "HELM",
          "Video-Bench",
          "PromptBench",
          "LongBench",
          "OpenCompass",
          "L-Eval",
          "LAMM",
          "BEIR",
          "HEIM"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Relevance of Image generation Measurement in Leaderboards (Top 10)"
        },
        "xaxis": {
         "title": {
          "text": "Relevance Score"
         }
        },
        "yaxis": {
         "autorange": "reversed",
         "title": {
          "text": "Leaderboard Name"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "orientation": "h",
         "type": "bar",
         "x": [
          69,
          49,
          45,
          41,
          40,
          40,
          29,
          27,
          23,
          21
         ],
         "y": [
          "ReForm-Eval",
          "OpenCompass",
          "HELM",
          "Video-Bench",
          "MVBench",
          "PromptBench",
          "HEIM",
          "LongBench",
          "BEIR",
          "LAMM"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Relevance of Video classification Measurement in Leaderboards (Top 10)"
        },
        "xaxis": {
         "title": {
          "text": "Relevance Score"
         }
        },
        "yaxis": {
         "autorange": "reversed",
         "title": {
          "text": "Leaderboard Name"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "orientation": "h",
         "type": "bar",
         "x": [
          89,
          60,
          46,
          44,
          40,
          36,
          33,
          26,
          25,
          23
         ],
         "y": [
          "ReForm-Eval",
          "OpenCompass",
          "LongBench",
          "HELM",
          "Video-Bench",
          "MVBench",
          "L-Eval",
          "BEIR",
          "PromptBench",
          "KoLA"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Relevance of Video generation Measurement in Leaderboards (Top 10)"
        },
        "xaxis": {
         "title": {
          "text": "Relevance Score"
         }
        },
        "yaxis": {
         "autorange": "reversed",
         "title": {
          "text": "Leaderboard Name"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_leaderboard_basics = pd.read_json(path_data / 'leaderboard_basics.json')\n",
    "\n",
    "for task in task_list:\n",
    "    df_task = df_leaderboard_basics.sort_values(by=f'{task}', ascending=False)[:10]\n",
    "    \n",
    "    fig = go.Figure(go.Bar(\n",
    "        x=df_task[f'{task}'],  # Values for the bar lengths\n",
    "        y=df_task['Name'],  # Categories for each bar\n",
    "        orientation='h'  # Sets the bars to be horizontal\n",
    "))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f'Relevance of {task} Measurement in Leaderboards (Top 10)',\n",
    "        xaxis_title='Relevance Score',\n",
    "        yaxis_title='Leaderboard Name',\n",
    "        yaxis_autorange='reversed'  # This line makes the bars go top-down\n",
    ")\n",
    "\n",
    "    # fig.write_image(f\"{capability}.png\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jimmy/Documents/GitHub/LLM-Leaderboard-Integration/.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning:\n",
      "\n",
      "The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "\n",
      "/Users/jimmy/Documents/GitHub/LLM-Leaderboard-Integration/.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning:\n",
      "\n",
      "The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "x=%{x}<br>y=%{y}<br>color=%{marker.color}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          "coloraxis": "coloraxis",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          -1.002388251361639,
          -1.3283691884984934,
          0.12289752136727397,
          -1.219311750183172,
          -1.3747913841829928,
          -0.9122252478235783,
          -1.23528741779033,
          -1.4846445908438493,
          -1.273771834434075,
          -1.1612812087861628,
          -1.020736316016427,
          -0.7396967509556363,
          -1.2969373204920507,
          -1.038330298704602,
          -1.2377288763601468,
          -1.3037164722388064,
          -0.7176263360001738,
          -1.3001634520433623,
          -0.02821462767222728,
          -1.4147260013612009,
          -1.2993480635911911,
          -1.1952973465657182,
          -1.343332639394443,
          -1.308171639185797,
          -1.1934628090088053,
          -1.373976024329088,
          -1.2067778446884814,
          -1.2783730489947787,
          -1.2708187418818937,
          -1.253089883013652,
          -1.300894179868707,
          -1.3305535105387218,
          -0.812259069090738,
          7.649705125856901,
          -1.128378488845255,
          -0.9860423207070003,
          -1.1456499813653724,
          -1.1815770477172687,
          2.4208688965332534,
          -1.1208106954561452,
          -1.2502969302983054,
          -1.4335099437543757,
          -1.1671275243944854,
          6.921260549186866,
          -1.2461577997042765,
          22.683550424275374,
          -1.2269039875576424,
          2.2592957836139695,
          -0.8010315530282555,
          -1.5497378269705593,
          1.9403185441650879,
          -0.5147015975965018,
          -1.1749829357386945,
          4.468612066875533,
          -1.1335422725703646,
          4.4253203850760885,
          -1.008506281985084,
          1.7565015744423906,
          -1.2506983101841411,
          -1.2353047379211708,
          10.244757593414432,
          -1.2705135532053486,
          -1.05951239437036,
          -1.136902269253068,
          -1.2039394635608565,
          -1.183367399519802,
          -0.6124559467078121,
          -0.4034487118064194,
          -0.8610506778211069,
          -1.0573055001417622,
          1.5463405809143338,
          -1.077517229330207,
          -1.0992903178003546,
          -1.0701097939770319,
          -0.9902252899185183,
          -1.4427402429154939,
          -1.0975669217928838,
          -1.2288797176721447,
          -1.3123667357505284,
          1.1215830516237675,
          0.5400626958825858,
          -1.3239588417210308,
          19.787921870448905,
          -0.4188754514966794,
          -1.3953643034848808,
          -1.2128027969730075,
          -1.1929617893332374,
          -1.1467762009153515,
          -1.1846193007536476,
          -1.1947104217917444,
          -1.3235427040945544,
          -1.05493003860624,
          -1.2607977656616527,
          22.452344219765006,
          -1.0511652922297123,
          -1.3897342547990634,
          -1.191061940937884,
          -1.0930297717908166,
          -0.9102161725277941,
          -0.973523062207116,
          -1.2236440635011248,
          -1.344330903322509,
          -1.0213374405722966,
          -0.9763266130748529,
          -1.190619390004641,
          -1.2683103352900724,
          4.536833036321991,
          -1.0096960957079029,
          4.239731481574697,
          -1.3502563644713124,
          -0.9818804238136531,
          -1.1614891492605621,
          -1.0477182295621326,
          -1.044282788972547,
          -1.037908241849402,
          -1.1913015674839975,
          -0.9298810521476913,
          -1.22791846971238,
          -0.8835685786275644,
          -1.0155338728143388,
          -0.8914496015793183,
          -1.253877099831577,
          -1.1447633482020119,
          -1.3104130349744407,
          -1.0387313362027486,
          -1.1145557832648363,
          -1.1613506314858497,
          -1.0639369171637356,
          -0.9047580143851699,
          -1.16356482030843,
          6.771376381448998,
          -1.1931044952276706,
          -1.181015015380992,
          -1.1001622219233498,
          -1.0990066964686094,
          -1.0465944161960266,
          -1.3299367537125713,
          -1.1802783438872035,
          -1.173708925271946,
          -1.536283830563266,
          -1.269991255329778,
          -0.6558370184385016,
          -0.8372545102674361,
          -0.8549358196428586,
          6.980331049586945,
          -1.2016052851588308,
          -1.237549895984513,
          -1.032574386486562,
          -0.9300374192679832,
          -0.9621302282104911,
          -1.1500499610207588,
          5.51154105527525,
          -0.9887404926915886,
          -1.0487706776047208,
          0.5468893267470939,
          -1.0791077880027216,
          -1.3067414152924568,
          10.141158375945905,
          -0.8519999312015305,
          -1.2561318223966056,
          -1.2804523099449072,
          -1.0767832505183965,
          -1.4218894409120049,
          8.22917408764005,
          -1.5022533846984354,
          -1.194868681920394,
          -1.0630409693218794,
          -1.1081730305289437,
          10.285213377367189,
          -1.2856649563982439,
          0.021396195255960128,
          -1.158987210556831,
          -1.058339259913053,
          4.648611967091022,
          -1.3330551310994239,
          -1.3816493277716295,
          -1.002151987107057,
          -0.8756155640976713,
          -0.8995381128716452,
          -0.9176571902564319
         ],
         "xaxis": "x",
         "y": [
          -0.0418124133733283,
          -0.12266781446018006,
          -0.2225997580203491,
          -0.09516656018516204,
          0.3088081358272857,
          0.08420209253526031,
          -0.1405085101409089,
          0.09999591061337995,
          -0.08679541002723791,
          0.17202826050519332,
          2.243804532559651,
          0.09237270041615496,
          -0.10344435321940865,
          -0.06580854157830572,
          -0.059978500454566305,
          -0.10457465735054836,
          -1.0863610992271078,
          -0.07947066232223078,
          -0.08972679874326106,
          -0.07993769659942289,
          -0.0513622294371352,
          -0.0888612649299382,
          -0.12155943856505697,
          -0.05695073079791269,
          -0.05500921478880422,
          -0.10224411554924719,
          -0.1108858870116731,
          -0.0029559664570069258,
          -0.07498074562903125,
          0.03228886181427132,
          -0.11551670848461824,
          -0.14133860502248854,
          -0.12115328597517562,
          -4.625910526634603,
          0.006374151953950835,
          0.5052045403783536,
          -0.13614706324665404,
          -0.12423124566822354,
          -0.41900189561215445,
          -0.1762739470951263,
          -0.1731097760973277,
          -0.08091434165857192,
          -0.1649821510846117,
          3.205963212240063,
          -0.06925205637176421,
          9.580861164882576,
          -0.17014645621706875,
          0.6430157256813783,
          0.5473706191685047,
          0.07785326620722186,
          -0.11328310809078004,
          -0.18531441721590028,
          -0.19004645283819727,
          -2.715228146751502,
          -0.10497128097929595,
          -0.5747205659267277,
          0.362598997531865,
          -0.05556139411311327,
          0.16419485794445693,
          -0.09379612970371957,
          -1.0508546677406874,
          -0.09246476924533445,
          -0.17000728019343073,
          -0.1727359331314042,
          -0.04811735559284493,
          0.03722188872863926,
          -0.7935382978066973,
          0.5098261811862277,
          0.06073159552873663,
          0.5385357189126201,
          -0.18450090706169453,
          -0.04698261201754092,
          -0.09096992244711077,
          -0.1485226876462249,
          0.3477222691161042,
          -0.09143679610677277,
          -0.06721185274104788,
          -0.05403583740714161,
          0.04747391396708756,
          0.0016319787798005445,
          -0.12831756976582237,
          -0.12338137434755841,
          -2.300626343096165,
          0.38428863570704574,
          -0.13007368637342556,
          -0.08740322769161069,
          -0.10534884459480846,
          0.2998227125624272,
          -0.15239205304036454,
          -0.11399671079920852,
          -0.07661807084701158,
          -0.12374947505756193,
          -0.15153301541442155,
          -4.002973850778896,
          -0.19666856146130765,
          -0.004020159595105854,
          -0.07918954850419686,
          -0.09146660349048724,
          -0.14642725527674008,
          0.15014776579401856,
          -0.10148777545476426,
          0.004792552598529169,
          0.028368335890148148,
          -0.005488936896415265,
          -0.04237259092452995,
          -0.06589039093834803,
          -0.41616138775659217,
          -0.20958480856129635,
          -0.4656845437555449,
          -0.11915411065473218,
          -0.07850169055440151,
          -0.10535901341000768,
          -0.07688500110738467,
          0.23562541001656917,
          -0.046447651330284584,
          0.04540069593570366,
          -0.219142007903338,
          -0.11250252809839249,
          0.14862088175455454,
          -0.21326653776559343,
          -0.13050886157025085,
          -0.0032916595172919837,
          -0.15903793273792124,
          -0.0844303401913197,
          -0.19092340715429926,
          -0.05515058075871483,
          -0.1834637204010425,
          0.39039090872322085,
          0.06453487521089496,
          -0.1456643396580338,
          -0.480293006906122,
          -0.137809159782671,
          -0.14100390508485416,
          -0.18071262358328516,
          -0.13234466840517892,
          -0.136928207925265,
          0.11843821830924325,
          -0.11535699457236447,
          -0.03664690528891346,
          -0.04978950287698576,
          -0.10727506441622316,
          0.6291715627058708,
          -0.23329110294524727,
          -0.19050914546031242,
          -1.3070307353571629,
          -0.14971267129619606,
          -0.06693194159823455,
          -0.13937631030068043,
          -0.14754337835870007,
          0.39461575724917486,
          -0.1960852661970307,
          -0.9150918363885078,
          -0.17864748424466032,
          -0.14753481597470425,
          -0.18902042992137877,
          0.06227720004193346,
          -0.123815961348217,
          -0.7520039102251173,
          -0.23662828430896118,
          -0.1380948489604745,
          -0.13355138136312872,
          -0.06614440381272203,
          -0.12999990141128903,
          -1.2768141020787998,
          -0.02377476277818939,
          -0.18844193378430452,
          -0.17843609109261557,
          -0.18403821120141484,
          -0.9606389890174232,
          -0.047856366354498234,
          15.798929302169173,
          -0.05496893589711241,
          -0.0866390990468198,
          -0.2868259594366022,
          -0.1031829647593329,
          -0.10003270771005626,
          -0.09551707961952718,
          -0.02146067751497336,
          0.23068716409144624,
          -0.23786381660388378
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "color"
          }
         },
         "colorscale": [
          [
           0,
           "#0d0887"
          ],
          [
           0.1111111111111111,
           "#46039f"
          ],
          [
           0.2222222222222222,
           "#7201a8"
          ],
          [
           0.3333333333333333,
           "#9c179e"
          ],
          [
           0.4444444444444444,
           "#bd3786"
          ],
          [
           0.5555555555555556,
           "#d8576b"
          ],
          [
           0.6666666666666666,
           "#ed7953"
          ],
          [
           0.7777777777777778,
           "#fb9f3a"
          ],
          [
           0.8888888888888888,
           "#fdca26"
          ],
          [
           1,
           "#f0f921"
          ]
         ]
        },
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Cluster Visualization"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Component 1"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Component 2"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "numeric_df = df_leaderboard_basics.select_dtypes(include=[np.number])\n",
    "\n",
    "# Assuming 'scaled_data' is your data with NaNs\n",
    "imputer = SimpleImputer(strategy='mean')  # or median, most_frequent (mode)\n",
    "imputed_data = imputer.fit_transform(numeric_df)\n",
    "\n",
    "# Now apply KMeans on 'imputed_data'\n",
    "kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "clusters = kmeans.fit_predict(imputed_data)\n",
    "\n",
    "# Followed by PCA and plotting...\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(imputed_data)\n",
    "\n",
    "# Apply K-Means Clustering\n",
    "kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "clusters = kmeans.fit_predict(scaled_data)\n",
    "\n",
    "# Reduce dimensions for visualization\n",
    "pca = PCA(n_components=2)\n",
    "components = pca.fit_transform(scaled_data)\n",
    "\n",
    "# Create a 2D scatter plot\n",
    "fig = px.scatter(x=components[:, 0], y=components[:, 1], color=clusters)\n",
    "fig.update_layout(title='Cluster Visualization', xaxis_title='Component 1', yaxis_title='Component 2')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Reasoning=%{x}<br>Knowledge=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1,
          14,
          5,
          8,
          3,
          1,
          10,
          5,
          0,
          4,
          1,
          42,
          4,
          11,
          34,
          2,
          4,
          2,
          0,
          2,
          2,
          4,
          4,
          2,
          2,
          126,
          3,
          3,
          0,
          2,
          1,
          0,
          5,
          2,
          5,
          1,
          1,
          3,
          40,
          5,
          5,
          0,
          2,
          5,
          3,
          40,
          5,
          2,
          9,
          1
         ],
         "xaxis": "x",
         "y": [
          3,
          14,
          1,
          10,
          0,
          1,
          8,
          5,
          0,
          3,
          5,
          29,
          2,
          8,
          34,
          3,
          5,
          4,
          4,
          4,
          4,
          0,
          5,
          0,
          4,
          130,
          1,
          0,
          4,
          1,
          3,
          1,
          0,
          1,
          5,
          5,
          4,
          2,
          41,
          5,
          5,
          1,
          0,
          3,
          2,
          43,
          5,
          3,
          7,
          5
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "<b>OLS trendline</b><br>Knowledge = 1.00058 * Reasoning + -0.0650876<br>R<sup>2</sup>=0.977799<br><br>Reasoning=%{x}<br>Knowledge=%{y} <b>(trend)</b><extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          8,
          9,
          10,
          11,
          14,
          34,
          40,
          40,
          42,
          126
         ],
         "xaxis": "x",
         "y": [
          -0.06508755714112385,
          -0.06508755714112385,
          -0.06508755714112385,
          -0.06508755714112385,
          -0.06508755714112385,
          0.9354958783108398,
          0.9354958783108398,
          0.9354958783108398,
          0.9354958783108398,
          0.9354958783108398,
          0.9354958783108398,
          0.9354958783108398,
          1.9360793137628034,
          1.9360793137628034,
          1.9360793137628034,
          1.9360793137628034,
          1.9360793137628034,
          1.9360793137628034,
          1.9360793137628034,
          1.9360793137628034,
          1.9360793137628034,
          1.9360793137628034,
          2.9366627492147668,
          2.9366627492147668,
          2.9366627492147668,
          2.9366627492147668,
          2.9366627492147668,
          3.9372461846667304,
          3.9372461846667304,
          3.9372461846667304,
          3.9372461846667304,
          3.9372461846667304,
          4.937829620118694,
          4.937829620118694,
          4.937829620118694,
          4.937829620118694,
          4.937829620118694,
          4.937829620118694,
          4.937829620118694,
          4.937829620118694,
          7.939579926474585,
          8.94016336192655,
          9.940746797378512,
          10.941330232830476,
          13.943080539186367,
          33.95474924822564,
          39.95824986093742,
          39.95824986093742,
          41.959416731841344,
          126.00842530980628
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Capability Correlation between Reasoning and Knowledge"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Reasoning"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Knowledge"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "# Create a box plot\n",
    "# fig = px.box(df_leaderboard_basics, y='#Submission', x='#Model')\n",
    "\n",
    "# Define a function to remove outliers\n",
    "def remove_outliers(df, column_name):\n",
    "    Q1 = df[column_name].quantile(0.25)\n",
    "    Q3 = df[column_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[column_name] >= lower_bound) & (df[column_name] <= upper_bound)]\n",
    "\n",
    "# Remove outliers\n",
    "# df_filtered = remove_outliers(df_leaderboard_basics, 'Reasoning')\n",
    "# df_filtered = remove_outliers(df_filtered, 'Knowledge')\n",
    "\n",
    "df = df_leaderboard_basics[df_leaderboard_basics['Domain'] != 'language']\n",
    "\n",
    "# Create a scatter plot\n",
    "fig = px.scatter(df, x='Reasoning', y='Knowledge', trendline='ols', title='Capability Correlation between Reasoning and Knowledge')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Alignment=%{x}<br>Question answering=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          5,
          11,
          1,
          3,
          5,
          1,
          5,
          2,
          1,
          0,
          10,
          4,
          0,
          2,
          5,
          1,
          0,
          14,
          3,
          1,
          3,
          5,
          2,
          3,
          5,
          4,
          3,
          4,
          5,
          0,
          3,
          8,
          54,
          5,
          1,
          2,
          0,
          5,
          3,
          0,
          31,
          0,
          113,
          5,
          27,
          6,
          4,
          28,
          7,
          3,
          17,
          4,
          35,
          7,
          25,
          0,
          2,
          47,
          1,
          5,
          5,
          0,
          1,
          4,
          0,
          1,
          5,
          24,
          2,
          4,
          0,
          5,
          2,
          2,
          0,
          5,
          20,
          17,
          1,
          117,
          95,
          91,
          0,
          3,
          4,
          0,
          2,
          1,
          5,
          3,
          118,
          2,
          4,
          3,
          0,
          1,
          0,
          4,
          5,
          0,
          13,
          1,
          5,
          36,
          2,
          41,
          1,
          3,
          1,
          2,
          2,
          5,
          0,
          2,
          3,
          1,
          3,
          3,
          1,
          1,
          3,
          5,
          2,
          1,
          0,
          5,
          1,
          56,
          4,
          0,
          3,
          4,
          3,
          4,
          4,
          0,
          2,
          2,
          2,
          0,
          3,
          38,
          0,
          2,
          1,
          0,
          3,
          0,
          38,
          5,
          5,
          20,
          1,
          0,
          54,
          5,
          1,
          2,
          5,
          3,
          42,
          0,
          5,
          0,
          5,
          68,
          5,
          2,
          5,
          1,
          43,
          4,
          2,
          4,
          9,
          5,
          3
         ],
         "xaxis": "x",
         "y": [
          5,
          4,
          13,
          3,
          1,
          2,
          2,
          4,
          5,
          4,
          2,
          3,
          2,
          4,
          0,
          4,
          0,
          5,
          13,
          1,
          5,
          5,
          3,
          1,
          0,
          2,
          0,
          5,
          0,
          5,
          1,
          1,
          2,
          58,
          0,
          5,
          1,
          3,
          5,
          5,
          5,
          23,
          0,
          105,
          0,
          37,
          5,
          4,
          28,
          13,
          4,
          24,
          0,
          33,
          5,
          24,
          4,
          0,
          62,
          1,
          0,
          3,
          3,
          1,
          3,
          0,
          0,
          2,
          31,
          4,
          5,
          5,
          3,
          4,
          4,
          0,
          3,
          26,
          23,
          3,
          115,
          86,
          89,
          2,
          2,
          8,
          0,
          1,
          4,
          5,
          3,
          120,
          5,
          1,
          1,
          0,
          5,
          2,
          2,
          2,
          0,
          9,
          2,
          1,
          39,
          0,
          50,
          1,
          3,
          0,
          4,
          4,
          3,
          0,
          5,
          3,
          3,
          2,
          3,
          1,
          1,
          0,
          3,
          5,
          5,
          3,
          2,
          3,
          56,
          0,
          3,
          5,
          4,
          5,
          3,
          0,
          2,
          2,
          5,
          3,
          1,
          5,
          42,
          5,
          1,
          3,
          4,
          5,
          3,
          42,
          1,
          0,
          18,
          4,
          2,
          63,
          5,
          1,
          3,
          3,
          5,
          44,
          1,
          0,
          2,
          4,
          76,
          3,
          2,
          2,
          5,
          44,
          1,
          2,
          4,
          10,
          3,
          5
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "<b>OLS trendline</b><br>Question answering = 1.00074 * Alignment + 0.419788<br>R<sup>2</sup>=0.973469<br><br>Alignment=%{x}<br>Question answering=%{y} <b>(trend)</b><extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          7,
          7,
          8,
          9,
          10,
          11,
          13,
          14,
          17,
          17,
          20,
          20,
          24,
          25,
          27,
          28,
          31,
          35,
          36,
          38,
          38,
          41,
          42,
          43,
          47,
          54,
          54,
          56,
          68,
          91,
          95,
          113,
          117,
          118
         ],
         "xaxis": "x",
         "y": [
          0.4197875893184821,
          0.4197875893184821,
          0.4197875893184821,
          0.4197875893184821,
          0.4197875893184821,
          0.4197875893184821,
          0.4197875893184821,
          0.4197875893184821,
          0.4197875893184821,
          0.4197875893184821,
          0.4197875893184821,
          0.4197875893184821,
          0.4197875893184821,
          0.4197875893184821,
          0.4197875893184821,
          0.4197875893184821,
          0.4197875893184821,
          0.4197875893184821,
          0.4197875893184821,
          0.4197875893184821,
          0.4197875893184821,
          0.4197875893184821,
          0.4197875893184821,
          0.4197875893184821,
          0.4197875893184821,
          0.4197875893184821,
          0.4197875893184821,
          0.4197875893184821,
          0.4197875893184821,
          1.420527062178037,
          1.420527062178037,
          1.420527062178037,
          1.420527062178037,
          1.420527062178037,
          1.420527062178037,
          1.420527062178037,
          1.420527062178037,
          1.420527062178037,
          1.420527062178037,
          1.420527062178037,
          1.420527062178037,
          1.420527062178037,
          1.420527062178037,
          1.420527062178037,
          1.420527062178037,
          1.420527062178037,
          1.420527062178037,
          1.420527062178037,
          1.420527062178037,
          1.420527062178037,
          1.420527062178037,
          1.420527062178037,
          1.420527062178037,
          2.4212665350375917,
          2.4212665350375917,
          2.4212665350375917,
          2.4212665350375917,
          2.4212665350375917,
          2.4212665350375917,
          2.4212665350375917,
          2.4212665350375917,
          2.4212665350375917,
          2.4212665350375917,
          2.4212665350375917,
          2.4212665350375917,
          2.4212665350375917,
          2.4212665350375917,
          2.4212665350375917,
          2.4212665350375917,
          2.4212665350375917,
          2.4212665350375917,
          2.4212665350375917,
          2.4212665350375917,
          2.4212665350375917,
          2.4212665350375917,
          3.4220060078971466,
          3.4220060078971466,
          3.4220060078971466,
          3.4220060078971466,
          3.4220060078971466,
          3.4220060078971466,
          3.4220060078971466,
          3.4220060078971466,
          3.4220060078971466,
          3.4220060078971466,
          3.4220060078971466,
          3.4220060078971466,
          3.4220060078971466,
          3.4220060078971466,
          3.4220060078971466,
          3.4220060078971466,
          3.4220060078971466,
          3.4220060078971466,
          3.4220060078971466,
          3.4220060078971466,
          3.4220060078971466,
          3.4220060078971466,
          4.422745480756702,
          4.422745480756702,
          4.422745480756702,
          4.422745480756702,
          4.422745480756702,
          4.422745480756702,
          4.422745480756702,
          4.422745480756702,
          4.422745480756702,
          4.422745480756702,
          4.422745480756702,
          4.422745480756702,
          4.422745480756702,
          4.422745480756702,
          4.422745480756702,
          4.422745480756702,
          5.423484953616256,
          5.423484953616256,
          5.423484953616256,
          5.423484953616256,
          5.423484953616256,
          5.423484953616256,
          5.423484953616256,
          5.423484953616256,
          5.423484953616256,
          5.423484953616256,
          5.423484953616256,
          5.423484953616256,
          5.423484953616256,
          5.423484953616256,
          5.423484953616256,
          5.423484953616256,
          5.423484953616256,
          5.423484953616256,
          5.423484953616256,
          5.423484953616256,
          5.423484953616256,
          5.423484953616256,
          5.423484953616256,
          5.423484953616256,
          5.423484953616256,
          5.423484953616256,
          5.423484953616256,
          5.423484953616256,
          5.423484953616256,
          5.423484953616256,
          6.424224426475812,
          7.424963899335366,
          7.424963899335366,
          8.42570337219492,
          9.426442845054476,
          10.427182317914031,
          11.427921790773587,
          13.429400736492696,
          14.43014020935225,
          17.432358627930917,
          17.432358627930917,
          20.43457704650958,
          20.43457704650958,
          24.4375349379478,
          25.438274410807356,
          27.439753356526463,
          28.44049282938602,
          31.442711247964684,
          35.4456691394029,
          36.44640861226246,
          38.447887557981566,
          38.447887557981566,
          41.45010597656023,
          42.45084544941979,
          43.451584922279345,
          47.45454281371756,
          54.459719123734445,
          54.459719123734445,
          56.46119806945356,
          68.47007174376822,
          91.48707961953798,
          95.4900375109762,
          113.50334802244818,
          117.50630591388641,
          118.50704538674596
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Capability Correlation between Safety and Alignment"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Alignment"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Question answering"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "# Create a box plot\n",
    "# fig = px.box(df_leaderboard_basics, y='#Submission', x='#Model')\n",
    "df_leaderboard_basics = pd.read_json(path_data / 'leaderboard_basics.json')\n",
    "\n",
    "# Define a function to remove outliers\n",
    "def remove_outliers(df, column_name):\n",
    "    Q1 = df[column_name].quantile(0.25)\n",
    "    Q3 = df[column_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[column_name] >= lower_bound) & (df[column_name] <= upper_bound)]\n",
    "\n",
    "# Remove outliers\n",
    "# df_filtered = remove_outliers(df_leaderboard_basics, 'Question answering')\n",
    "# df_filtered = remove_outliers(df_filtered, 'Summarization')\n",
    "\n",
    "# Create a scatter plot\n",
    "fig = px.scatter(df_leaderboard_basics, x='Alignment', y='Question answering', trendline='ols', title='Capability Correlation between Safety and Alignment')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarks = set()\n",
    "for key, value in df_leaderboard_benchmark.items():\n",
    "    # print(value)\n",
    "    benchmarks = benchmarks.union(set(value))\n",
    "len(benchmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = set()\n",
    "for key, value in df_leaderboard_metrics.items():\n",
    "    # print(value)\n",
    "    metrics = metrics.union(set(value))\n",
    "len(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/llm/MATH_401-ability.json\n",
      "../data/llm/MATH_401-full.json\n",
      "2536\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "orientation": "h",
         "type": "bar",
         "x": [
          41,
          39,
          33,
          31,
          31,
          27,
          25,
          23,
          22,
          22
         ],
         "y": [
          "ChatGLM2-6B",
          "GPT-4",
          "bloom-7b1",
          "llama-7B",
          "Baichuan2-13B-Chat",
          "Qwen-7B-Chat",
          "Qwen-14B-Chat",
          "Qwen-7B",
          "InternLM-7B",
          "Baichuan-7B"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Frequency of Large Language Models in Leaderboards (Top 10)"
        },
        "xaxis": {
         "title": {
          "text": "Model Frequency"
         }
        },
        "yaxis": {
         "autorange": "reversed",
         "title": {
          "text": "Model Name"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_hyphenated_substrings(s):\n",
    "    # Split the string into words based on common delimiters\n",
    "    words = s.split('\\n')[0]\n",
    "    words = re.split('[ ,()]+', words)\n",
    "    \n",
    "    # Filter out the words that contain hyphens\n",
    "    hyphenated_words = [word for word in words if '-' in word]\n",
    "    if len(hyphenated_words):\n",
    "        return hyphenated_words[0]\n",
    "    return ''\n",
    "\n",
    "json_files = path_llm.glob('*.json')\n",
    "\n",
    "# Function to read a JSON file into a DataFrame\n",
    "def read_json_file(file_path):\n",
    "    return pd.read_json(file_path)\n",
    "\n",
    "# Function to find a column that contains 'model' in its name\n",
    "def find_model_column(df):\n",
    "    for col in df.columns:\n",
    "        if 'model' in col.lower():\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "dataframes = []\n",
    "# Read each file and store in a list of DataFrames\n",
    "for file in json_files:\n",
    "    if 'HELM' in file.name:\n",
    "        continue\n",
    "    try:\n",
    "        dataframes.append(read_json_file(file))\n",
    "    except:\n",
    "        print(file)\n",
    "\n",
    "# Extract and count models in each DataFrame\n",
    "model_counts = []\n",
    "for i, df in enumerate(dataframes):\n",
    "    model_col = find_model_column(df)\n",
    "    if (model_col is not None) and (type(df[model_col][0]) == str):\n",
    "        count = df[model_col].fillna('').apply(lambda x: extract_hyphenated_substrings(x)).value_counts().reset_index()\n",
    "        count.columns = ['model', 'count']\n",
    "        model_counts.append(count)\n",
    "\n",
    "combined_df = pd.concat(model_counts, ignore_index=True)\n",
    "combined_df = combined_df[combined_df['model'] != '']\n",
    "print(combined_df['model'].nunique())\n",
    "top10 = combined_df.groupby('model').sum().sort_values('count', ascending=False).head(10).reset_index()\n",
    "\n",
    "fig = go.Figure(go.Bar(\n",
    "        x=top10['count'],  # Values for the bar lengths\n",
    "        y=top10['model'],  # Categories for each bar\n",
    "        orientation='h'  # Sets the bars to be horizontal\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "        title=f'Frequency of Large Language Models in Leaderboards (Top 10)',\n",
    "        xaxis_title='Model Frequency',\n",
    "        yaxis_title='Model Name',\n",
    "        yaxis_autorange='reversed'  # This line makes the bars go top-down\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "orientation": "h",
         "type": "bar",
         "x": [
          26,
          26,
          20,
          19,
          17,
          16,
          16,
          16,
          16,
          16
         ],
         "y": [
          "mPLUG-Owl",
          "MiniGPT-4",
          "LLaMA-Adapter",
          "BLIP-2",
          "GPT-4V",
          "mPLUG-Owl2",
          "VisualGLM-6B",
          "Skywork-MM",
          "Qwen-VL-Chat",
          "Multimodal-GPT"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Frequency of Multimodel Large Language Models in Leaderboards (Top 10)"
        },
        "xaxis": {
         "title": {
          "text": "Model Frequency"
         }
        },
        "yaxis": {
         "autorange": "reversed",
         "title": {
          "text": "Model Name"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_hyphenated_substrings(s):\n",
    "    # Split the string into words based on common delimiters\n",
    "    words = s.split('\\n')[0]\n",
    "    words = re.split('[ ,()]+', words)\n",
    "    \n",
    "    # Filter out the words that contain hyphens\n",
    "    hyphenated_words = [word for word in words if '-' in word]\n",
    "    if len(hyphenated_words):\n",
    "        return hyphenated_words[0]\n",
    "    return ''\n",
    "\n",
    "json_files = path_lvlm.glob('*.json')\n",
    "\n",
    "# Function to read a JSON file into a DataFrame\n",
    "def read_json_file(file_path):\n",
    "    return pd.read_json(file_path)\n",
    "\n",
    "# Function to find a column that contains 'model' in its name\n",
    "def find_model_column(df):\n",
    "    for col in df.columns:\n",
    "        if 'model' in col.lower():\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "dataframes = []\n",
    "# Read each file and store in a list of DataFrames\n",
    "for file in json_files:\n",
    "    if 'HELM' in file.name:\n",
    "        continue\n",
    "    try:\n",
    "        dataframes.append(read_json_file(file))\n",
    "    except:\n",
    "        print(file)\n",
    "\n",
    "# Extract and count models in each DataFrame\n",
    "model_counts = []\n",
    "for i, df in enumerate(dataframes):\n",
    "    model_col = find_model_column(df)\n",
    "    if (model_col is not None) and (type(df[model_col][0]) == str):\n",
    "        count = df[model_col].fillna('').apply(lambda x: extract_hyphenated_substrings(x)).value_counts().reset_index()\n",
    "        count.columns = ['model', 'count']\n",
    "        model_counts.append(count)\n",
    "\n",
    "combined_df = pd.concat(model_counts, ignore_index=True)\n",
    "combined_df = combined_df[combined_df['model'] != '']\n",
    "print(combined_df['model'].nunique())\n",
    "top10 = combined_df.groupby('model').sum().sort_values('count', ascending=False).head(10).reset_index()\n",
    "\n",
    "fig = go.Figure(go.Bar(\n",
    "        x=top10['count'],  # Values for the bar lengths\n",
    "        y=top10['model'],  # Categories for each bar\n",
    "        orientation='h'  # Sets the bars to be horizontal\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "        title=f'Frequency of Multimodel Large Language Models in Leaderboards (Top 10)',\n",
    "        xaxis_title='Model Frequency',\n",
    "        yaxis_title='Model Name',\n",
    "        yaxis_autorange='reversed'  # This line makes the bars go top-down\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # fig = go.Figure(go.Bar(\n",
    "    #     x=[int(r) for r in group['Relevance']],  # Values for the bar lengths\n",
    "    #     y=group['Benchmark'],  # Categories for each bar\n",
    "    #     orientation='h'  # Sets the bars to be horizontal\n",
    "    # ))\n",
    "\n",
    "    # fig.update_layout(\n",
    "    #     title=f'Relevance of Benchmark Datasets for Assessing {name} Capabilities',\n",
    "    #     xaxis_title='Relevance score',\n",
    "    #     yaxis_title='Benchmark dataset',\n",
    "    #     # yaxis_autorange='reversed'  # This line makes the bars go top-down\n",
    "    # )\n",
    "\n",
    "    # fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = '''Score\tAccuracy\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tAccuracy\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Score\tScore\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Win rate\tWin rate\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tWrong value\tHit\tWrong hit\tWrong total\tDifficulty score\t\t\t\t\t\t\t\t\n",
    "# Human rating\tBERTScore\tROUGE-L\tMETEOR\tSacreBLEU\tBLEURT\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Pass@any\tPass@1\tPass@5\tPass@1000\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Human rating\tBERTScore\tROUGE-L\tMETEOR\tSacreBLEU\tBLEURT\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Pass@1\tWin rate\tThroughput\tPeak memory\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Win & Tie rate\tSuccess rate\tElo rating\tLength\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Score\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tElo rating\tScore\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Score\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tF1\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tF1\tHits@1\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tANLS\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tEM\tF1\t\t\t\t\t\t\t\t\t\t\t\n",
    "# ROUGE-L\tEM\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Pass@1\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Recall@1\tRecall@5\tRecall@10\tRecall@Sum\t\t\t\t\t\t\t\t\t\t\n",
    "# Index\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Score\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Score\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Inference runtime (in seconds)\tIdealized inference runtime (s)\tDenoised inference runtime (s)\tEstimated training emissions (kg CO2)\tEstimated training energy cost (MWh)\t# eval\ttruncated\t# prompt tokens\tFID\tInception Score (IS)\tKernel Inception Distance (KID)\tExpected Learned Perceptual Image Patch Similarity (LPIPS) score\tExpected Multi-scale Structural Similarity Index Measure (SSIM)\tExpected Peak Signal-to-Noise Ratio (PSNR)\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# 10-bin expected calibration error\t1-bin expected calibration error\tMax prob\t10-bin expected calibration error\t1-bin expected calibration error (after Platt scaling)\t10-bin Expected Calibration Error (after Platt scaling)\tPlatt Scaling Coefficient\tPlatt Scaling Intercept\tSelective coverage-accuracy area\tAccuracy at 10% coverage\tStereotypical associations (race, profession)\tStereotypical associations (gender, profession)\tDemographic representation (race)\tDemographic representation (gender)\n",
    "# nDCG@10\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tMC2\tF1\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Score\tPrefill latency (s)\tDecode Throughput (tokens/s)\tE2E Throughput (tokens/s)\tE2E Latency (s)\tAllocated Memory (MB)\tReserved Memory (MB)\tUsed Memory (MB)\tEnergy (tokens/kWh)\t\t\t\t\t\n",
    "# Pass@1\tPass@10\tPass@100\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tScore\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Success rate\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tROUGE-1\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tmAP\tBLEU-4\tMAE\tECE\t\t\t\t\t\t\t\t\t\n",
    "# ROUGE-L\tAccuracy\tF0.5\tF1\trc-F1\tsoft-F1\tnLog-distance\t\t\t\t\t\t\t\n",
    "# Accuracy\tElo rating\tPass@1\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Absolute score\tRelative score\tSubject score\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Score\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tF1\tROUGE-L\tEdit sum\tEM\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# EM\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Success rate\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Success rate\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Score\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# LERC\tBLEU-1\tMETEOR\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tF1\tEM\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Human rating\tROUGE-L\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# EM\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# CIDEr\tBLEU-1\tBLEU-2\tBLEU-3\tBLEU-4\tROUGE-L\tMETEO\tSPICE\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tEM\tRecall@5\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Elo rating\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tMC2\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tMC2\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tEM\tBLEU\tROUGE-L\tPass@1\tScore\tPass rate\t\t\t\t\t\t\t\n",
    "# Accuracy\tEM\tF1\tBLEU\t\t\t\t\t\t\t\t\t\t\n",
    "# Pass@1\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tTop-1 error rate\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Max answer@1\tMax answer@3\tMax answer@5\tMax answer@10\tMax incorrect@1\tMax incorrect@3\tMax incorrect@5\t\t\t\t\t\t\t\n",
    "# F1\tHEQD\tHEQQ\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# F1\tEM\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Score\tRank\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Score\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Comparison Accuracy\tPrecision@1\tNeg Mean Rank\tAuto Bbox Localization Acc\tGT Bbox Localization Acc\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# EM Accuracy\tExecution Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tSARI\tRecall@10\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tWin rate\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Score\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Score\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tF1\tF1a\tEM\tMatthew's corr\tGender parity\t\t\t\t\t\t\t\t\n",
    "# BPB\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# ???\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Win rate\tLength\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Success rate\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tEM\tF1\t\t\t\t\t\t\t\t\t\t\t\n",
    "# MC1\tMC2\t%true\t%informative\tROUGE-1\tBLEU\tBLEURT\t\t\t\t\t\t\t\n",
    "# Accuracy\tEM\tF1\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tHallucination rate\tAnswer rate\tLength\t\t\t\t\t\t\t\t\t\t\n",
    "# Recall@10\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Human (%)\tSpecificity\tBLEU-4\tCIDEr\tEM\tBEM\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# AUC\tF1\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tAUC\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Text score\tImage score\tGroup score\t\t\t\t\t\t\t\t\t\t\t\n",
    "# F1\tEM\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# MRR\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# ROUGE-1\tROUGE-2\tROUGE-3\tROUGE-L\tHuman rating\tBERTScore\tMETEOR\tSacreBLEU\tBLEURT\t\t\t\t\t\n",
    "# EM\tF1\tBLEU-4\tROUGE-L\tMETEOR\t\t\t\t\t\t\t\t\t\n",
    "# F1\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# F1\tROUGE-L\tAccuracy\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tExecution accuracy\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tRelative error\tNon-number ratio\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tPerplexity\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# ICAT score\tLM score\tStereotype score\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Score\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Non-hallucination rate\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t#Keywords\t#Valid\tBLEU-4\tROUGE-L\tkwPrec\tLength\t\t\t\t\t\t\t\n",
    "# GPT-4 score\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tConfidence score\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tConfidence score\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tConfidence score\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tConfidence score\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Recall@1\tRecall@5\tRecall@10\tMedian rank\tMean rank\tBLEU-4\tBLEU-3\tCIDEr\tROUGE-L\tMETEOR\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Top-1 accuracy\tTop-5 accuracy\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Weighted Claim-Level Accuracy\tResponse-Level Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# %respond\t#facts/res\tFAct Score\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tnDCG@10\tmAP@100\tMAP\tPrecision@20\t\t\t\t\t\t\t\t\t\n",
    "# nDCG@10\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# mAP@100\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# nDCG@20\tMAP\tPrecision@20\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# PDR\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tMCC\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# EM\tF1\tROUGE-L\t#win\t#draw\tWin rate\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tSAT-style score\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy score\tCoherence score\tFactuality score\tComprehensiveness score\tScore\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tMacro-F1\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tF1\tEM\t\t\t\t\t\t\t\t\t\t\t\n",
    "# F1\tEM\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# F1\tEM\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tF1\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tElo rating\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy\tTop-1 Accuracy\tTop-5 Accuracy\tTop-1 Error Rate\t\t\t\t\t\t\t\t\t\t\n",
    "# Accuracy'''\n",
    "\n",
    "# from collections import defaultdict\n",
    "# df = defaultdict(int)\n",
    "# for items in text.split('\\n'):\n",
    "#     for item in items.split():\n",
    "#         df[item] += 1\n",
    "\n",
    "# sorted(df.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = '''10-bin expected calibration error\n",
    "# 1-bin expected calibration error\n",
    "# Max prob\n",
    "# 10-bin expected calibration error\n",
    "# 1-bin expected calibration error (after Platt scaling)\n",
    "# 10-bin Expected Calibration Error (after Platt scaling)\n",
    "# Platt Scaling Coefficient\n",
    "# Platt Scaling Intercept\n",
    "# Selective coverage-accuracy area\n",
    "# Accuracy at 10% coverage\n",
    "# Stereotypical associations (race, profession)\n",
    "# Stereotypical associations (gender, profession)\n",
    "# Demographic representation (race)\n",
    "# Demographic representation (gender)\n",
    "# Toxic fraction\n",
    "# Denoised inference runtime (s)\n",
    "# Estimated training emissions (kg CO2)\n",
    "# Estimated training energy cost (MWh)\n",
    "# Observed inference runtime (s)\n",
    "# Idealized inference runtime (s)\n",
    "# Denoised inference runtime (s)\n",
    "# # trials\n",
    "# # prompt tokens\n",
    "# # output tokens\n",
    "# # eval\n",
    "# # train\n",
    "# truncated\n",
    "# SummaC\n",
    "# QAFactEval\n",
    "# Coverage\n",
    "# Density\n",
    "# Compression\n",
    "# BERTScore (F1)\n",
    "# HumanEval-faithfulness\n",
    "# HumanEval-relevance\n",
    "# HumanEval-coherence\n",
    "# Avg. # tests passed\n",
    "# Strict correctness\n",
    "# BBQ (ambiguous)\n",
    "# BBQ (unambiguous)\n",
    "# Longest common prefix length\n",
    "# Edit distance (Levenshtein)\n",
    "# Edit similarity (Levenshtein)\n",
    "# Self-BLEU\n",
    "# Entropy (Monte Carlo)\n",
    "# Macro-F1\n",
    "# Micro-F1\n",
    "# Chinese iBLEU\n",
    "# Chinese Top-1 Accuracy\n",
    "# Chinese ROUGE-2 score\n",
    "# Chinese BLEU-1 score\n",
    "# CLEVA Math Exact Match\n",
    "# Chinese BLEU-1 score\n",
    "# Chinese BLEU-1 score'''\n",
    "\n",
    "# # s = set()\n",
    "# df = pd.DataFrame()\n",
    "# for scenario in metrics.split('\\n'):\n",
    "#     # scenario_ = scenario.split('(')[0].strip()\n",
    "#     s = {\n",
    "#         'Name': scenario\n",
    "#     }\n",
    "#     df = pd.concat([df, pd.DataFrame([s])], ignore_index=True)\n",
    "#     # s.add(scenario)\n",
    "# # len(df)\n",
    "# df.to_csv('metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenarios = '''BoolQ\n",
    "# NarrativeQA\n",
    "# NaturalQuestions (closed-book)\n",
    "# NaturalQuestions (open-book)\n",
    "# QuAC (Question Answering in Context)\n",
    "# HellaSwag\n",
    "# OpenbookQA\n",
    "# TruthfulQA\n",
    "# MMLU (Massive Multitask Language Understanding)\n",
    "# MS MARCO (regular track)\n",
    "# MS MARCO (TREC track)\n",
    "# CNN/DailyMail\n",
    "# XSUM\n",
    "# IMDB\n",
    "# CivilComments\n",
    "# RAFT (Real-world Annotated Few-Shot)\n",
    "# ICE (International Corpus of English)\n",
    "# The Pile\n",
    "# TwitterAAE\n",
    "# BLiMP (The Benchmark of Linguistic Minimal Pairs for English)\n",
    "# NaturalQuestions (closed-book)\n",
    "# HellaSwag\n",
    "# OpenbookQA\n",
    "# TruthfulQA\n",
    "# MMLU (Massive Multitask Language Understanding)\n",
    "# WikiFact\n",
    "# bAbI\n",
    "# Dyck\n",
    "# Synthetic reasoning (abstract symbols)\n",
    "# Synthetic reasoning (natural language)\n",
    "# GSM8K (Grade school math word problems)\n",
    "# MATH\n",
    "# MATH (chain-of-thoughts)\n",
    "# APPS (Code)\n",
    "# HumanEval (Code)\n",
    "# LegalSupport\n",
    "# LSAT\n",
    "# Data imputation\n",
    "# Entity matching\n",
    "# Copyright (text)\n",
    "# Copyright (code)\n",
    "# Disinformation (reiteration)\n",
    "# Disinformation (wedging)\n",
    "# BBQ (Bias Benchmark for Question Answering)\n",
    "# BOLD (Bias in Open-Ended Language Generation Dataset)\n",
    "# RealToxicityPrompts\n",
    "# Synthetic efficiency\n",
    "# MMLU (Massive Multitask Language Understanding)\n",
    "# IMDB\n",
    "# RAFT (Real-world Annotated Few-Shot)\n",
    "# CivilComments\n",
    "# NaturalQuestions (open-book)\n",
    "# CNN/DailyMail\n",
    "# IMDB\n",
    "# CivilComments\n",
    "# HellaSwag\n",
    "# OpenbookQA\n",
    "# TruthfulQA\n",
    "# MMLU (Massive Multitask Language Understanding)\n",
    "# BLiMP (The Benchmark of Linguistic Minimal Pairs for English)\n",
    "# LegalSupport\n",
    "# LSAT\n",
    "# BBQ (Bias Benchmark for Question Answering)\n",
    "# NaturalQuestions (open-book)\n",
    "# CNN/DailyMail\n",
    "# IMDB\n",
    "# CivilComments\n",
    "# BoolQ\n",
    "# IMDB'''\n",
    "# s = set()\n",
    "# for scenario in scenarios.split('\\n'):\n",
    "#     scenario_ = scenario.split('(')[0].strip()\n",
    "#     s.add(scenario_)\n",
    "# # len(s)\n",
    "# s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenarios = '''MS-COCO (base)\n",
    "# Caltech-UCSD Birds-200-2011\n",
    "# DrawBench (image quality categories)\n",
    "# DrawBench (reasoning categories)\n",
    "# DrawBench (knowledge categories)\n",
    "# PartiPrompts (image quality categories)\n",
    "# PartiPrompts (reasoning categories)\n",
    "# PartiPrompts (knowledge categories)\n",
    "# MS-COCO (base)\n",
    "# DrawBench (image quality categories)\n",
    "# PartiPrompts (image quality categories)\n",
    "# MS-COCO (base)\n",
    "# MS-COCO (Art styles)\n",
    "# dailydall.e\n",
    "# Logos\n",
    "# Landing Page\n",
    "# Magazine Cover Photos\n",
    "# dailydall.e\n",
    "# Logos\n",
    "# Landing Page\n",
    "# Magazine Cover Photos\n",
    "# Common Syntactic Processes\n",
    "# DrawBench (reasoning categories)\n",
    "# PartiPrompts (reasoning categories)\n",
    "# Relational Understanding\n",
    "# Detection (PaintSkills)\n",
    "# Winoground\n",
    "# TIME\n",
    "# DrawBench (knowledge categories)\n",
    "# PartiPrompts (knowledge categories)\n",
    "# Demographic Stereotypes\n",
    "# Mental Disorders\n",
    "# Inappropriate Image Prompts (I2P)\n",
    "# MS-COCO (fairness - AAVE dialect)\n",
    "# MS-COCO (fairness - gender)\n",
    "# MS-COCO (robustness)\n",
    "# MS-COCO (Chinese)\n",
    "# MS-COCO (Hindi)\n",
    "# MS-COCO (Spanish)\n",
    "# MS-COCO Fidelity\n",
    "# MS-COCO Efficiency\n",
    "# MS-COCO (Art styles)'''\n",
    "# s = set()\n",
    "# for scenario in scenarios.split('\\n'):\n",
    "#     scenario = scenario.split('(')[0].strip()\n",
    "#     s.add(scenario)\n",
    "# s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1223"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "sum = 0\n",
    "\n",
    "for file in glob.glob(str(path_llm / \"*.json\")):\n",
    "    if 'imagenet' not in file.lower():\n",
    "        continue\n",
    "    df = pd.read_json(file)\n",
    "    sum += len(df)\n",
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_json('/Users/jimmy/Downloads/LMExamQA.json')\n",
    "# df['domain'].nunique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
